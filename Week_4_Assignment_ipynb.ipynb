{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP69LnHqxImm"
      },
      "source": [
        "# Welcome to Multi-agent Training using IPPO!\n",
        "You will be responsible for completing two functions below (you can search for `NotImplementedError` functions to skip straight to them!) Once you have instantiated those, you will be able to run all cells and begin training your IPPO policies!\n",
        "\n",
        "This tutorial will walk you through code for teaching a robotic ant to walk!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CR6wuERXMor"
      },
      "source": [
        "![GIF](https://gymnasium.farama.org/_images/ant.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qyn-a8tYNhw"
      },
      "source": [
        "In this assignment, we will treat each of the ant's 4 legs as seperate agents:\n",
        "\n",
        "![Diagram](https://robotics.farama.org/_images/ant_2x4.png)\n",
        "\n",
        "As such, Agent 1 will control joints 0 and 1, Agent 2 will control joints 2 and 3, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D33ZbVWLUjW6"
      },
      "source": [
        "# Intial Setup\n",
        "In this section we just install the necessary packages and download the `demo.xml` file from the shared drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3pMsdx9MUZNm",
        "outputId": "831b1bea-e7d4-4ace-c85a-8e3cb3f45a6b"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade pip                # Update pip\n",
        "# !pip install equinox brax distreqx        # Install neccesary libraries\n",
        "# !gdown 1ulG1WBbTFxkr2N9Yuf7DbGWSjBZBN04j  # Download demo.xml file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA_dbJeiVzOS"
      },
      "source": [
        "# Multi-Agent Reinforcement Learning\n",
        "This code is set up to perform the neccesary inputs once and be able to run all cells below to develop the classes and helper functions needed to train policies. Each agent in the scenario will be modelled by an ActorCritic object, which internally handles the parameters for its Multi-Layer-Preceptron(MLP)/Artifical-Neural-Network(ANN) machine learning model.\n",
        "\n",
        "We also have a training environment class `IPPO_Ant_Env` which takes in our description of the Ant robot in `demo.xml` and creates a high-fidelity simulator which can be vectorized (meaning we can make many many copies of the training environment at once and load them onto a GPU for very fast computation!)\n",
        "\n",
        "We then have seperate training functions **(some of which you will have to fill in as part of your assignment)** which uses our ActorCritic networks to sample trajectories from our IPPO_Ant_env training environment and update the network parameters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1bsq6K6SAP"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w0rLfSFfZfTJ"
      },
      "outputs": [],
      "source": [
        "# Environment Wrapper\n",
        "import os, json\n",
        "from datetime import datetime\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "from jaxtyping import Array, PRNGKeyArray\n",
        "import optax\n",
        "import equinox as eqx\n",
        "from tensorboardX import SummaryWriter\n",
        "import mujoco as mj # we use mj to change some foundational things in the simulation\n",
        "from brax import math # this contains some useful things, like safe_norm and quaternion utils\n",
        "from typing import Dict, Literal, Optional, Tuple, Callable, List, Union, NamedTuple, Sequence\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Mujoco/BRAX requires our env inherits from PipelineEnv, and the state used is State\n",
        "from brax.envs.base import PipelineEnv, State\n",
        "\n",
        "# mjcf interprets Mujoco XML files for BRAX, html will render rollouts of BRAX States\n",
        "from brax.io import mjcf, html\n",
        "\n",
        "import distreqx.distributions as dist\n",
        "import dataclasses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRYezQvGIS5l"
      },
      "source": [
        "## Training Code (Assignment Functions are here!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HGJyIxT-ZFe2"
      },
      "outputs": [],
      "source": [
        "def make_train(env, train_config, rng_init):\n",
        "    # create a directory for saving the model and logs\n",
        "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_path = f'data/ippo_ant/{current_datetime}'\n",
        "    os.makedirs(save_path, exist_ok=False)\n",
        "    writer = SummaryWriter(log_dir=save_path)\n",
        "    with open(os.path.join(save_path, 'config.json'), 'w') as f:\n",
        "        json.dump(train_config, f, indent=4)\n",
        "\n",
        "    train_config[\"NUM_ACTORS\"] = env.num_agents * train_config[\"NUM_ENVS\"]\n",
        "    train_config[\"NUM_UPDATES\"] = (\n",
        "        train_config[\"TOTAL_TIMESTEPS\"] // train_config[\"NUM_STEPS\"] // train_config[\"NUM_ENVS\"]\n",
        "    )\n",
        "    train_config[\"MINIBATCH_SIZE\"] = (\n",
        "        train_config[\"NUM_ACTORS\"] * train_config[\"NUM_STEPS\"] // train_config[\"NUM_MINIBATCHES\"]\n",
        "    )\n",
        "\n",
        "    def linear_schedule(count):\n",
        "        frac = 1.0 - (count // (train_config[\"NUM_MINIBATCHES\"] * train_config[\"UPDATE_EPOCHS\"])) / train_config[\"NUM_UPDATES\"]\n",
        "        return config[\"LR\"] * frac\n",
        "\n",
        "    network = ActorCritic(\n",
        "        key=rng_init,\n",
        "        actor_layer_sizes=[env.observation_space(env.agents[0]).shape[0], 64, 64, env.action_space(env.agents[0]).shape[0]],\n",
        "        critic_layer_sizes=[env.observation_space(env.agents[0]).shape[0], 64, 64, 1],\n",
        "        actor_kernel_init=[jnp.sqrt(2), jnp.sqrt(2), 0.01],\n",
        "        critic_kernel_init=[jnp.sqrt(2), jnp.sqrt(2), 1],\n",
        "        activation=jax.nn.tanh,\n",
        "    )\n",
        "\n",
        "    if config[\"ANNEAL_LR\"]:\n",
        "        opt = optax.chain(\n",
        "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
        "            optax.adam(learning_rate=linear_schedule, eps=1e-5),\n",
        "        )\n",
        "    else:\n",
        "        opt = optax.chain(\n",
        "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
        "            optax.adam(config[\"LR\"], eps=1e-5)\n",
        "        )\n",
        "\n",
        "    opt_state = opt.init(network)\n",
        "\n",
        "    def train(rng):\n",
        "        # INIT ENV\n",
        "        rng, _rng = jr.split(rng)\n",
        "        reset_rng = jr.split(_rng, config[\"NUM_ENVS\"])\n",
        "        obsv, env_state = jax.vmap(env.reset)(reset_rng)\n",
        "\n",
        "        # TRAIN LOOP\n",
        "        def _update_step(runner_state, unused):\n",
        "            # COLLECT TRAJECTORIES\n",
        "            def _env_step(runner_state, unused):\n",
        "                network, opt_state, env_state, last_obs, update_count, rng = runner_state\n",
        "                obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "                # SELECT ACTION\n",
        "                rng, _rng = jr.split(rng)\n",
        "                mean, scale, value = eqx.filter_vmap(network)(obs_batch)\n",
        "\n",
        "                pi = eqx.filter_vmap(dist.MultivariateNormalDiag)(mean, scale)\n",
        "                pi_log_prob = lambda d, a: d.log_prob(a)  # helper for filter_vmap\n",
        "                action = pi.sample(_rng)\n",
        "                log_prob = eqx.filter_vmap(pi_log_prob)(pi, action)\n",
        "\n",
        "                env_act = unbatchify(action, env.agents, config[\"NUM_ENVS\"], env.num_agents)\n",
        "\n",
        "                # STEP ENV\n",
        "                rng, _rng = jr.split(rng)\n",
        "                rng_step = jr.split(_rng, config[\"NUM_ENVS\"])\n",
        "                obsv, env_state, reward, done, info = jax.vmap(env.step)(\n",
        "                    rng_step, env_state, env_act,\n",
        "                )\n",
        "\n",
        "                info = jax.tree.map(lambda x: x.reshape((config[\"NUM_ACTORS\"])), info)\n",
        "                transition = Transition(\n",
        "                    batchify(done, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    action,\n",
        "                    value,\n",
        "                    batchify(reward, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    log_prob,\n",
        "                    obs_batch,\n",
        "                    info,\n",
        "                )\n",
        "                runner_state = (network, opt_state, env_state, obsv, update_count, rng)\n",
        "                return runner_state, transition\n",
        "\n",
        "            runner_state, traj_batch = filter_scan(\n",
        "                _env_step, runner_state, None, config[\"NUM_STEPS\"]\n",
        "            )\n",
        "            # CALCULATE ADVANTAGE\n",
        "            network, opt_state, env_state, last_obs, update_count, rng = runner_state\n",
        "\n",
        "            last_obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "            _, _, last_val = eqx.filter_vmap(network)(last_obs_batch)\n",
        "\n",
        "            def _calculate_gae(traj_batch, last_val):\n",
        "                def _get_advantages(gae_and_next_value, transition) -> Tuple[Tuple[jax.Array, jax.Array], jax.Array]:\n",
        "\n",
        "                    gae, next_value = gae_and_next_value       \n",
        "                    done, value, reward = transition.done, transition.value, transition.reward\n",
        "                    gamma      = config[\"GAMMA\"] * (1.0 - done)\n",
        "                    gae_lambda = config[\"GAE_LAMBDA\"]\n",
        "\n",
        "                    delta = reward + gamma * next_value - value\n",
        "                    gae = delta + gamma * gae_lambda * gae\n",
        "\n",
        "                    return (gae, value), gae\n",
        "\n",
        "                _, advantages = jax.lax.scan(\n",
        "                    _get_advantages,\n",
        "                    (jnp.zeros_like(last_val), last_val),\n",
        "                    traj_batch,\n",
        "                    reverse=True,\n",
        "                    unroll=8,\n",
        "                )\n",
        "                return advantages, advantages + traj_batch.value\n",
        "\n",
        "            advantages, targets = _calculate_gae(traj_batch, last_val)\n",
        "\n",
        "            # UPDATE NETWORK\n",
        "            def _update_epoch(update_state, unused):\n",
        "                def _update_minbatch(train_state, batch_info):\n",
        "                    traj_batch, advantages, targets = batch_info\n",
        "\n",
        "                    def _loss_fn(network, traj_batch, gae, targets):\n",
        "                        # RERUN NETWORK\n",
        "                        mean, scale, value = eqx.filter_vmap(network)(traj_batch.obs)\n",
        "                        pi = eqx.filter_vmap(dist.MultivariateNormalDiag)(mean, scale)\n",
        "                        pi_log_prob = lambda d, a: d.log_prob(a)  # helper for filter_vmap\n",
        "                        log_prob = eqx.filter_vmap(pi_log_prob)(pi, traj_batch.action)\n",
        "\n",
        "                        # CALCULATE VALUE LOSS\n",
        "                        value_pred_clipped = traj_batch.value + (\n",
        "                            value - traj_batch.value\n",
        "                        ).clip(-config[\"CLIP_EPS\"], config[\"CLIP_EPS\"])\n",
        "                        value_losses = jnp.square(value - targets)\n",
        "                        value_losses_clipped = jnp.square(value_pred_clipped - targets)\n",
        "                        value_loss = (\n",
        "                            0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n",
        "                        )\n",
        "\n",
        "                        # CALCULATE ACTOR LOSS\n",
        "                        gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
        "\n",
        "                        # def _loss_actor(log_prob, log_prob_k, normalized_gae, clip_epsilon):\n",
        "                        #   raise NotImplementedError('Actor Loss not implemented yet!')\n",
        "                        #   # TODO: USE THE INPUTS TO THIS FUNCTION TO CALCULATE THE ACTOR LOSS\n",
        "\n",
        "                        #   return loss_actor\n",
        "                        def _loss_actor(log_prob, log_prob_k, normalized_gae, clip_epsilon):\n",
        "                            ratio        = jnp.exp(log_prob - log_prob_k)                     # r_t(θ)\n",
        "                            surrogate_1  = ratio * normalized_gae\n",
        "                            surrogate_2  = jnp.clip(ratio, 1.0 - clip_epsilon,\n",
        "                                                           1.0 + clip_epsilon) * normalized_gae\n",
        "                            loss_clipped = jnp.minimum(surrogate_1, surrogate_2)              # element-wise\n",
        "                            return loss_clipped, ratio\n",
        "                        \n",
        "                        loss_actor, ratio = _loss_actor(log_prob, traj_batch.log_prob, gae, config[\"CLIP_EPS\"])\n",
        "                        # loss_actor = -_loss_actor(log_prob, traj_batch.log_prob, gae, config[\"CLIP_EPS\"]).mean()\n",
        "                        loss_actor = -loss_actor.mean()\n",
        "\n",
        "                        pi_entropy = lambda d: d.entropy()\n",
        "                        entropy = eqx.filter_vmap(pi_entropy)(pi).mean()\n",
        "\n",
        "                        total_loss = (\n",
        "                            loss_actor\n",
        "                            + config[\"VF_COEF\"] * value_loss\n",
        "                            - config[\"ENT_COEF\"] * entropy\n",
        "                        )\n",
        "                        return total_loss, (value_loss, loss_actor, entropy, ratio)\n",
        "\n",
        "                    network, opt_state = train_state\n",
        "                    grad_fn = eqx.filter_value_and_grad(_loss_fn, has_aux=True)\n",
        "                    total_loss, grads = grad_fn(network, traj_batch, advantages, targets)\n",
        "                    updates, opt_state = opt.update(grads, opt_state)\n",
        "                    network = eqx.apply_updates(network, updates)\n",
        "\n",
        "                    loss_info = {\n",
        "                        \"total_loss\": total_loss[0],\n",
        "                        \"actor_loss\": total_loss[1][1],\n",
        "                        \"critic_loss\": total_loss[1][0],\n",
        "                        \"entropy\": total_loss[1][2],\n",
        "                        \"ratio\": total_loss[1][3],\n",
        "                    }\n",
        "                    return (network, opt_state), loss_info\n",
        "                network, opt_state, traj_batch, advantages, targets, rng = update_state\n",
        "\n",
        "                rng, _rng = jr.split(rng)\n",
        "                batch_size = config[\"MINIBATCH_SIZE\"] * config[\"NUM_MINIBATCHES\"]\n",
        "                assert (\n",
        "                    batch_size == config[\"NUM_STEPS\"] * config[\"NUM_ACTORS\"]\n",
        "                ), \"batch size must be equal to number of steps * number of actors\"\n",
        "                permutation = jr.permutation(_rng, batch_size)\n",
        "                batch = (traj_batch, advantages, targets)\n",
        "                batch = jax.tree.map(\n",
        "                    lambda x: x.reshape((batch_size,) + x.shape[2:]), batch\n",
        "                )\n",
        "                shuffled_batch = jax.tree.map(\n",
        "                    lambda x: jnp.take(x, permutation, axis=0), batch\n",
        "                )\n",
        "                minibatches = jax.tree.map(\n",
        "                    lambda x: jnp.reshape(\n",
        "                        x, [config[\"NUM_MINIBATCHES\"], -1] + list(x.shape[1:])\n",
        "                    ),\n",
        "                    shuffled_batch,\n",
        "                )\n",
        "                (network, opt_state), loss_info = filter_scan(\n",
        "                    _update_minbatch, (network, opt_state), minibatches\n",
        "                )\n",
        "                update_state = (network, opt_state, traj_batch, advantages, targets, rng)\n",
        "                return update_state, loss_info\n",
        "\n",
        "            def callback(metric):\n",
        "                step = metric[\"update_step\"]\n",
        "                for key, value in metric.items():\n",
        "                    if key != \"update_step\":\n",
        "                        writer.add_scalar(key, value, step)\n",
        "\n",
        "            update_state = (network, opt_state, traj_batch, advantages, targets, rng)\n",
        "\n",
        "            update_state, loss_info = filter_scan(\n",
        "                _update_epoch, update_state, None, config[\"UPDATE_EPOCHS\"]\n",
        "            )\n",
        "            network, opt_state = update_state[0], update_state[1]\n",
        "\n",
        "            metric = traj_batch.info\n",
        "            rng = update_state[-1]\n",
        "\n",
        "            update_count = update_count + 1\n",
        "            r0 = {\"ratio0\": loss_info[\"ratio\"][0,0].mean()}\n",
        "            loss_info = jax.tree.map(lambda x: x.mean(), loss_info)\n",
        "            metric = jax.tree.map(lambda x: x.mean(), metric)\n",
        "            metric[\"update_step\"] = update_count\n",
        "            metric[\"env_step\"] = update_count * config[\"NUM_STEPS\"] * config[\"NUM_ENVS\"]\n",
        "            metric = {**metric, **loss_info, **r0}\n",
        "            jax.experimental.io_callback(callback, None, metric)\n",
        "            runner_state = (network, opt_state, env_state, last_obs, update_count, rng)\n",
        "            return runner_state, metric\n",
        "\n",
        "        rng, _rng = jr.split(rng)\n",
        "        runner_state = (network, opt_state, env_state, obsv, jnp.array(0), _rng)\n",
        "        runner_state, metric = filter_scan(\n",
        "            _update_step, runner_state, None, config[\"NUM_UPDATES\"]\n",
        "        )\n",
        "\n",
        "        current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "        eqx.tree_serialise_leaves(f\"data/training_network_{current_datetime}.eqx\", network)\n",
        "        return {\"runner_state\": runner_state, \"metrics\": metric, \"network\": network}\n",
        "\n",
        "    return train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_KpuEg6Yh8R"
      },
      "source": [
        "## Our Actor-Critic Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BctJ-vimV1xr"
      },
      "outputs": [],
      "source": [
        "class ActorCritic(eqx.Module):\n",
        "    \"\"\"\n",
        "    This is a feed forward actor critic combined module. This is useful for IPPO\n",
        "    where we modify both the actor and critic simultaneously and therefore can\n",
        "    group the actor and critic together here and use optax to get an optimization\n",
        "    state across the entire eqx.Module\n",
        "    \"\"\"\n",
        "\n",
        "    # Learned variables\n",
        "    actor_layers: Tuple[eqx.nn.Linear, ...]\n",
        "    critic_layers: Tuple[eqx.nn.Linear, ...]\n",
        "    log_std: jax.Array\n",
        "\n",
        "    # Static parameters\n",
        "    activation: Callable = eqx.field(static=True)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        key: jr.PRNGKey,\n",
        "        actor_layer_sizes: List[int] = [6, 64, 64, 2],\n",
        "        critic_layer_sizes: List[int] = [6, 64, 64, 1],\n",
        "        actor_kernel_init: List[float] = [jnp.sqrt(2), jnp.sqrt(2), 0.01],\n",
        "        critic_kernel_init: List[float] = [jnp.sqrt(2), jnp.sqrt(2), 1.0],\n",
        "        activation: Callable = jax.nn.relu,\n",
        "    ):\n",
        "        self.activation = activation\n",
        "        actor_key, critic_key = jr.split(key)\n",
        "\n",
        "        # —— actor network ——\n",
        "        actor_keys = jr.split(actor_key, num=len(actor_layer_sizes))\n",
        "        self.actor_layers = []\n",
        "\n",
        "        for i, (in_f, out_f) in enumerate(\n",
        "            zip(actor_layer_sizes[:-1], actor_layer_sizes[1:])\n",
        "        ):\n",
        "            layer = eqx.nn.Linear(in_f, out_f, key=actor_keys[i])\n",
        "\n",
        "            # (Re‑)initialise using orthogonal(scale) + constant(0) bias\n",
        "            wkey, _ = jr.split(actor_keys[i])\n",
        "            weight = jax.nn.initializers.orthogonal(actor_kernel_init[i])(\n",
        "                wkey, (out_f, in_f), jnp.float32\n",
        "            )\n",
        "            bias = jnp.zeros((out_f,), dtype=jnp.float32)\n",
        "\n",
        "            # Update the layer – eqx Modules are frozen, so use object.__setattr__\n",
        "            object.__setattr__(layer, \"weight\", weight)\n",
        "            object.__setattr__(layer, \"bias\", bias)\n",
        "\n",
        "            self.actor_layers.append(layer)\n",
        "\n",
        "        # —— critic network ——\n",
        "        critic_keys = jr.split(critic_key, len(critic_layer_sizes) - 1)\n",
        "        self.critic_layers = []\n",
        "\n",
        "        for i, (in_f, out_f) in enumerate(\n",
        "            zip(critic_layer_sizes[:-1], critic_layer_sizes[1:])\n",
        "        ):\n",
        "            layer = eqx.nn.Linear(in_f, out_f, key=critic_keys[i])\n",
        "\n",
        "            wkey, _ = jr.split(critic_keys[i])\n",
        "            weight = jax.nn.initializers.orthogonal(critic_kernel_init[i])(\n",
        "                wkey, (out_f, in_f), jnp.float32\n",
        "            )\n",
        "            bias = jnp.zeros((out_f,), dtype=jnp.float32)\n",
        "\n",
        "            object.__setattr__(layer, \"weight\", weight)\n",
        "            object.__setattr__(layer, \"bias\", bias)\n",
        "\n",
        "            self.critic_layers.append(layer)\n",
        "\n",
        "        # —— learnable log‑std parameter ——\n",
        "        self.log_std = jnp.zeros((actor_layer_sizes[-1],))  # broadcasted over batch at runtime\n",
        "\n",
        "    def __call__(self, x: jax.Array) -> Tuple[jax.Array, jax.Array, jax.Array]:\n",
        "        \"\"\"Returns (policy_dist, value_estimate) for an input batch `x`.\"\"\"\n",
        "\n",
        "        # —— actor ——\n",
        "        h = x\n",
        "        for layer in self.actor_layers[:-1]:\n",
        "            h = self.activation(layer(h))\n",
        "        actor_mean = self.actor_layers[-1](h)                        # (B, action_dim)\n",
        "        actor_scale = jnp.exp(self.log_std)\n",
        "\n",
        "        # —— critic ——\n",
        "        h = x\n",
        "        for layer in self.critic_layers[:-1]:\n",
        "            h = self.activation(layer(h))\n",
        "        value = jnp.squeeze(self.critic_layers[-1](h), axis=-1)      # (B,)\n",
        "\n",
        "        return actor_mean, actor_scale, value\n",
        "\n",
        "\n",
        "def filter_scan(f, init, xs, length=None, reverse=False, unroll=1):\n",
        "    \"\"\"\n",
        "    although simple to implement equinox does not by default include a filter_scan\n",
        "    function; see: https://github.com/patrick-kidger/equinox/issues/709\n",
        "    \"\"\"\n",
        "\n",
        "    # Partition the initial carry and sequence inputs into dynamic and static parts\n",
        "    init_dynamic, init_static = eqx.partition(init, eqx.is_array)\n",
        "    xs_dynamic, xs_static = eqx.partition(xs, eqx.is_array)\n",
        "\n",
        "    # Define the scanned function, handling the combination and partitioning\n",
        "    def scanned_fn(carry_dynamic, x_dynamic):\n",
        "        # Combine dynamic and static parts for the carry and input\n",
        "        carry = eqx.combine(carry_dynamic, init_static)\n",
        "        x = eqx.combine(x_dynamic, xs_static)\n",
        "\n",
        "        # Apply the original function\n",
        "        out_carry, out_y = f(carry, x)\n",
        "\n",
        "        # Partition the outputs into dynamic and static parts\n",
        "        out_carry_dynamic, out_carry_static = eqx.partition(out_carry, eqx.is_array)\n",
        "        out_y_dynamic, out_y_static = eqx.partition(out_y, eqx.is_array)\n",
        "\n",
        "        # Return dynamic outputs and wrap static outputs using Static to prevent tracing\n",
        "        return out_carry_dynamic, (out_y_dynamic, eqx.internal.Static((out_carry_static, out_y_static)))\n",
        "\n",
        "    # Use lax.scan with the modified scanned function\n",
        "    final_carry_dynamic, (ys_dynamic, static_out) = jax.lax.scan(\n",
        "        scanned_fn, init_dynamic, xs_dynamic, length=length, reverse=reverse, unroll=unroll\n",
        "    )\n",
        "\n",
        "    # Extract static outputs\n",
        "    out_carry_static, ys_static = static_out.value\n",
        "\n",
        "    # Combine dynamic and static parts of the outputs\n",
        "    final_carry = eqx.combine(final_carry_dynamic, out_carry_static)\n",
        "    ys = eqx.combine(ys_dynamic, ys_static)\n",
        "\n",
        "    return final_carry, ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnlM4z669Ytw"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ECo-U6Ck9pRW"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Built off Gymnax spaces.py, this module contains jittable classes for action and\n",
        "observation spaces.\n",
        "\"\"\"\n",
        "class Space(object):\n",
        "    \"\"\"\n",
        "    Minimal jittable class for abstract jaxmarl space.\n",
        "    \"\"\"\n",
        "\n",
        "    def sample(self, rng: PRNGKeyArray) -> Array:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def contains(self, x: jnp.int_) -> bool: # pyright: ignore\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Box(Space):\n",
        "\t\"\"\"\n",
        "\tMinimal jittable class for array-shaped gymnax spaces.\n",
        "\tAdd unboundedness - sampling from other distributions, etc.\n",
        "\t\"\"\"\n",
        "\tdef __init__(\n",
        "\t\tself,\n",
        "\t\tlow: float,\n",
        "\t\thigh: float,\n",
        "\t\tshape: Tuple[int],\n",
        "\t\tdtype: jnp.dtype = jnp.float32,\n",
        "\t):\n",
        "\t\tself.low = low\n",
        "\t\tself.high = high\n",
        "\t\tself.shape = shape\n",
        "\t\tself.dtype = dtype\n",
        "\n",
        "\tdef sample(self, rng: PRNGKeyArray) -> Array:\n",
        "\t\t\"\"\"Sample random action uniformly from 1D continuous range.\"\"\"\n",
        "\t\treturn jax.random.uniform(\n",
        "\t\t\trng, shape=self.shape, minval=self.low, maxval=self.high\n",
        "\t\t).astype(self.dtype)\n",
        "\n",
        "\tdef contains(self, x: jnp.int_) -> bool: # pyright: ignore\n",
        "\t\t\"\"\"Check whether specific object is within space.\"\"\"\n",
        "\t\t# type_cond = isinstance(x, self.dtype)\n",
        "\t\t# shape_cond = (x.shape == self.shape)\n",
        "\t\trange_cond = jnp.logical_and(\n",
        "\t\t\tjnp.all(x >= self.low), jnp.all(x <= self.high)\n",
        "\t\t)\n",
        "\t\treturn range_cond\n",
        "\n",
        "class Transition(NamedTuple):\n",
        "  done: jnp.ndarray\n",
        "  action: jnp.ndarray\n",
        "  value: jnp.ndarray\n",
        "  reward: jnp.ndarray\n",
        "  log_prob: jnp.ndarray\n",
        "  obs: jnp.ndarray\n",
        "  info: jnp.ndarray\n",
        "\n",
        "def batchify(x: dict, agent_list, num_actors):\n",
        "    max_dim = max([x[a].shape[-1] for a in agent_list])\n",
        "    def pad(z):\n",
        "        return jnp.concatenate([z, jnp.zeros(z.shape[:-1] + (max_dim - z.shape[-1],))], -1)\n",
        "    x = jnp.stack([x[a] if x[a].shape[-1] == max_dim else pad(x[a]) for a in agent_list])\n",
        "    return x.reshape((num_actors, -1))\n",
        "\n",
        "def unbatchify(x: jnp.ndarray, agent_list, num_envs, num_actors):\n",
        "    x = x.reshape((num_actors, num_envs, -1))\n",
        "    return {a: x[i] for i, a in enumerate(agent_list)}\n",
        "\n",
        "class LogEnvState(NamedTuple):\n",
        "    env_state: State\n",
        "    episode_returns: float\n",
        "    episode_lengths: int\n",
        "    returned_episode_returns: float\n",
        "    returned_episode_lengths: int\n",
        "    step_in_episode: jnp.ndarray\n",
        "    first_pipeline_state: State\n",
        "    first_obs: jnp.ndarray\n",
        "    truncation: jnp.ndarray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXnX38fSad9_"
      },
      "source": [
        "## IPPO Training Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EYPHudGYadBA"
      },
      "outputs": [],
      "source": [
        "# LEAVE EVERYTHING IN THIS CELL UNCHANGED FOR ASSIGNMENT\n",
        "\n",
        "\n",
        "# we must map each agent to their observations and actions in the whole environment\n",
        "# This is a helper function to convert the ranges of observations\n",
        "def listerize(ranges: List[Union[int, Tuple[int, int]]]) -> List[int]:\n",
        "    \"\"\"\n",
        "    tuples mean that all global observations indexed from (0, 5) are included in that agents observation\n",
        "    integers add that single global observation to the agent's observation\n",
        "    in this case I am passing global observations to each agent for simplicity.\n",
        "    Here is an example:\n",
        "\n",
        "    ranges = {\n",
        "        \"agent_0\": [(0,8)], # example: [(0, 5), 6, 7] == [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "        \"agent_1\": [(0,8)] # example: [(2, 5), 9, 10] == [2, 3, 4, 5, 9, 10]\n",
        "    }\n",
        "    agent_obs_mapping = {k: jnp.array(listerize(v)) for k, v in ranges.items()} # _agent_observation_mapping[env_name]\n",
        "    \"\"\"\n",
        "    return [\n",
        "        i\n",
        "        for r in ranges\n",
        "        for i in (range(r[0], r[1] + 1) if isinstance(r, tuple) else [r])\n",
        "    ]\n",
        "\n",
        "# ================================ #\n",
        "# Our Multi-agent Ant Training Environment!\n",
        "# ================================ #\n",
        "class IPPO_Ant_Env(PipelineEnv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        mode: Literal[\"centralized\", \"decentralized\"] = \"decentralized\",\n",
        "\n",
        "        # base env settings\n",
        "        xml_path='demo.xml',\n",
        "        backend='positional', # this is important for the ant\n",
        "        ctrl_cost_weight=0.5,\n",
        "        use_contact_forces=False,\n",
        "        contact_cost_weight=5e-4,\n",
        "        healthy_reward=1.0,\n",
        "        terminate_when_unhealthy=True,\n",
        "        healthy_z_range=(0.2, 1.0),\n",
        "        contact_force_range=(-1.0, 1.0),\n",
        "        reset_noise_scale=0.1,\n",
        "        exclude_current_positions_from_observation=True,\n",
        "\n",
        "        # multi agent env settings\n",
        "        episode_length: int = 1000,\n",
        "        action_repeat: int = 1,\n",
        "        auto_reset: bool = True,\n",
        "        homogenisation_method: Optional[Literal[\"max\", \"concat\"]] = None,\n",
        "\n",
        "        # logging settings\n",
        "        replace_info: bool = False,\n",
        "        **kwargs\n",
        "    ):\n",
        "\n",
        "        # ============================= #\n",
        "        # Mujoco/BRAX System Init #\n",
        "        # ============================= #\n",
        "\n",
        "        # brax provides utils to load xml file into mujoco\n",
        "        sys = mjcf.load(xml_path)\n",
        "\n",
        "        # n_frames are the number of simulation timesteps between new actions\n",
        "        # in the interim we zero-order-hold the previous action\n",
        "        n_frames = 5\n",
        "\n",
        "        # in the case of the Ant the physics backed matters, and they reduce the physics timestep\n",
        "        # from 0.01 to 0.005 and double n_frames to keep the interaction timestep the same.\n",
        "        # I speculate that the increased fidelity of the timestep for these backends is required\n",
        "        # for reliable, robust physics calculations\n",
        "        if backend in ['spring', 'positional']:\n",
        "            sys = sys.tree_replace({'opt.timestep': 0.005})\n",
        "            n_frames = 10\n",
        "\n",
        "        # again more examples of using the \"sys\" to modify fundamental parts of the simulator.\n",
        "        if backend == 'mjx':\n",
        "            sys = sys.tree_replace({\n",
        "                'opt.solver': mj.mjtSolver.mjSOL_NEWTON, # this determins how we solve contact forces\n",
        "                'opt.disableflags': mj.mjtDisableBit.mjDSBL_EULERDAMP, # I believe this damping term stabilizes some dynamics\n",
        "                'opt.iterations': 1, # number of optimization iterations for contact\n",
        "                'opt.ls_iterations': 4, # number of line search iterations per optimization iteration for contact\n",
        "            })\n",
        "\n",
        "        # again more examples of using the \"sys\" to modify fundamental parts of the simulator\n",
        "        if backend == 'positional':\n",
        "            # does the same actuator strength work as in spring\n",
        "            sys = sys.replace(\n",
        "                actuator=sys.actuator.replace(\n",
        "                    gear=200 * jnp.ones_like(sys.actuator.gear)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # the kwargs are designed to pass options to the brax backend, in this case we\n",
        "        # modify the kwargs n_frames according to the above code before passing it to super\n",
        "        kwargs['n_frames'] = kwargs.get('n_frames', n_frames)\n",
        "\n",
        "        # actually creating the BRAX system\n",
        "        super().__init__(sys=sys, backend=backend, **kwargs)\n",
        "\n",
        "        # various parameters for the Ant environment\n",
        "        self._ctrl_cost_weight = ctrl_cost_weight\n",
        "        self._use_contact_forces = use_contact_forces\n",
        "        self._contact_cost_weight = contact_cost_weight\n",
        "        self._healthy_reward = healthy_reward\n",
        "        self._terminate_when_unhealthy = terminate_when_unhealthy\n",
        "        self._healthy_z_range = healthy_z_range\n",
        "        self._contact_force_range = contact_force_range\n",
        "        self._reset_noise_scale = reset_noise_scale\n",
        "        self._exclude_current_positions_from_observation = (\n",
        "            exclude_current_positions_from_observation\n",
        "        )\n",
        "        if self._use_contact_forces:\n",
        "            raise NotImplementedError('use_contact_forces not implemented.')\n",
        "\n",
        "\n",
        "        # ================================== #\n",
        "        # Multi-Agent Environment Init #\n",
        "        # ================================== #\n",
        "\n",
        "        # UNCHANGED logging settings\n",
        "        self.replace_info = replace_info\n",
        "        self.episode_length = episode_length\n",
        "        self.action_repeat = action_repeat\n",
        "        self.auto_reset = auto_reset\n",
        "        self.homogenisation_method = homogenisation_method\n",
        "\n",
        "        # tuples mean that all global observations indexed from (0, 5) are included in that agents observation\n",
        "        # integers add that single global observation to the agent's observation\n",
        "        # in this case I am passing global observations to each agent for simplicity\n",
        "        ranges = {\n",
        "            # below is an example, also check out the listerize helper function above\n",
        "            \"agent_0\": [(0, 5), 6, 7, 9, 11, (13, 18), 19, 20],\n",
        "            \"agent_1\": [(0, 5), 7, 8, 9, 11, (13, 18), 21, 22],\n",
        "            \"agent_2\": [(0, 5), 7, 9, 10, 11, (13, 18), 23, 24],\n",
        "            \"agent_3\": [(0, 5), 7, 9, 11, 12, (13, 18), 25, 26],\n",
        "        }\n",
        "        self.agent_obs_mapping = {k: jnp.array(listerize(v)) for k, v in ranges.items()} # _agent_observation_mapping[env_name]\n",
        "\n",
        "        # the agent action mapping is simpler, so we just use the indices of the actions\n",
        "        self.agent_action_mapping = {\n",
        "            \"agent_0\": jnp.array([0, 1]),\n",
        "            \"agent_1\": jnp.array([2, 3]),\n",
        "            \"agent_2\": jnp.array([4, 5]),\n",
        "            \"agent_3\": jnp.array([6, 7]),\n",
        "        }\n",
        "        self.agents = list(self.agent_obs_mapping.keys())\n",
        "\n",
        "        # ======================================================== #\n",
        "        # UNCHANGED: Boilerplate That Doesn't Require Modification #\n",
        "        # ======================================================== #\n",
        "\n",
        "        # setup the obs and action spaces for each agent\n",
        "        self.num_agents = len(self.agent_obs_mapping)\n",
        "        obs_sizes = {\n",
        "            agent: self.num_agents\n",
        "            + max([o.size for o in self.agent_obs_mapping.values()])\n",
        "            if homogenisation_method == \"max\"\n",
        "            else self.env.observation_size\n",
        "            if homogenisation_method == \"concat\"\n",
        "            else obs.size\n",
        "            for agent, obs in self.agent_obs_mapping.items()\n",
        "        }\n",
        "        act_sizes = {\n",
        "            agent: max([a.size for a in self.agent_action_mapping.values()])\n",
        "            if homogenisation_method == \"max\"\n",
        "            else self.env.action_size\n",
        "            if homogenisation_method == \"concat\"\n",
        "            else act.size\n",
        "            for agent, act in self.agent_action_mapping.items()\n",
        "        }\n",
        "        self.observation_spaces = {\n",
        "            agent: Box(-jnp.inf, jnp.inf, shape=(obs_sizes[agent],),)\n",
        "            for agent in self.agents\n",
        "        }\n",
        "        self.action_spaces = {\n",
        "            agent: Box(-1.0, 1.0, shape=(act_sizes[agent],),)\n",
        "            for agent in self.agents\n",
        "        }\n",
        "\n",
        "        # utility function to batchify floats originally placed in JaxMARLWrapper\n",
        "        self._batchify_floats = lambda x: jnp.stack([x[a] for a in self.agents])\n",
        "\n",
        "        # utility function to get obs, action spaces for each agent - required by the ppo algs\n",
        "        self.observation_space = lambda agent: self.observation_spaces[agent]\n",
        "        self.action_space = lambda agent: self.action_spaces[agent]\n",
        "\n",
        "    # ======================================== #\n",
        "    # design global observation function #\n",
        "    # ======================================== #\n",
        "\n",
        "    def get_global_obs(self, pipeline_state: State) -> jax.Array:\n",
        "\n",
        "        # the pipeline_state is an attribute of env_state, which in turn is an attribute of state.\n",
        "        # pipeline_state is what defines the physical simulation state, primarily through\n",
        "        # pipeline_state.q and pipeline_state.qd which are the generalized positions and\n",
        "        # velocities respectively. The rest of pipeline_state is read_only and useful\n",
        "        # for creating expressive observations - as we can do in this function\n",
        "\n",
        "        qpos = pipeline_state.q\n",
        "        qvel = pipeline_state.qd\n",
        "\n",
        "        if self._exclude_current_positions_from_observation:\n",
        "            qpos = pipeline_state.q[2:]\n",
        "\n",
        "        return jnp.concatenate([qpos] + [qvel])\n",
        "\n",
        "    # ================================================= #\n",
        "    # design pipeline_state random reset function #\n",
        "    # ================================================= #\n",
        "\n",
        "    def get_random_pipeline_state(self, rng):\n",
        "\n",
        "        # here you must decide how to randomly instantiate the generalized positions and\n",
        "        # velocities q, and qd of the pipeline_state and then create the pipeline_state\n",
        "        # to be used in the reset function and the automatic reset functionality later on.\n",
        "        # I will explain the automatic reset later! fear not!\n",
        "\n",
        "        rng, rng1, rng2 = jax.random.split(rng, 3)\n",
        "\n",
        "        low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
        "        q = self.sys.init_q + jax.random.uniform(\n",
        "            rng1, (self.sys.q_size(),), minval=low, maxval=hi\n",
        "        )\n",
        "        qd = hi * jax.random.normal(rng2, (self.sys.qd_size(),))\n",
        "\n",
        "        pipeline_state = self.pipeline_init(q, qd)\n",
        "        return pipeline_state\n",
        "\n",
        "    def reset(self, rng: jr.PRNGKey) -> Tuple[Dict[str, jax.Array], State]:\n",
        "        # =========================== #\n",
        "        # ResetS the environment #\n",
        "        # =========================== #\n",
        "\n",
        "        # reset the global environment as you see fit for your environment. You\n",
        "        # should end up with a new env_state: State and agent_obs: Dict[str, jax.Array]\n",
        "        # as the below example does. NOTE you should also include the exact same info\n",
        "        # dict in the resulting env_state as the example does.\n",
        "\n",
        "        pipeline_state = self.get_random_pipeline_state(rng); rng, _ = jr.split(rng)\n",
        "        global_obs = self.get_global_obs(pipeline_state)\n",
        "\n",
        "        reward, done, zero = jnp.zeros(3)\n",
        "        metrics = {\n",
        "            'reward_forward': zero,\n",
        "            'reward_survive': zero,\n",
        "            'reward_ctrl': zero,\n",
        "            'reward_contact': zero,\n",
        "            'x_position': zero,\n",
        "            'y_position': zero,\n",
        "            'distance_from_origin': zero,\n",
        "            'x_velocity': zero,\n",
        "            'y_velocity': zero,\n",
        "            'forward_reward': zero,\n",
        "        }\n",
        "\n",
        "        # NOTE it is essential that info is created like this and added to env_state\n",
        "        info = {\n",
        "            \"returned_episode_returns\": jnp.zeros(self.num_agents),\n",
        "            \"returned_episode_lengths\": jnp.zeros(self.num_agents),\n",
        "            \"returned_episode\": jnp.zeros(self.num_agents).astype(jnp.bool_)\n",
        "        }\n",
        "\n",
        "        env_state = State(pipeline_state, global_obs, reward, done, metrics, info)\n",
        "\n",
        "        agent_obs = self.map_global_obs_to_agents(global_obs)\n",
        "\n",
        "        # ============================= #\n",
        "        # UNCHANGED: log state wrapping #\n",
        "        # ============================= #\n",
        "\n",
        "        # NOTE we change the \"first_pipeline_state\" and \"first_obs\" at every\n",
        "        # usage, therefore we generate a new pair here to be used as the first\n",
        "        # upon the next automatic reset in step - I will explain the automatic reset\n",
        "        # later! fear not!\n",
        "\n",
        "        new_first_pipeline_state = self.get_random_pipeline_state(rng)\n",
        "        new_first_obs = self.get_global_obs(new_first_pipeline_state)\n",
        "\n",
        "        # the struct we use to log the agent observations and the env state\n",
        "        log_state = LogEnvState(\n",
        "            env_state,\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((self.num_agents,)),\n",
        "            jnp.zeros((), jnp.int32), # the env step number in the current rollout\n",
        "            new_first_pipeline_state,\n",
        "            new_first_obs,\n",
        "            jnp.array(0.)\n",
        "        )\n",
        "\n",
        "        return agent_obs, log_state\n",
        "\n",
        "    def step(\n",
        "        self,\n",
        "        rng: jr.PRNGKey, # this is not used in our deterministic env\n",
        "        state: State, # this is the LogEnvState\n",
        "        actions: Dict[str, jax.Array], # this is the agentic actions\n",
        "    ) -> Tuple[\n",
        "        Dict[str, jax.Array], State, Dict[str, float], Dict[str, bool], Dict\n",
        "    ]:\n",
        "\n",
        "        # We first ensure that states that were previously done (that already\n",
        "        # have had their states reset) have their done flag reset\n",
        "        state = state._replace(\n",
        "            env_state=state.env_state.replace(\n",
        "                done=jnp.zeros_like(state.env_state.done)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # =============================================================== #\n",
        "        # global env_state step (reward, obs, state, metrics, done) #\n",
        "        # =============================================================== #\n",
        "        # here we calculate the global reward, obs, state, metrics, and the global_done\n",
        "        # NOTE the global_done is only for early termination (the end of episode termination\n",
        "        # situation is handled later automatically - look through the remainder of this\n",
        "        # method to understand)\n",
        "\n",
        "        # we get the global actions\n",
        "        global_action = self.map_agents_to_global_action(actions)\n",
        "\n",
        "        # save the old pipeline_state to calculate some velocities\n",
        "        pipeline_state0 = state.env_state.pipeline_state\n",
        "        assert pipeline_state0 is not None\n",
        "\n",
        "        # get the NEXT pipeline state yaaay\n",
        "        next_pipeline_state = self.pipeline_step(state.env_state.pipeline_state, global_action)  # type: ignore\n",
        "\n",
        "        # environment specific calculations\n",
        "        velocity = (next_pipeline_state.x.pos[0] - pipeline_state0.x.pos[0]) / self.dt\n",
        "        forward_reward = velocity[0]\n",
        "\n",
        "        min_z, max_z = self._healthy_z_range\n",
        "\n",
        "        is_healthy = jnp.where(next_pipeline_state.x.pos[0, 2] < min_z, 0.0, 1.0)\n",
        "        is_healthy = jnp.where(next_pipeline_state.x.pos[0, 2] > max_z, 0.0, is_healthy)\n",
        "\n",
        "        if self._terminate_when_unhealthy:\n",
        "            healthy_reward = self._healthy_reward\n",
        "        else:\n",
        "            healthy_reward = self._healthy_reward * is_healthy\n",
        "        ctrl_cost = self._ctrl_cost_weight * jnp.sum(jnp.square(global_action))\n",
        "        contact_cost = 0.0\n",
        "\n",
        "        # finalise the global_obs, global_reward, and global_done (just for early termination)\n",
        "        global_obs = self.get_global_obs(next_pipeline_state)\n",
        "        global_reward = forward_reward + healthy_reward - ctrl_cost - contact_cost\n",
        "        global_done = 1.0 - is_healthy if self._terminate_when_unhealthy else 0.0\n",
        "\n",
        "        # finally we update the environment specific metrics that you have chosen to track\n",
        "        state.env_state.metrics.update(\n",
        "            reward_forward=forward_reward,\n",
        "            reward_survive=healthy_reward,\n",
        "            reward_ctrl=-ctrl_cost,\n",
        "            reward_contact=-contact_cost,\n",
        "            x_position=next_pipeline_state.x.pos[0, 0],\n",
        "            y_position=next_pipeline_state.x.pos[0, 1],\n",
        "            distance_from_origin=math.safe_norm(next_pipeline_state.x.pos[0]),\n",
        "            x_velocity=velocity[0],\n",
        "            y_velocity=velocity[1],\n",
        "            forward_reward=forward_reward,\n",
        "        )\n",
        "\n",
        "        # agent obs is formed AFTER we decide if the env is reset or not as this will\n",
        "        # change the state which we observe\n",
        "\n",
        "        # ==================================================================== #\n",
        "        # UNCHANGED: Episode Wrapping Step (brax.envs.wrappers.EpisodeWrapper) #\n",
        "        # ==================================================================== #\n",
        "\n",
        "        step_in_episode = state.step_in_episode + self.action_repeat\n",
        "\n",
        "        global_done = jnp.where(step_in_episode >= self.episode_length, jnp.ones_like(state.env_state.done), global_done)\n",
        "        state = state._replace(\n",
        "            truncation = jnp.where(\n",
        "                step_in_episode >= jnp.array(self.episode_length), 1 - global_done, jnp.zeros_like(state.env_state.done)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # ===================================== #\n",
        "        # Agentic Rewards Dones Transform #\n",
        "        # ===================================== #\n",
        "        # default behaviour is just to give all agents same global reward\n",
        "        reward = {agent: global_reward for agent in self.agents}\n",
        "        reward[\"__all__\"] = global_reward\n",
        "        done = {agent: global_done.astype(jnp.bool_) for agent in self.agents}\n",
        "        done[\"__all__\"] = global_done.astype(jnp.bool_)\n",
        "\n",
        "        # create new env_state here in ase global rewards or global dones rely on agentic things\n",
        "        env_state = state.env_state.replace(\n",
        "            pipeline_state=next_pipeline_state,\n",
        "            obs=global_obs,\n",
        "            reward=global_reward,\n",
        "            done=global_done\n",
        "        )\n",
        "\n",
        "        # ============================================================================== #\n",
        "        # UNCHANGED: Auto Reset Wrapping Post-Step (brax.envs.wrappers.AutoResetWrapper) #\n",
        "        # ============================================================================== #\n",
        "        def where_done(x, y):\n",
        "            done = env_state.done\n",
        "            if done.shape:\n",
        "                done = jnp.reshape(done, [x.shape[0]] + [1] * (len(x.shape) - 1))  # type: ignore\n",
        "            return jnp.where(done, x, y)\n",
        "\n",
        "\n",
        "        next_pipeline_state = jax.tree.map(\n",
        "            where_done, state.first_pipeline_state, env_state.pipeline_state\n",
        "        )\n",
        "\n",
        "        global_obs = jax.tree.map(where_done, state.first_obs, global_obs)\n",
        "        env_state = env_state.replace(pipeline_state=next_pipeline_state, obs=global_obs)\n",
        "        agent_obs = self.map_global_obs_to_agents(global_obs)\n",
        "\n",
        "        first_pipeline_state = self.get_random_pipeline_state(rng); rng, _ = jr.split(rng)\n",
        "        first_obs = self.get_global_obs(first_pipeline_state)\n",
        "        state = state._replace(\n",
        "            first_pipeline_state=first_pipeline_state,\n",
        "            first_obs=first_obs\n",
        "        )\n",
        "\n",
        "        if self.auto_reset is True:\n",
        "            step_in_episode = jnp.where(env_state.done, jnp.zeros_like(step_in_episode), step_in_episode)\n",
        "            state = state._replace(step_in_episode=step_in_episode)\n",
        "\n",
        "        # ======================= #\n",
        "        # UNCHANGED: Log wrapping #\n",
        "        # ======================= #\n",
        "        ep_done = done[\"__all__\"]\n",
        "        new_episode_return = state.episode_returns + self._batchify_floats(reward)\n",
        "        new_episode_length = state.episode_lengths + 1\n",
        "        state = state._replace(\n",
        "            env_state=env_state,\n",
        "            episode_returns=new_episode_return * (1 - ep_done),\n",
        "            episode_lengths=new_episode_length * (1 - ep_done),\n",
        "            returned_episode_returns=state.returned_episode_returns * (1 - ep_done)\n",
        "            + new_episode_return * ep_done,\n",
        "            returned_episode_lengths=state.returned_episode_lengths * (1 - ep_done)\n",
        "            + new_episode_length * ep_done,\n",
        "            step_in_episode=step_in_episode\n",
        "        )\n",
        "\n",
        "        info = env_state.info\n",
        "        if self.replace_info:\n",
        "            info = {}\n",
        "        info[\"returned_episode_returns\"] = state.returned_episode_returns\n",
        "        info[\"returned_episode_lengths\"] = state.returned_episode_lengths\n",
        "        info[\"returned_episode\"] = jnp.full((self.num_agents,), ep_done)\n",
        "\n",
        "        return agent_obs, state, reward, done, info\n",
        "\n",
        "    # ================================================================ #\n",
        "    # UNCHANGED: mapping agent actions and obs to and from global actions and obs #\n",
        "    # ================================================================ #\n",
        "    def map_agents_to_global_action(\n",
        "        self, agent_actions: Dict[str, jnp.ndarray]\n",
        "    ) -> jnp.ndarray:\n",
        "        global_action = jnp.zeros(self.action_size)\n",
        "        for agent_name, action_indices in self.agent_action_mapping.items():\n",
        "            if self.homogenisation_method == \"max\":\n",
        "                global_action = global_action.at[action_indices].set(\n",
        "                    agent_actions[agent_name][: action_indices.size]\n",
        "                )\n",
        "            elif self.homogenisation_method == \"concat\":\n",
        "                global_action = global_action.at[action_indices].set(\n",
        "                    agent_actions[agent_name][action_indices]\n",
        "                )\n",
        "            else:\n",
        "                global_action = global_action.at[action_indices].set(\n",
        "                    agent_actions[agent_name]\n",
        "                )\n",
        "        return global_action\n",
        "\n",
        "    def map_global_obs_to_agents(self, global_obs: jax.Array) -> Dict[str, jax.Array]:\n",
        "        \"\"\"Maps the global observation vector to the individual agent observations.\n",
        "        Args:\n",
        "            global_obs: The global observation vector.\n",
        "        Returns:\n",
        "            A dictionary mapping agent names to their observations. The mapping method\n",
        "            is determined by the homogenisation_method parameter.\n",
        "        \"\"\"\n",
        "        agent_obs = {}\n",
        "        for agent_idx, (agent_name, obs_indices) in enumerate(\n",
        "            self.agent_obs_mapping.items()\n",
        "        ):\n",
        "            if self.homogenisation_method == \"max\":\n",
        "                # Vector with the agent idx one-hot encoded as the first num_agents\n",
        "                # elements and then the agent's own observations (zero padded to\n",
        "                # the size of the largest agent observation vector)\n",
        "                agent_obs[agent_name] = (\n",
        "                    jnp.zeros(\n",
        "                        self.num_agents\n",
        "                        + max([v.size for v in self.agent_obs_mapping.values()])\n",
        "                    )\n",
        "                    .at[agent_idx]\n",
        "                    .set(1)\n",
        "                    .at[agent_idx + 1 : agent_idx + 1 + obs_indices.size]\n",
        "                    .set(global_obs[obs_indices])\n",
        "                )\n",
        "            elif self.homogenisation_method == \"concat\":\n",
        "                # Zero vector except for the agent's own observations\n",
        "                # (size of the global observation vector)\n",
        "                agent_obs[agent_name] = (\n",
        "                    jnp.zeros(global_obs.shape)\n",
        "                    .at[obs_indices]\n",
        "                    .set(global_obs[obs_indices])\n",
        "                )\n",
        "            else:\n",
        "                # Just agent's own observations\n",
        "                agent_obs[agent_name] = global_obs[obs_indices]\n",
        "        return agent_obs\n",
        "\n",
        "def IPPO_generate_rollout(env, rng, jit=True, num_timesteps=100):\n",
        "    agent_obs, state = env.reset(rng=rng); rng, _rng = jr.split(rng)\n",
        "    rollout = []\n",
        "    if jit is True:\n",
        "        env_step = jax.jit(env.step)\n",
        "    else:\n",
        "        env_step = env.step\n",
        "    ctrl = jr.uniform(_rng, shape=(env.action_size), minval=-1, maxval=1)\n",
        "\n",
        "    agents = env.agents\n",
        "    agent_ctrls = {\"agent_0\": ctrl[:2], \"agent_1\": ctrl[2:4], \"agent_2\": ctrl[4:6], \"agent_3\": ctrl[6:]}\n",
        "    for i in range(num_timesteps):\n",
        "        print(f\"ctrl action chosen: {ctrl}\")\n",
        "        agent_obs, state, reward, done, info = env_step(rng, state, agent_ctrls)\n",
        "        print(f\"state.done: {done}\")\n",
        "        print(f\"state.reward: {reward}\")\n",
        "        rollout.append(state.env_state.pipeline_state)\n",
        "        print(f\"step: {i}\")\n",
        "        print(f\"info: {info}\")\n",
        "        if i == env.episode_length:\n",
        "            print(\"THE PRIOR STATE.DONE SHOULD HAVE BEEN TRUE\")\n",
        "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_name = f'data/rollouts/{current_datetime}.html'\n",
        "    os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "    with open(save_name, 'w') as f:\n",
        "        f.write(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))\n",
        "\n",
        "# def generate_rollout(env, policy, rng, jit=True, num_timesteps=100):\n",
        "#     agent_obs, state = env.reset(rng=rng); rng, _rng = jr.split(rng)\n",
        "#     rollout = []\n",
        "#     if jit is True:\n",
        "#         env_step = jax.jit(env.step)\n",
        "#     else:\n",
        "#         env_step = env.step\n",
        "#     # ctrl = network(agent_obs)\n",
        "#     ctrl = policy(agent_obs)\n",
        "\n",
        "#     agents = env.agents\n",
        "#     agent_ctrls = {\"agent_0\": ctrl[:2], \"agent_1\": ctrl[2:4], \"agent_2\": ctrl[4:6], \"agent_3\": ctrl[6:]}\n",
        "#     # agent_ctrls = {agents[i]: ctrl[:2], \"agent_1\": ctrl[2:]}\n",
        "#     for i in range(num_timesteps):\n",
        "#         print(f\"ctrl action chosen: {ctrl}\")\n",
        "#         agent_obs, state, reward, done, info = env_step(rng, state, agent_ctrls)\n",
        "#         print(f\"state.done: {done}\")\n",
        "#         print(f\"state.reward: {reward}\")\n",
        "#         rollout.append(state.env_state.pipeline_state)\n",
        "#         print(f\"step: {i}\")\n",
        "#         print(f\"info: {info}\")\n",
        "#         if i == env.episode_length:\n",
        "#             print(\"THE PRIOR STATE.DONE SHOULD HAVE BEEN TRUE\")\n",
        "#     current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "#     save_name = f'data/rollouts/{current_datetime}.html'\n",
        "#     os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "#     with open(save_name, 'w') as f:\n",
        "#         f.write(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))\n",
        "\n",
        "# def generate_rollout(env, policy, rng, jit=True, num_timesteps=100):\n",
        "#     agent_obs, state = env.reset(rng=rng)\n",
        "#     rng, _rng = jr.split(rng)\n",
        "#     rollout = []\n",
        "\n",
        "#     env_step = jax.jit(env.step) if jit else env.step\n",
        "\n",
        "#     def get_actions(agent_obs_dict):\n",
        "#         actions = []\n",
        "#         for agent_id in env.agents:\n",
        "#             obs = agent_obs_dict[agent_id].reshape(1, -1)  # (1, obs_dim)\n",
        "#             mean, scale, value = eqx.filter_vmap(policy)(obs)\n",
        "#             actions.append(mean[0])\n",
        "#         return jnp.concatenate(actions)\n",
        "\n",
        "#     ctrl = get_actions(agent_obs)\n",
        "#     agent_ctrls = {\n",
        "#         \"agent_0\": ctrl[:2],\n",
        "#         \"agent_1\": ctrl[2:4],\n",
        "#         \"agent_2\": ctrl[4:6],\n",
        "#         \"agent_3\": ctrl[6:]\n",
        "#     }\n",
        "\n",
        "#     for i in range(num_timesteps):\n",
        "#         agent_obs, state, reward, done, info = env_step(rng, state, agent_ctrls)\n",
        "#         rollout.append(state.env_state.pipeline_state)\n",
        "#         ctrl = get_actions(agent_obs)\n",
        "#         agent_ctrls = {\n",
        "#             \"agent_0\": ctrl[:2],\n",
        "#             \"agent_1\": ctrl[2:4],\n",
        "#             \"agent_2\": ctrl[4:6],\n",
        "#             \"agent_3\": ctrl[6:]\n",
        "#         }\n",
        "\n",
        "#     current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "#     save_name = f'data/rollouts/{current_datetime}.html'\n",
        "#     os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "#     with open(save_name, 'w') as f:\n",
        "#         f.write(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj2Nd-Vd6NLu"
      },
      "source": [
        "## Perform IPPO Training\n",
        "\n",
        "Here we can begin training our IPPO policies! The first time you run this cell, set `debug_mode` to `True` so that you can ensure that all code has been compiled correctly. **Note: This will print out a lot of information**\n",
        "\n",
        "If there are no errors, turn `debug_mode` to `False` to train your IPPO policies!\n",
        "\n",
        "# ***REMEMBER TO DOWNLOAD YOUR `data/` FOLDER AFTER TRAINING!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0AdrS8-uZT0P",
        "outputId": "a4329f1d-b803-4c83-d6d0-bf8453885656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO: training started!\n"
          ]
        }
      ],
      "source": [
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false' # dynamically allocate memory like pytorch does\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"                       # if you have NVIDIA + EGL drivers for rendering\n",
        "\n",
        "jax.config.update('jax_default_matmul_precision', \"highest\") # sometimes certain contact dynamics need higher accuracy to prevent nans\n",
        "\n",
        "# this set of configs lets us cache more values to lower JIT and thus compute times\n",
        "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
        "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
        "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)\n",
        "jax.config.update(\"jax_persistent_cache_enable_xla_caches\", \"xla_gpu_per_fusion_autotune_cache_dir\")\n",
        "\n",
        "config = {\n",
        "    \"LR\": 1e-3,\n",
        "    # \"LR\": 3e-4,\n",
        "    \"NUM_ENVS\": 64,\n",
        "    \"NUM_STEPS\": 300,\n",
        "    # \"TOTAL_TIMESTEPS\": 1e7,\n",
        "    \"TOTAL_TIMESTEPS\": 1.5e7,\n",
        "    \"UPDATE_EPOCHS\": 4,\n",
        "    \"NUM_MINIBATCHES\": 4,\n",
        "    \"GAMMA\": 0.99,\n",
        "    \"GAE_LAMBDA\": 0.95,\n",
        "    # \"GAE_LAMBDA\": 0.97,\n",
        "    \"CLIP_EPS\": 0.2,\n",
        "    \"ENT_COEF\": 2e-6,\n",
        "    # \"ENT_COEF\": 5e-4,\n",
        "    \"VF_COEF\": 4.5,\n",
        "    \"MAX_GRAD_NORM\": 0.5,\n",
        "    \"SEED\": 0,\n",
        "    \"ANNEAL_LR\": True,\n",
        "    \"DEVICE\": 0,\n",
        "    \"DISABLE_JIT\": False,\n",
        "}\n",
        "\n",
        "rng = jr.PRNGKey(config[\"SEED\"])\n",
        "rng, _rng = jr.split(rng)\n",
        "env = IPPO_Ant_Env()\n",
        "agent_obs, state = env.reset(jr.PRNGKey(0))\n",
        "\n",
        "debug_mode = False  # set to True to debug the environment, False to train\n",
        "if(debug_mode):\n",
        "  jax.config.update(\"jax_debug_nans\", True)   # will error if a nan is detected\n",
        "  jax.config.update(\"jax_log_compiles\", True) # will print out recompilations\n",
        "\n",
        "  # a single test step\n",
        "  action = {\"agent_0\": jnp.array([0.5, 0.5]), \"agent_1\": jnp.array([-0.5, -0.5]), \"agent_2\": jnp.array([-0.5, -0.5]), \"agent_3\": jnp.array([-0.5, -0.5])}\n",
        "  agent_obs, state, reward, done, info = env.step(jr.PRNGKey(0), state, action)\n",
        "\n",
        "  # a test rollout\n",
        "  IPPO_generate_rollout(env, jr.PRNGKey(0), jit=True, num_timesteps=700)\n",
        "\n",
        "else:\n",
        "  jax.config.update(\"jax_debug_nans\", False)\n",
        "  jax.config.update(\"jax_log_compiles\", False)\n",
        "\n",
        "  # Start Training!\n",
        "  print(\"INFO: training started!\")\n",
        "  config[\"ENV_NAME\"] = env.__class__.__name__\n",
        "  train = make_train(env, config, _rng)\n",
        "  train_jit = jax.jit(train, device=jax.devices()[config[\"DEVICE\"]])\n",
        "  out = train_jit(rng)\n",
        "  print(out)\n",
        "\n",
        "  print(\"INFO: training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow installation not found - running with reduced feature set.\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.16.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "E0802 01:31:47.300530 139926460945984 _internal.py:97] Error on request:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/werkzeug/serving.py\", line 370, in run_wsgi\n",
            "    execute(self.server.app)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/werkzeug/serving.py\", line 331, in execute\n",
            "    application_iter = app(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
            "    return self._app(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
            "    return wsgi_app(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
            "    return self._application(environ, start_response_proxy)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
            "    return self.exact_routes[clean_path](environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/werkzeug/wrappers/request.py\", line 193, in application\n",
            "    resp = f(*args[:-2] + (request,))\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 121, in get_experiment_route\n",
            "    json_format.MessageToJson(\n",
            "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
            "E0802 01:31:49.924302 139926452553280 _internal.py:97] Error on request:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/werkzeug/serving.py\", line 370, in run_wsgi\n",
            "    execute(self.server.app)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/werkzeug/serving.py\", line 331, in execute\n",
            "    application_iter = app(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
            "    return self._app(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
            "    return wsgi_app(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
            "    return self._application(environ, start_response_proxy)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
            "    return self._application(environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
            "    return self.exact_routes[clean_path](environ, start_response)\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/werkzeug/wrappers/request.py\", line 193, in application\n",
            "    resp = f(*args[:-2] + (request,))\n",
            "  File \"/home/eason/.local/lib/python3.10/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 121, in get_experiment_route\n",
            "    json_format.MessageToJson(\n",
            "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!tensorboard --logdir data/ippo_ant/ --port 6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eason/.local/lib/python3.10/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_0': Array([ 0.63621485,  0.9577485 , -0.03741715, -0.02109581, -0.2843818 ,\n",
            "        0.54502654,  0.639573  ,  0.6016803 ,  0.57119787,  0.47272632,\n",
            "        0.01628697, -0.524652  ,  1.1542678 , -1.0204514 ,  3.1842296 ,\n",
            "       -4.380011  ,  6.1515512 , -7.7769604 ], dtype=float32), 'agent_1': Array([ 0.63621485,  0.9577485 , -0.03741715, -0.02109581, -0.2843818 ,\n",
            "        0.54502654,  0.6016803 , -1.1852491 ,  0.57119787,  0.47272632,\n",
            "        0.01628697, -0.524652  ,  1.1542678 , -1.0204514 ,  3.1842296 ,\n",
            "       -4.380011  ,  4.0937934 , -4.939177  ], dtype=float32), 'agent_2': Array([ 0.63621485,  0.9577485 , -0.03741715, -0.02109581, -0.2843818 ,\n",
            "        0.54502654,  0.6016803 ,  0.57119787, -1.2633228 ,  0.47272632,\n",
            "        0.01628697, -0.524652  ,  1.1542678 , -1.0204514 ,  3.1842296 ,\n",
            "       -4.380011  ,  4.8827505 , -2.9076722 ], dtype=float32), 'agent_3': Array([ 0.63621485,  0.9577485 , -0.03741715, -0.02109581, -0.2843818 ,\n",
            "        0.54502654,  0.6016803 ,  0.57119787,  0.47272632,  0.6561348 ,\n",
            "        0.01628697, -0.524652  ,  1.1542678 , -1.0204514 ,  3.1842296 ,\n",
            "       -4.380011  ,  7.724368  , -9.120439  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2624944  -0.40792328 -1.262495   -0.40394932 -1.2580594  -0.40503064\n",
            " -1.2611723  -0.4074397 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.4844527, dtype=float32), 'agent_0': Array(-2.4844527, dtype=float32), 'agent_1': Array(-2.4844527, dtype=float32), 'agent_2': Array(-2.4844527, dtype=float32), 'agent_3': Array(-2.4844527, dtype=float32)}\n",
            "step: 0\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6806689 ,   0.99324065,  -0.02665535,   0.02852967,\n",
            "        -0.10930956,   0.14352679,   0.47681767,   0.13556963,\n",
            "         0.1516403 ,   0.08293699,   0.30244738,  -0.36948025,\n",
            "         0.60647726,   0.44762057,   0.8793815 ,  11.019169  ,\n",
            "       -13.18858   ,   0.17672813], dtype=float32), 'agent_1': Array([  0.6806689 ,   0.99324065,  -0.02665535,   0.02852967,\n",
            "        -0.10930956,   0.14352679,   0.13556963,  -1.2600638 ,\n",
            "         0.1516403 ,   0.08293699,   0.30244738,  -0.36948025,\n",
            "         0.60647726,   0.44762057,   0.8793815 ,  11.019169  ,\n",
            "       -14.818592  ,  -0.58868   ], dtype=float32), 'agent_2': Array([  0.6806689 ,   0.99324065,  -0.02665535,   0.02852967,\n",
            "        -0.10930956,   0.14352679,   0.13556963,   0.1516403 ,\n",
            "        -1.2589849 ,   0.08293699,   0.30244738,  -0.36948025,\n",
            "         0.60647726,   0.44762057,   0.8793815 ,  11.019169  ,\n",
            "       -13.681206  ,   0.618854  ], dtype=float32), 'agent_3': Array([  0.6806689 ,   0.99324065,  -0.02665535,   0.02852967,\n",
            "        -0.10930956,   0.14352679,   0.13556963,   0.1516403 ,\n",
            "         0.08293699,   0.47668582,   0.30244738,  -0.36948025,\n",
            "         0.60647726,   0.44762057,   0.8793815 ,  11.019169  ,\n",
            "       -13.274639  ,   0.41178185], dtype=float32)}\n",
            "ctrl action chosen: [ 1.0562509  -0.03463368  1.0572058  -0.0326077   1.0575244  -0.03517902\n",
            "  1.0561445  -0.03488128]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3201017, dtype=float32), 'agent_0': Array(-2.3201017, dtype=float32), 'agent_1': Array(-2.3201017, dtype=float32), 'agent_2': Array(-2.3201017, dtype=float32), 'agent_3': Array(-2.3201017, dtype=float32)}\n",
            "step: 1\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7142433 ,  0.9766768 , -0.01859102,  0.04847789, -0.2083427 ,\n",
            "        0.4232809 ,  0.51395774,  0.3394406 ,  0.3867156 ,  0.3534856 ,\n",
            "        0.2360493 , -0.4989028 ,  0.57679415,  0.0208387 ,  1.0719687 ,\n",
            "       -9.171052  , 12.454102  ,  0.81239074], dtype=float32), 'agent_1': Array([ 0.7142433 ,  0.9766768 , -0.01859102,  0.04847789, -0.2083427 ,\n",
            "        0.4232809 ,  0.3394406 , -1.2251939 ,  0.3867156 ,  0.3534856 ,\n",
            "        0.2360493 , -0.4989028 ,  0.57679415,  0.0208387 ,  1.0719687 ,\n",
            "       -9.171052  , 10.977491  ,  0.74463093], dtype=float32), 'agent_2': Array([ 0.7142433 ,  0.9766768 , -0.01859102,  0.04847789, -0.2083427 ,\n",
            "        0.4232809 ,  0.3394406 ,  0.3867156 , -1.175695  ,  0.3534856 ,\n",
            "        0.2360493 , -0.4989028 ,  0.57679415,  0.0208387 ,  1.0719687 ,\n",
            "       -9.171052  , 11.274703  ,  1.9195902 ], dtype=float32), 'agent_3': Array([ 0.7142433 ,  0.9766768 , -0.01859102,  0.04847789, -0.2083427 ,\n",
            "        0.4232809 ,  0.3394406 ,  0.3867156 ,  0.3534856 ,  0.5109968 ,\n",
            "        0.2360493 , -0.4989028 ,  0.57679415,  0.0208387 ,  1.0719687 ,\n",
            "       -9.171052  , 12.221112  ,  0.89970255], dtype=float32)}\n",
            "ctrl action chosen: [0.12461753 0.10839574 0.12726657 0.1092898  0.1269057  0.10713262\n",
            " 0.12467133 0.10828454]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.959913, dtype=float32), 'agent_0': Array(-0.959913, dtype=float32), 'agent_1': Array(-0.959913, dtype=float32), 'agent_2': Array(-0.959913, dtype=float32), 'agent_3': Array(-0.959913, dtype=float32)}\n",
            "step: 2\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7269787 ,  0.96249235, -0.01054416,  0.06205619, -0.2639062 ,\n",
            "        0.55310124,  0.6447915 ,  0.5109719 ,  0.5419519 ,  0.5440737 ,\n",
            "        0.34450963, -0.24698973, -0.02623796,  0.43681398,  0.34077695,\n",
            "        0.86863697, -1.7088832 ,  4.134664  ], dtype=float32), 'agent_1': Array([ 0.7269787 ,  0.96249235, -0.01054416,  0.06205619, -0.2639062 ,\n",
            "        0.55310124,  0.5109719 , -1.1180979 ,  0.5419519 ,  0.5440737 ,\n",
            "        0.34450963, -0.24698973, -0.02623796,  0.43681398,  0.34077695,\n",
            "        0.86863697,  0.10675255,  2.8555055 ], dtype=float32), 'agent_2': Array([ 0.7269787 ,  0.96249235, -0.01054416,  0.06205619, -0.2639062 ,\n",
            "        0.55310124,  0.5109719 ,  0.5419519 , -1.0473511 ,  0.5440737 ,\n",
            "        0.34450963, -0.24698973, -0.02623796,  0.43681398,  0.34077695,\n",
            "        0.86863697, -0.7528916 ,  2.5428207 ], dtype=float32), 'agent_3': Array([ 0.7269787 ,  0.96249235, -0.01054416,  0.06205619, -0.2639062 ,\n",
            "        0.55310124,  0.5109719 ,  0.5419519 ,  0.5440737 ,  0.6344725 ,\n",
            "        0.34450963, -0.24698973, -0.02623796,  0.43681398,  0.34077695,\n",
            "        0.86863697, -0.55971307,  3.945036  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.87342244  1.8456107  -0.87048167  1.8479646  -0.8706595   1.8411825\n",
            " -0.8720934   1.8456386 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2215618, dtype=float32), 'agent_0': Array(1.2215618, dtype=float32), 'agent_1': Array(1.2215618, dtype=float32), 'agent_2': Array(1.2215618, dtype=float32), 'agent_3': Array(1.2215618, dtype=float32)}\n",
            "step: 3\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.0891625e-01,  9.9910116e-01,  1.5842512e-02,  1.9280069e-02,\n",
            "       -3.4269005e-02, -6.3246742e-02,  1.1198375e+00, -1.1002249e-02,\n",
            "       -2.3940783e-02,  1.1537379e-02,  7.5389075e-01, -3.3502877e-01,\n",
            "       -7.1761608e-01,  5.3285635e-01, -2.4093301e+00,  1.2320927e+01,\n",
            "       -1.6258900e+01,  1.1373981e+01], dtype=float32), 'agent_1': Array([ 7.0891625e-01,  9.9910116e-01,  1.5842512e-02,  1.9280069e-02,\n",
            "       -3.4269005e-02, -6.3246742e-02, -1.1002249e-02, -7.0049381e-01,\n",
            "       -2.3940783e-02,  1.1537379e-02,  7.5389075e-01, -3.3502877e-01,\n",
            "       -7.1761608e-01,  5.3285635e-01, -2.4093301e+00,  1.2320927e+01,\n",
            "       -1.3731320e+01,  1.0495902e+01], dtype=float32), 'agent_2': Array([ 7.0891625e-01,  9.9910116e-01,  1.5842512e-02,  1.9280069e-02,\n",
            "       -3.4269005e-02, -6.3246742e-02, -1.1002249e-02, -2.3940783e-02,\n",
            "       -6.4204037e-01,  1.1537379e-02,  7.5389075e-01, -3.3502877e-01,\n",
            "       -7.1761608e-01,  5.3285635e-01, -2.4093301e+00,  1.2320927e+01,\n",
            "       -1.5423107e+01,  1.0600715e+01], dtype=float32), 'agent_3': Array([ 7.0891625e-01,  9.9910116e-01,  1.5842512e-02,  1.9280069e-02,\n",
            "       -3.4269005e-02, -6.3246742e-02, -1.1002249e-02, -2.3940783e-02,\n",
            "        1.1537379e-02,  1.1075337e+00,  7.5389075e-01, -3.3502877e-01,\n",
            "       -7.1761608e-01,  5.3285635e-01, -2.4093301e+00,  1.2320927e+01,\n",
            "       -1.4328136e+01,  1.1114644e+01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9970725  -0.94400406  0.9978067  -0.94217116  0.9966838  -0.9432901\n",
            "  0.9976748  -0.94339603]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.698529, dtype=float32), 'agent_0': Array(-6.698529, dtype=float32), 'agent_1': Array(-6.698529, dtype=float32), 'agent_2': Array(-6.698529, dtype=float32), 'agent_3': Array(-6.698529, dtype=float32)}\n",
            "step: 4\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.6197664e-01,  9.8691392e-01,  2.1089658e-02,  5.3289331e-02,\n",
            "       -1.5072006e-01,  1.7168759e-01,  1.1443193e+00,  3.1583393e-01,\n",
            "        2.5160381e-01,  3.0714488e-01, -1.2120232e-03, -2.1874011e-01,\n",
            "       -9.5354319e-01,  2.4364974e-02,  2.6796405e+00, -9.7100563e+00,\n",
            "        1.1019001e+01, -3.5009415e+00], dtype=float32), 'agent_1': Array([ 6.6197664e-01,  9.8691392e-01,  2.1089658e-02,  5.3289331e-02,\n",
            "       -1.5072006e-01,  1.7168759e-01,  3.1583393e-01, -6.9738519e-01,\n",
            "        2.5160381e-01,  3.0714488e-01, -1.2120232e-03, -2.1874011e-01,\n",
            "       -9.5354319e-01,  2.4364974e-02,  2.6796405e+00, -9.7100563e+00,\n",
            "        1.3076144e+01, -3.9108026e+00], dtype=float32), 'agent_2': Array([ 6.6197664e-01,  9.8691392e-01,  2.1089658e-02,  5.3289331e-02,\n",
            "       -1.5072006e-01,  1.7168759e-01,  3.1583393e-01,  2.5160381e-01,\n",
            "       -6.4133859e-01,  3.0714488e-01, -1.2120232e-03, -2.1874011e-01,\n",
            "       -9.5354319e-01,  2.4364974e-02,  2.6796405e+00, -9.7100563e+00,\n",
            "        1.2169459e+01, -3.8093574e+00], dtype=float32), 'agent_3': Array([ 6.6197664e-01,  9.8691392e-01,  2.1089658e-02,  5.3289331e-02,\n",
            "       -1.5072006e-01,  1.7168759e-01,  3.1583393e-01,  2.5160381e-01,\n",
            "        3.0714488e-01,  1.1215084e+00, -1.2120232e-03, -2.1874011e-01,\n",
            "       -9.5354319e-01,  2.4364974e-02,  2.6796405e+00, -9.7100563e+00,\n",
            "        1.2691981e+01, -4.4705286e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.46330726 -0.49164027 -0.46331534 -0.4906975  -0.4628837  -0.49143925\n",
            " -0.464292   -0.49183404]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.5414257, dtype=float32), 'agent_0': Array(-2.5414257, dtype=float32), 'agent_1': Array(-2.5414257, dtype=float32), 'agent_2': Array(-2.5414257, dtype=float32), 'agent_3': Array(-2.5414257, dtype=float32)}\n",
            "step: 5\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.67070854,  0.9859258 ,  0.03148402,  0.09119203, -0.13654034,\n",
            "        0.13001083,  1.0079992 ,  0.33888695,  0.25883427,  0.37660652,\n",
            "       -0.12932643,  0.31884015,  0.18447638,  0.15748234,  1.837508  ,\n",
            "        3.562193  , -4.5205684 , -3.3413508 ], dtype=float32), 'agent_1': Array([ 0.67070854,  0.9859258 ,  0.03148402,  0.09119203, -0.13654034,\n",
            "        0.13001083,  0.33888695, -0.87856674,  0.25883427,  0.37660652,\n",
            "       -0.12932643,  0.31884015,  0.18447638,  0.15748234,  1.837508  ,\n",
            "        3.562193  , -3.8501413 , -5.07269   ], dtype=float32), 'agent_2': Array([ 0.67070854,  0.9859258 ,  0.03148402,  0.09119203, -0.13654034,\n",
            "        0.13001083,  0.33888695,  0.25883427, -0.8052179 ,  0.37660652,\n",
            "       -0.12932643,  0.31884015,  0.18447638,  0.15748234,  1.837508  ,\n",
            "        3.562193  , -3.6007264 , -4.5495644 ], dtype=float32), 'agent_3': Array([ 0.67070854,  0.9859258 ,  0.03148402,  0.09119203, -0.13654034,\n",
            "        0.13001083,  0.33888695,  0.25883427,  0.37660652,  0.91713434,\n",
            "       -0.12932643,  0.31884015,  0.18447638,  0.15748234,  1.837508  ,\n",
            "        3.562193  , -2.2698798 , -5.4006147 ], dtype=float32)}\n",
            "ctrl action chosen: [0.26576042 0.7211744  0.2662411  0.7180459  0.26789975 0.7167452\n",
            " 0.26639012 0.71677995]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.05790806, dtype=float32), 'agent_0': Array(0.05790806, dtype=float32), 'agent_1': Array(0.05790806, dtype=float32), 'agent_2': Array(0.05790806, dtype=float32), 'agent_3': Array(0.05790806, dtype=float32)}\n",
            "step: 6\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6692362 ,  0.9847374 ,  0.04253535,  0.09616132, -0.13869436,\n",
            "        0.13182676,  1.0691423 ,  0.38020253,  0.30490354,  0.45162037,\n",
            "        0.08091759,  0.37203133, -0.15733242,  0.35955638, -0.5573764 ,\n",
            "       -1.0930115 ,  1.6912762 ,  2.8196008 ], dtype=float32), 'agent_1': Array([ 0.6692362 ,  0.9847374 ,  0.04253535,  0.09616132, -0.13869436,\n",
            "        0.13182676,  0.38020253, -0.8688425 ,  0.30490354,  0.45162037,\n",
            "        0.08091759,  0.37203133, -0.15733242,  0.35955638, -0.5573764 ,\n",
            "       -1.0930115 ,  2.6007018 ,  2.700155  ], dtype=float32), 'agent_2': Array([ 0.6692362 ,  0.9847374 ,  0.04253535,  0.09616132, -0.13869436,\n",
            "        0.13182676,  0.38020253,  0.30490354, -0.78675205,  0.45162037,\n",
            "        0.08091759,  0.37203133, -0.15733242,  0.35955638, -0.5573764 ,\n",
            "       -1.0930115 ,  2.2318013 ,  2.377083  ], dtype=float32), 'agent_3': Array([ 0.6692362 ,  0.9847374 ,  0.04253535,  0.09616132, -0.13869436,\n",
            "        0.13182676,  0.38020253,  0.30490354,  0.45162037,  0.92083645,\n",
            "        0.08091759,  0.37203133, -0.15733242,  0.35955638, -0.5573764 ,\n",
            "       -1.0930115 ,  2.7236423 ,  2.1865532 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.40474996 -2.56665     0.4058071  -2.5676036   0.40726602 -2.5708458\n",
            "  0.40417328 -2.5692923 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.19963247, dtype=float32), 'agent_0': Array(-0.19963247, dtype=float32), 'agent_1': Array(-0.19963247, dtype=float32), 'agent_2': Array(-0.19963247, dtype=float32), 'agent_3': Array(-0.19963247, dtype=float32)}\n",
            "step: 7\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6650476 ,  0.9698737 ,  0.02169359,  0.15203176, -0.1891052 ,\n",
            "        0.31451938,  0.79066634,  0.56318784,  0.50365657,  0.5667425 ,\n",
            "       -0.64783096,  0.19750297, -0.08423328, -1.4333582 ,  2.7102556 ,\n",
            "       -0.32848918,  1.7177521 , -8.265785  ], dtype=float32), 'agent_1': Array([ 0.6650476 ,  0.9698737 ,  0.02169359,  0.15203176, -0.1891052 ,\n",
            "        0.31451938,  0.56318784, -1.1293832 ,  0.50365657,  0.5667425 ,\n",
            "       -0.64783096,  0.19750297, -0.08423328, -1.4333582 ,  2.7102556 ,\n",
            "       -0.32848918,  0.5717991 , -7.7720137 ], dtype=float32), 'agent_2': Array([ 0.6650476 ,  0.9698737 ,  0.02169359,  0.15203176, -0.1891052 ,\n",
            "        0.31451938,  0.56318784,  0.50365657, -1.0775197 ,  0.5667425 ,\n",
            "       -0.64783096,  0.19750297, -0.08423328, -1.4333582 ,  2.7102556 ,\n",
            "       -0.32848918,  2.1707385 , -8.183743  ], dtype=float32), 'agent_3': Array([ 0.6650476 ,  0.9698737 ,  0.02169359,  0.15203176, -0.1891052 ,\n",
            "        0.31451938,  0.56318784,  0.50365657,  0.5667425 ,  0.5845856 ,\n",
            "       -0.64783096,  0.19750297, -0.08423328, -1.4333582 ,  2.7102556 ,\n",
            "       -0.32848918, -0.8137051 , -9.75566   ], dtype=float32)}\n",
            "ctrl action chosen: [2.7225842 1.2678086 2.721898  1.2708671 2.724586  1.2669679 2.723035\n",
            " 1.2688458]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.892633, dtype=float32), 'agent_0': Array(-12.892633, dtype=float32), 'agent_1': Array(-12.892633, dtype=float32), 'agent_2': Array(-12.892633, dtype=float32), 'agent_3': Array(-12.892633, dtype=float32)}\n",
            "step: 8\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.64854324,  0.9701502 ,  0.02845722,  0.12466283, -0.20605363,\n",
            "        0.5097742 ,  0.94199014,  0.5574823 ,  0.5867009 ,  0.53472304,\n",
            "        0.46342164, -0.03578961, -0.64833164,  1.0623288 , -2.2817202 ,\n",
            "       -0.36553016,  4.695222  ,  7.007136  ], dtype=float32), 'agent_1': Array([ 0.64854324,  0.9701502 ,  0.02845722,  0.12466283, -0.20605363,\n",
            "        0.5097742 ,  0.5574823 , -0.9751282 ,  0.5867009 ,  0.53472304,\n",
            "        0.46342164, -0.03578961, -0.64833164,  1.0623288 , -2.2817202 ,\n",
            "       -0.36553016, -0.51612425,  6.9864655 ], dtype=float32), 'agent_2': Array([ 0.64854324,  0.9701502 ,  0.02845722,  0.12466283, -0.20605363,\n",
            "        0.5097742 ,  0.5574823 ,  0.5867009 , -0.93865275,  0.53472304,\n",
            "        0.46342164, -0.03578961, -0.64833164,  1.0623288 , -2.2817202 ,\n",
            "       -0.36553016,  0.06001158,  6.566457  ], dtype=float32), 'agent_3': Array([ 0.64854324,  0.9701502 ,  0.02845722,  0.12466283, -0.20605363,\n",
            "        0.5097742 ,  0.5574823 ,  0.5867009 ,  0.53472304,  0.6804646 ,\n",
            "        0.46342164, -0.03578961, -0.64833164,  1.0623288 , -2.2817202 ,\n",
            "       -0.36553016, -0.6544863 ,  6.5620704 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.7297607  -0.81313425  0.72883624 -0.81081915  0.7297584  -0.8156381\n",
            "  0.72832483 -0.813102  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-16.973988, dtype=float32), 'agent_0': Array(-16.973988, dtype=float32), 'agent_1': Array(-16.973988, dtype=float32), 'agent_2': Array(-16.973988, dtype=float32), 'agent_3': Array(-16.973988, dtype=float32)}\n",
            "step: 9\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.61008584,  0.9703969 ,  0.01603672,  0.1465078 , -0.19133292,\n",
            "        0.60890675,  0.78672105,  0.5168496 ,  0.5245151 ,  0.515514  ,\n",
            "       -0.5822137 , -0.09638965, -0.7703185 , -1.088699  ,  1.8167841 ,\n",
            "        0.33823586,  0.10589249, -6.3884006 ], dtype=float32), 'agent_1': Array([ 0.61008584,  0.9703969 ,  0.01603672,  0.1465078 , -0.19133292,\n",
            "        0.60890675,  0.5168496 , -1.1053516 ,  0.5245151 ,  0.515514  ,\n",
            "       -0.5822137 , -0.09638965, -0.7703185 , -1.088699  ,  1.8167841 ,\n",
            "        0.33823586,  0.13275732, -5.940884  ], dtype=float32), 'agent_2': Array([ 0.61008584,  0.9703969 ,  0.01603672,  0.1465078 , -0.19133292,\n",
            "        0.60890675,  0.5168496 ,  0.5245151 , -1.0867839 ,  0.515514  ,\n",
            "       -0.5822137 , -0.09638965, -0.7703185 , -1.088699  ,  1.8167841 ,\n",
            "        0.33823586, -0.99783987, -6.2737026 ], dtype=float32), 'agent_3': Array([ 0.61008584,  0.9703969 ,  0.01603672,  0.1465078 , -0.19133292,\n",
            "        0.60890675,  0.5168496 ,  0.5245151 ,  0.515514  ,  0.52038145,\n",
            "       -0.5822137 , -0.09638965, -0.7703185 , -1.088699  ,  1.8167841 ,\n",
            "        0.33823586,  0.759161  , -6.746323  ], dtype=float32)}\n",
            "ctrl action chosen: [0.40571043 0.73088634 0.40452614 0.7339975  0.40856418 0.72922134\n",
            " 0.4057655  0.7307151 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5255326, dtype=float32), 'agent_0': Array(-1.5255326, dtype=float32), 'agent_1': Array(-1.5255326, dtype=float32), 'agent_2': Array(-1.5255326, dtype=float32), 'agent_3': Array(-1.5255326, dtype=float32)}\n",
            "step: 10\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.59512615,  0.97546023,  0.01815446,  0.11406841, -0.18744648,\n",
            "        0.5287563 ,  0.8658392 ,  0.53998107,  0.5263977 ,  0.5417354 ,\n",
            "       -0.41153282,  0.06387532, -0.27747154,  0.8021186 , -2.3284652 ,\n",
            "        0.14145572, -2.0239143 ,  4.7739882 ], dtype=float32), 'agent_1': Array([ 0.59512615,  0.97546023,  0.01815446,  0.11406841, -0.18744648,\n",
            "        0.5287563 ,  0.53998107, -0.9707858 ,  0.5263977 ,  0.5417354 ,\n",
            "       -0.41153282,  0.06387532, -0.27747154,  0.8021186 , -2.3284652 ,\n",
            "        0.14145572,  0.6001018 ,  5.958227  ], dtype=float32), 'agent_2': Array([ 0.59512615,  0.97546023,  0.01815446,  0.11406841, -0.18744648,\n",
            "        0.5287563 ,  0.53998107,  0.5263977 , -0.98110175,  0.5417354 ,\n",
            "       -0.41153282,  0.06387532, -0.27747154,  0.8021186 , -2.3284652 ,\n",
            "        0.14145572,  0.58427244,  5.2834787 ], dtype=float32), 'agent_3': Array([ 0.59512615,  0.97546023,  0.01815446,  0.11406841, -0.18744648,\n",
            "        0.5287563 ,  0.53998107,  0.5263977 ,  0.5417354 ,  0.6239581 ,\n",
            "       -0.41153282,  0.06387532, -0.27747154,  0.8021186 , -2.3284652 ,\n",
            "        0.14145572,  0.40832698,  4.4192414 ], dtype=float32)}\n",
            "ctrl action chosen: [0.21898694 0.05311877 0.22057192 0.05560846 0.22140619 0.05035442\n",
            " 0.22047174 0.05284086]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9337313, dtype=float32), 'agent_0': Array(-0.9337313, dtype=float32), 'agent_1': Array(-0.9337313, dtype=float32), 'agent_2': Array(-0.9337313, dtype=float32), 'agent_3': Array(-0.9337313, dtype=float32)}\n",
            "step: 11\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5731703 ,  0.9810579 ,  0.01889012,  0.08075708, -0.17506294,\n",
            "        0.4289365 ,  0.95961314,  0.5381492 ,  0.5330512 ,  0.5244577 ,\n",
            "       -0.6172538 , -0.21471977, -0.3117442 ,  0.09443763, -1.2291112 ,\n",
            "        0.25069642, -0.95624435,  0.28697696], dtype=float32), 'agent_1': Array([ 0.5731703 ,  0.9810579 ,  0.01889012,  0.08075708, -0.17506294,\n",
            "        0.4289365 ,  0.5381492 , -0.84181845,  0.5330512 ,  0.5244577 ,\n",
            "       -0.6172538 , -0.21471977, -0.3117442 ,  0.09443763, -1.2291112 ,\n",
            "        0.25069642, -0.15155254,  1.8671548 ], dtype=float32), 'agent_2': Array([ 0.5731703 ,  0.9810579 ,  0.01889012,  0.08075708, -0.17506294,\n",
            "        0.4289365 ,  0.5381492 ,  0.5330512 , -0.85691434,  0.5244577 ,\n",
            "       -0.6172538 , -0.21471977, -0.3117442 ,  0.09443763, -1.2291112 ,\n",
            "        0.25069642,  0.31050363,  1.6934234 ], dtype=float32), 'agent_3': Array([ 0.5731703 ,  0.9810579 ,  0.01889012,  0.08075708, -0.17506294,\n",
            "        0.4289365 ,  0.5381492 ,  0.5330512 ,  0.5244577 ,  0.69846445,\n",
            "       -0.6172538 , -0.21471977, -0.3117442 ,  0.09443763, -1.2291112 ,\n",
            "        0.25069642, -0.39918932,  0.29074678], dtype=float32)}\n",
            "ctrl action chosen: [-1.6872134 -0.893723  -1.6843859 -0.8896221 -1.6827047 -0.8973887\n",
            " -1.6869295 -0.8947978]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3476837, dtype=float32), 'agent_0': Array(0.3476837, dtype=float32), 'agent_1': Array(0.3476837, dtype=float32), 'agent_2': Array(0.3476837, dtype=float32), 'agent_3': Array(0.3476837, dtype=float32)}\n",
            "step: 12\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.56255305,   0.99345034,   0.02834985,   0.08273207,\n",
            "         0.07354045,  -0.18289332,   0.690758  ,  -0.06227352,\n",
            "        -0.03552797,  -0.09193247,  -0.9632647 ,  -0.188604  ,\n",
            "        -0.46299696,  -0.54427063,   1.0954221 ,  12.988352  ,\n",
            "       -16.237156  ,  -7.9921374 ], dtype=float32), 'agent_1': Array([  0.56255305,   0.99345034,   0.02834985,   0.08273207,\n",
            "         0.07354045,  -0.18289332,  -0.06227352,  -1.0167226 ,\n",
            "        -0.03552797,  -0.09193247,  -0.9632647 ,  -0.188604  ,\n",
            "        -0.46299696,  -0.54427063,   1.0954221 ,  12.988352  ,\n",
            "       -15.980861  ,  -6.128245  ], dtype=float32), 'agent_2': Array([  0.56255305,   0.99345034,   0.02834985,   0.08273207,\n",
            "         0.07354045,  -0.18289332,  -0.06227352,  -0.03552797,\n",
            "        -1.0566398 ,  -0.09193247,  -0.9632647 ,  -0.188604  ,\n",
            "        -0.46299696,  -0.54427063,   1.0954221 ,  12.988352  ,\n",
            "       -15.3292885 ,  -6.5077252 ], dtype=float32), 'agent_3': Array([  0.56255305,   0.99345034,   0.02834985,   0.08273207,\n",
            "         0.07354045,  -0.18289332,  -0.06227352,  -0.03552797,\n",
            "        -0.09193247,   0.4746774 ,  -0.9632647 ,  -0.188604  ,\n",
            "        -0.46299696,  -0.54427063,   1.0954221 ,  12.988352  ,\n",
            "       -15.913895  ,  -3.248698  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.7009163  -1.2774396   0.7011824  -1.2773378   0.7013337  -1.2788391\n",
            "  0.70143414 -1.2785037 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.174965, dtype=float32), 'agent_0': Array(-7.174965, dtype=float32), 'agent_1': Array(-7.174965, dtype=float32), 'agent_2': Array(-7.174965, dtype=float32), 'agent_3': Array(-7.174965, dtype=float32)}\n",
            "step: 13\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.30886948e-01,  9.95036602e-01,  9.30958893e-03,  8.89167264e-02,\n",
            "        4.36961539e-02, -1.22437954e-01,  4.46155012e-01, -2.05515511e-03,\n",
            "        6.54889867e-02, -2.25438830e-02, -6.20964170e-01, -2.55355239e-01,\n",
            "       -2.86281109e-01, -1.57843351e-01, -1.29337394e+00, -5.49277258e+00,\n",
            "        7.10823727e+00,  1.06549633e+00], dtype=float32), 'agent_1': Array([ 5.30886948e-01,  9.95036602e-01,  9.30958893e-03,  8.89167264e-02,\n",
            "        4.36961539e-02, -1.22437954e-01, -2.05515511e-03, -1.29594922e+00,\n",
            "        6.54889867e-02, -2.25438830e-02, -6.20964170e-01, -2.55355239e-01,\n",
            "       -2.86281109e-01, -1.57843351e-01, -1.29337394e+00, -5.49277258e+00,\n",
            "        6.53545952e+00, -5.41890621e-01], dtype=float32), 'agent_2': Array([ 5.30886948e-01,  9.95036602e-01,  9.30958893e-03,  8.89167264e-02,\n",
            "        4.36961539e-02, -1.22437954e-01, -2.05515511e-03,  6.54889867e-02,\n",
            "       -1.29254937e+00, -2.25438830e-02, -6.20964170e-01, -2.55355239e-01,\n",
            "       -2.86281109e-01, -1.57843351e-01, -1.29337394e+00, -5.49277258e+00,\n",
            "        7.56440449e+00,  9.82020438e-01], dtype=float32), 'agent_3': Array([ 5.30886948e-01,  9.95036602e-01,  9.30958893e-03,  8.89167264e-02,\n",
            "        4.36961539e-02, -1.22437954e-01, -2.05515511e-03,  6.54889867e-02,\n",
            "       -2.25438830e-02,  4.59603339e-01, -6.20964170e-01, -2.55355239e-01,\n",
            "       -2.86281109e-01, -1.57843351e-01, -1.29337394e+00, -5.49277258e+00,\n",
            "        7.19932175e+00, -3.07444613e-02], dtype=float32)}\n",
            "ctrl action chosen: [ 0.4178304  -1.1955535   0.41874194 -1.1955117   0.41884622 -1.1973451\n",
            "  0.4170479  -1.1962042 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.127731, dtype=float32), 'agent_0': Array(-4.127731, dtype=float32), 'agent_1': Array(-4.127731, dtype=float32), 'agent_2': Array(-4.127731, dtype=float32), 'agent_3': Array(-4.127731, dtype=float32)}\n",
            "step: 14\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5555591 ,  0.99041486, -0.01826952,  0.07460757, -0.1147975 ,\n",
            "        0.29343465,  0.46668068,  0.4082188 ,  0.51166165,  0.38444245,\n",
            "       -0.37549734, -0.41466653,  0.5351901 , -0.5827802 , -0.24098018,\n",
            "       -6.746913  ,  8.601524  ,  0.81418234], dtype=float32), 'agent_1': Array([ 0.5555591 ,  0.99041486, -0.01826952,  0.07460757, -0.1147975 ,\n",
            "        0.29343465,  0.4082188 , -1.281305  ,  0.51166165,  0.38444245,\n",
            "       -0.37549734, -0.41466653,  0.5351901 , -0.5827802 , -0.24098018,\n",
            "       -6.746913  ,  8.98159   ,  0.75918764], dtype=float32), 'agent_2': Array([ 0.5555591 ,  0.99041486, -0.01826952,  0.07460757, -0.1147975 ,\n",
            "        0.29343465,  0.4082188 ,  0.51166165, -1.2766646 ,  0.38444245,\n",
            "       -0.37549734, -0.41466653,  0.5351901 , -0.5827802 , -0.24098018,\n",
            "       -6.746913  ,  9.363191  ,  0.80063087], dtype=float32), 'agent_3': Array([ 0.5555591 ,  0.99041486, -0.01826952,  0.07460757, -0.1147975 ,\n",
            "        0.29343465,  0.4082188 ,  0.51166165,  0.38444245,  0.49569732,\n",
            "       -0.37549734, -0.41466653,  0.5351901 , -0.5827802 , -0.24098018,\n",
            "       -6.746913  ,  8.330612  ,  0.35316238], dtype=float32)}\n",
            "ctrl action chosen: [ 0.06357557 -0.989027    0.06537702 -0.9890738   0.06533828 -0.99089646\n",
            "  0.06356275 -0.9893373 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.6523762, dtype=float32), 'agent_0': Array(-2.6523762, dtype=float32), 'agent_1': Array(-2.6523762, dtype=float32), 'agent_2': Array(-2.6523762, dtype=float32), 'agent_3': Array(-2.6523762, dtype=float32)}\n",
            "step: 15\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5593619 ,  0.9878667 , -0.03157423,  0.06465273, -0.13763216,\n",
            "        0.4016614 ,  0.50279737,  0.52844   ,  0.54322195,  0.47992203,\n",
            "       -0.28204918, -0.47295392, -0.195992  , -0.44936794, -0.22036187,\n",
            "        0.24705675,  0.7303775 ,  0.09040482], dtype=float32), 'agent_1': Array([ 0.5593619 ,  0.9878667 , -0.03157423,  0.06465273, -0.13763216,\n",
            "        0.4016614 ,  0.52844   , -1.2444825 ,  0.54322195,  0.47992203,\n",
            "       -0.28204918, -0.47295392, -0.195992  , -0.44936794, -0.22036187,\n",
            "        0.24705675,  0.7121232 , -0.07487829], dtype=float32), 'agent_2': Array([ 0.5593619 ,  0.9878667 , -0.03157423,  0.06465273, -0.13763216,\n",
            "        0.4016614 ,  0.52844   ,  0.54322195, -1.249383  ,  0.47992203,\n",
            "       -0.28204918, -0.47295392, -0.195992  , -0.44936794, -0.22036187,\n",
            "        0.24705675, -1.2534775 ,  0.01715001], dtype=float32), 'agent_3': Array([ 0.5593619 ,  0.9878667 , -0.03157423,  0.06465273, -0.13763216,\n",
            "        0.4016614 ,  0.52844   ,  0.54322195,  0.47992203,  0.4910075 ,\n",
            "       -0.28204918, -0.47295392, -0.195992  , -0.44936794, -0.22036187,\n",
            "        0.24705675,  0.5642752 , -0.71571946], dtype=float32)}\n",
            "ctrl action chosen: [-1.9519511  0.9725549 -1.9497659  0.975975  -1.9501272  0.9705465\n",
            " -1.9523922  0.9707001]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.2567444, dtype=float32), 'agent_0': Array(-1.2567444, dtype=float32), 'agent_1': Array(-1.2567444, dtype=float32), 'agent_2': Array(-1.2567444, dtype=float32), 'agent_3': Array(-1.2567444, dtype=float32)}\n",
            "step: 16\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.44047177e-01,  9.93588567e-01, -1.87543333e-02,  7.03278743e-03,\n",
            "        1.11268602e-01, -1.60001040e-01,  9.03494895e-01, -3.15304101e-02,\n",
            "       -1.26897171e-01, -8.36583823e-02,  2.23979354e-01, -2.88549066e-01,\n",
            "       -4.35769558e-01, -2.70181477e-01, -3.30088758e+00,  1.30455904e+01,\n",
            "       -1.52881365e+01,  1.04811687e+01], dtype=float32), 'agent_1': Array([ 5.4404718e-01,  9.9358857e-01, -1.8754333e-02,  7.0327874e-03,\n",
            "        1.1126860e-01, -1.6000104e-01, -3.1530410e-02, -8.8952303e-01,\n",
            "       -1.2689717e-01, -8.3658382e-02,  2.2397935e-01, -2.8854907e-01,\n",
            "       -4.3576956e-01, -2.7018148e-01, -3.3008876e+00,  1.3045590e+01,\n",
            "       -1.4921469e+01,  9.2446566e+00], dtype=float32), 'agent_2': Array([ 5.4404718e-01,  9.9358857e-01, -1.8754333e-02,  7.0327874e-03,\n",
            "        1.1126860e-01, -1.6000104e-01, -3.1530410e-02, -1.2689717e-01,\n",
            "       -8.8414830e-01, -8.3658382e-02,  2.2397935e-01, -2.8854907e-01,\n",
            "       -4.3576956e-01, -2.7018148e-01, -3.3008876e+00,  1.3045590e+01,\n",
            "       -1.7567907e+01,  1.0200023e+01], dtype=float32), 'agent_3': Array([ 5.4404718e-01,  9.9358857e-01, -1.8754333e-02,  7.0327874e-03,\n",
            "        1.1126860e-01, -1.6000104e-01, -3.1530410e-02, -1.2689717e-01,\n",
            "       -8.3658382e-02,  7.7006638e-01,  2.2397935e-01, -2.8854907e-01,\n",
            "       -4.3576956e-01, -2.7018148e-01, -3.3008876e+00,  1.3045590e+01,\n",
            "       -1.5115542e+01,  7.7218337e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.39383397 -0.05810159 -0.39467022 -0.05756037 -0.39518043 -0.05848596\n",
            " -0.3956256  -0.05928404]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.437286, dtype=float32), 'agent_0': Array(-8.437286, dtype=float32), 'agent_1': Array(-8.437286, dtype=float32), 'agent_2': Array(-8.437286, dtype=float32), 'agent_3': Array(-8.437286, dtype=float32)}\n",
            "step: 17\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.521159  ,  0.9566363 , -0.02585771, -0.02915799,  0.28866646,\n",
            "       -0.5607796 ,  1.0692233 , -0.45888236, -0.59046483, -0.5337451 ,\n",
            "        0.08147955, -0.02712011, -0.28179884, -0.74749625, -1.2720526 ,\n",
            "        1.0281119 ,  0.31769523, -0.7615901 ], dtype=float32), 'agent_1': Array([ 0.521159  ,  0.9566363 , -0.02585771, -0.02915799,  0.28866646,\n",
            "       -0.5607796 , -0.45888236, -0.6538678 , -0.59046483, -0.5337451 ,\n",
            "        0.08147955, -0.02712011, -0.28179884, -0.74749625, -1.2720526 ,\n",
            "        1.0281119 , -2.235774  ,  3.886534  ], dtype=float32), 'agent_2': Array([ 0.521159  ,  0.9566363 , -0.02585771, -0.02915799,  0.28866646,\n",
            "       -0.5607796 , -0.45888236, -0.59046483, -0.6077595 , -0.5337451 ,\n",
            "        0.08147955, -0.02712011, -0.28179884, -0.74749625, -1.2720526 ,\n",
            "        1.0281119 ,  0.6229207 ,  4.0283265 ], dtype=float32), 'agent_3': Array([ 0.521159  ,  0.9566363 , -0.02585771, -0.02915799,  0.28866646,\n",
            "       -0.5607796 , -0.45888236, -0.59046483, -0.5337451 ,  0.95145375,\n",
            "        0.08147955, -0.02712011, -0.28179884, -0.74749625, -1.2720526 ,\n",
            "        1.0281119 , -2.1842694 ,  3.0854983 ], dtype=float32)}\n",
            "ctrl action chosen: [0.33123255 1.4329134  0.32534376 1.4401917  0.32769224 1.4389552\n",
            " 0.32698125 1.4397503 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.78330415, dtype=float32), 'agent_0': Array(0.78330415, dtype=float32), 'agent_1': Array(0.78330415, dtype=float32), 'agent_2': Array(0.78330415, dtype=float32), 'agent_3': Array(0.78330415, dtype=float32)}\n",
            "step: 18\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5168051 ,  0.96738964, -0.02860042, -0.10163962,  0.23023619,\n",
            "       -0.3526354 ,  1.2550653 , -0.32053152, -0.36721528, -0.42723837,\n",
            "        0.09521842,  0.44301152,  0.15772581,  0.57539684, -1.5244287 ,\n",
            "       -4.2675476 ,  6.702071  ,  2.6003318 ], dtype=float32), 'agent_1': Array([ 0.5168051 ,  0.96738964, -0.02860042, -0.10163962,  0.23023619,\n",
            "       -0.3526354 , -0.32053152, -0.44432324, -0.36721528, -0.42723837,\n",
            "        0.09521842,  0.44301152,  0.15772581,  0.57539684, -1.5244287 ,\n",
            "       -4.2675476 ,  4.684897  , -1.4401327 ], dtype=float32), 'agent_2': Array([ 0.5168051 ,  0.96738964, -0.02860042, -0.10163962,  0.23023619,\n",
            "       -0.3526354 , -0.32053152, -0.36721528, -0.44406626, -0.42723837,\n",
            "        0.09521842,  0.44301152,  0.15772581,  0.57539684, -1.5244287 ,\n",
            "       -4.2675476 ,  7.0749907 , -0.9385565 ], dtype=float32), 'agent_3': Array([ 0.5168051 ,  0.96738964, -0.02860042, -0.10163962,  0.23023619,\n",
            "       -0.3526354 , -0.32053152, -0.36721528, -0.42723837,  1.309581  ,\n",
            "        0.09521842,  0.44301152,  0.15772581,  0.57539684, -1.5244287 ,\n",
            "       -4.2675476 ,  4.1850014 ,  0.745207  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.4795722  -1.2656713   0.4790046  -1.2668263   0.47695062 -1.2660995\n",
            "  0.4800396  -1.2662411 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0900872, dtype=float32), 'agent_0': Array(-3.0900872, dtype=float32), 'agent_1': Array(-3.0900872, dtype=float32), 'agent_2': Array(-3.0900872, dtype=float32), 'agent_3': Array(-3.0900872, dtype=float32)}\n",
            "step: 19\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53724784,  0.99383587,  0.01031416, -0.07168329,  0.08393761,\n",
            "        0.07157017,  0.9838829 ,  0.0472106 ,  0.08750647, -0.07365815,\n",
            "       -0.67215264,  0.2824217 ,  0.16344786,  0.9525049 ,  1.4744178 ,\n",
            "       -6.1701427 ,  8.266944  , -6.0371957 ], dtype=float32), 'agent_1': Array([ 0.53724784,  0.99383587,  0.01031416, -0.07168329,  0.08393761,\n",
            "        0.07157017,  0.0472106 , -0.78872514,  0.08750647, -0.07365815,\n",
            "       -0.67215264,  0.2824217 ,  0.16344786,  0.9525049 ,  1.4744178 ,\n",
            "       -6.1701427 ,  8.094711  , -8.889106  ], dtype=float32), 'agent_2': Array([ 0.53724784,  0.99383587,  0.01031416, -0.07168329,  0.08393761,\n",
            "        0.07157017,  0.0472106 ,  0.08750647, -0.75727415, -0.07365815,\n",
            "       -0.67215264,  0.2824217 ,  0.16344786,  0.9525049 ,  1.4744178 ,\n",
            "       -6.1701427 ,  9.435742  , -7.84737   ], dtype=float32), 'agent_3': Array([ 0.53724784,  0.99383587,  0.01031416, -0.07168329,  0.08393761,\n",
            "        0.07157017,  0.0472106 ,  0.08750647, -0.07365815,  0.9906448 ,\n",
            "       -0.67215264,  0.2824217 ,  0.16344786,  0.9525049 ,  1.4744178 ,\n",
            "       -6.1701427 ,  7.775325  , -7.887247  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9059179  -0.7494636   0.90446043 -0.74953175  0.9065313  -0.74923223\n",
            "  0.90412354 -0.7505109 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.1700435, dtype=float32), 'agent_0': Array(-3.1700435, dtype=float32), 'agent_1': Array(-3.1700435, dtype=float32), 'agent_2': Array(-3.1700435, dtype=float32), 'agent_3': Array(-3.1700435, dtype=float32)}\n",
            "step: 20\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8094311e-01,  9.9460346e-01,  1.5929971e-02, -3.0059994e-03,\n",
            "       -1.0247540e-01,  5.7804418e-01,  5.8924085e-01,  5.3310066e-01,\n",
            "        6.3124132e-01,  4.3463346e-01, -9.8869205e-01, -5.5881143e-01,\n",
            "        1.1311650e+00, -1.5114174e+00,  3.0058138e+00, -6.5115415e-02,\n",
            "        8.8559121e-01, -1.1203555e+01], dtype=float32), 'agent_1': Array([ 5.8094311e-01,  9.9460346e-01,  1.5929971e-02, -3.0059994e-03,\n",
            "       -1.0247540e-01,  5.7804418e-01,  5.3310066e-01, -1.1738338e+00,\n",
            "        6.3124132e-01,  4.3463346e-01, -9.8869205e-01, -5.5881143e-01,\n",
            "        1.1311650e+00, -1.5114174e+00,  3.0058138e+00, -6.5115415e-02,\n",
            "        1.2854524e+00, -7.4156618e+00], dtype=float32), 'agent_2': Array([ 5.80943108e-01,  9.94603455e-01,  1.59299709e-02, -3.00599937e-03,\n",
            "       -1.02475397e-01,  5.78044176e-01,  5.33100665e-01,  6.31241322e-01,\n",
            "       -1.10410035e+00,  4.34633464e-01, -9.88692045e-01, -5.58811426e-01,\n",
            "        1.13116503e+00, -1.51141739e+00,  3.00581384e+00, -6.51154146e-02,\n",
            "       -1.02956064e-01, -5.78696775e+00], dtype=float32), 'agent_3': Array([ 5.8094311e-01,  9.9460346e-01,  1.5929971e-02, -3.0059994e-03,\n",
            "       -1.0247540e-01,  5.7804418e-01,  5.3310066e-01,  6.3124132e-01,\n",
            "        4.3463346e-01,  5.0577343e-01, -9.8869205e-01, -5.5881143e-01,\n",
            "        1.1311650e+00, -1.5114174e+00,  3.0058138e+00, -6.5115415e-02,\n",
            "        3.1895511e+00, -1.0477072e+01], dtype=float32)}\n",
            "ctrl action chosen: [-0.55920833 -0.1680276  -0.5628947  -0.16586092 -0.56116897 -0.17115706\n",
            " -0.55922663 -0.16867462]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.7417521, dtype=float32), 'agent_0': Array(-2.7417521, dtype=float32), 'agent_1': Array(-2.7417521, dtype=float32), 'agent_2': Array(-2.7417521, dtype=float32), 'agent_3': Array(-2.7417521, dtype=float32)}\n",
            "step: 21\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.3690358e-01,  9.9918425e-01, -1.1578243e-04,  1.6209092e-02,\n",
            "        3.6990181e-02,  3.1845355e-01,  4.7636119e-01,  2.4427424e-01,\n",
            "        3.3961737e-01,  1.6854145e-01, -6.6706538e-01, -4.0967464e-01,\n",
            "        1.3686061e+00,  3.7057385e-01,  9.4658539e-02,  8.0002174e+00,\n",
            "       -8.7586660e+00,  1.3866016e+00], dtype=float32), 'agent_1': Array([ 6.3690358e-01,  9.9918425e-01, -1.1578243e-04,  1.6209092e-02,\n",
            "        3.6990181e-02,  3.1845355e-01,  2.4427424e-01, -1.2466565e+00,\n",
            "        3.3961737e-01,  1.6854145e-01, -6.6706538e-01, -4.0967464e-01,\n",
            "        1.3686061e+00,  3.7057385e-01,  9.4658539e-02,  8.0002174e+00,\n",
            "       -8.6035795e+00,  2.6234534e-01], dtype=float32), 'agent_2': Array([ 6.3690358e-01,  9.9918425e-01, -1.1578243e-04,  1.6209092e-02,\n",
            "        3.6990181e-02,  3.1845355e-01,  2.4427424e-01,  3.3961737e-01,\n",
            "       -1.2555966e+00,  1.6854145e-01, -6.6706538e-01, -4.0967464e-01,\n",
            "        1.3686061e+00,  3.7057385e-01,  9.4658539e-02,  8.0002174e+00,\n",
            "       -1.0021944e+01,  4.5660099e-01], dtype=float32), 'agent_3': Array([ 6.3690358e-01,  9.9918425e-01, -1.1578243e-04,  1.6209092e-02,\n",
            "        3.6990181e-02,  3.1845355e-01,  2.4427424e-01,  3.3961737e-01,\n",
            "        1.6854145e-01,  4.9301878e-01, -6.6706538e-01, -4.0967464e-01,\n",
            "        1.3686061e+00,  3.7057385e-01,  9.4658539e-02,  8.0002174e+00,\n",
            "       -8.1494598e+00,  3.2627475e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.74606216 -1.3684915   0.74743897 -1.3670616   0.7478137  -1.3701003\n",
            "  0.7457563  -1.3694934 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.43484247, dtype=float32), 'agent_0': Array(-0.43484247, dtype=float32), 'agent_1': Array(-0.43484247, dtype=float32), 'agent_2': Array(-0.43484247, dtype=float32), 'agent_3': Array(-0.43484247, dtype=float32)}\n",
            "step: 22\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.8735814e-01,  9.9899006e-01, -4.3379115e-03,  3.5307098e-02,\n",
            "       -2.7450541e-02,  5.4249674e-01,  4.9987531e-01,  4.6720067e-01,\n",
            "        5.0086153e-01,  4.0975010e-01, -7.0233345e-01, -5.1151514e-01,\n",
            "        5.5972338e-01, -1.4694867e-01,  1.7354295e-01, -6.0804229e+00,\n",
            "        8.4450760e+00,  9.9919653e-01], dtype=float32), 'agent_1': Array([ 6.8735814e-01,  9.9899006e-01, -4.3379115e-03,  3.5307098e-02,\n",
            "       -2.7450541e-02,  5.4249674e-01,  4.6720067e-01, -1.2673568e+00,\n",
            "        5.0086153e-01,  4.0975010e-01, -7.0233345e-01, -5.1151514e-01,\n",
            "        5.5972338e-01, -1.4694867e-01,  1.7354295e-01, -6.0804229e+00,\n",
            "        8.9788504e+00,  1.0155433e+00], dtype=float32), 'agent_2': Array([ 6.8735814e-01,  9.9899006e-01, -4.3379115e-03,  3.5307098e-02,\n",
            "       -2.7450541e-02,  5.4249674e-01,  4.6720067e-01,  5.0086153e-01,\n",
            "       -1.2742925e+00,  4.0975010e-01, -7.0233345e-01, -5.1151514e-01,\n",
            "        5.5972338e-01, -1.4694867e-01,  1.7354295e-01, -6.0804229e+00,\n",
            "        7.9895029e+00,  7.7156579e-01], dtype=float32), 'agent_3': Array([ 6.8735814e-01,  9.9899006e-01, -4.3379115e-03,  3.5307098e-02,\n",
            "       -2.7450541e-02,  5.4249674e-01,  4.6720067e-01,  5.0086153e-01,\n",
            "        4.0975010e-01,  4.9080455e-01, -7.0233345e-01, -5.1151514e-01,\n",
            "        5.5972338e-01, -1.4694867e-01,  1.7354295e-01, -6.0804229e+00,\n",
            "        9.3928347e+00,  9.9352652e-01], dtype=float32)}\n",
            "ctrl action chosen: [0.0912247  0.40310836 0.09317928 0.40339142 0.09400488 0.4014821\n",
            " 0.09066911 0.40256542]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.643203, dtype=float32), 'agent_0': Array(-4.643203, dtype=float32), 'agent_1': Array(-4.643203, dtype=float32), 'agent_2': Array(-4.643203, dtype=float32), 'agent_3': Array(-4.643203, dtype=float32)}\n",
            "step: 23\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6979477 ,  0.9995851 ,  0.00925049,  0.01515879, -0.02268003,\n",
            "        0.5327696 ,  0.7725906 ,  0.54031605,  0.52811885,  0.52875054,\n",
            "       -0.6688297 , -0.35632253,  0.05427599,  0.81063366, -1.0760224 ,\n",
            "        1.4525323 , -1.8612045 ,  6.5925093 ], dtype=float32), 'agent_1': Array([ 0.6979477 ,  0.9995851 ,  0.00925049,  0.01515879, -0.02268003,\n",
            "        0.5327696 ,  0.54031605, -1.0312595 ,  0.52811885,  0.52875054,\n",
            "       -0.6688297 , -0.35632253,  0.05427599,  0.81063366, -1.0760224 ,\n",
            "        1.4525323 , -0.6268562 ,  6.05029   ], dtype=float32), 'agent_2': Array([ 0.6979477 ,  0.9995851 ,  0.00925049,  0.01515879, -0.02268003,\n",
            "        0.5327696 ,  0.54031605,  0.52811885, -1.0583385 ,  0.52875054,\n",
            "       -0.6688297 , -0.35632253,  0.05427599,  0.81063366, -1.0760224 ,\n",
            "        1.4525323 , -0.821013  ,  5.811845  ], dtype=float32), 'agent_3': Array([ 0.6979477 ,  0.9995851 ,  0.00925049,  0.01515879, -0.02268003,\n",
            "        0.5327696 ,  0.54031605,  0.52811885,  0.52875054,  0.7368304 ,\n",
            "       -0.6688297 , -0.35632253,  0.05427599,  0.81063366, -1.0760224 ,\n",
            "        1.4525323 ,  0.6341357 ,  5.9877863 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3034752   0.08719379 -0.30363014  0.08921577 -0.3021771   0.08422581\n",
            " -0.3033608   0.08765015]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.01972973, dtype=float32), 'agent_0': Array(-0.01972973, dtype=float32), 'agent_1': Array(-0.01972973, dtype=float32), 'agent_2': Array(-0.01972973, dtype=float32), 'agent_3': Array(-0.01972973, dtype=float32)}\n",
            "step: 24\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.8731618e-01,  9.9491090e-01,  2.4804248e-02, -3.6150177e-03,\n",
            "        9.7590752e-02,  2.2299017e-01,  1.0021378e+00,  3.0942467e-01,\n",
            "        2.7734143e-01,  3.6676931e-01, -7.6110363e-01, -3.8897395e-01,\n",
            "       -5.0603151e-01,  4.5461935e-01, -4.0982741e-01,  5.6547065e+00,\n",
            "       -7.0222182e+00,  3.7811320e+00], dtype=float32), 'agent_1': Array([ 6.8731618e-01,  9.9491090e-01,  2.4804248e-02, -3.6150177e-03,\n",
            "        9.7590752e-02,  2.2299017e-01,  3.0942467e-01, -8.1160128e-01,\n",
            "        2.7734143e-01,  3.6676931e-01, -7.6110363e-01, -3.8897395e-01,\n",
            "       -5.0603151e-01,  4.5461935e-01, -4.0982741e-01,  5.6547065e+00,\n",
            "       -5.8037891e+00,  3.3323171e+00], dtype=float32), 'agent_2': Array([ 6.8731618e-01,  9.9491090e-01,  2.4804248e-02, -3.6150177e-03,\n",
            "        9.7590752e-02,  2.2299017e-01,  3.0942467e-01,  2.7734143e-01,\n",
            "       -8.1829995e-01,  3.6676931e-01, -7.6110363e-01, -3.8897395e-01,\n",
            "       -5.0603151e-01,  4.5461935e-01, -4.0982741e-01,  5.6547065e+00,\n",
            "       -5.9597259e+00,  3.9406226e+00], dtype=float32), 'agent_3': Array([ 6.8731618e-01,  9.9491090e-01,  2.4804248e-02, -3.6150177e-03,\n",
            "        9.7590752e-02,  2.2299017e-01,  3.0942467e-01,  2.7734143e-01,\n",
            "        3.6676931e-01,  9.4445676e-01, -7.6110363e-01, -3.8897395e-01,\n",
            "       -5.0603151e-01,  4.5461935e-01, -4.0982741e-01,  5.6547065e+00,\n",
            "       -4.2916293e+00,  3.4679179e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.9526645  -0.15501599 -0.9530575  -0.15379094 -0.9503576  -0.15505935\n",
            " -0.9515442  -0.1538472 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.08435756, dtype=float32), 'agent_0': Array(0.08435756, dtype=float32), 'agent_1': Array(0.08435756, dtype=float32), 'agent_2': Array(0.08435756, dtype=float32), 'agent_3': Array(0.08435756, dtype=float32)}\n",
            "step: 25\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.4694953e-01,  9.2476952e-01,  2.7148359e-02, -7.1390644e-03,\n",
            "        3.7949082e-01, -4.9519673e-01,  1.0806029e+00, -3.5480729e-01,\n",
            "       -3.9258566e-01, -2.3675369e-01, -8.0702305e-01, -4.5412183e-01,\n",
            "       -1.0082483e+00,  1.9083683e-01,  3.8002163e-01,  1.3726900e+01,\n",
            "       -1.6977591e+01,  2.8623638e-01], dtype=float32), 'agent_1': Array([ 6.4694953e-01,  9.2476952e-01,  2.7148359e-02, -7.1390644e-03,\n",
            "        3.7949082e-01, -4.9519673e-01, -3.5480729e-01, -7.3464435e-01,\n",
            "       -3.9258566e-01, -2.3675369e-01, -8.0702305e-01, -4.5412183e-01,\n",
            "       -1.0082483e+00,  1.9083683e-01,  3.8002163e-01,  1.3726900e+01,\n",
            "       -1.5970856e+01,  9.9102610e-01], dtype=float32), 'agent_2': Array([ 6.4694953e-01,  9.2476952e-01,  2.7148359e-02, -7.1390644e-03,\n",
            "        3.7949082e-01, -4.9519673e-01, -3.5480729e-01, -3.9258566e-01,\n",
            "       -7.3586082e-01, -2.3675369e-01, -8.0702305e-01, -4.5412183e-01,\n",
            "       -1.0082483e+00,  1.9083683e-01,  3.8002163e-01,  1.3726900e+01,\n",
            "       -1.6044058e+01,  6.5525573e-01], dtype=float32), 'agent_3': Array([ 6.4694953e-01,  9.2476952e-01,  2.7148359e-02, -7.1390644e-03,\n",
            "        3.7949082e-01, -4.9519673e-01, -3.5480729e-01, -3.9258566e-01,\n",
            "       -2.3675369e-01,  1.0272770e+00, -8.0702305e-01, -4.5412183e-01,\n",
            "       -1.0082483e+00,  1.9083683e-01,  3.8002163e-01,  1.3726900e+01,\n",
            "       -1.4822223e+01,  6.6696221e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 1.3897204 -2.5551136  1.3886454 -2.5542018  1.38874   -2.5549195\n",
            "  1.3888026 -2.5557883]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6561015, dtype=float32), 'agent_0': Array(-1.6561015, dtype=float32), 'agent_1': Array(-1.6561015, dtype=float32), 'agent_2': Array(-1.6561015, dtype=float32), 'agent_3': Array(-1.6561015, dtype=float32)}\n",
            "step: 26\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58624923,  0.95174205,  0.02301083,  0.05846058,  0.3003998 ,\n",
            "       -0.284632  ,  0.79142827, -0.10584   , -0.14793012,  0.07201488,\n",
            "       -1.1692643 , -0.67347884, -1.4030933 ,  0.8854079 ,  3.6601465 ,\n",
            "       -8.524524  , 11.057015  , -8.763201  ], dtype=float32), 'agent_1': Array([ 0.58624923,  0.95174205,  0.02301083,  0.05846058,  0.3003998 ,\n",
            "       -0.284632  , -0.10584   , -1.0092827 , -0.14793012,  0.07201488,\n",
            "       -1.1692643 , -0.67347884, -1.4030933 ,  0.8854079 ,  3.6601465 ,\n",
            "       -8.524524  , 11.616178  , -9.337407  ], dtype=float32), 'agent_2': Array([ 0.58624923,  0.95174205,  0.02301083,  0.05846058,  0.3003998 ,\n",
            "       -0.284632  , -0.10584   , -0.14793012, -1.0162143 ,  0.07201488,\n",
            "       -1.1692643 , -0.67347884, -1.4030933 ,  0.8854079 ,  3.6601465 ,\n",
            "       -8.524524  , 11.681305  , -8.869986  ], dtype=float32), 'agent_3': Array([ 0.58624923,  0.95174205,  0.02301083,  0.05846058,  0.3003998 ,\n",
            "       -0.284632  , -0.10584   , -0.14793012,  0.07201488,  0.72991055,\n",
            "       -1.1692643 , -0.67347884, -1.4030933 ,  0.8854079 ,  3.6601465 ,\n",
            "       -8.524524  , 12.9587965 , -9.578271  ], dtype=float32)}\n",
            "ctrl action chosen: [0.5713392  1.4868429  0.57200474 1.4869837  0.5727008  1.4866233\n",
            " 0.5717864  1.4870249 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-16.946772, dtype=float32), 'agent_0': Array(-16.946772, dtype=float32), 'agent_1': Array(-16.946772, dtype=float32), 'agent_2': Array(-16.946772, dtype=float32), 'agent_3': Array(-16.946772, dtype=float32)}\n",
            "step: 27\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5233016 ,  0.99197936,  0.01285913,  0.06084884,  0.11004149,\n",
            "        0.2514452 ,  0.8508325 ,  0.43855277,  0.42205894,  0.6346333 ,\n",
            "       -0.32788515,  0.14733076, -0.9950876 ,  0.30571705, -1.463936  ,\n",
            "       -3.6919215 ,  6.5083275 ,  4.8478594 ], dtype=float32), 'agent_1': Array([ 0.5233016 ,  0.99197936,  0.01285913,  0.06084884,  0.11004149,\n",
            "        0.2514452 ,  0.43855277, -0.9628495 ,  0.42205894,  0.6346333 ,\n",
            "       -0.32788515,  0.14733076, -0.9950876 ,  0.30571705, -1.463936  ,\n",
            "       -3.6919215 ,  7.2076225 ,  5.7428575 ], dtype=float32), 'agent_2': Array([ 0.5233016 ,  0.99197936,  0.01285913,  0.06084884,  0.11004149,\n",
            "        0.2514452 ,  0.43855277,  0.42205894, -0.9593787 ,  0.6346333 ,\n",
            "       -0.32788515,  0.14733076, -0.9950876 ,  0.30571705, -1.463936  ,\n",
            "       -3.6919215 ,  7.055281  ,  4.7721057 ], dtype=float32), 'agent_3': Array([ 0.5233016 ,  0.99197936,  0.01285913,  0.06084884,  0.11004149,\n",
            "        0.2514452 ,  0.43855277,  0.42205894,  0.6346333 ,  0.7078276 ,\n",
            "       -0.32788515,  0.14733076, -0.9950876 ,  0.30571705, -1.463936  ,\n",
            "       -3.6919215 ,  3.3349748 ,  2.7467945 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2267028  -0.19072312 -1.2264186  -0.19038431 -1.2247754  -0.19361635\n",
            " -1.2261173  -0.19079028]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.7876854, dtype=float32), 'agent_0': Array(-4.7876854, dtype=float32), 'agent_1': Array(-4.7876854, dtype=float32), 'agent_2': Array(-4.7876854, dtype=float32), 'agent_3': Array(-4.7876854, dtype=float32)}\n",
            "step: 28\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.0362098e-01,  9.4256437e-01,  1.5780751e-02,  6.0801733e-02,\n",
            "        3.2806471e-01, -2.0998906e-01,  8.1992120e-01,  8.4966114e-03,\n",
            "       -3.3963908e-02,  7.3097549e-02, -6.2245131e-01,  5.3691864e-02,\n",
            "        1.8671751e-01, -7.3803931e-02,  1.9327533e-01,  1.2383715e+01,\n",
            "       -1.4234993e+01, -2.0662253e+00], dtype=float32), 'agent_1': Array([ 5.0362098e-01,  9.4256437e-01,  1.5780751e-02,  6.0801733e-02,\n",
            "        3.2806471e-01, -2.0998906e-01,  8.4966114e-03, -9.2946810e-01,\n",
            "       -3.3963908e-02,  7.3097549e-02, -6.2245131e-01,  5.3691864e-02,\n",
            "        1.8671751e-01, -7.3803931e-02,  1.9327533e-01,  1.2383715e+01,\n",
            "       -1.3270076e+01, -6.8780273e-01], dtype=float32), 'agent_2': Array([ 5.0362098e-01,  9.4256437e-01,  1.5780751e-02,  6.0801733e-02,\n",
            "        3.2806471e-01, -2.0998906e-01,  8.4966114e-03, -3.3963908e-02,\n",
            "       -9.3894649e-01,  7.3097549e-02, -6.2245131e-01,  5.3691864e-02,\n",
            "        1.8671751e-01, -7.3803931e-02,  1.9327533e-01,  1.2383715e+01,\n",
            "       -1.4033073e+01,  3.6608076e-01], dtype=float32), 'agent_3': Array([ 5.0362098e-01,  9.4256437e-01,  1.5780751e-02,  6.0801733e-02,\n",
            "        3.2806471e-01, -2.0998906e-01,  8.4966114e-03, -3.3963908e-02,\n",
            "        7.3097549e-02,  5.8036196e-01, -6.2245131e-01,  5.3691864e-02,\n",
            "        1.8671751e-01, -7.3803931e-02,  1.9327533e-01,  1.2383715e+01,\n",
            "       -1.7065817e+01, -3.4724340e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.623963    0.8964045  -1.62366     0.89718515 -1.6222596   0.8959122\n",
            " -1.6238183   0.8981154 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.5768094, dtype=float32), 'agent_0': Array(-2.5768094, dtype=float32), 'agent_1': Array(-2.5768094, dtype=float32), 'agent_2': Array(-2.5768094, dtype=float32), 'agent_3': Array(-2.5768094, dtype=float32)}\n",
            "step: 29\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5191418 ,  0.852336  ,  0.02084739, -0.01903244,  0.5222322 ,\n",
            "       -0.6224632 ,  1.0458907 , -0.52496064, -0.5479214 , -0.58085746,\n",
            "        0.49420595, -0.37361383, -0.01459122, -2.7159944 , -3.2067654 ,\n",
            "       -0.15915059,  3.8878253 ,  7.7014813 ], dtype=float32), 'agent_1': Array([ 0.5191418 ,  0.852336  ,  0.02084739, -0.01903244,  0.5222322 ,\n",
            "       -0.6224632 , -0.52496064, -0.5720658 , -0.5479214 , -0.58085746,\n",
            "        0.49420595, -0.37361383, -0.01459122, -2.7159944 , -3.2067654 ,\n",
            "       -0.15915059, -1.5275484 , 10.943423  ], dtype=float32), 'agent_2': Array([ 0.5191418 ,  0.852336  ,  0.02084739, -0.01903244,  0.5222322 ,\n",
            "       -0.6224632 , -0.52496064, -0.5479214 , -0.54123753, -0.58085746,\n",
            "        0.49420595, -0.37361383, -0.01459122, -2.7159944 , -3.2067654 ,\n",
            "       -0.15915059, -0.17225307, 10.253302  ], dtype=float32), 'agent_3': Array([ 0.5191418 ,  0.852336  ,  0.02084739, -0.01903244,  0.5222322 ,\n",
            "       -0.6224632 , -0.52496064, -0.5479214 , -0.58085746,  0.8037888 ,\n",
            "        0.49420595, -0.37361383, -0.01459122, -2.7159944 , -3.2067654 ,\n",
            "       -0.15915059, -1.5353091 ,  8.266806  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8396486 -1.361888   0.8356108 -1.3623112  0.835776  -1.3624103\n",
            "  0.836102  -1.3615581]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.8744955, dtype=float32), 'agent_0': Array(-5.8744955, dtype=float32), 'agent_1': Array(-5.8744955, dtype=float32), 'agent_2': Array(-5.8744955, dtype=float32), 'agent_3': Array(-5.8744955, dtype=float32)}\n",
            "step: 30\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.16962230e-01,  9.31194425e-01,  6.62919879e-03, -2.53475066e-02,\n",
            "        3.63580316e-01,  4.41964762e-03,  8.98188710e-01, -1.26360744e-01,\n",
            "       -1.13603182e-01, -2.38144398e-01, -1.49536133e-01, -6.38109446e-01,\n",
            "       -6.73532486e-02, -5.89051306e-01,  1.17567635e+00, -1.12438755e+01,\n",
            "        1.86030369e+01, -6.72709370e+00], dtype=float32), 'agent_1': Array([ 5.16962230e-01,  9.31194425e-01,  6.62919879e-03, -2.53475066e-02,\n",
            "        3.63580316e-01,  4.41964762e-03, -1.26360744e-01, -6.14097178e-01,\n",
            "       -1.13603182e-01, -2.38144398e-01, -1.49536133e-01, -6.38109446e-01,\n",
            "       -6.73532486e-02, -5.89051306e-01,  1.17567635e+00, -1.12438755e+01,\n",
            "        1.26297159e+01, -5.38318253e+00], dtype=float32), 'agent_2': Array([ 5.16962230e-01,  9.31194425e-01,  6.62919879e-03, -2.53475066e-02,\n",
            "        3.63580316e-01,  4.41964762e-03, -1.26360744e-01, -1.13603182e-01,\n",
            "       -6.58134103e-01, -2.38144398e-01, -1.49536133e-01, -6.38109446e-01,\n",
            "       -6.73532486e-02, -5.89051306e-01,  1.17567635e+00, -1.12438755e+01,\n",
            "        1.35323982e+01, -5.75470972e+00], dtype=float32), 'agent_3': Array([ 5.16962230e-01,  9.31194425e-01,  6.62919879e-03, -2.53475066e-02,\n",
            "        3.63580316e-01,  4.41964762e-03, -1.26360744e-01, -1.13603182e-01,\n",
            "       -2.38144398e-01,  7.25538194e-01, -1.49536133e-01, -6.38109446e-01,\n",
            "       -6.73532486e-02, -5.89051306e-01,  1.17567635e+00, -1.12438755e+01,\n",
            "        1.24652023e+01, -5.97517538e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.48659217  1.1563451  -0.49045578  1.1581672  -0.48940766  1.1576397\n",
            " -0.49046478  1.157064  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.099804, dtype=float32), 'agent_0': Array(-4.099804, dtype=float32), 'agent_1': Array(-4.099804, dtype=float32), 'agent_2': Array(-4.099804, dtype=float32), 'agent_3': Array(-4.099804, dtype=float32)}\n",
            "step: 31\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49929443,  0.92755955,  0.01100044, -0.08159543,  0.3644923 ,\n",
            "        0.1774941 ,  1.0651215 , -0.174141  , -0.11167456, -0.29065332,\n",
            "        0.23789406, -0.36790967, -0.68641305, -0.3234172 , -2.7028234 ,\n",
            "        4.1132402 , -2.0619829 ,  6.351903  ], dtype=float32), 'agent_1': Array([ 0.49929443,  0.92755955,  0.01100044, -0.08159543,  0.3644923 ,\n",
            "        0.1774941 , -0.174141  , -0.4770164 , -0.11167456, -0.29065332,\n",
            "        0.23789406, -0.36790967, -0.68641305, -0.3234172 , -2.7028234 ,\n",
            "        4.1132402 , -5.674108  ,  1.6549845 ], dtype=float32), 'agent_2': Array([ 0.49929443,  0.92755955,  0.01100044, -0.08159543,  0.3644923 ,\n",
            "        0.1774941 , -0.174141  , -0.11167456, -0.47418165, -0.29065332,\n",
            "        0.23789406, -0.36790967, -0.68641305, -0.3234172 , -2.7028234 ,\n",
            "        4.1132402 , -5.314658  ,  3.5079722 ], dtype=float32), 'agent_3': Array([ 0.49929443,  0.92755955,  0.01100044, -0.08159543,  0.3644923 ,\n",
            "        0.1774941 , -0.174141  , -0.11167456, -0.29065332,  0.9001201 ,\n",
            "        0.23789406, -0.36790967, -0.68641305, -0.3234172 , -2.7028234 ,\n",
            "        4.1132402 , -5.7914166 ,  6.1306624 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.07140324 -1.3759466  -0.07836251 -1.3817743  -0.07636962 -1.3797013\n",
            " -0.07436369 -1.378322  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0177794, dtype=float32), 'agent_0': Array(-2.0177794, dtype=float32), 'agent_1': Array(-2.0177794, dtype=float32), 'agent_2': Array(-2.0177794, dtype=float32), 'agent_3': Array(-2.0177794, dtype=float32)}\n",
            "step: 32\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.9656323e-01,  9.0142161e-01, -1.2434119e-03, -6.0581725e-02,\n",
            "        4.2868114e-01,  1.3269396e-01,  8.6488515e-01, -3.8158447e-01,\n",
            "       -2.9477078e-01, -5.1016450e-01, -3.8363934e-01, -8.7809563e-01,\n",
            "        2.7232766e-01,  2.8828719e-01,  1.2486526e+00,  2.2831235e+00,\n",
            "       -1.1556780e+00, -6.4027147e+00], dtype=float32), 'agent_1': Array([ 4.9656323e-01,  9.0142161e-01, -1.2434119e-03, -6.0581725e-02,\n",
            "        4.2868114e-01,  1.3269396e-01, -3.8158447e-01, -6.8161476e-01,\n",
            "       -2.9477078e-01, -5.1016450e-01, -3.8363934e-01, -8.7809563e-01,\n",
            "        2.7232766e-01,  2.8828719e-01,  1.2486526e+00,  2.2831235e+00,\n",
            "       -3.2135139e+00, -5.4777699e+00], dtype=float32), 'agent_2': Array([ 4.9656323e-01,  9.0142161e-01, -1.2434119e-03, -6.0581725e-02,\n",
            "        4.2868114e-01,  1.3269396e-01, -3.8158447e-01, -2.9477078e-01,\n",
            "       -7.5190455e-01, -5.1016450e-01, -3.8363934e-01, -8.7809563e-01,\n",
            "        2.7232766e-01,  2.8828719e-01,  1.2486526e+00,  2.2831235e+00,\n",
            "       -2.9778910e+00, -7.9392166e+00], dtype=float32), 'agent_3': Array([ 4.9656323e-01,  9.0142161e-01, -1.2434119e-03, -6.0581725e-02,\n",
            "        4.2868114e-01,  1.3269396e-01, -3.8158447e-01, -2.9477078e-01,\n",
            "       -5.1016450e-01,  6.7699289e-01, -3.8363934e-01, -8.7809563e-01,\n",
            "        2.7232766e-01,  2.8828719e-01,  1.2486526e+00,  2.2831235e+00,\n",
            "       -3.3283911e+00, -7.1332827e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.18319911 -1.426366    0.18125041 -1.4253974   0.1825089  -1.4280812\n",
            "  0.18219472 -1.4277782 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.1516252, dtype=float32), 'agent_0': Array(-3.1516252, dtype=float32), 'agent_1': Array(-3.1516252, dtype=float32), 'agent_2': Array(-3.1516252, dtype=float32), 'agent_3': Array(-3.1516252, dtype=float32)}\n",
            "step: 33\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5247405 ,  0.91816527, -0.0159034 , -0.02507844,  0.3950831 ,\n",
            "        0.27292246,  0.48110783, -0.34445474, -0.20785575, -0.43978825,\n",
            "       -0.7046461 , -1.2584329 ,  1.2702823 , -0.743558  ,  2.3137925 ,\n",
            "       -2.5274897 ,  4.2775955 , -8.477614  ], dtype=float32), 'agent_1': Array([ 0.5247405 ,  0.91816527, -0.0159034 , -0.02507844,  0.3950831 ,\n",
            "        0.27292246, -0.34445474, -0.95621943, -0.20785575, -0.43978825,\n",
            "       -0.7046461 , -1.2584329 ,  1.2702823 , -0.743558  ,  2.3137925 ,\n",
            "       -2.5274897 ,  1.3461782 , -4.5997086 ], dtype=float32), 'agent_2': Array([ 0.5247405 ,  0.91816527, -0.0159034 , -0.02507844,  0.3950831 ,\n",
            "        0.27292246, -0.34445474, -0.20785575, -1.1098858 , -0.43978825,\n",
            "       -0.7046461 , -1.2584329 ,  1.2702823 , -0.743558  ,  2.3137925 ,\n",
            "       -2.5274897 ,  3.858371  , -6.003776  ], dtype=float32), 'agent_3': Array([ 0.5247405 ,  0.91816527, -0.0159034 , -0.02507844,  0.3950831 ,\n",
            "        0.27292246, -0.34445474, -0.20785575, -0.43978825,  0.4594942 ,\n",
            "       -0.7046461 , -1.2584329 ,  1.2702823 , -0.743558  ,  2.3137925 ,\n",
            "       -2.5274897 ,  2.6562624 , -0.08866135], dtype=float32)}\n",
            "ctrl action chosen: [-0.7805476  2.2568092 -0.782088   2.2591786 -0.7812231  2.2561462\n",
            " -0.7795165  2.2636135]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.661382, dtype=float32), 'agent_0': Array(-3.661382, dtype=float32), 'agent_1': Array(-3.661382, dtype=float32), 'agent_2': Array(-3.661382, dtype=float32), 'agent_3': Array(-3.661382, dtype=float32)}\n",
            "step: 34\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6188437 ,  0.8859831 , -0.02427439, -0.02983694,  0.46211958,\n",
            "        0.10889817,  0.5636756 , -0.5922209 , -0.3695629 , -0.5797387 ,\n",
            "       -0.5946636 , -1.0220647 ,  1.9349933 , -0.27732792, -0.56847376,\n",
            "        1.1575696 , -2.6750093 ,  2.7060125 ], dtype=float32), 'agent_1': Array([ 0.6188437 ,  0.8859831 , -0.02427439, -0.02983694,  0.46211958,\n",
            "        0.10889817, -0.5922209 , -0.6933089 , -0.3695629 , -0.5797387 ,\n",
            "       -0.5946636 , -1.0220647 ,  1.9349933 , -0.27732792, -0.56847376,\n",
            "        1.1575696 , -0.92195415,  6.5159645 ], dtype=float32), 'agent_2': Array([ 0.6188437 ,  0.8859831 , -0.02427439, -0.02983694,  0.46211958,\n",
            "        0.10889817, -0.5922209 , -0.3695629 , -0.91374624, -0.5797387 ,\n",
            "       -0.5946636 , -1.0220647 ,  1.9349933 , -0.27732792, -0.56847376,\n",
            "        1.1575696 , -2.9179575 ,  6.6689396 ], dtype=float32), 'agent_3': Array([ 0.6188437 ,  0.8859831 , -0.02427439, -0.02983694,  0.46211958,\n",
            "        0.10889817, -0.5922209 , -0.3695629 , -0.5797387 ,  0.6342851 ,\n",
            "       -0.5946636 , -1.0220647 ,  1.9349933 , -0.27732792, -0.56847376,\n",
            "        1.1575696 ,  0.1317979 ,  4.6784744 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.94463086 -0.4484643  -0.9396581  -0.4475189  -0.94058305 -0.44851166\n",
            " -0.93743473 -0.44833413]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-11.003098, dtype=float32), 'agent_0': Array(-11.003098, dtype=float32), 'agent_1': Array(-11.003098, dtype=float32), 'agent_2': Array(-11.003098, dtype=float32), 'agent_3': Array(-11.003098, dtype=float32)}\n",
            "step: 35\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6837135 ,  0.86992544, -0.03224083,  0.00641856,  0.49208647,\n",
            "       -0.10882867,  0.5141581 , -0.55964607, -0.5737111 , -0.5374034 ,\n",
            "       -0.8916378 , -1.1070371 ,  0.8633852 ,  0.6739409 ,  1.619918  ,\n",
            "        0.7054108 , -5.179137  ,  0.10996168], dtype=float32), 'agent_1': Array([ 0.6837135 ,  0.86992544, -0.03224083,  0.00641856,  0.49208647,\n",
            "       -0.10882867, -0.55964607, -0.75918925, -0.5737111 , -0.5374034 ,\n",
            "       -0.8916378 , -1.1070371 ,  0.8633852 ,  0.6739409 ,  1.619918  ,\n",
            "        0.7054108 ,  2.3795922 , -2.1320703 ], dtype=float32), 'agent_2': Array([ 0.6837135 ,  0.86992544, -0.03224083,  0.00641856,  0.49208647,\n",
            "       -0.10882867, -0.55964607, -0.5737111 , -0.98044676, -0.5374034 ,\n",
            "       -0.8916378 , -1.1070371 ,  0.8633852 ,  0.6739409 ,  1.619918  ,\n",
            "        0.7054108 , -2.451015  , -2.6463692 ], dtype=float32), 'agent_3': Array([ 0.6837135 ,  0.86992544, -0.03224083,  0.00641856,  0.49208647,\n",
            "       -0.10882867, -0.55964607, -0.5737111 , -0.5374034 ,  0.6554105 ,\n",
            "       -0.8916378 , -1.1070371 ,  0.8633852 ,  0.6739409 ,  1.619918  ,\n",
            "        0.7054108 ,  1.9426068 , -0.2242769 ], dtype=float32)}\n",
            "ctrl action chosen: [ 2.1457393  -0.1492453   2.149946   -0.15870695  2.1493292  -0.15627979\n",
            "  2.1502614  -0.15492654]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.9343736, dtype=float32), 'agent_0': Array(-1.9343736, dtype=float32), 'agent_1': Array(-1.9343736, dtype=float32), 'agent_2': Array(-1.9343736, dtype=float32), 'agent_3': Array(-1.9343736, dtype=float32)}\n",
            "step: 36\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.2160274e-01,  9.6302623e-01, -3.6957633e-02,  2.1719020e-02,\n",
            "        2.6597553e-01,  2.9723790e-01,  5.4246002e-01,  1.9621688e-01,\n",
            "       -9.0286098e-02,  2.0550498e-01, -7.0720911e-01, -8.4079504e-01,\n",
            "        6.0927868e-01,  7.5046748e-02,  8.8817489e-01, -1.2693375e+01,\n",
            "        1.1887296e+01,  1.1457366e-02], dtype=float32), 'agent_1': Array([  0.72160274,   0.9630262 ,  -0.03695763,   0.02171902,\n",
            "         0.26597553,   0.2972379 ,   0.19621688,  -0.7642832 ,\n",
            "        -0.0902861 ,   0.20550498,  -0.7072091 ,  -0.84079504,\n",
            "         0.6092787 ,   0.07504675,   0.8881749 , -12.693375  ,\n",
            "        18.933811  ,  -0.16702671], dtype=float32), 'agent_2': Array([  0.72160274,   0.9630262 ,  -0.03695763,   0.02171902,\n",
            "         0.26597553,   0.2972379 ,   0.19621688,  -0.0902861 ,\n",
            "        -0.98178995,   0.20550498,  -0.7072091 ,  -0.84079504,\n",
            "         0.6092787 ,   0.07504675,   0.8881749 , -12.693375  ,\n",
            "        14.016811  ,  -0.03681903], dtype=float32), 'agent_3': Array([  0.72160274,   0.9630262 ,  -0.03695763,   0.02171902,\n",
            "         0.26597553,   0.2972379 ,   0.19621688,  -0.0902861 ,\n",
            "         0.20550498,   0.6603214 ,  -0.7072091 ,  -0.84079504,\n",
            "         0.6092787 ,   0.07504675,   0.8881749 , -12.693375  ,\n",
            "        18.508936  ,  -0.50203747], dtype=float32)}\n",
            "ctrl action chosen: [-0.00712232 -0.6971073  -0.00959399 -0.6972394  -0.00742747 -0.6968849\n",
            " -0.01032573 -0.69742984]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.041543, dtype=float32), 'agent_0': Array(-9.041543, dtype=float32), 'agent_1': Array(-9.041543, dtype=float32), 'agent_2': Array(-9.041543, dtype=float32), 'agent_3': Array(-9.041543, dtype=float32)}\n",
            "step: 37\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7314147 ,  0.98133576, -0.06334579,  0.07305095,  0.16622634,\n",
            "        0.41253197,  0.47116473,  0.5648769 ,  0.11011952,  0.55799025,\n",
            "       -1.060605  , -1.1547685 , -0.07548332, -0.57765913,  2.7233326 ,\n",
            "        1.2452033 , -3.2123642 , -0.28118327], dtype=float32), 'agent_1': Array([ 0.7314147 ,  0.98133576, -0.06334579,  0.07305095,  0.16622634,\n",
            "        0.41253197,  0.5648769 , -1.0383141 ,  0.11011952,  0.55799025,\n",
            "       -1.060605  , -1.1547685 , -0.07548332, -0.57765913,  2.7233326 ,\n",
            "        1.2452033 , -0.4858332 , -8.545269  ], dtype=float32), 'agent_2': Array([ 0.7314147 ,  0.98133576, -0.06334579,  0.07305095,  0.16622634,\n",
            "        0.41253197,  0.5648769 ,  0.11011952, -1.2484283 ,  0.55799025,\n",
            "       -1.060605  , -1.1547685 , -0.07548332, -0.57765913,  2.7233326 ,\n",
            "        1.2452033 , -1.609748  , -6.665652  ], dtype=float32), 'agent_3': Array([ 0.7314147 ,  0.98133576, -0.06334579,  0.07305095,  0.16622634,\n",
            "        0.41253197,  0.5648769 ,  0.11011952,  0.55799025,  0.4610794 ,\n",
            "       -1.060605  , -1.1547685 , -0.07548332, -0.57765913,  2.7233326 ,\n",
            "        1.2452033 , -0.78762156, -1.748453  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.6153682  -0.1763949   0.6229297  -0.18314163  0.6252739  -0.18631469\n",
            "  0.61673725 -0.17785436]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9100425, dtype=float32), 'agent_0': Array(-0.9100425, dtype=float32), 'agent_1': Array(-0.9100425, dtype=float32), 'agent_2': Array(-0.9100425, dtype=float32), 'agent_3': Array(-0.9100425, dtype=float32)}\n",
            "step: 38\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.73640525,  0.97888637, -0.06740096,  0.10044178,  0.16477299,\n",
            "        0.38059962,  0.5293053 ,  0.557636  ,  0.15904246,  0.55369973,\n",
            "       -0.6637335 , -0.82126856, -0.00668764, -0.24643464,  0.7748918 ,\n",
            "       -0.50497   ,  0.9881126 ,  1.1017027 ], dtype=float32), 'agent_1': Array([ 0.73640525,  0.97888637, -0.06740096,  0.10044178,  0.16477299,\n",
            "        0.38059962,  0.557636  , -1.2541904 ,  0.15904246,  0.55369973,\n",
            "       -0.6637335 , -0.82126856, -0.00668764, -0.24643464,  0.7748918 ,\n",
            "       -0.50497   , -0.38449386, -0.1917691 ], dtype=float32), 'agent_2': Array([ 0.73640525,  0.97888637, -0.06740096,  0.10044178,  0.16477299,\n",
            "        0.38059962,  0.557636  ,  0.15904246, -1.2417035 ,  0.55369973,\n",
            "       -0.6637335 , -0.82126856, -0.00668764, -0.24643464,  0.7748918 ,\n",
            "       -0.50497   ,  2.3648636 ,  0.19396071], dtype=float32), 'agent_3': Array([ 0.73640525,  0.97888637, -0.06740096,  0.10044178,  0.16477299,\n",
            "        0.38059962,  0.557636  ,  0.15904246,  0.55369973,  0.51391464,\n",
            "       -0.6637335 , -0.82126856, -0.00668764, -0.24643464,  0.7748918 ,\n",
            "       -0.50497   , -0.13195258,  0.8557264 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.01924317 -0.4025809  -0.02160689 -0.40111783 -0.01277279 -0.40856147\n",
            " -0.02276625 -0.3996579 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6389043, dtype=float32), 'agent_0': Array(-0.6389043, dtype=float32), 'agent_1': Array(-0.6389043, dtype=float32), 'agent_2': Array(-0.6389043, dtype=float32), 'agent_3': Array(-0.6389043, dtype=float32)}\n",
            "step: 39\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.70304537,  0.97439986, -0.07712957,  0.12154994,  0.17268948,\n",
            "        0.38095054,  0.5387193 ,  0.4776376 ,  0.21944167,  0.4886863 ,\n",
            "       -0.7446408 , -0.93910694, -1.1607766 , -0.20585884,  0.90202934,\n",
            "        0.05184455,  0.49558115, -0.78877044], dtype=float32), 'agent_1': Array([ 0.70304537,  0.97439986, -0.07712957,  0.12154994,  0.17268948,\n",
            "        0.38095054,  0.4776376 , -1.256296  ,  0.21944167,  0.4886863 ,\n",
            "       -0.7446408 , -0.93910694, -1.1607766 , -0.20585884,  0.90202934,\n",
            "        0.05184455, -1.4839364 ,  0.7004681 ], dtype=float32), 'agent_2': Array([ 0.70304537,  0.97439986, -0.07712957,  0.12154994,  0.17268948,\n",
            "        0.38095054,  0.4776376 ,  0.21944167, -1.2288611 ,  0.4886863 ,\n",
            "       -0.7446408 , -0.93910694, -1.1607766 , -0.20585884,  0.90202934,\n",
            "        0.05184455,  1.5226111 ,  0.32106665], dtype=float32), 'agent_3': Array([ 0.70304537,  0.97439986, -0.07712957,  0.12154994,  0.17268948,\n",
            "        0.38095054,  0.4776376 ,  0.21944167,  0.4886863 ,  0.52857876,\n",
            "       -0.7446408 , -0.93910694, -1.1607766 , -0.20585884,  0.90202934,\n",
            "        0.05184455, -1.1169884 , -0.2977142 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.093537    0.24556077 -1.094265    0.25327903 -1.0864843   0.24410559\n",
            " -1.0957305   0.25002563]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.03385159, dtype=float32), 'agent_0': Array(-0.03385159, dtype=float32), 'agent_1': Array(-0.03385159, dtype=float32), 'agent_2': Array(-0.03385159, dtype=float32), 'agent_3': Array(-0.03385159, dtype=float32)}\n",
            "step: 40\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.633123  ,   0.9038882 ,  -0.04598337,   0.14130932,\n",
            "         0.40112752,  -0.18855445,   0.5914742 ,  -0.16938691,\n",
            "        -0.3045813 ,  -0.14241977,  -0.6292224 ,  -0.8064985 ,\n",
            "        -1.4746189 ,   0.03306789,   0.02232283,  12.629196  ,\n",
            "       -15.321169  ,   1.2264941 ], dtype=float32), 'agent_1': Array([  0.633123  ,   0.9038882 ,  -0.04598337,   0.14130932,\n",
            "         0.40112752,  -0.18855445,  -0.16938691,  -1.1114665 ,\n",
            "        -0.3045813 ,  -0.14241977,  -0.6292224 ,  -0.8064985 ,\n",
            "        -1.4746189 ,   0.03306789,   0.02232283,  12.629196  ,\n",
            "       -16.516645  ,   4.2936473 ], dtype=float32), 'agent_2': Array([  0.633123  ,   0.9038882 ,  -0.04598337,   0.14130932,\n",
            "         0.40112752,  -0.18855445,  -0.16938691,  -0.3045813 ,\n",
            "        -1.091258  ,  -0.14241977,  -0.6292224 ,  -0.8064985 ,\n",
            "        -1.4746189 ,   0.03306789,   0.02232283,  12.629196  ,\n",
            "       -14.4136505 ,   3.5963979 ], dtype=float32), 'agent_3': Array([  0.633123  ,   0.9038882 ,  -0.04598337,   0.14130932,\n",
            "         0.40112752,  -0.18855445,  -0.16938691,  -0.3045813 ,\n",
            "        -0.14241977,   0.6216598 ,  -0.6292224 ,  -0.8064985 ,\n",
            "        -1.4746189 ,   0.03306789,   0.02232283,  12.629196  ,\n",
            "       -16.351904  ,   1.8248894 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.27061024 -0.37888706  0.270468   -0.37550202  0.2719767  -0.37656572\n",
            "  0.27073386 -0.37885278]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.1798038, dtype=float32), 'agent_0': Array(-2.1798038, dtype=float32), 'agent_1': Array(-2.1798038, dtype=float32), 'agent_2': Array(-2.1798038, dtype=float32), 'agent_3': Array(-2.1798038, dtype=float32)}\n",
            "step: 41\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56205064,  0.87162554, -0.0419137 ,  0.17116176,  0.45740125,\n",
            "       -0.3473284 ,  0.48105305, -0.37942293, -0.425691  , -0.35142884,\n",
            "       -0.45784712, -0.61181784, -0.98353624,  0.34895498,  0.83220285,\n",
            "       -0.16498882,  0.66944677, -1.4716649 ], dtype=float32), 'agent_1': Array([ 0.56205064,  0.87162554, -0.0419137 ,  0.17116176,  0.45740125,\n",
            "       -0.3473284 , -0.37942293, -1.063515  , -0.425691  , -0.35142884,\n",
            "       -0.45784712, -0.61181784, -0.98353624,  0.34895498,  0.83220285,\n",
            "       -0.16498882, -0.36883533, -0.79479736], dtype=float32), 'agent_2': Array([ 0.56205064,  0.87162554, -0.0419137 ,  0.17116176,  0.45740125,\n",
            "       -0.3473284 , -0.37942293, -0.425691  , -1.1222693 , -0.35142884,\n",
            "       -0.45784712, -0.61181784, -0.98353624,  0.34895498,  0.83220285,\n",
            "       -0.16498882,  1.1893222 , -2.448876  ], dtype=float32), 'agent_3': Array([ 0.56205064,  0.87162554, -0.0419137 ,  0.17116176,  0.45740125,\n",
            "       -0.3473284 , -0.37942293, -0.425691  , -0.35142884,  0.49077618,\n",
            "       -0.45784712, -0.61181784, -0.98353624,  0.34895498,  0.83220285,\n",
            "       -0.16498882, -0.11650525, -2.9399433 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0688548  -0.21501032 -1.0713085  -0.21153986 -1.0690035  -0.21877706\n",
            " -1.0712087  -0.21554565]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.03192645, dtype=float32), 'agent_0': Array(-0.03192645, dtype=float32), 'agent_1': Array(-0.03192645, dtype=float32), 'agent_2': Array(-0.03192645, dtype=float32), 'agent_3': Array(-0.03192645, dtype=float32)}\n",
            "step: 42\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5357334 ,  0.8341805 , -0.02538074,  0.16218399,  0.52649325,\n",
            "       -0.5507359 ,  0.49295428, -0.5673295 , -0.54683214, -0.55080646,\n",
            "       -0.25810003, -0.03150702, -0.20854473, -0.13694438, -0.6417476 ,\n",
            "        0.23767595, -1.2413651 ,  0.04465497], dtype=float32), 'agent_1': Array([ 0.5357334 ,  0.8341805 , -0.02538074,  0.16218399,  0.52649325,\n",
            "       -0.5507359 , -0.5673295 , -1.0923316 , -0.54683214, -0.55080646,\n",
            "       -0.25810003, -0.03150702, -0.20854473, -0.13694438, -0.6417476 ,\n",
            "        0.23767595, -0.1212638 , -0.97314966], dtype=float32), 'agent_2': Array([ 0.5357334 ,  0.8341805 , -0.02538074,  0.16218399,  0.52649325,\n",
            "       -0.5507359 , -0.5673295 , -0.54683214, -1.1703668 , -0.55080646,\n",
            "       -0.25810003, -0.03150702, -0.20854473, -0.13694438, -0.6417476 ,\n",
            "        0.23767595,  0.3213883 , -0.7290434 ], dtype=float32), 'agent_3': Array([ 0.5357334 ,  0.8341805 , -0.02538074,  0.16218399,  0.52649325,\n",
            "       -0.5507359 , -0.5673295 , -0.54683214, -0.55080646,  0.48857588,\n",
            "       -0.25810003, -0.03150702, -0.20854473, -0.13694438, -0.6417476 ,\n",
            "        0.23767595, -0.89870477,  0.15982468], dtype=float32)}\n",
            "ctrl action chosen: [-0.6468181   0.17808563 -0.64659005  0.17426616 -0.6454164   0.17147624\n",
            " -0.64755744  0.17762284]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8022766, dtype=float32), 'agent_0': Array(-1.8022766, dtype=float32), 'agent_1': Array(-1.8022766, dtype=float32), 'agent_2': Array(-1.8022766, dtype=float32), 'agent_3': Array(-1.8022766, dtype=float32)}\n",
            "step: 43\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5386709 ,  0.8385731 , -0.01692186,  0.13028313,  0.52871096,\n",
            "       -0.5374926 ,  0.5509205 , -0.52992845, -0.5266833 , -0.55212355,\n",
            "       -0.05482435,  0.0721693 ,  0.07166862, -0.539906  , -1.5468261 ,\n",
            "        0.44711533,  0.7965442 ,  1.535163  ], dtype=float32), 'agent_1': Array([ 0.5386709 ,  0.8385731 , -0.01692186,  0.13028313,  0.52871096,\n",
            "       -0.5374926 , -0.52992845, -1.089456  , -0.5266833 , -0.55212355,\n",
            "       -0.05482435,  0.0721693 ,  0.07166862, -0.539906  , -1.5468261 ,\n",
            "        0.44711533,  0.41835418,  0.32821873], dtype=float32), 'agent_2': Array([ 0.5386709 ,  0.8385731 , -0.01692186,  0.13028313,  0.52871096,\n",
            "       -0.5374926 , -0.52992845, -0.5266833 , -1.1619279 , -0.55212355,\n",
            "       -0.05482435,  0.0721693 ,  0.07166862, -0.539906  , -1.5468261 ,\n",
            "        0.44711533, -0.3018095 ,  0.3270726 ], dtype=float32), 'agent_3': Array([ 0.5386709 ,  0.8385731 , -0.01692186,  0.13028313,  0.52871096,\n",
            "       -0.5374926 , -0.52992845, -0.5266833 , -0.55212355,  0.53529084,\n",
            "       -0.05482435,  0.0721693 ,  0.07166862, -0.539906  , -1.5468261 ,\n",
            "        0.44711533,  0.09671888,  0.93945825], dtype=float32)}\n",
            "ctrl action chosen: [-0.86310387  0.29715535 -0.8647668   0.29457128 -0.8649829   0.2917252\n",
            " -0.8642458   0.29597163]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.05325657, dtype=float32), 'agent_0': Array(0.05325657, dtype=float32), 'agent_1': Array(0.05325657, dtype=float32), 'agent_2': Array(0.05325657, dtype=float32), 'agent_3': Array(0.05325657, dtype=float32)}\n",
            "step: 44\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5324714 ,  0.83686364, -0.00791675,  0.07803249,  0.5417634 ,\n",
            "       -0.5322959 ,  0.68943465, -0.5440087 , -0.55457926, -0.5568776 ,\n",
            "       -0.00656843, -0.07756948, -0.2739668 , -1.0768608 , -2.2140892 ,\n",
            "        0.34485167, -0.24568011,  3.3385148 ], dtype=float32), 'agent_1': Array([ 0.5324714 ,  0.83686364, -0.00791675,  0.07803249,  0.5417634 ,\n",
            "       -0.5322959 , -0.5440087 , -0.9954763 , -0.55457926, -0.5568776 ,\n",
            "       -0.00656843, -0.07756948, -0.2739668 , -1.0768608 , -2.2140892 ,\n",
            "        0.34485167, -0.41347474,  3.0946152 ], dtype=float32), 'agent_2': Array([ 0.5324714 ,  0.83686364, -0.00791675,  0.07803249,  0.5417634 ,\n",
            "       -0.5322959 , -0.5440087 , -0.55457926, -1.0723407 , -0.5568776 ,\n",
            "       -0.00656843, -0.07756948, -0.2739668 , -1.0768608 , -2.2140892 ,\n",
            "        0.34485167, -0.2149227 ,  2.9813519 ], dtype=float32), 'agent_3': Array([ 0.5324714 ,  0.83686364, -0.00791675,  0.07803249,  0.5417634 ,\n",
            "       -0.5322959 , -0.5440087 , -0.55457926, -0.5568776 ,  0.64629894,\n",
            "       -0.00656843, -0.07756948, -0.2739668 , -1.0768608 , -2.2140892 ,\n",
            "        0.34485167,  0.18752979,  2.86688   ], dtype=float32)}\n",
            "ctrl action chosen: [0.23494186 1.3428715  0.23319858 1.3424977  0.2345271  1.3404021\n",
            " 0.23476891 1.3412071 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6780677, dtype=float32), 'agent_0': Array(-0.6780677, dtype=float32), 'agent_1': Array(-0.6780677, dtype=float32), 'agent_2': Array(-0.6780677, dtype=float32), 'agent_3': Array(-0.6780677, dtype=float32)}\n",
            "step: 45\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2008510e-01,  8.6772203e-01,  5.9796316e-03, -2.7164893e-02,\n",
            "        4.9627090e-01, -3.7426326e-01,  1.0679866e+00, -4.0638703e-01,\n",
            "       -4.0680110e-01, -3.9989519e-01,  1.7172098e-01,  2.4023056e-01,\n",
            "       -3.0105114e-01, -1.6744676e+00, -4.8841100e+00, -3.2427669e+00,\n",
            "        4.6410842e+00,  9.0162210e+00], dtype=float32), 'agent_1': Array([ 5.2008510e-01,  8.6772203e-01,  5.9796316e-03, -2.7164893e-02,\n",
            "        4.9627090e-01, -3.7426326e-01, -4.0638703e-01, -5.7286191e-01,\n",
            "       -4.0680110e-01, -3.9989519e-01,  1.7172098e-01,  2.4023056e-01,\n",
            "       -3.0105114e-01, -1.6744676e+00, -4.8841100e+00, -3.2427669e+00,\n",
            "        4.0986772e+00,  1.0973988e+01], dtype=float32), 'agent_2': Array([ 5.2008510e-01,  8.6772203e-01,  5.9796316e-03, -2.7164893e-02,\n",
            "        4.9627090e-01, -3.7426326e-01, -4.0638703e-01, -4.0680110e-01,\n",
            "       -6.5364450e-01, -3.9989519e-01,  1.7172098e-01,  2.4023056e-01,\n",
            "       -3.0105114e-01, -1.6744676e+00, -4.8841100e+00, -3.2427669e+00,\n",
            "        4.3398719e+00,  1.0951378e+01], dtype=float32), 'agent_3': Array([ 5.2008510e-01,  8.6772203e-01,  5.9796316e-03, -2.7164893e-02,\n",
            "        4.9627090e-01, -3.7426326e-01, -4.0638703e-01, -4.0680110e-01,\n",
            "       -3.9989519e-01,  1.0257246e+00,  1.7172098e-01,  2.4023056e-01,\n",
            "       -3.0105114e-01, -1.6744676e+00, -4.8841100e+00, -3.2427669e+00,\n",
            "        4.1485043e+00,  9.8127785e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.48595107 -0.44702628 -0.4883143  -0.4462543  -0.48779806 -0.44648385\n",
            " -0.48817977 -0.44816568]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.581348, dtype=float32), 'agent_0': Array(-2.581348, dtype=float32), 'agent_1': Array(-2.581348, dtype=float32), 'agent_2': Array(-2.581348, dtype=float32), 'agent_3': Array(-2.581348, dtype=float32)}\n",
            "step: 46\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49714985,  0.8319841 ,  0.0266095 , -0.08552873,  0.54752105,\n",
            "       -0.47426638,  1.147236  , -0.56049395, -0.5264852 , -0.5559479 ,\n",
            "       -0.34713745, -0.01969337, -0.3641069 , -0.3329779 , -1.5253549 ,\n",
            "        1.4148126 , -1.5855595 , -1.0557895 ], dtype=float32), 'agent_1': Array([ 0.49714985,  0.8319841 ,  0.0266095 , -0.08552873,  0.54752105,\n",
            "       -0.47426638, -0.56049395, -0.5237747 , -0.5264852 , -0.5559479 ,\n",
            "       -0.34713745, -0.01969337, -0.3641069 , -0.3329779 , -1.5253549 ,\n",
            "        1.4148126 , -1.1483305 , -0.757774  ], dtype=float32), 'agent_2': Array([ 0.49714985,  0.8319841 ,  0.0266095 , -0.08552873,  0.54752105,\n",
            "       -0.47426638, -0.56049395, -0.5264852 , -0.506704  , -0.5559479 ,\n",
            "       -0.34713745, -0.01969337, -0.3641069 , -0.3329779 , -1.5253549 ,\n",
            "        1.4148126 , -1.3796533 , -0.6243703 ], dtype=float32), 'agent_3': Array([ 0.49714985,  0.8319841 ,  0.0266095 , -0.08552873,  0.54752105,\n",
            "       -0.47426638, -0.56049395, -0.5264852 , -0.5559479 ,  1.1418278 ,\n",
            "       -0.34713745, -0.01969337, -0.3641069 , -0.3329779 , -1.5253549 ,\n",
            "        1.4148126 , -1.2436038 , -0.859035  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8924617  -0.5873957  -0.8942098  -0.589711   -0.8944833  -0.58924985\n",
            " -0.89234024 -0.58937484]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.05488497, dtype=float32), 'agent_0': Array(-0.05488497, dtype=float32), 'agent_1': Array(-0.05488497, dtype=float32), 'agent_2': Array(-0.05488497, dtype=float32), 'agent_3': Array(-0.05488497, dtype=float32)}\n",
            "step: 47\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4947771 ,  0.821981  ,  0.03505524, -0.11559015,  0.5565585 ,\n",
            "       -0.55412287,  0.99207324, -0.55568016, -0.5368307 , -0.54498965,\n",
            "       -0.60266256, -0.14145374,  0.8982718 ,  0.23484021, -0.09936024,\n",
            "       -0.10143038, -0.7441003 , -4.706292  ], dtype=float32), 'agent_1': Array([ 0.4947771 ,  0.821981  ,  0.03505524, -0.11559015,  0.5565585 ,\n",
            "       -0.55412287, -0.55568016, -0.61697006, -0.5368307 , -0.54498965,\n",
            "       -0.60266256, -0.14145374,  0.8982718 ,  0.23484021, -0.09936024,\n",
            "       -0.10143038,  0.61099344, -1.9141229 ], dtype=float32), 'agent_2': Array([ 0.4947771 ,  0.821981  ,  0.03505524, -0.11559015,  0.5565585 ,\n",
            "       -0.55412287, -0.55568016, -0.5368307 , -0.5519738 , -0.54498965,\n",
            "       -0.60266256, -0.14145374,  0.8982718 ,  0.23484021, -0.09936024,\n",
            "       -0.10143038,  0.78365785, -1.0824028 ], dtype=float32), 'agent_3': Array([ 0.4947771 ,  0.821981  ,  0.03505524, -0.11559015,  0.5565585 ,\n",
            "       -0.55412287, -0.55568016, -0.5368307 , -0.54498965,  1.0197036 ,\n",
            "       -0.60266256, -0.14145374,  0.8982718 ,  0.23484021, -0.09936024,\n",
            "       -0.10143038,  1.1723858 , -3.97162   ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.6515621  -0.5280919   0.65033036 -0.52760136  0.65060735 -0.5272564\n",
            "  0.65063757 -0.5256334 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7413163, dtype=float32), 'agent_0': Array(-1.7413163, dtype=float32), 'agent_1': Array(-1.7413163, dtype=float32), 'agent_2': Array(-1.7413163, dtype=float32), 'agent_3': Array(-1.7413163, dtype=float32)}\n",
            "step: 48\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5633433 ,  0.9053985 ,  0.05327149, -0.07866573,  0.41379648,\n",
            "       -0.1927526 ,  0.64207065, -0.1658626 , -0.05410324, -0.08565043,\n",
            "       -0.32360554, -0.08434057,  1.4135718 ,  0.38109982,  1.4889532 ,\n",
            "       -8.58535   , 10.082729  , -8.2537    ], dtype=float32), 'agent_1': Array([ 0.5633433 ,  0.9053985 ,  0.05327149, -0.07866573,  0.41379648,\n",
            "       -0.1927526 , -0.1658626 , -0.7818375 , -0.05410324, -0.08565043,\n",
            "       -0.32360554, -0.08434057,  1.4135718 ,  0.38109982,  1.4889532 ,\n",
            "       -8.58535   , 10.010547  , -4.422125  ], dtype=float32), 'agent_2': Array([ 0.5633433 ,  0.9053985 ,  0.05327149, -0.07866573,  0.41379648,\n",
            "       -0.1927526 , -0.1658626 , -0.05410324, -0.6430754 , -0.08565043,\n",
            "       -0.32360554, -0.08434057,  1.4135718 ,  0.38109982,  1.4889532 ,\n",
            "       -8.58535   , 12.289778  , -2.5728786 ], dtype=float32), 'agent_3': Array([ 0.5633433 ,  0.9053985 ,  0.05327149, -0.07866573,  0.41379648,\n",
            "       -0.1927526 , -0.1658626 , -0.05410324, -0.08565043,  0.69444484,\n",
            "       -0.32360554, -0.08434057,  1.4135718 ,  0.38109982,  1.4889532 ,\n",
            "       -8.58535   , 11.313777  , -7.9392924 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8251753  -0.21809754 -0.8231602  -0.21600613 -0.8201962  -0.21572854\n",
            " -0.8244756  -0.2180475 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.79682577, dtype=float32), 'agent_0': Array(-0.79682577, dtype=float32), 'agent_1': Array(-0.79682577, dtype=float32), 'agent_2': Array(-0.79682577, dtype=float32), 'agent_3': Array(-0.79682577, dtype=float32)}\n",
            "step: 49\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.61854273,   0.85471326,   0.04246078,  -0.0628916 ,\n",
            "         0.51352406,  -0.4793512 ,   0.47374964,  -0.45519385,\n",
            "        -0.24114314,  -0.32873458,  -0.19235611,   0.10663271,\n",
            "         0.979352  ,   0.04166267,  -0.13271719,   8.440147  ,\n",
            "       -11.009255  ,   0.92972356], dtype=float32), 'agent_1': Array([  0.61854273,   0.85471326,   0.04246078,  -0.0628916 ,\n",
            "         0.51352406,  -0.4793512 ,  -0.45519385,  -0.9753784 ,\n",
            "        -0.24114314,  -0.32873458,  -0.19235611,   0.10663271,\n",
            "         0.979352  ,   0.04166267,  -0.13271719,   8.440147  ,\n",
            "       -10.913796  ,  -3.9399316 ], dtype=float32), 'agent_2': Array([ 0.61854273,  0.85471326,  0.04246078, -0.0628916 ,  0.51352406,\n",
            "       -0.4793512 , -0.45519385, -0.24114314, -0.7828586 , -0.32873458,\n",
            "       -0.19235611,  0.10663271,  0.979352  ,  0.04166267, -0.13271719,\n",
            "        8.440147  , -9.133504  , -3.308404  ], dtype=float32), 'agent_3': Array([  0.61854273,   0.85471326,   0.04246078,  -0.0628916 ,\n",
            "         0.51352406,  -0.4793512 ,  -0.45519385,  -0.24114314,\n",
            "        -0.32873458,   0.4738987 ,  -0.19235611,   0.10663271,\n",
            "         0.979352  ,   0.04166267,  -0.13271719,   8.440147  ,\n",
            "       -10.214233  ,   0.65533626], dtype=float32)}\n",
            "ctrl action chosen: [1.9473526  0.19854069 1.9456122  0.1979742  1.9446083  0.19617842\n",
            " 1.9458904  0.1975179 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.7065817, dtype=float32), 'agent_0': Array(-0.7065817, dtype=float32), 'agent_1': Array(-0.7065817, dtype=float32), 'agent_2': Array(-0.7065817, dtype=float32), 'agent_3': Array(-0.7065817, dtype=float32)}\n",
            "step: 50\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.67643607,  0.91593987,  0.05468436, -0.06796188,  0.3917207 ,\n",
            "       -0.17175479,  0.561539  , -0.14379822,  0.14430395,  0.01466527,\n",
            "       -0.15047789, -0.18644333,  1.0068417 , -0.07466042, -0.47133586,\n",
            "       -9.778059  , 12.049915  ,  2.7970238 ], dtype=float32), 'agent_1': Array([ 0.67643607,  0.91593987,  0.05468436, -0.06796188,  0.3917207 ,\n",
            "       -0.17175479, -0.14379822, -1.0319197 ,  0.14430395,  0.01466527,\n",
            "       -0.15047789, -0.18644333,  1.0068417 , -0.07466042, -0.47133586,\n",
            "       -9.778059  , 12.027305  , -0.65549374], dtype=float32), 'agent_2': Array([ 0.67643607,  0.91593987,  0.05468436, -0.06796188,  0.3917207 ,\n",
            "       -0.17175479, -0.14379822,  0.14430395, -0.82400197,  0.01466527,\n",
            "       -0.15047789, -0.18644333,  1.0068417 , -0.07466042, -0.47133586,\n",
            "       -9.778059  , 13.33085   , -0.27221972], dtype=float32), 'agent_3': Array([ 0.67643607,  0.91593987,  0.05468436, -0.06796188,  0.3917207 ,\n",
            "       -0.17175479, -0.14379822,  0.14430395,  0.01466527,  0.5409535 ,\n",
            "       -0.15047789, -0.18644333,  1.0068417 , -0.07466042, -0.47133586,\n",
            "       -9.778059  , 12.696964  ,  1.6637417 ], dtype=float32)}\n",
            "ctrl action chosen: [1.914321  1.6113615 1.9109297 1.6120149 1.9105376 1.6111698 1.9119743\n",
            " 1.6114383]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.814908, dtype=float32), 'agent_0': Array(-6.814908, dtype=float32), 'agent_1': Array(-6.814908, dtype=float32), 'agent_2': Array(-6.814908, dtype=float32), 'agent_3': Array(-6.814908, dtype=float32)}\n",
            "step: 51\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.70002335,  0.9740414 ,  0.10845988, -0.10312719,  0.16983688,\n",
            "        0.45955706,  1.0400343 ,  0.48928952,  0.65401566,  0.6005139 ,\n",
            "        0.72886944,  0.6434202 ,  0.18693209,  1.8691459 , -3.088036  ,\n",
            "       -1.7866658 ,  6.0141153 , 12.1316    ], dtype=float32), 'agent_1': Array([ 0.70002335,  0.9740414 ,  0.10845988, -0.10312719,  0.16983688,\n",
            "        0.45955706,  0.48928952, -0.7750247 ,  0.65401566,  0.6005139 ,\n",
            "        0.72886944,  0.6434202 ,  0.18693209,  1.8691459 , -3.088036  ,\n",
            "       -1.7866658 ,  5.853772  ,  8.785744  ], dtype=float32), 'agent_2': Array([ 0.70002335,  0.9740414 ,  0.10845988, -0.10312719,  0.16983688,\n",
            "        0.45955706,  0.48928952,  0.65401566, -0.5614598 ,  0.6005139 ,\n",
            "        0.72886944,  0.6434202 ,  0.18693209,  1.8691459 , -3.088036  ,\n",
            "       -1.7866658 , -1.9556823 ,  8.437587  ], dtype=float32), 'agent_3': Array([ 0.70002335,  0.9740414 ,  0.10845988, -0.10312719,  0.16983688,\n",
            "        0.45955706,  0.48928952,  0.65401566,  0.6005139 ,  0.9693549 ,\n",
            "        0.72886944,  0.6434202 ,  0.18693209,  1.8691459 , -3.088036  ,\n",
            "       -1.7866658 ,  1.151778  , 11.555642  ], dtype=float32)}\n",
            "ctrl action chosen: [0.23743884 1.2446647  0.23721235 1.2440615  0.235682   1.2405996\n",
            " 0.23507285 1.2434657 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-11.269229, dtype=float32), 'agent_0': Array(-11.269229, dtype=float32), 'agent_1': Array(-11.269229, dtype=float32), 'agent_2': Array(-11.269229, dtype=float32), 'agent_3': Array(-11.269229, dtype=float32)}\n",
            "step: 52\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7018607 ,  0.9601012 ,  0.12668785, -0.1564094 ,  0.19414425,\n",
            "        0.5621011 ,  1.307518  ,  0.5318979 ,  0.41503292,  0.48497707,\n",
            "        0.21140575,  0.02323389, -0.05278587, -0.6171947 ,  0.774341  ,\n",
            "        2.2991533 ,  0.06733222, -1.8759571 ], dtype=float32), 'agent_1': Array([ 0.7018607 ,  0.9601012 ,  0.12668785, -0.1564094 ,  0.19414425,\n",
            "        0.5621011 ,  0.5318979 , -0.43040612,  0.41503292,  0.48497707,\n",
            "        0.21140575,  0.02323389, -0.05278587, -0.6171947 ,  0.774341  ,\n",
            "        2.2991533 , -0.6501147 , -1.2274511 ], dtype=float32), 'agent_2': Array([ 0.7018607 ,  0.9601012 ,  0.12668785, -0.1564094 ,  0.19414425,\n",
            "        0.5621011 ,  0.5318979 ,  0.41503292, -0.45373514,  0.48497707,\n",
            "        0.21140575,  0.02323389, -0.05278587, -0.6171947 ,  0.774341  ,\n",
            "        2.2991533 , -6.7562957 , -1.3996853 ], dtype=float32), 'agent_3': Array([ 0.7018607 ,  0.9601012 ,  0.12668785, -0.1564094 ,  0.19414425,\n",
            "        0.5621011 ,  0.5318979 ,  0.41503292,  0.48497707,  1.3238357 ,\n",
            "        0.21140575,  0.02323389, -0.05278587, -0.6171947 ,  0.774341  ,\n",
            "        2.2991533 , -3.4262693 , -1.6247661 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.20707153 -0.8224456  -0.20904939 -0.8205757  -0.20783539 -0.8193574\n",
            " -0.21076575 -0.8217152 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4996328, dtype=float32), 'agent_0': Array(-1.4996328, dtype=float32), 'agent_1': Array(-1.4996328, dtype=float32), 'agent_2': Array(-1.4996328, dtype=float32), 'agent_3': Array(-1.4996328, dtype=float32)}\n",
            "step: 53\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6795203 ,  0.9463016 ,  0.09141449, -0.12887867,  0.28204086,\n",
            "        0.45854628,  1.076994  ,  0.43034646,  0.04043644,  0.24981664,\n",
            "        0.23386478, -0.13375282, -0.4467368 , -0.8844602 ,  1.5197197 ,\n",
            "        3.0474813 , -2.58456   , -6.5074186 ], dtype=float32), 'agent_1': Array([ 0.6795203 ,  0.9463016 ,  0.09141449, -0.12887867,  0.28204086,\n",
            "        0.45854628,  0.43034646, -0.7002056 ,  0.04043644,  0.24981664,\n",
            "        0.23386478, -0.13375282, -0.4467368 , -0.8844602 ,  1.5197197 ,\n",
            "        3.0474813 , -2.370855  , -5.868845  ], dtype=float32), 'agent_2': Array([ 0.6795203 ,  0.9463016 ,  0.09141449, -0.12887867,  0.28204086,\n",
            "        0.45854628,  0.43034646,  0.04043644, -0.7884407 ,  0.24981664,\n",
            "        0.23386478, -0.13375282, -0.4467368 , -0.8844602 ,  1.5197197 ,\n",
            "        3.0474813 , -5.7677517 , -7.2932444 ], dtype=float32), 'agent_3': Array([ 0.6795203 ,  0.9463016 ,  0.09141449, -0.12887867,  0.28204086,\n",
            "        0.45854628,  0.43034646,  0.04043644,  0.24981664,  1.0784535 ,\n",
            "        0.23386478, -0.13375282, -0.4467368 , -0.8844602 ,  1.5197197 ,\n",
            "        3.0474813 , -3.698754  , -6.15731   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.936909   -0.20124714 -0.9382756  -0.19913995 -0.93734485 -0.20239648\n",
            " -0.9385195  -0.20027797]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.34242058, dtype=float32), 'agent_0': Array(-0.34242058, dtype=float32), 'agent_1': Array(-0.34242058, dtype=float32), 'agent_2': Array(-0.34242058, dtype=float32), 'agent_3': Array(-0.34242058, dtype=float32)}\n",
            "step: 54\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6863352 ,   0.84856653,   0.01933778,  -0.09849489,\n",
            "         0.5194803 ,  -0.09424667,   0.7010314 ,  -0.18229763,\n",
            "        -0.5924466 ,  -0.40381178,  -0.02020597,  -0.4964471 ,\n",
            "         0.5865216 ,   0.42192587,   2.9663658 ,  10.375748  ,\n",
            "       -11.060559  ,  -8.504059  ], dtype=float32), 'agent_1': Array([  0.6863352 ,   0.84856653,   0.01933778,  -0.09849489,\n",
            "         0.5194803 ,  -0.09424667,  -0.18229763,  -0.92338467,\n",
            "        -0.5924466 ,  -0.40381178,  -0.02020597,  -0.4964471 ,\n",
            "         0.5865216 ,   0.42192587,   2.9663658 ,  10.375748  ,\n",
            "       -13.888963  ,  -4.8586373 ], dtype=float32), 'agent_2': Array([  0.6863352 ,   0.84856653,   0.01933778,  -0.09849489,\n",
            "         0.5194803 ,  -0.09424667,  -0.18229763,  -0.5924466 ,\n",
            "        -0.973428  ,  -0.40381178,  -0.02020597,  -0.4964471 ,\n",
            "         0.5865216 ,   0.42192587,   2.9663658 ,  10.375748  ,\n",
            "       -10.596285  ,  -2.3889182 ], dtype=float32), 'agent_3': Array([  0.6863352 ,   0.84856653,   0.01933778,  -0.09849489,\n",
            "         0.5194803 ,  -0.09424667,  -0.18229763,  -0.5924466 ,\n",
            "        -0.40381178,   0.7604503 ,  -0.02020597,  -0.4964471 ,\n",
            "         0.5865216 ,   0.42192587,   2.9663658 ,  10.375748  ,\n",
            "       -13.913467  ,  -7.2872686 ], dtype=float32)}\n",
            "ctrl action chosen: [2.1541338  0.11691168 2.154737   0.11927848 2.1555517  0.11964487\n",
            " 2.1519833  0.11807704]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5439769, dtype=float32), 'agent_0': Array(-0.5439769, dtype=float32), 'agent_1': Array(-0.5439769, dtype=float32), 'agent_2': Array(-0.5439769, dtype=float32), 'agent_3': Array(-0.5439769, dtype=float32)}\n",
            "step: 55\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.9075453e-01,  9.1619074e-01,  9.2236260e-03, -4.6014171e-02,\n",
            "        3.9798510e-01,  3.2877788e-01,  4.9908659e-01,  1.0818548e-01,\n",
            "       -1.9269991e-01, -1.2957679e-01, -4.7731400e-02, -2.1187067e-01,\n",
            "       -7.2729588e-02, -7.1741268e-02,  1.5436870e+00, -9.7694645e+00,\n",
            "        1.4114029e+01,  4.0570161e-01], dtype=float32), 'agent_1': Array([ 6.9075453e-01,  9.1619074e-01,  9.2236260e-03, -4.6014171e-02,\n",
            "        3.9798510e-01,  3.2877788e-01,  1.0818548e-01, -1.0767995e+00,\n",
            "       -1.9269991e-01, -1.2957679e-01, -4.7731400e-02, -2.1187067e-01,\n",
            "       -7.2729588e-02, -7.1741268e-02,  1.5436870e+00, -9.7694645e+00,\n",
            "        1.1790734e+01, -1.4156572e+00], dtype=float32), 'agent_2': Array([ 6.9075453e-01,  9.1619074e-01,  9.2236260e-03, -4.6014171e-02,\n",
            "        3.9798510e-01,  3.2877788e-01,  1.0818548e-01, -1.9269991e-01,\n",
            "       -1.0422888e+00, -1.2957679e-01, -4.7731400e-02, -2.1187067e-01,\n",
            "       -7.2729588e-02, -7.1741268e-02,  1.5436870e+00, -9.7694645e+00,\n",
            "        1.3825419e+01, -9.5482367e-01], dtype=float32), 'agent_3': Array([ 6.9075453e-01,  9.1619074e-01,  9.2236260e-03, -4.6014171e-02,\n",
            "        3.9798510e-01,  3.2877788e-01,  1.0818548e-01, -1.9269991e-01,\n",
            "       -1.2957679e-01,  5.0163400e-01, -4.7731400e-02, -2.1187067e-01,\n",
            "       -7.2729588e-02, -7.1741268e-02,  1.5436870e+00, -9.7694645e+00,\n",
            "        1.1267181e+01, -2.5247769e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.7314122   0.01082904 -0.7314119   0.01203768 -0.7312612   0.01025363\n",
            " -0.73345655  0.01047793]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.39229, dtype=float32), 'agent_0': Array(-8.39229, dtype=float32), 'agent_1': Array(-8.39229, dtype=float32), 'agent_2': Array(-8.39229, dtype=float32), 'agent_3': Array(-8.39229, dtype=float32)}\n",
            "step: 56\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6849401 ,  0.8929513 , -0.01363526, -0.02572177,  0.449211  ,\n",
            "        0.27238363,  0.51910204, -0.04652393, -0.25056726, -0.30780149,\n",
            "        0.04894733, -0.3468871 , -0.1714468 , -0.25351283,  0.9320885 ,\n",
            "        6.211413  , -6.561134  ,  0.5983307 ], dtype=float32), 'agent_1': Array([ 0.6849401 ,  0.8929513 , -0.01363526, -0.02572177,  0.449211  ,\n",
            "        0.27238363, -0.04652393, -1.0954608 , -0.25056726, -0.30780149,\n",
            "        0.04894733, -0.3468871 , -0.1714468 , -0.25351283,  0.9320885 ,\n",
            "        6.211413  , -8.248417  ,  0.45950368], dtype=float32), 'agent_2': Array([ 0.6849401 ,  0.8929513 , -0.01363526, -0.02572177,  0.449211  ,\n",
            "        0.27238363, -0.04652393, -0.25056726, -1.044803  , -0.30780149,\n",
            "        0.04894733, -0.3468871 , -0.1714468 , -0.25351283,  0.9320885 ,\n",
            "        6.211413  , -6.6038885 ,  0.7422124 ], dtype=float32), 'agent_3': Array([ 0.6849401 ,  0.8929513 , -0.01363526, -0.02572177,  0.449211  ,\n",
            "        0.27238363, -0.04652393, -0.25056726, -0.30780149,  0.52588797,\n",
            "        0.04894733, -0.3468871 , -0.1714468 , -0.25351283,  0.9320885 ,\n",
            "        6.211413  , -8.707331  ,  0.624886  ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1723204  -0.81171167  1.1710083  -0.81013805  1.1727599  -0.8120573\n",
            "  1.1719401  -0.81197625]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.05782592, dtype=float32), 'agent_0': Array(-0.05782592, dtype=float32), 'agent_1': Array(-0.05782592, dtype=float32), 'agent_2': Array(-0.05782592, dtype=float32), 'agent_3': Array(-0.05782592, dtype=float32)}\n",
            "step: 57\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.652886  ,  0.9440979 , -0.04123517,  0.0107863 ,  0.32689837,\n",
            "        0.61488044,  0.49760407,  0.2601604 ,  0.13365382, -0.01287701,\n",
            "       -0.2393961 , -0.48006773, -0.8798957 , -0.978732  ,  1.7488896 ,\n",
            "       -6.021083  ,  5.6042023 , -0.30112886], dtype=float32), 'agent_1': Array([ 0.652886  ,  0.9440979 , -0.04123517,  0.0107863 ,  0.32689837,\n",
            "        0.61488044,  0.2601604 , -1.2753984 ,  0.13365382, -0.01287701,\n",
            "       -0.2393961 , -0.48006773, -0.8798957 , -0.978732  ,  1.7488896 ,\n",
            "       -6.021083  ,  8.202668  , -1.3779377 ], dtype=float32), 'agent_2': Array([ 0.652886  ,  0.9440979 , -0.04123517,  0.0107863 ,  0.32689837,\n",
            "        0.61488044,  0.2601604 ,  0.13365382, -1.2576894 , -0.01287701,\n",
            "       -0.2393961 , -0.48006773, -0.8798957 , -0.978732  ,  1.7488896 ,\n",
            "       -6.021083  ,  9.697843  , -4.093276  ], dtype=float32), 'agent_3': Array([ 0.652886  ,  0.9440979 , -0.04123517,  0.0107863 ,  0.32689837,\n",
            "        0.61488044,  0.2601604 ,  0.13365382, -0.01287701,  0.491808  ,\n",
            "       -0.2393961 , -0.48006773, -0.8798957 , -0.978732  ,  1.7488896 ,\n",
            "       -6.021083  ,  8.264958  , -0.3415751 ], dtype=float32)}\n",
            "ctrl action chosen: [0.01914627 0.2630597  0.02007014 0.26339152 0.01895761 0.26013157\n",
            " 0.01932955 0.26217592]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.1902585, dtype=float32), 'agent_0': Array(-3.1902585, dtype=float32), 'agent_1': Array(-3.1902585, dtype=float32), 'agent_2': Array(-3.1902585, dtype=float32), 'agent_3': Array(-3.1902585, dtype=float32)}\n",
            "step: 58\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60504395,  0.9495851 , -0.05574436,  0.01563401,  0.3081176 ,\n",
            "        0.5310068 ,  0.6038016 ,  0.3648195 ,  0.3075693 ,  0.08585524,\n",
            "       -0.36411285, -0.3782034 , -1.0146499 , -0.3114741 ,  0.93950415,\n",
            "       -0.3966103 , -2.9778922 ,  2.4987557 ], dtype=float32), 'agent_1': Array([ 0.60504395,  0.9495851 , -0.05574436,  0.01563401,  0.3081176 ,\n",
            "        0.5310068 ,  0.3648195 , -1.2073953 ,  0.3075693 ,  0.08585524,\n",
            "       -0.36411285, -0.3782034 , -1.0146499 , -0.3114741 ,  0.93950415,\n",
            "       -0.3966103 ,  1.5489284 ,  0.47946906], dtype=float32), 'agent_2': Array([ 0.60504395,  0.9495851 , -0.05574436,  0.01563401,  0.3081176 ,\n",
            "        0.5310068 ,  0.3648195 ,  0.3075693 , -1.218198  ,  0.08585524,\n",
            "       -0.36411285, -0.3782034 , -1.0146499 , -0.3114741 ,  0.93950415,\n",
            "       -0.3966103 ,  2.7342765 , -0.02545463], dtype=float32), 'agent_3': Array([ 0.60504395,  0.9495851 , -0.05574436,  0.01563401,  0.3081176 ,\n",
            "        0.5310068 ,  0.3648195 ,  0.3075693 ,  0.08585524,  0.5976233 ,\n",
            "       -0.36411285, -0.3782034 , -1.0146499 , -0.3114741 ,  0.93950415,\n",
            "       -0.3966103 ,  1.1757797 ,  2.3745942 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.7033782   0.00446658  1.7137122   0.00240883  1.7168915  -0.00624928\n",
            "  1.711212    0.0025736 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.55353236, dtype=float32), 'agent_0': Array(0.55353236, dtype=float32), 'agent_1': Array(0.55353236, dtype=float32), 'agent_2': Array(0.55353236, dtype=float32), 'agent_3': Array(0.55353236, dtype=float32)}\n",
            "step: 59\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5527572 ,  0.9689218 , -0.07491274,  0.03272855,  0.23346876,\n",
            "        0.52060986,  0.6481627 ,  0.58820564,  0.5970955 ,  0.39869708,\n",
            "       -0.10275841, -0.5841613 , -0.62453747, -0.19142179,  0.69533086,\n",
            "       -0.8930073 , -0.6674509 , -0.6415474 ], dtype=float32), 'agent_1': Array([ 0.5527572 ,  0.9689218 , -0.07491274,  0.03272855,  0.23346876,\n",
            "        0.52060986,  0.58820564, -1.1837947 ,  0.5970955 ,  0.39869708,\n",
            "       -0.10275841, -0.5841613 , -0.62453747, -0.19142179,  0.69533086,\n",
            "       -0.8930073 ,  0.9564414 ,  1.1600183 ], dtype=float32), 'agent_2': Array([ 0.5527572 ,  0.9689218 , -0.07491274,  0.03272855,  0.23346876,\n",
            "        0.52060986,  0.58820564,  0.5970955 , -1.2091975 ,  0.39869708,\n",
            "       -0.10275841, -0.5841613 , -0.62453747, -0.19142179,  0.69533086,\n",
            "       -0.8930073 ,  1.73451   ,  0.84560245], dtype=float32), 'agent_3': Array([ 0.5527572 ,  0.9689218 , -0.07491274,  0.03272855,  0.23346876,\n",
            "        0.52060986,  0.58820564,  0.5970955 ,  0.39869708,  0.6497171 ,\n",
            "       -0.10275841, -0.5841613 , -0.62453747, -0.19142179,  0.69533086,\n",
            "       -0.8930073 ,  5.431366  ,  0.8326567 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.55812424 -0.6673051  -0.5524074  -0.6613541  -0.54927284 -0.6704164\n",
            " -0.5510926  -0.6731103 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.1542974, dtype=float32), 'agent_0': Array(-5.1542974, dtype=float32), 'agent_1': Array(-5.1542974, dtype=float32), 'agent_2': Array(-5.1542974, dtype=float32), 'agent_3': Array(-5.1542974, dtype=float32)}\n",
            "step: 60\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5299655 ,   0.9278207 ,  -0.08116348,   0.08529118,\n",
            "         0.3539586 ,   0.10578859,   0.46345037,   0.2745677 ,\n",
            "         0.32631594,   0.25472867,  -0.09502172,  -0.6971359 ,\n",
            "        -0.4968047 ,   0.6526256 ,   1.5535762 ,   7.51906   ,\n",
            "       -10.813122  ,  -0.93178636], dtype=float32), 'agent_1': Array([ 0.5299655 ,  0.9278207 , -0.08116348,  0.08529118,  0.3539586 ,\n",
            "        0.10578859,  0.2745677 , -1.2630875 ,  0.32631594,  0.25472867,\n",
            "       -0.09502172, -0.6971359 , -0.4968047 ,  0.6526256 ,  1.5535762 ,\n",
            "        7.51906   , -9.8932295 , -0.3266107 ], dtype=float32), 'agent_2': Array([ 0.5299655 ,  0.9278207 , -0.08116348,  0.08529118,  0.3539586 ,\n",
            "        0.10578859,  0.2745677 ,  0.32631594, -1.2507658 ,  0.25472867,\n",
            "       -0.09502172, -0.6971359 , -0.4968047 ,  0.6526256 ,  1.5535762 ,\n",
            "        7.51906   , -8.907547  , -0.1900622 ], dtype=float32), 'agent_3': Array([ 0.5299655 ,  0.9278207 , -0.08116348,  0.08529118,  0.3539586 ,\n",
            "        0.10578859,  0.2745677 ,  0.32631594,  0.25472867,  0.5105092 ,\n",
            "       -0.09502172, -0.6971359 , -0.4968047 ,  0.6526256 ,  1.5535762 ,\n",
            "        7.51906   , -5.6230855 , -3.7152517 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3900476   1.4129     -0.39072314  1.413878   -0.38912958  1.4105549\n",
            " -0.39255235  1.4116912 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6862252, dtype=float32), 'agent_0': Array(-0.6862252, dtype=float32), 'agent_1': Array(-0.6862252, dtype=float32), 'agent_2': Array(-0.6862252, dtype=float32), 'agent_3': Array(-0.6862252, dtype=float32)}\n",
            "step: 61\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5152395 ,  0.85414034, -0.02852514,  0.0701462 ,  0.5145    ,\n",
            "       -0.42052278,  0.68610984, -0.17741445, -0.10667624, -0.03995724,\n",
            "        0.5166054 , -0.45571327, -0.01584291,  0.36531398, -2.5035307 ,\n",
            "        6.3061976 , -9.512005  ,  5.477607  ], dtype=float32), 'agent_1': Array([ 0.5152395 ,  0.85414034, -0.02852514,  0.0701462 ,  0.5145    ,\n",
            "       -0.42052278, -0.17741445, -0.9716887 , -0.10667624, -0.03995724,\n",
            "        0.5166054 , -0.45571327, -0.01584291,  0.36531398, -2.5035307 ,\n",
            "        6.3061976 , -7.7325897 ,  8.6661005 ], dtype=float32), 'agent_2': Array([ 0.5152395 ,  0.85414034, -0.02852514,  0.0701462 ,  0.5145    ,\n",
            "       -0.42052278, -0.17741445, -0.10667624, -0.9281325 , -0.03995724,\n",
            "        0.5166054 , -0.45571327, -0.01584291,  0.36531398, -2.5035307 ,\n",
            "        6.3061976 , -8.004208  ,  9.33466   ], dtype=float32), 'agent_3': Array([ 0.5152395 ,  0.85414034, -0.02852514,  0.0701462 ,  0.5145    ,\n",
            "       -0.42052278, -0.17741445, -0.10667624, -0.03995724,  0.7172179 ,\n",
            "        0.5166054 , -0.45571327, -0.01584291,  0.36531398, -2.5035307 ,\n",
            "        6.3061976 , -5.9568386 ,  5.411364  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.83042353  1.2398723  -0.82577     1.2425008  -0.82575333  1.2410917\n",
            " -0.82616925  1.2415041 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.985204, dtype=float32), 'agent_0': Array(-2.985204, dtype=float32), 'agent_1': Array(-2.985204, dtype=float32), 'agent_2': Array(-2.985204, dtype=float32), 'agent_3': Array(-2.985204, dtype=float32)}\n",
            "step: 62\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2887875e-01,  7.8324801e-01,  1.5009894e-02, -9.3213273e-03,\n",
            "        6.2145835e-01, -6.1828434e-01,  1.0636860e+00, -5.5975312e-01,\n",
            "       -4.9854109e-01, -4.1377810e-01,  1.5866160e+00, -4.7006607e-01,\n",
            "        3.3994913e-01, -1.7702383e+00, -3.7475586e+00,  2.1327105e+00,\n",
            "        2.2777233e+00,  9.5486574e+00], dtype=float32), 'agent_1': Array([ 0.52887875,  0.783248  ,  0.01500989, -0.00932133,  0.62145835,\n",
            "       -0.61828434, -0.5597531 , -0.43000916, -0.4985411 , -0.4137781 ,\n",
            "        1.586616  , -0.47006607,  0.33994913, -1.7702383 , -3.7475586 ,\n",
            "        2.1327105 , -4.226342  ,  7.521278  ], dtype=float32), 'agent_2': Array([ 0.52887875,  0.783248  ,  0.01500989, -0.00932133,  0.62145835,\n",
            "       -0.61828434, -0.5597531 , -0.4985411 , -0.42491218, -0.4137781 ,\n",
            "        1.586616  , -0.47006607,  0.33994913, -1.7702383 , -3.7475586 ,\n",
            "        2.1327105 , -4.7427154 ,  4.612961  ], dtype=float32), 'agent_3': Array([ 0.52887875,  0.783248  ,  0.01500989, -0.00932133,  0.62145835,\n",
            "       -0.61828434, -0.5597531 , -0.4985411 , -0.4137781 ,  1.0186388 ,\n",
            "        1.586616  , -0.47006607,  0.33994913, -1.7702383 , -3.7475586 ,\n",
            "        2.1327105 , -6.1318316 ,  7.2060127 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.3597058  -0.08717663  0.35857564 -0.08741844  0.3569629  -0.09004533\n",
            "  0.35957778 -0.08944252]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.451322, dtype=float32), 'agent_0': Array(-2.451322, dtype=float32), 'agent_1': Array(-2.451322, dtype=float32), 'agent_2': Array(-2.451322, dtype=float32), 'agent_3': Array(-2.451322, dtype=float32)}\n",
            "step: 63\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5775004 ,  0.83534   ,  0.03375317, -0.0383068 ,  0.5473578 ,\n",
            "       -0.15144135,  1.2396331 , -0.4393552 , -0.36160445, -0.36810133,\n",
            "        1.3724446 , -0.35238266,  1.535964  ,  0.01562675, -1.6026008 ,\n",
            "       -5.139344  , 11.9929495 ,  1.109948  ], dtype=float32), 'agent_1': Array([ 0.5775004 ,  0.83534   ,  0.03375317, -0.0383068 ,  0.5473578 ,\n",
            "       -0.15144135, -0.4393552 , -0.49374965, -0.36160445, -0.36810133,\n",
            "        1.3724446 , -0.35238266,  1.535964  ,  0.01562675, -1.6026008 ,\n",
            "       -5.139344  ,  4.555451  , -1.0729786 ], dtype=float32), 'agent_2': Array([ 0.5775004 ,  0.83534   ,  0.03375317, -0.0383068 ,  0.5473578 ,\n",
            "       -0.15144135, -0.4393552 , -0.36160445, -0.5000777 , -0.36810133,\n",
            "        1.3724446 , -0.35238266,  1.535964  ,  0.01562675, -1.6026008 ,\n",
            "       -5.139344  ,  4.45936   , -0.5657439 ], dtype=float32), 'agent_3': Array([ 0.5775004 ,  0.83534   ,  0.03375317, -0.0383068 ,  0.5473578 ,\n",
            "       -0.15144135, -0.4393552 , -0.36160445, -0.36810133,  1.1406794 ,\n",
            "        1.3724446 , -0.35238266,  1.535964  ,  0.01562675, -1.6026008 ,\n",
            "       -5.139344  ,  2.7891998 ,  1.081197  ], dtype=float32)}\n",
            "ctrl action chosen: [2.0407577  0.09494715 2.0436158  0.09582908 2.044291   0.09575309\n",
            " 2.0460396  0.09398182]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(2.1592388, dtype=float32), 'agent_0': Array(2.1592388, dtype=float32), 'agent_1': Array(2.1592388, dtype=float32), 'agent_2': Array(2.1592388, dtype=float32), 'agent_3': Array(2.1592388, dtype=float32)}\n",
            "step: 64\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6217385 ,  0.9485928 ,  0.06556973, -0.05754007,  0.3042394 ,\n",
            "        0.6779345 ,  1.2354251 ,  0.16397254,  0.23316859,  0.16158377,\n",
            "        1.0110378 , -0.37417412,  0.25082827,  0.4383079 , -0.77780986,\n",
            "       -7.3444934 ,  7.92959   , -0.9248224 ], dtype=float32), 'agent_1': Array([ 0.6217385 ,  0.9485928 ,  0.06556973, -0.05754007,  0.3042394 ,\n",
            "        0.6779345 ,  0.16397254, -0.5994041 ,  0.23316859,  0.16158377,\n",
            "        1.0110378 , -0.37417412,  0.25082827,  0.4383079 , -0.77780986,\n",
            "       -7.3444934 ,  9.602775  , -3.2692275 ], dtype=float32), 'agent_2': Array([ 0.6217385 ,  0.9485928 ,  0.06556973, -0.05754007,  0.3042394 ,\n",
            "        0.6779345 ,  0.16397254,  0.23316859, -0.58966464,  0.16158377,\n",
            "        1.0110378 , -0.37417412,  0.25082827,  0.4383079 , -0.77780986,\n",
            "       -7.3444934 ,  9.329396  , -3.2654855 ], dtype=float32), 'agent_3': Array([ 0.6217385 ,  0.9485928 ,  0.06556973, -0.05754007,  0.3042394 ,\n",
            "        0.6779345 ,  0.16397254,  0.23316859,  0.16158377,  1.2509614 ,\n",
            "        1.0110378 , -0.37417412,  0.25082827,  0.4383079 , -0.77780986,\n",
            "       -7.3444934 ,  8.246246  , -0.3309438 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.606941   -2.577142    0.60450196 -2.5763302   0.6056536  -2.5772443\n",
            "  0.60589856 -2.5772512 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.072812, dtype=float32), 'agent_0': Array(-6.072812, dtype=float32), 'agent_1': Array(-6.072812, dtype=float32), 'agent_2': Array(-6.072812, dtype=float32), 'agent_3': Array(-6.072812, dtype=float32)}\n",
            "step: 65\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.62147266,   0.96911484,   0.05260155,  -0.0271329 ,\n",
            "         0.23940217,   0.58944064,   0.864496  ,   0.4087726 ,\n",
            "         0.48465776,   0.36164746,  -0.09689331,  -1.2568235 ,\n",
            "        -0.05341768,  -1.1222719 ,   1.9698201 ,  -3.3000677 ,\n",
            "        -4.2725506 , -11.459249  ], dtype=float32), 'agent_1': Array([  0.62147266,   0.96911484,   0.05260155,  -0.0271329 ,\n",
            "         0.23940217,   0.58944064,   0.4087726 ,  -1.0902056 ,\n",
            "         0.48465776,   0.36164746,  -0.09689331,  -1.2568235 ,\n",
            "        -0.05341768,  -1.1222719 ,   1.9698201 ,  -3.3000677 ,\n",
            "         5.836009  , -11.669601  ], dtype=float32), 'agent_2': Array([ 0.62147266,  0.96911484,  0.05260155, -0.0271329 ,  0.23940217,\n",
            "        0.58944064,  0.4087726 ,  0.48465776, -1.0284474 ,  0.36164746,\n",
            "       -0.09689331, -1.2568235 , -0.05341768, -1.1222719 ,  1.9698201 ,\n",
            "       -3.3000677 ,  5.7189403 , -9.632778  ], dtype=float32), 'agent_3': Array([  0.62147266,   0.96911484,   0.05260155,  -0.0271329 ,\n",
            "         0.23940217,   0.58944064,   0.4087726 ,   0.48465776,\n",
            "         0.36164746,   0.91026664,  -0.09689331,  -1.2568235 ,\n",
            "        -0.05341768,  -1.1222719 ,   1.9698201 ,  -3.3000677 ,\n",
            "         5.151551  , -10.076849  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.16969626 -1.5386856   0.16695365 -1.5370299   0.17004165 -1.539135\n",
            "  0.16786408 -1.5384134 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.69613, dtype=float32), 'agent_0': Array(-12.69613, dtype=float32), 'agent_1': Array(-12.69613, dtype=float32), 'agent_2': Array(-12.69613, dtype=float32), 'agent_3': Array(-12.69613, dtype=float32)}\n",
            "step: 66\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2610042e-01,  9.7194731e-01,  2.1102441e-02,  4.3898555e-03,\n",
            "        2.3420896e-01,  2.4872459e-01,  4.1932955e-01,  5.3616202e-01,\n",
            "        5.5659592e-01,  4.6968991e-01,  4.7497749e-01, -9.1443062e-01,\n",
            "        3.4991503e-01,  6.0103279e-01, -3.5877329e-01,  4.9865168e-01,\n",
            "       -6.2628946e+00,  9.2984611e-01], dtype=float32), 'agent_1': Array([ 0.6261004 ,  0.9719473 ,  0.02110244,  0.00438986,  0.23420896,\n",
            "        0.2487246 ,  0.536162  , -1.3142071 ,  0.5565959 ,  0.4696899 ,\n",
            "        0.4749775 , -0.9144306 ,  0.34991503,  0.6010328 , -0.3587733 ,\n",
            "        0.49865168,  1.3513042 ,  0.8770897 ], dtype=float32), 'agent_2': Array([ 0.6261004 ,  0.9719473 ,  0.02110244,  0.00438986,  0.23420896,\n",
            "        0.2487246 ,  0.536162  ,  0.5565959 , -1.2895417 ,  0.4696899 ,\n",
            "        0.4749775 , -0.9144306 ,  0.34991503,  0.6010328 , -0.3587733 ,\n",
            "        0.49865168,  0.07471406,  1.0577204 ], dtype=float32), 'agent_3': Array([ 0.6261004 ,  0.9719473 ,  0.02110244,  0.00438986,  0.23420896,\n",
            "        0.2487246 ,  0.536162  ,  0.5565959 ,  0.4696899 ,  0.43015593,\n",
            "        0.4749775 , -0.9144306 ,  0.34991503,  0.6010328 , -0.3587733 ,\n",
            "        0.49865168,  1.3899255 , -2.2416904 ], dtype=float32)}\n",
            "ctrl action chosen: [ 3.1430247  -0.24904425  3.157297   -0.24754298  3.157095   -0.25501853\n",
            "  3.1511507  -0.2577686 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.7420425, dtype=float32), 'agent_0': Array(-3.7420425, dtype=float32), 'agent_1': Array(-3.7420425, dtype=float32), 'agent_2': Array(-3.7420425, dtype=float32), 'agent_3': Array(-3.7420425, dtype=float32)}\n",
            "step: 67\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.67382014,  0.97540593,  0.032171  , -0.0225087 ,  0.21689102,\n",
            "        0.15444392,  0.50426966,  0.57581496,  0.55553234,  0.57599825,\n",
            "        1.151681  , -0.46403408,  1.3237    , -0.621107  , -0.26767895,\n",
            "       -0.20353614, -0.30234653,  0.03545143], dtype=float32), 'agent_1': Array([ 0.67382014,  0.97540593,  0.032171  , -0.0225087 ,  0.21689102,\n",
            "        0.15444392,  0.57581496, -1.1945605 ,  0.55553234,  0.57599825,\n",
            "        1.151681  , -0.46403408,  1.3237    , -0.621107  , -0.26767895,\n",
            "       -0.20353614, -0.2750896 ,  2.1061835 ], dtype=float32), 'agent_2': Array([ 0.67382014,  0.97540593,  0.032171  , -0.0225087 ,  0.21689102,\n",
            "        0.15444392,  0.57581496,  0.55553234, -1.240721  ,  0.57599825,\n",
            "        1.151681  , -0.46403408,  1.3237    , -0.621107  , -0.26767895,\n",
            "       -0.20353614, -1.0068578 , -0.22319552], dtype=float32), 'agent_3': Array([ 0.67382014,  0.97540593,  0.032171  , -0.0225087 ,  0.21689102,\n",
            "        0.15444392,  0.57581496,  0.55553234,  0.57599825,  0.4878676 ,\n",
            "        1.151681  , -0.46403408,  1.3237    , -0.621107  , -0.26767895,\n",
            "       -0.20353614,  0.65343845,  0.0757542 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1649609  -0.88873976 -1.1631353  -0.88222885 -1.1594454  -0.893268\n",
            " -1.1629367  -0.8889403 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-17.900856, dtype=float32), 'agent_0': Array(-17.900856, dtype=float32), 'agent_1': Array(-17.900856, dtype=float32), 'agent_2': Array(-17.900856, dtype=float32), 'agent_3': Array(-17.900856, dtype=float32)}\n",
            "step: 68\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.7255377 ,   0.89848024,   0.02119579,  -0.03216706,\n",
            "         0.43732077,  -0.45711213,   0.49706188,  -0.03749094,\n",
            "        -0.09545331,   0.03465869,   1.0139942 ,  -0.27616024,\n",
            "         0.8224726 ,  -0.24898234,  -0.3219074 ,  12.256178  ,\n",
            "       -15.464386  ,   0.2634868 ], dtype=float32), 'agent_1': Array([  0.7255377 ,   0.89848024,   0.02119579,  -0.03216706,\n",
            "         0.43732077,  -0.45711213,  -0.03749094,  -1.2496319 ,\n",
            "        -0.09545331,   0.03465869,   1.0139942 ,  -0.27616024,\n",
            "         0.8224726 ,  -0.24898234,  -0.3219074 ,  12.256178  ,\n",
            "       -16.359854  ,  -0.6580227 ], dtype=float32), 'agent_2': Array([  0.7255377 ,   0.89848024,   0.02119579,  -0.03216706,\n",
            "         0.43732077,  -0.45711213,  -0.03749094,  -0.09545331,\n",
            "        -1.2553339 ,   0.03465869,   1.0139942 ,  -0.27616024,\n",
            "         0.8224726 ,  -0.24898234,  -0.3219074 ,  12.256178  ,\n",
            "       -16.680855  ,   0.23643269], dtype=float32), 'agent_3': Array([  0.7255377 ,   0.89848024,   0.02119579,  -0.03216706,\n",
            "         0.43732077,  -0.45711213,  -0.03749094,  -0.09545331,\n",
            "         0.03465869,   0.5010554 ,   1.0139942 ,  -0.27616024,\n",
            "         0.8224726 ,  -0.24898234,  -0.3219074 ,  12.256178  ,\n",
            "       -15.073816  ,   0.5419387 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.91030306 -0.6491996   0.9097873  -0.6480752   0.91108835 -0.6499325\n",
            "  0.9098631  -0.6495514 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.263012, dtype=float32), 'agent_0': Array(-2.263012, dtype=float32), 'agent_1': Array(-2.263012, dtype=float32), 'agent_2': Array(-2.263012, dtype=float32), 'agent_3': Array(-2.263012, dtype=float32)}\n",
            "step: 69\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7456326 ,  0.93626153,  0.01911964, -0.04077232,  0.34840557,\n",
            "       -0.261587  ,  0.5013963 ,  0.13063078,  0.06375537,  0.26982373,\n",
            "        1.2094021 , -0.50320625,  0.03513098, -0.42206234, -0.07312772,\n",
            "       -8.789573  , 10.471677  , -0.5593426 ], dtype=float32), 'agent_1': Array([ 0.7456326 ,  0.93626153,  0.01911964, -0.04077232,  0.34840557,\n",
            "       -0.261587  ,  0.13063078, -1.2612877 ,  0.06375537,  0.26982373,\n",
            "        1.2094021 , -0.50320625,  0.03513098, -0.42206234, -0.07312772,\n",
            "       -8.789573  ,  9.792768  , -0.38122496], dtype=float32), 'agent_2': Array([ 0.7456326 ,  0.93626153,  0.01911964, -0.04077232,  0.34840557,\n",
            "       -0.261587  ,  0.13063078,  0.06375537, -1.2458849 ,  0.26982373,\n",
            "        1.2094021 , -0.50320625,  0.03513098, -0.42206234, -0.07312772,\n",
            "       -8.789573  ,  9.61977   , -0.1856013 ], dtype=float32), 'agent_3': Array([ 0.7456326 ,  0.93626153,  0.01911964, -0.04077232,  0.34840557,\n",
            "       -0.261587  ,  0.13063078,  0.06375537,  0.26982373,  0.50849295,\n",
            "        1.2094021 , -0.50320625,  0.03513098, -0.42206234, -0.07312772,\n",
            "       -8.789573  , 11.322094  , -0.5846714 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0257497   0.49506125 -1.0237038   0.49639505 -1.0236746   0.49437237\n",
            " -1.026943    0.49519834]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.35502577, dtype=float32), 'agent_0': Array(-0.35502577, dtype=float32), 'agent_1': Array(-0.35502577, dtype=float32), 'agent_2': Array(-0.35502577, dtype=float32), 'agent_3': Array(-0.35502577, dtype=float32)}\n",
            "step: 70\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.3761177e-01,  8.8754010e-01,  1.5389653e-02, -7.6253980e-02,\n",
            "        4.5411587e-01, -5.6084305e-01,  6.3728154e-01, -1.9576676e-01,\n",
            "       -2.8078321e-01, -1.5209672e-03,  1.1782527e+00, -1.5075207e-01,\n",
            "       -3.0490160e-01, -3.9664060e-01, -1.4512273e+00,  7.8033543e+00,\n",
            "       -9.5001059e+00,  3.6036530e+00], dtype=float32), 'agent_1': Array([ 7.3761177e-01,  8.8754010e-01,  1.5389653e-02, -7.6253980e-02,\n",
            "        4.5411587e-01, -5.6084305e-01, -1.9576676e-01, -1.1317961e+00,\n",
            "       -2.8078321e-01, -1.5209672e-03,  1.1782527e+00, -1.5075207e-01,\n",
            "       -3.0490160e-01, -3.9664060e-01, -1.4512273e+00,  7.8033543e+00,\n",
            "       -1.0835876e+01,  3.7511578e+00], dtype=float32), 'agent_2': Array([ 7.3761177e-01,  8.8754010e-01,  1.5389653e-02, -7.6253980e-02,\n",
            "        4.5411587e-01, -5.6084305e-01, -1.9576676e-01, -2.8078321e-01,\n",
            "       -1.0778779e+00, -1.5209672e-03,  1.1782527e+00, -1.5075207e-01,\n",
            "       -3.0490160e-01, -3.9664060e-01, -1.4512273e+00,  7.8033543e+00,\n",
            "       -1.1400390e+01,  4.8080773e+00], dtype=float32), 'agent_3': Array([ 7.3761177e-01,  8.8754010e-01,  1.5389653e-02, -7.6253980e-02,\n",
            "        4.5411587e-01, -5.6084305e-01, -1.9576676e-01, -2.8078321e-01,\n",
            "       -1.5209672e-03,  6.5042192e-01,  1.1782527e+00, -1.5075207e-01,\n",
            "       -3.0490160e-01, -3.9664060e-01, -1.4512273e+00,  7.8033543e+00,\n",
            "       -1.0249020e+01,  3.4290168e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.89616495 1.9302483  0.8937494  1.9317105  0.8948419  1.9312264\n",
            " 0.8938328  1.930727  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.34941435, dtype=float32), 'agent_0': Array(-0.34941435, dtype=float32), 'agent_1': Array(-0.34941435, dtype=float32), 'agent_2': Array(-0.34941435, dtype=float32), 'agent_3': Array(-0.34941435, dtype=float32)}\n",
            "step: 71\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.71182775,  0.92829263,  0.04241039, -0.15460314,  0.3355175 ,\n",
            "       -0.2345406 ,  1.0939025 ,  0.05077945, -0.05528863,  0.27251226,\n",
            "        1.6604424 , -0.09016991, -0.8096695 , -0.8046572 , -4.485038  ,\n",
            "       -8.829452  , 12.135241  , 12.38553   ], dtype=float32), 'agent_1': Array([ 0.71182775,  0.92829263,  0.04241039, -0.15460314,  0.3355175 ,\n",
            "       -0.2345406 ,  0.05077945, -0.6647969 , -0.05528863,  0.27251226,\n",
            "        1.6604424 , -0.09016991, -0.8096695 , -0.8046572 , -4.485038  ,\n",
            "       -8.829452  , 10.05177   , 12.692662  ], dtype=float32), 'agent_2': Array([ 0.71182775,  0.92829263,  0.04241039, -0.15460314,  0.3355175 ,\n",
            "       -0.2345406 ,  0.05077945, -0.05528863, -0.6172862 ,  0.27251226,\n",
            "        1.6604424 , -0.09016991, -0.8096695 , -0.8046572 , -4.485038  ,\n",
            "       -8.829452  , 10.081382  , 11.541969  ], dtype=float32), 'agent_3': Array([ 0.71182775,  0.92829263,  0.04241039, -0.15460314,  0.3355175 ,\n",
            "       -0.2345406 ,  0.05077945, -0.05528863,  0.27251226,  1.0689857 ,\n",
            "        1.6604424 , -0.09016991, -0.8096695 , -0.8046572 , -4.485038  ,\n",
            "       -8.829452  , 10.412209  , 12.0627165 ], dtype=float32)}\n",
            "ctrl action chosen: [1.323849  1.2648278 1.3216636 1.2663801 1.3230133 1.2638029 1.3215226\n",
            " 1.2646613]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.566578, dtype=float32), 'agent_0': Array(-6.566578, dtype=float32), 'agent_1': Array(-6.566578, dtype=float32), 'agent_2': Array(-6.566578, dtype=float32), 'agent_3': Array(-6.566578, dtype=float32)}\n",
            "step: 72\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6517062 ,  0.9727241 ,  0.08591446, -0.18309999,  0.11358333,\n",
            "        0.44559518,  1.2901826 ,  0.57415605,  0.54086024,  0.6432846 ,\n",
            "        0.76512694, -0.15118122, -1.2518525 , -0.9300589 ,  0.9821369 ,\n",
            "       -2.3101351 ,  7.165777  , -1.8922775 ], dtype=float32), 'agent_1': Array([ 0.6517062 ,  0.9727241 ,  0.08591446, -0.18309999,  0.11358333,\n",
            "        0.44559518,  0.57415605, -0.45170388,  0.54086024,  0.6432846 ,\n",
            "        0.76512694, -0.15118122, -1.2518525 , -0.9300589 ,  0.9821369 ,\n",
            "       -2.3101351 ,  1.5862223 , -2.5407152 ], dtype=float32), 'agent_2': Array([ 0.6517062 ,  0.9727241 ,  0.08591446, -0.18309999,  0.11358333,\n",
            "        0.44559518,  0.57415605,  0.54086024, -0.44720727,  0.6432846 ,\n",
            "        0.76512694, -0.15118122, -1.2518525 , -0.9300589 ,  0.9821369 ,\n",
            "       -2.3101351 ,  4.576448  , -1.6220123 ], dtype=float32), 'agent_3': Array([ 0.6517062 ,  0.9727241 ,  0.08591446, -0.18309999,  0.11358333,\n",
            "        0.44559518,  0.57415605,  0.54086024,  0.6432846 ,  1.298458  ,\n",
            "        0.76512694, -0.15118122, -1.2518525 , -0.9300589 ,  0.9821369 ,\n",
            "       -2.3101351 , -3.247491  , -2.5760264 ], dtype=float32)}\n",
            "ctrl action chosen: [0.6389143 1.5532659 0.6362747 1.5551736 0.6396833 1.5532404 0.634583\n",
            " 1.554731 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.3730483, dtype=float32), 'agent_0': Array(-4.3730483, dtype=float32), 'agent_1': Array(-4.3730483, dtype=float32), 'agent_2': Array(-4.3730483, dtype=float32), 'agent_3': Array(-4.3730483, dtype=float32)}\n",
            "step: 73\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.587576  ,  0.970409  ,  0.07920053, -0.19476828,  0.11873887,\n",
            "        0.5858122 ,  1.2622718 ,  0.509904  ,  0.5539751 ,  0.38582784,\n",
            "        0.9718716 , -0.08163452, -0.9483576 , -0.32699752, -0.18259256,\n",
            "        1.1944176 ,  0.40534014, -0.9574661 ], dtype=float32), 'agent_1': Array([ 0.587576  ,  0.970409  ,  0.07920053, -0.19476828,  0.11873887,\n",
            "        0.5858122 ,  0.509904  , -0.46292764,  0.5539751 ,  0.38582784,\n",
            "        0.9718716 , -0.08163452, -0.9483576 , -0.32699752, -0.18259256,\n",
            "        1.1944176 , -1.9178054 ,  0.9075161 ], dtype=float32), 'agent_2': Array([ 0.587576  ,  0.970409  ,  0.07920053, -0.19476828,  0.11873887,\n",
            "        0.5858122 ,  0.509904  ,  0.5539751 , -0.49013135,  0.38582784,\n",
            "        0.9718716 , -0.08163452, -0.9483576 , -0.32699752, -0.18259256,\n",
            "        1.1944176 , -0.8946908 , -0.9568555 ], dtype=float32), 'agent_3': Array([ 0.587576  ,  0.970409  ,  0.07920053, -0.19476828,  0.11873887,\n",
            "        0.5858122 ,  0.509904  ,  0.5539751 ,  0.38582784,  1.2631475 ,\n",
            "        0.9718716 , -0.08163452, -0.9483576 , -0.32699752, -0.18259256,\n",
            "        1.1944176 , -6.2136245 , -0.62331796], dtype=float32)}\n",
            "ctrl action chosen: [0.8062672  0.7209712  0.80360156 0.72560704 0.80671245 0.7178008\n",
            " 0.8009861  0.72132796]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.5777607, dtype=float32), 'agent_0': Array(-3.5777607, dtype=float32), 'agent_1': Array(-3.5777607, dtype=float32), 'agent_2': Array(-3.5777607, dtype=float32), 'agent_3': Array(-3.5777607, dtype=float32)}\n",
            "step: 74\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57622415,  0.97799945,  0.07054314, -0.1633799 ,  0.1088476 ,\n",
            "        0.5808072 ,  1.2316064 ,  0.527172  ,  0.56497276,  0.2926704 ,\n",
            "        0.56925416,  0.07324219, -0.10057688, -0.23093441,  1.175437  ,\n",
            "       -1.2038616 , -1.1584004 ,  0.22769322], dtype=float32), 'agent_1': Array([ 0.57622415,  0.97799945,  0.07054314, -0.1633799 ,  0.1088476 ,\n",
            "        0.5808072 ,  0.527172  , -0.47309455,  0.56497276,  0.2926704 ,\n",
            "        0.56925416,  0.07324219, -0.10057688, -0.23093441,  1.175437  ,\n",
            "       -1.2038616 ,  1.5061811 ,  0.02921821], dtype=float32), 'agent_2': Array([ 0.57622415,  0.97799945,  0.07054314, -0.1633799 ,  0.1088476 ,\n",
            "        0.5808072 ,  0.527172  ,  0.56497276, -0.50420463,  0.2926704 ,\n",
            "        0.56925416,  0.07324219, -0.10057688, -0.23093441,  1.175437  ,\n",
            "       -1.2038616 ,  0.21526797,  0.26034218], dtype=float32), 'agent_3': Array([ 0.57622415,  0.97799945,  0.07054314, -0.1633799 ,  0.1088476 ,\n",
            "        0.5808072 ,  0.527172  ,  0.56497276,  0.2926704 ,  1.2203656 ,\n",
            "        0.56925416,  0.07324219, -0.10057688, -0.23093441,  1.175437  ,\n",
            "       -1.2038616 ,  0.8514009 ,  0.4175289 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.59109354 -1.2648765  -0.5879749  -1.2652146  -0.5883114  -1.2687215\n",
            " -0.58864003 -1.2659428 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.65079427, dtype=float32), 'agent_0': Array(-0.65079427, dtype=float32), 'agent_1': Array(-0.65079427, dtype=float32), 'agent_2': Array(-0.65079427, dtype=float32), 'agent_3': Array(-0.65079427, dtype=float32)}\n",
            "step: 75\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7944012e-01,  9.6855807e-01,  3.0185748e-02, -9.2335500e-02,\n",
            "        2.2903794e-01,  1.5205382e-01,  9.1179359e-01,  2.3408101e-01,\n",
            "        2.1462208e-01, -3.3600517e-02, -4.9769878e-03, -7.2121620e-02,\n",
            "       -5.8710575e-02,  8.0888703e-02,  4.2492661e+00,  6.9225912e+00,\n",
            "       -1.1615180e+01, -8.4440355e+00], dtype=float32), 'agent_1': Array([ 5.7944012e-01,  9.6855807e-01,  3.0185748e-02, -9.2335500e-02,\n",
            "        2.2903794e-01,  1.5205382e-01,  2.3408101e-01, -7.4857581e-01,\n",
            "        2.1462208e-01, -3.3600517e-02, -4.9769878e-03, -7.2121620e-02,\n",
            "       -5.8710575e-02,  8.0888703e-02,  4.2492661e+00,  6.9225912e+00,\n",
            "       -8.6013336e+00, -8.2805672e+00], dtype=float32), 'agent_2': Array([ 5.7944012e-01,  9.6855807e-01,  3.0185748e-02, -9.2335500e-02,\n",
            "        2.2903794e-01,  1.5205382e-01,  2.3408101e-01,  2.1462208e-01,\n",
            "       -8.0464101e-01, -3.3600517e-02, -4.9769878e-03, -7.2121620e-02,\n",
            "       -5.8710575e-02,  8.0888703e-02,  4.2492661e+00,  6.9225912e+00,\n",
            "       -9.8240547e+00, -8.5037289e+00], dtype=float32), 'agent_3': Array([ 5.7944012e-01,  9.6855807e-01,  3.0185748e-02, -9.2335500e-02,\n",
            "        2.2903794e-01,  1.5205382e-01,  2.3408101e-01,  2.1462208e-01,\n",
            "       -3.3600517e-02,  8.9710301e-01, -4.9769878e-03, -7.2121620e-02,\n",
            "       -5.8710575e-02,  8.0888703e-02,  4.2492661e+00,  6.9225912e+00,\n",
            "       -8.4398098e+00, -7.9479141e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.92522764 -0.39913782 -0.9247705  -0.40048575 -0.9239436  -0.4011532\n",
            " -0.92431    -0.40180847]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.6988163, dtype=float32), 'agent_0': Array(-2.6988163, dtype=float32), 'agent_1': Array(-2.6988163, dtype=float32), 'agent_2': Array(-2.6988163, dtype=float32), 'agent_3': Array(-2.6988163, dtype=float32)}\n",
            "step: 76\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7589191e-01,  8.8670051e-01,  1.7900106e-02, -3.1861975e-03,\n",
            "        4.6198663e-01, -5.6956708e-01,  5.5136293e-01, -4.3866977e-01,\n",
            "       -4.2652452e-01, -6.3340580e-01,  8.9412928e-02, -2.5773048e-01,\n",
            "        4.7683716e-02,  2.2516925e+00,  3.2874177e+00,  5.1399279e+00,\n",
            "       -7.6547418e+00, -8.1121454e+00], dtype=float32), 'agent_1': Array([ 5.7589191e-01,  8.8670051e-01,  1.7900106e-02, -3.1861975e-03,\n",
            "        4.6198663e-01, -5.6956708e-01, -4.3866977e-01, -1.0703456e+00,\n",
            "       -4.2652452e-01, -6.3340580e-01,  8.9412928e-02, -2.5773048e-01,\n",
            "        4.7683716e-02,  2.2516925e+00,  3.2874177e+00,  5.1399279e+00,\n",
            "       -9.8013744e+00, -5.7976842e+00], dtype=float32), 'agent_2': Array([ 5.7589191e-01,  8.8670051e-01,  1.7900106e-02, -3.1861975e-03,\n",
            "        4.6198663e-01, -5.6956708e-01, -4.3866977e-01, -4.2652452e-01,\n",
            "       -1.0890445e+00, -6.3340580e-01,  8.9412928e-02, -2.5773048e-01,\n",
            "        4.7683716e-02,  2.2516925e+00,  3.2874177e+00,  5.1399279e+00,\n",
            "       -7.8791552e+00, -4.0956998e+00], dtype=float32), 'agent_3': Array([ 5.7589191e-01,  8.8670051e-01,  1.7900106e-02, -3.1861975e-03,\n",
            "        4.6198663e-01, -5.6956708e-01, -4.3866977e-01, -4.2652452e-01,\n",
            "       -6.3340580e-01,  5.5777037e-01,  8.9412928e-02, -2.5773048e-01,\n",
            "        4.7683716e-02,  2.2516925e+00,  3.2874177e+00,  5.1399279e+00,\n",
            "       -3.9831269e+00, -7.8751845e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.5129632 2.6672597 1.513183  2.671208  1.5138682 2.6729517 1.513737\n",
            " 2.6662436]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.95314467, dtype=float32), 'agent_0': Array(-0.95314467, dtype=float32), 'agent_1': Array(-0.95314467, dtype=float32), 'agent_2': Array(-0.95314467, dtype=float32), 'agent_3': Array(-0.95314467, dtype=float32)}\n",
            "step: 77\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8148158e-01,  9.5874161e-01,  2.2943605e-02,  4.0853158e-02,\n",
            "        2.8039125e-01, -1.4848363e-01,  6.0187215e-01, -1.0610096e-01,\n",
            "       -8.9258642e-04, -1.2183086e-01,  4.8818588e-01, -4.4696331e-01,\n",
            "        9.9146366e-02,  3.7526548e-01,  3.3716789e-01, -1.2187853e+01,\n",
            "        1.4192462e+01,  4.5189695e+00], dtype=float32), 'agent_1': Array([ 5.8148158e-01,  9.5874161e-01,  2.2943605e-02,  4.0853158e-02,\n",
            "        2.8039125e-01, -1.4848363e-01, -1.0610096e-01, -9.9956310e-01,\n",
            "       -8.9258642e-04, -1.2183086e-01,  4.8818588e-01, -4.4696331e-01,\n",
            "        9.9146366e-02,  3.7526548e-01,  3.3716789e-01, -1.2187853e+01,\n",
            "        1.2519082e+01,  4.3923907e+00], dtype=float32), 'agent_2': Array([ 5.8148158e-01,  9.5874161e-01,  2.2943605e-02,  4.0853158e-02,\n",
            "        2.8039125e-01, -1.4848363e-01, -1.0610096e-01, -8.9258642e-04,\n",
            "       -8.9664441e-01, -1.2183086e-01,  4.8818588e-01, -4.4696331e-01,\n",
            "        9.9146366e-02,  3.7526548e-01,  3.3716789e-01, -1.2187853e+01,\n",
            "        1.3661487e+01,  6.8421335e+00], dtype=float32), 'agent_3': Array([ 5.8148158e-01,  9.5874161e-01,  2.2943605e-02,  4.0853158e-02,\n",
            "        2.8039125e-01, -1.4848363e-01, -1.0610096e-01, -8.9258642e-04,\n",
            "       -1.2183086e-01,  5.9227026e-01,  4.8818588e-01, -4.4696331e-01,\n",
            "        9.9146366e-02,  3.7526548e-01,  3.3716789e-01, -1.2187853e+01,\n",
            "        1.6626591e+01,  4.3556390e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.28919706 0.3354863  0.28930715 0.3355867  0.28914458 0.33362973\n",
            " 0.28727868 0.3343206 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-17.497953, dtype=float32), 'agent_0': Array(-17.497953, dtype=float32), 'agent_1': Array(-17.497953, dtype=float32), 'agent_2': Array(-17.497953, dtype=float32), 'agent_3': Array(-17.497953, dtype=float32)}\n",
            "step: 78\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5678356 ,  0.9951761 ,  0.01167488,  0.06624121,  0.07141651,\n",
            "        0.34163868,  0.792263  ,  0.3167827 ,  0.4564436 ,  0.45505995,\n",
            "        0.6527394 , -0.53761005, -0.13306141, -0.02544235,  0.32452077,\n",
            "       -6.8367224 ,  7.667785  ,  4.9428105 ], dtype=float32), 'agent_1': Array([ 0.5678356 ,  0.9951761 ,  0.01167488,  0.06624121,  0.07141651,\n",
            "        0.34163868,  0.3167827 , -0.7816862 ,  0.4564436 ,  0.45505995,\n",
            "        0.6527394 , -0.53761005, -0.13306141, -0.02544235,  0.32452077,\n",
            "       -6.8367224 ,  6.472454  ,  6.0386434 ], dtype=float32), 'agent_2': Array([ 0.5678356 ,  0.9951761 ,  0.01167488,  0.06624121,  0.07141651,\n",
            "        0.34163868,  0.3167827 ,  0.4564436 , -0.6441623 ,  0.45505995,\n",
            "        0.6527394 , -0.53761005, -0.13306141, -0.02544235,  0.32452077,\n",
            "       -6.8367224 ,  7.071092  ,  5.7949586 ], dtype=float32), 'agent_3': Array([ 0.5678356 ,  0.9951761 ,  0.01167488,  0.06624121,  0.07141651,\n",
            "        0.34163868,  0.3167827 ,  0.4564436 ,  0.45505995,  0.76278657,\n",
            "        0.6527394 , -0.53761005, -0.13306141, -0.02544235,  0.32452077,\n",
            "       -6.8367224 ,  8.794763  ,  2.0269172 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.16164142  0.43842095 -0.16268052  0.4397632  -0.16177592  0.4379011\n",
            " -0.16316237  0.43687916]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0814102, dtype=float32), 'agent_0': Array(1.0814102, dtype=float32), 'agent_1': Array(1.0814102, dtype=float32), 'agent_2': Array(1.0814102, dtype=float32), 'agent_3': Array(1.0814102, dtype=float32)}\n",
            "step: 79\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58287853,  0.9978875 ,  0.01082119,  0.04491679,  0.04567328,\n",
            "        0.38805187,  1.1029718 ,  0.2790176 ,  0.45788753,  0.5261418 ,\n",
            "        1.0775268 , -0.25119781,  0.44888258, -0.2830861 , -0.33196673,\n",
            "        0.92760926, -1.3294373 ,  6.509072  ], dtype=float32), 'agent_1': Array([ 0.58287853,  0.9978875 ,  0.01082119,  0.04491679,  0.04567328,\n",
            "        0.38805187,  0.2790176 , -0.44929323,  0.45788753,  0.5261418 ,\n",
            "        1.0775268 , -0.25119781,  0.44888258, -0.2830861 , -0.33196673,\n",
            "        0.92760926, -2.971564  ,  0.96330553], dtype=float32), 'agent_2': Array([ 0.58287853,  0.9978875 ,  0.01082119,  0.04491679,  0.04567328,\n",
            "        0.38805187,  0.2790176 ,  0.45788753, -0.4608697 ,  0.5261418 ,\n",
            "        1.0775268 , -0.25119781,  0.44888258, -0.2830861 , -0.33196673,\n",
            "        0.92760926, -2.3180928 , -1.0693675 ], dtype=float32), 'agent_3': Array([ 0.58287853,  0.9978875 ,  0.01082119,  0.04491679,  0.04567328,\n",
            "        0.38805187,  0.2790176 ,  0.45788753,  0.5261418 ,  0.8954516 ,\n",
            "        1.0775268 , -0.25119781,  0.44888258, -0.2830861 , -0.33196673,\n",
            "        0.92760926, -0.7290707 ,  2.8260193 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.35676885 -1.2736938   0.35171607 -1.2720668   0.35593644 -1.2807691\n",
            "  0.35544375 -1.2718366 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.637654, dtype=float32), 'agent_0': Array(1.637654, dtype=float32), 'agent_1': Array(1.637654, dtype=float32), 'agent_2': Array(1.637654, dtype=float32), 'agent_3': Array(1.637654, dtype=float32)}\n",
            "step: 80\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6352679 ,  0.9948334 , -0.01522043,  0.09976599,  0.01102526,\n",
            "        0.48457694,  0.93022764,  0.3123639 ,  0.51027656,  0.5624973 ,\n",
            "        0.6758541 , -0.38895607,  1.1204839 , -1.2281315 ,  2.7783859 ,\n",
            "       -1.7639141 ,  2.7473216 , -6.5610733 ], dtype=float32), 'agent_1': Array([ 0.6352679 ,  0.9948334 , -0.01522043,  0.09976599,  0.01102526,\n",
            "        0.48457694,  0.3123639 , -0.71649086,  0.51027656,  0.5624973 ,\n",
            "        0.6758541 , -0.38895607,  1.1204839 , -1.2281315 ,  2.7783859 ,\n",
            "       -1.7639141 ,  1.3522749 , -7.826759  ], dtype=float32), 'agent_2': Array([ 0.6352679 ,  0.9948334 , -0.01522043,  0.09976599,  0.01102526,\n",
            "        0.48457694,  0.3123639 ,  0.51027656, -0.7456604 ,  0.5624973 ,\n",
            "        0.6758541 , -0.38895607,  1.1204839 , -1.2281315 ,  2.7783859 ,\n",
            "       -1.7639141 ,  1.9699087 , -9.368064  ], dtype=float32), 'agent_3': Array([ 0.6352679 ,  0.9948334 , -0.01522043,  0.09976599,  0.01102526,\n",
            "        0.48457694,  0.3123639 ,  0.51027656,  0.5624973 ,  0.580641  ,\n",
            "        0.6758541 , -0.38895607,  1.1204839 , -1.2281315 ,  2.7783859 ,\n",
            "       -1.7639141 ,  0.2266173 , -8.884449  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.20651987 -0.5395662   0.20676492 -0.5377763   0.2103142  -0.5406494\n",
            "  0.20816247 -0.5392207 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6990769, dtype=float32), 'agent_0': Array(-1.6990769, dtype=float32), 'agent_1': Array(-1.6990769, dtype=float32), 'agent_2': Array(-1.6990769, dtype=float32), 'agent_3': Array(-1.6990769, dtype=float32)}\n",
            "step: 81\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.5186036e-01,  9.8761821e-01, -5.3172134e-02,  1.4757864e-01,\n",
            "       -1.8877053e-03,  5.4831845e-01,  6.3232470e-01,  3.2121333e-01,\n",
            "        5.4763609e-01,  4.9003404e-01,  7.4095428e-01, -3.9353371e-01,\n",
            "        3.7086010e-02, -1.8083766e+00,  1.6746364e+00,  1.2977448e-01,\n",
            "        1.8390909e-02, -7.3418179e+00], dtype=float32), 'agent_1': Array([ 6.5186036e-01,  9.8761821e-01, -5.3172134e-02,  1.4757864e-01,\n",
            "       -1.8877053e-03,  5.4831845e-01,  3.2121333e-01, -1.1397611e+00,\n",
            "        5.4763609e-01,  4.9003404e-01,  7.4095428e-01, -3.9353371e-01,\n",
            "        3.7086010e-02, -1.8083766e+00,  1.6746364e+00,  1.2977448e-01,\n",
            "       -5.2831465e-01, -8.5948238e+00], dtype=float32), 'agent_2': Array([ 6.5186036e-01,  9.8761821e-01, -5.3172134e-02,  1.4757864e-01,\n",
            "       -1.8877053e-03,  5.4831845e-01,  3.2121333e-01,  5.4763609e-01,\n",
            "       -1.2564540e+00,  4.9003404e-01,  7.4095428e-01, -3.9353371e-01,\n",
            "        3.7086010e-02, -1.8083766e+00,  1.6746364e+00,  1.2977448e-01,\n",
            "       -3.4561502e-03, -9.1379023e+00], dtype=float32), 'agent_3': Array([ 6.5186036e-01,  9.8761821e-01, -5.3172134e-02,  1.4757864e-01,\n",
            "       -1.8877053e-03,  5.4831845e-01,  3.2121333e-01,  5.4763609e-01,\n",
            "        4.9003404e-01,  4.7804654e-01,  7.4095428e-01, -3.9353371e-01,\n",
            "        3.7086010e-02, -1.8083766e+00,  1.6746364e+00,  1.2977448e-01,\n",
            "       -2.2694647e+00, -2.5180247e-01], dtype=float32)}\n",
            "ctrl action chosen: [1.4105269  0.1271825  1.4104712  0.1289663  1.4144304  0.12486168\n",
            " 1.4054387  0.13648751]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0841113, dtype=float32), 'agent_0': Array(1.0841113, dtype=float32), 'agent_1': Array(1.0841113, dtype=float32), 'agent_2': Array(1.0841113, dtype=float32), 'agent_3': Array(1.0841113, dtype=float32)}\n",
            "step: 82\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6501025 ,  0.9839143 , -0.06872382,  0.15928833, -0.04262733,\n",
            "        0.5814277 ,  0.508482  ,  0.5057499 ,  0.5653944 ,  0.54214066,\n",
            "        0.8466676 , -0.05395412, -0.39920807,  0.00873603, -0.03223951,\n",
            "       -1.5511603 , -0.45534593,  0.98408115], dtype=float32), 'agent_1': Array([ 0.6501025 ,  0.9839143 , -0.06872382,  0.15928833, -0.04262733,\n",
            "        0.5814277 ,  0.5057499 , -1.256148  ,  0.5653944 ,  0.54214066,\n",
            "        0.8466676 , -0.05395412, -0.39920807,  0.00873603, -0.03223951,\n",
            "       -1.5511603 ,  5.127755  ,  0.3663682 ], dtype=float32), 'agent_2': Array([ 0.6501025 ,  0.9839143 , -0.06872382,  0.15928833, -0.04262733,\n",
            "        0.5814277 ,  0.5057499 ,  0.5653944 , -1.2415955 ,  0.54214066,\n",
            "        0.8466676 , -0.05395412, -0.39920807,  0.00873603, -0.03223951,\n",
            "       -1.5511603 , -0.70656484,  0.6995334 ], dtype=float32), 'agent_3': Array([ 0.6501025 ,  0.9839143 , -0.06872382,  0.15928833, -0.04262733,\n",
            "        0.5814277 ,  0.5057499 ,  0.5653944 ,  0.54214066,  0.53320754,\n",
            "        0.8466676 , -0.05395412, -0.39920807,  0.00873603, -0.03223951,\n",
            "       -1.5511603 ,  1.3121018 ,  1.6210551 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.19100767 -1.2655308  -0.18718693 -1.2708251  -0.18801177 -1.270589\n",
            " -0.19026081 -1.2666053 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.1502192, dtype=float32), 'agent_0': Array(-2.1502192, dtype=float32), 'agent_1': Array(-2.1502192, dtype=float32), 'agent_2': Array(-2.1502192, dtype=float32), 'agent_3': Array(-2.1502192, dtype=float32)}\n",
            "step: 83\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1192298e-01,  9.8135430e-01, -6.9922060e-02,  1.7903845e-01,\n",
            "        2.3499125e-04,  3.5529506e-01,  4.6913552e-01,  5.3232020e-01,\n",
            "        3.3365813e-01,  4.2985696e-01,  7.2342342e-01, -1.7900467e-01,\n",
            "       -8.2465410e-01, -5.6961495e-02,  5.7807691e-02,  2.6315606e+00,\n",
            "       -6.0338254e+00, -2.0171338e-01], dtype=float32), 'agent_1': Array([ 6.1192298e-01,  9.8135430e-01, -6.9922060e-02,  1.7903845e-01,\n",
            "        2.3499125e-04,  3.5529506e-01,  5.3232020e-01, -1.2637146e+00,\n",
            "        3.3365813e-01,  4.2985696e-01,  7.2342342e-01, -1.7900467e-01,\n",
            "       -8.2465410e-01, -5.6961495e-02,  5.7807691e-02,  2.6315606e+00,\n",
            "       -7.2147739e-01,  1.5409219e+00], dtype=float32), 'agent_2': Array([ 6.1192298e-01,  9.8135430e-01, -6.9922060e-02,  1.7903845e-01,\n",
            "        2.3499125e-04,  3.5529506e-01,  5.3232020e-01,  3.3365813e-01,\n",
            "       -1.2442608e+00,  4.2985696e-01,  7.2342342e-01, -1.7900467e-01,\n",
            "       -8.2465410e-01, -5.6961495e-02,  5.7807691e-02,  2.6315606e+00,\n",
            "       -5.7768750e+00,  7.1134531e-01], dtype=float32), 'agent_3': Array([ 6.1192298e-01,  9.8135430e-01, -6.9922060e-02,  1.7903845e-01,\n",
            "        2.3499125e-04,  3.5529506e-01,  5.3232020e-01,  3.3365813e-01,\n",
            "        4.2985696e-01,  4.9814156e-01,  7.2342342e-01, -1.7900467e-01,\n",
            "       -8.2465410e-01, -5.6961495e-02,  5.7807691e-02,  2.6315606e+00,\n",
            "       -3.3893752e+00, -2.3227638e-02], dtype=float32)}\n",
            "ctrl action chosen: [0.8524637  0.6134223  0.8577648  0.6170355  0.85528296 0.6111526\n",
            " 0.8531571  0.61330384]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5970786, dtype=float32), 'agent_0': Array(-1.5970786, dtype=float32), 'agent_1': Array(-1.5970786, dtype=float32), 'agent_2': Array(-1.5970786, dtype=float32), 'agent_3': Array(-1.5970786, dtype=float32)}\n",
            "step: 84\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60188204,  0.98849314, -0.05177841,  0.13240741, -0.05165972,\n",
            "        0.493721  ,  0.6471758 ,  0.59735763,  0.42684904,  0.56243604,\n",
            "        0.73095345, -0.09980202, -0.1679182 ,  1.4713527 , -1.9898183 ,\n",
            "       -1.5864722 ,  4.1799674 ,  4.5156503 ], dtype=float32), 'agent_1': Array([ 0.60188204,  0.98849314, -0.05177841,  0.13240741, -0.05165972,\n",
            "        0.493721  ,  0.59735763, -0.9060459 ,  0.42684904,  0.56243604,\n",
            "        0.73095345, -0.09980202, -0.1679182 ,  1.4713527 , -1.9898183 ,\n",
            "       -1.5864722 , -0.7006946 ,  9.037159  ], dtype=float32), 'agent_2': Array([ 0.60188204,  0.98849314, -0.05177841,  0.13240741, -0.05165972,\n",
            "        0.493721  ,  0.59735763,  0.42684904, -0.9227323 ,  0.56243604,\n",
            "        0.73095345, -0.09980202, -0.1679182 ,  1.4713527 , -1.9898183 ,\n",
            "       -1.5864722 ,  2.6688273 ,  7.902336  ], dtype=float32), 'agent_3': Array([ 0.60188204,  0.98849314, -0.05177841,  0.13240741, -0.05165972,\n",
            "        0.493721  ,  0.59735763,  0.42684904,  0.56243604,  0.7071823 ,\n",
            "        0.73095345, -0.09980202, -0.1679182 ,  1.4713527 , -1.9898183 ,\n",
            "       -1.5864722 ,  1.6481308 ,  4.8887568 ], dtype=float32)}\n",
            "ctrl action chosen: [0.9587178  0.01156982 0.95586276 0.01600203 0.95881784 0.01402458\n",
            " 0.9587143  0.01508907]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5187297, dtype=float32), 'agent_0': Array(-0.5187297, dtype=float32), 'agent_1': Array(-0.5187297, dtype=float32), 'agent_2': Array(-0.5187297, dtype=float32), 'agent_3': Array(-0.5187297, dtype=float32)}\n",
            "step: 85\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5928062 ,  0.9912499 , -0.034783  ,  0.10741569, -0.06837926,\n",
            "        0.5882467 ,  0.74588084,  0.49520388,  0.5616423 ,  0.5463194 ,\n",
            "        0.31865275,  0.11603832, -0.02717972,  0.61394346, -0.83895147,\n",
            "        0.05491978,  0.2351317 ,  0.97597724], dtype=float32), 'agent_1': Array([ 0.5928062 ,  0.9912499 , -0.034783  ,  0.10741569, -0.06837926,\n",
            "        0.5882467 ,  0.49520388, -0.6586168 ,  0.5616423 ,  0.5463194 ,\n",
            "        0.31865275,  0.11603832, -0.02717972,  0.61394346, -0.83895147,\n",
            "        0.05491978, -1.8964436 ,  3.5399683 ], dtype=float32), 'agent_2': Array([ 0.5928062 ,  0.9912499 , -0.034783  ,  0.10741569, -0.06837926,\n",
            "        0.5882467 ,  0.49520388,  0.5616423 , -0.72968405,  0.5463194 ,\n",
            "        0.31865275,  0.11603832, -0.02717972,  0.61394346, -0.83895147,\n",
            "        0.05491978,  1.6013685 ,  2.5341432 ], dtype=float32), 'agent_3': Array([ 0.5928062 ,  0.9912499 , -0.034783  ,  0.10741569, -0.06837926,\n",
            "        0.5882467 ,  0.49520388,  0.5616423 ,  0.5463194 ,  0.7770339 ,\n",
            "        0.31865275,  0.11603832, -0.02717972,  0.61394346, -0.83895147,\n",
            "        0.05491978, -1.4072009 ,  0.09579987], dtype=float32)}\n",
            "ctrl action chosen: [1.2376902 1.4520515 1.2342234 1.4567351 1.2409357 1.4486533 1.2335865\n",
            " 1.4508052]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.38676763, dtype=float32), 'agent_0': Array(-0.38676763, dtype=float32), 'agent_1': Array(-0.38676763, dtype=float32), 'agent_2': Array(-0.38676763, dtype=float32), 'agent_3': Array(-0.38676763, dtype=float32)}\n",
            "step: 86\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.9638292e-01,  9.9644256e-01,  3.3285208e-03,  4.8352953e-02,\n",
            "       -6.8943232e-02,  5.6028950e-01,  1.0824898e+00,  4.8864093e-01,\n",
            "        5.9247196e-01,  5.2600580e-01,  6.8999976e-01,  4.6834946e-01,\n",
            "        1.4889240e-02,  1.4584167e+00, -1.7211678e+00, -4.1657460e-01,\n",
            "       -5.6437021e-01,  9.1710463e+00], dtype=float32), 'agent_1': Array([ 0.5963829 ,  0.99644256,  0.00332852,  0.04835295, -0.06894323,\n",
            "        0.5602895 ,  0.48864093, -0.44312552,  0.59247196,  0.5260058 ,\n",
            "        0.68999976,  0.46834946,  0.01488924,  1.4584167 , -1.7211678 ,\n",
            "       -0.4165746 ,  2.2192366 , -1.0086844 ], dtype=float32), 'agent_2': Array([ 0.5963829 ,  0.99644256,  0.00332852,  0.04835295, -0.06894323,\n",
            "        0.5602895 ,  0.48864093,  0.59247196, -0.43484774,  0.5260058 ,\n",
            "        0.68999976,  0.46834946,  0.01488924,  1.4584167 , -1.7211678 ,\n",
            "       -0.4165746 , -0.12200443,  0.5577761 ], dtype=float32), 'agent_3': Array([ 5.9638292e-01,  9.9644256e-01,  3.3285208e-03,  4.8352953e-02,\n",
            "       -6.8943232e-02,  5.6028950e-01,  4.8864093e-01,  5.9247196e-01,\n",
            "        5.2600580e-01,  1.0294499e+00,  6.8999976e-01,  4.6834946e-01,\n",
            "        1.4889240e-02,  1.4584167e+00, -1.7211678e+00, -4.1657460e-01,\n",
            "        7.1969503e-01,  6.3073449e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.5817735  2.0949798  0.58814806 2.086383   0.5878242  2.08724\n",
            " 0.58330625 2.0955925 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.745467, dtype=float32), 'agent_0': Array(-5.745467, dtype=float32), 'agent_1': Array(-5.745467, dtype=float32), 'agent_2': Array(-5.745467, dtype=float32), 'agent_3': Array(-5.745467, dtype=float32)}\n",
            "step: 87\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63663954,  0.99753   ,  0.00870824,  0.00432691, -0.06956572,\n",
            "        0.5253009 ,  1.2901357 ,  0.56928915,  0.51926625,  0.53682786,\n",
            "        0.9807989 , -0.18844604,  1.2257695 , -0.27787855, -1.526912  ,\n",
            "       -0.10398142, -0.01087797, -0.15305687], dtype=float32), 'agent_1': Array([ 0.63663954,  0.99753   ,  0.00870824,  0.00432691, -0.06956572,\n",
            "        0.5253009 ,  0.56928915, -0.46976167,  0.51926625,  0.53682786,\n",
            "        0.9807989 , -0.18844604,  1.2257695 , -0.27787855, -1.526912  ,\n",
            "       -0.10398142,  0.94845366, -0.8913484 ], dtype=float32), 'agent_2': Array([ 0.63663954,  0.99753   ,  0.00870824,  0.00432691, -0.06956572,\n",
            "        0.5253009 ,  0.56928915,  0.51926625, -0.47630087,  0.53682786,\n",
            "        0.9807989 , -0.18844604,  1.2257695 , -0.27787855, -1.526912  ,\n",
            "       -0.10398142, -1.3531393 , -1.3770336 ], dtype=float32), 'agent_3': Array([ 0.63663954,  0.99753   ,  0.00870824,  0.00432691, -0.06956572,\n",
            "        0.5253009 ,  0.56928915,  0.51926625,  0.53682786,  1.2868482 ,\n",
            "        0.9807989 , -0.18844604,  1.2257695 , -0.27787855, -1.526912  ,\n",
            "       -0.10398142,  0.2190297 ,  1.7567867 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0746708 -1.1691406 -1.0727174 -1.1707729 -1.0752499 -1.1740367\n",
            " -1.0758792 -1.1655918]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.463323, dtype=float32), 'agent_0': Array(-7.463323, dtype=float32), 'agent_1': Array(-7.463323, dtype=float32), 'agent_2': Array(-7.463323, dtype=float32), 'agent_3': Array(-7.463323, dtype=float32)}\n",
            "step: 88\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.5959209e-01,  9.8520863e-01, -8.8118156e-03,  2.6769143e-02,\n",
            "        1.6902569e-01, -8.6752176e-02,  1.0735434e+00,  3.8826838e-02,\n",
            "       -1.5701576e-01, -1.7223826e-02,  3.7718713e-01, -3.3907890e-01,\n",
            "       -1.4311075e-01, -6.2178689e-01,  1.6695727e+00,  1.2479232e+01,\n",
            "       -1.6125059e+01, -6.9742832e+00], dtype=float32), 'agent_1': Array([ 6.5959209e-01,  9.8520863e-01, -8.8118156e-03,  2.6769143e-02,\n",
            "        1.6902569e-01, -8.6752176e-02,  3.8826838e-02, -9.4282293e-01,\n",
            "       -1.5701576e-01, -1.7223826e-02,  3.7718713e-01, -3.3907890e-01,\n",
            "       -1.4311075e-01, -6.2178689e-01,  1.6695727e+00,  1.2479232e+01,\n",
            "       -1.5266348e+01, -1.2901832e+01], dtype=float32), 'agent_2': Array([ 6.59592092e-01,  9.85208631e-01, -8.81181564e-03,  2.67691426e-02,\n",
            "        1.69025689e-01, -8.67521763e-02,  3.88268381e-02, -1.57015756e-01,\n",
            "       -9.61143732e-01, -1.72238257e-02,  3.77187133e-01, -3.39078903e-01,\n",
            "       -1.43110752e-01, -6.21786892e-01,  1.66957271e+00,  1.24792318e+01,\n",
            "       -1.68706799e+01, -1.25356655e+01], dtype=float32), 'agent_3': Array([ 6.5959209e-01,  9.8520863e-01, -8.8118156e-03,  2.6769143e-02,\n",
            "        1.6902569e-01, -8.6752176e-02,  3.8826838e-02, -1.5701576e-01,\n",
            "       -1.7223826e-02,  1.1029848e+00,  3.7718713e-01, -3.3907890e-01,\n",
            "       -1.4311075e-01, -6.2178689e-01,  1.6695727e+00,  1.2479232e+01,\n",
            "       -1.4700324e+01, -4.9784937e+00], dtype=float32)}\n",
            "ctrl action chosen: [-2.4863255   0.45999312 -2.486818    0.45728126 -2.486989    0.45791927\n",
            " -2.486893    0.45984432]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.496564, dtype=float32), 'agent_0': Array(-3.496564, dtype=float32), 'agent_1': Array(-3.496564, dtype=float32), 'agent_2': Array(-3.496564, dtype=float32), 'agent_3': Array(-3.496564, dtype=float32)}\n",
            "step: 89\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63874745,  0.9329478 , -0.01639552,  0.01904718,  0.3591334 ,\n",
            "       -0.5887665 ,  0.9323832 , -0.532953  , -0.61765134, -0.54377323,\n",
            "        0.5616665 , -0.05381107, -0.57718754, -0.6071897 , -0.5869481 ,\n",
            "       -0.744461  ,  1.3333288 , -1.2122467 ], dtype=float32), 'agent_1': Array([ 0.63874745,  0.9329478 , -0.01639552,  0.01904718,  0.3591334 ,\n",
            "       -0.5887665 , -0.532953  , -1.1799979 , -0.61765134, -0.54377323,\n",
            "        0.5616665 , -0.05381107, -0.57718754, -0.6071897 , -0.5869481 ,\n",
            "       -0.744461  , -2.258194  , -2.2549565 ], dtype=float32), 'agent_2': Array([ 0.63874745,  0.9329478 , -0.01639552,  0.01904718,  0.3591334 ,\n",
            "       -0.5887665 , -0.532953  , -0.61765134, -1.168479  , -0.54377323,\n",
            "        0.5616665 , -0.05381107, -0.57718754, -0.6071897 , -0.5869481 ,\n",
            "       -0.744461  ,  2.5812593 , -1.6859227 ], dtype=float32), 'agent_3': Array([ 0.63874745,  0.9329478 , -0.01639552,  0.01904718,  0.3591334 ,\n",
            "       -0.5887665 , -0.532953  , -0.61765134, -0.54377323,  1.0414613 ,\n",
            "        0.5616665 , -0.05381107, -0.57718754, -0.6071897 , -0.5869481 ,\n",
            "       -0.744461  , -1.0839338 , -0.9349979 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.68226725 -1.3966808   0.6722713  -1.3963398   0.68047833 -1.3979692\n",
            "  0.6764456  -1.3942277 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-11.2513275, dtype=float32), 'agent_0': Array(-11.2513275, dtype=float32), 'agent_1': Array(-11.2513275, dtype=float32), 'agent_2': Array(-11.2513275, dtype=float32), 'agent_3': Array(-11.2513275, dtype=float32)}\n",
            "step: 90\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6131672 ,  0.9763848 , -0.02371187,  0.0350854 ,  0.21184756,\n",
            "       -0.1828597 ,  0.5615839 , -0.27261373, -0.15064678, -0.24553768,\n",
            "        0.42341948, -0.24254322, -0.8824825 , -0.29281345,  0.07255267,\n",
            "       -9.751467  , 12.736994  , -8.389372  ], dtype=float32), 'agent_1': Array([ 0.6131672 ,  0.9763848 , -0.02371187,  0.0350854 ,  0.21184756,\n",
            "       -0.1828597 , -0.27261373, -1.2929568 , -0.15064678, -0.24553768,\n",
            "        0.42341948, -0.24254322, -0.8824825 , -0.29281345,  0.07255267,\n",
            "       -9.751467  ,  9.518446  ,  1.4379146 ], dtype=float32), 'agent_2': Array([ 0.6131672 ,  0.9763848 , -0.02371187,  0.0350854 ,  0.21184756,\n",
            "       -0.1828597 , -0.27261373, -0.15064678, -1.2934766 , -0.24553768,\n",
            "        0.42341948, -0.24254322, -0.8824825 , -0.29281345,  0.07255267,\n",
            "       -9.751467  , 14.6490135 ,  1.1163285 ], dtype=float32), 'agent_3': Array([ 0.6131672 ,  0.9763848 , -0.02371187,  0.0350854 ,  0.21184756,\n",
            "       -0.1828597 , -0.27261373, -0.15064678, -0.24553768,  0.66264594,\n",
            "        0.42341948, -0.24254322, -0.8824825 , -0.29281345,  0.07255267,\n",
            "       -9.751467  , 10.442441  , -8.618247  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.199205   -0.20486367  0.20288298 -0.20311746  0.19905187 -0.20488825\n",
            "  0.19490449 -0.20623797]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.5087214, dtype=float32), 'agent_0': Array(-3.5087214, dtype=float32), 'agent_1': Array(-3.5087214, dtype=float32), 'agent_2': Array(-3.5087214, dtype=float32), 'agent_3': Array(-3.5087214, dtype=float32)}\n",
            "step: 91\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54978   ,  0.9972836 , -0.02286873,  0.01212803,  0.06896022,\n",
            "        0.19770263,  0.4911253 ,  0.01157369,  0.31105536,  0.05427334,\n",
            "        0.8122444 , -0.90646744, -0.79791546,  0.1677629 , -0.45323074,\n",
            "       -3.8003447 ,  5.2592444 , -0.83146214], dtype=float32), 'agent_1': Array([ 0.54978   ,  0.9972836 , -0.02286873,  0.01212803,  0.06896022,\n",
            "        0.19770263,  0.01157369, -1.190661  ,  0.31105536,  0.05427334,\n",
            "        0.8122444 , -0.90646744, -0.79791546,  0.1677629 , -0.45323074,\n",
            "       -3.8003447 ,  4.2004576 ,  2.0367763 ], dtype=float32), 'agent_2': Array([ 0.54978   ,  0.9972836 , -0.02286873,  0.01212803,  0.06896022,\n",
            "        0.19770263,  0.01157369,  0.31105536, -1.1915338 ,  0.05427334,\n",
            "        0.8122444 , -0.90646744, -0.79791546,  0.1677629 , -0.45323074,\n",
            "       -3.8003447 ,  6.522182  ,  2.2978742 ], dtype=float32), 'agent_3': Array([ 0.54978   ,  0.9972836 , -0.02286873,  0.01212803,  0.06896022,\n",
            "        0.19770263,  0.01157369,  0.31105536,  0.05427334,  0.48143288,\n",
            "        0.8122444 , -0.90646744, -0.79791546,  0.1677629 , -0.45323074,\n",
            "       -3.8003447 ,  3.8730822 , -1.2495769 ], dtype=float32)}\n",
            "ctrl action chosen: [-2.0734327  1.907948  -2.0716257  1.9106865 -2.0728917  1.9063191\n",
            " -2.074737   1.9067596]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.5401962, dtype=float32), 'agent_0': Array(1.5401962, dtype=float32), 'agent_1': Array(1.5401962, dtype=float32), 'agent_2': Array(1.5401962, dtype=float32), 'agent_3': Array(1.5401962, dtype=float32)}\n",
            "step: 92\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.56420296,   0.9609209 ,  -0.01881017,  -0.02687332,\n",
            "         0.27487305,  -0.28880534,   0.6796714 ,  -0.4829308 ,\n",
            "        -0.1391652 ,  -0.480602  ,   1.164943  ,  -1.0202408 ,\n",
            "         0.25203228,  -0.28901652,  -2.279079  ,  12.115068  ,\n",
            "       -14.666162  ,   7.341219  ], dtype=float32), 'agent_1': Array([  0.56420296,   0.9609209 ,  -0.01881017,  -0.02687332,\n",
            "         0.27487305,  -0.28880534,  -0.4829308 ,  -0.7353454 ,\n",
            "        -0.1391652 ,  -0.480602  ,   1.164943  ,  -1.0202408 ,\n",
            "         0.25203228,  -0.28901652,  -2.279079  ,  12.115068  ,\n",
            "       -14.506843  ,  10.225021  ], dtype=float32), 'agent_2': Array([  0.56420296,   0.9609209 ,  -0.01881017,  -0.02687332,\n",
            "         0.27487305,  -0.28880534,  -0.4829308 ,  -0.1391652 ,\n",
            "        -0.7650126 ,  -0.480602  ,   1.164943  ,  -1.0202408 ,\n",
            "         0.25203228,  -0.28901652,  -2.279079  ,  12.115068  ,\n",
            "       -14.306416  ,   9.401641  ], dtype=float32), 'agent_3': Array([  0.56420296,   0.9609209 ,  -0.01881017,  -0.02687332,\n",
            "         0.27487305,  -0.28880534,  -0.4829308 ,  -0.1391652 ,\n",
            "        -0.480602  ,   0.6227843 ,   1.164943  ,  -1.0202408 ,\n",
            "         0.25203228,  -0.28901652,  -2.279079  ,  12.115068  ,\n",
            "       -15.557641  ,   5.005521  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.1079144  -0.28402627 -0.10656825 -0.28312296 -0.10663991 -0.2835445\n",
            " -0.11048194 -0.28525364]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-13.799143, dtype=float32), 'agent_0': Array(-13.799143, dtype=float32), 'agent_1': Array(-13.799143, dtype=float32), 'agent_2': Array(-13.799143, dtype=float32), 'agent_3': Array(-13.799143, dtype=float32)}\n",
            "step: 93\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5427558 ,  0.9485394 , -0.01463775, -0.04614291,  0.31293738,\n",
            "       -0.435036  ,  0.8519028 , -0.5460061 , -0.24797978, -0.55265903,\n",
            "        0.8894026 , -1.1432886 , -0.6996155 , -0.03157291, -0.5287879 ,\n",
            "       -0.13136546, -0.6874191 ,  2.1686604 ], dtype=float32), 'agent_1': Array([ 0.5427558 ,  0.9485394 , -0.01463775, -0.04614291,  0.31293738,\n",
            "       -0.435036  , -0.5460061 , -0.5697725 , -0.24797978, -0.55265903,\n",
            "        0.8894026 , -1.1432886 , -0.6996155 , -0.03157291, -0.5287879 ,\n",
            "       -0.13136546,  1.2789533 ,  2.1512694 ], dtype=float32), 'agent_2': Array([ 0.5427558 ,  0.9485394 , -0.01463775, -0.04614291,  0.31293738,\n",
            "       -0.435036  , -0.5460061 , -0.24797978, -0.5827997 , -0.55265903,\n",
            "        0.8894026 , -1.1432886 , -0.6996155 , -0.03157291, -0.5287879 ,\n",
            "       -0.13136546,  0.3875937 ,  3.0283825 ], dtype=float32), 'agent_3': Array([ 0.5427558 ,  0.9485394 , -0.01463775, -0.04614291,  0.31293738,\n",
            "       -0.435036  , -0.5460061 , -0.24797978, -0.55265903,  0.7163316 ,\n",
            "        0.8894026 , -1.1432886 , -0.6996155 , -0.03157291, -0.5287879 ,\n",
            "       -0.13136546,  1.5272808 ,  1.795583  ], dtype=float32)}\n",
            "ctrl action chosen: [0.7365427  0.12567157 0.73957753 0.12316553 0.736766   0.12289058\n",
            " 0.7404008  0.12249567]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.775126, dtype=float32), 'agent_0': Array(1.775126, dtype=float32), 'agent_1': Array(1.775126, dtype=float32), 'agent_2': Array(1.775126, dtype=float32), 'agent_3': Array(1.775126, dtype=float32)}\n",
            "step: 94\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.02063096e-01,  9.90072191e-01,  1.64128467e-03, -6.88500404e-02,\n",
            "        1.22531734e-01, -8.36400688e-03,  1.02496898e+00, -1.71848871e-02,\n",
            "        2.35567510e-01, -4.36275825e-03,  9.45436954e-01, -1.15675926e+00,\n",
            "       -8.80527496e-01,  1.22788645e-01, -2.20312595e-01, -1.02278242e+01,\n",
            "        1.13000898e+01,  2.98026466e+00], dtype=float32), 'agent_1': Array([ 5.02063096e-01,  9.90072191e-01,  1.64128467e-03, -6.88500404e-02,\n",
            "        1.22531734e-01, -8.36400688e-03, -1.71848871e-02, -4.95789081e-01,\n",
            "        2.35567510e-01, -4.36275825e-03,  9.45436954e-01, -1.15675926e+00,\n",
            "       -8.80527496e-01,  1.22788645e-01, -2.20312595e-01, -1.02278242e+01,\n",
            "        1.35582705e+01, -1.00492370e+00], dtype=float32), 'agent_2': Array([ 5.02063096e-01,  9.90072191e-01,  1.64128467e-03, -6.88500404e-02,\n",
            "        1.22531734e-01, -8.36400688e-03, -1.71848871e-02,  2.35567510e-01,\n",
            "       -4.98075098e-01, -4.36275825e-03,  9.45436954e-01, -1.15675926e+00,\n",
            "       -8.80527496e-01,  1.22788645e-01, -2.20312595e-01, -1.02278242e+01,\n",
            "        1.21703634e+01, -1.22159779e+00], dtype=float32), 'agent_3': Array([ 5.02063096e-01,  9.90072191e-01,  1.64128467e-03, -6.88500404e-02,\n",
            "        1.22531734e-01, -8.36400688e-03, -1.71848871e-02,  2.35567510e-01,\n",
            "       -4.36275825e-03,  8.81105304e-01,  9.45436954e-01, -1.15675926e+00,\n",
            "       -8.80527496e-01,  1.22788645e-01, -2.20312595e-01, -1.02278242e+01,\n",
            "        1.40685329e+01,  2.82309723e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.3598896  -0.15199357 -0.36427513 -0.15157798 -0.36329204 -0.15292057\n",
            " -0.36291164 -0.15328594]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.858436, dtype=float32), 'agent_0': Array(0.858436, dtype=float32), 'agent_1': Array(0.858436, dtype=float32), 'agent_2': Array(0.858436, dtype=float32), 'agent_3': Array(0.858436, dtype=float32)}\n",
            "step: 95\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.46532315,  0.9913401 ,  0.00607511, -0.05997087,  0.11666834,\n",
            "       -0.02739861,  1.0103602 ,  0.05093575,  0.25636488,  0.08898309,\n",
            "        0.49872398, -0.79329014, -0.16029477,  0.45572916,  0.78941125,\n",
            "        2.3420978 , -3.651076  , -1.9928485 ], dtype=float32), 'agent_1': Array([ 0.46532315,  0.9913401 ,  0.00607511, -0.05997087,  0.11666834,\n",
            "       -0.02739861,  0.05093575, -0.5504528 ,  0.25636488,  0.08898309,\n",
            "        0.49872398, -0.79329014, -0.16029477,  0.45572916,  0.78941125,\n",
            "        2.3420978 , -2.5733125 , -1.2213962 ], dtype=float32), 'agent_2': Array([ 0.46532315,  0.9913401 ,  0.00607511, -0.05997087,  0.11666834,\n",
            "       -0.02739861,  0.05093575,  0.25636488, -0.5859564 ,  0.08898309,\n",
            "        0.49872398, -0.79329014, -0.16029477,  0.45572916,  0.78941125,\n",
            "        2.3420978 , -3.0134048 , -2.2006776 ], dtype=float32), 'agent_3': Array([ 0.46532315,  0.9913401 ,  0.00607511, -0.05997087,  0.11666834,\n",
            "       -0.02739861,  0.05093575,  0.25636488,  0.08898309,  0.8762983 ,\n",
            "        0.49872398, -0.79329014, -0.16029477,  0.45572916,  0.78941125,\n",
            "        2.3420978 , -1.7788438 , -1.0868099 ], dtype=float32)}\n",
            "ctrl action chosen: [0.99067736 1.5283816  0.9892983  1.5300534  0.9916755  1.5252366\n",
            " 0.98986477 1.5280168 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.4814558, dtype=float32), 'agent_0': Array(1.4814558, dtype=float32), 'agent_1': Array(1.4814558, dtype=float32), 'agent_2': Array(1.4814558, dtype=float32), 'agent_3': Array(1.4814558, dtype=float32)}\n",
            "step: 96\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4551618 ,  0.9946741 ,  0.04011066, -0.07878903, -0.05297969,\n",
            "        0.36984658,  1.1990092 ,  0.4935051 ,  0.6144154 ,  0.5564935 ,\n",
            "        1.09604   , -0.6138563 , -0.11352897,  1.0501469 , -1.2712358 ,\n",
            "       -4.5356703 ,  6.8925877 ,  5.5815253 ], dtype=float32), 'agent_1': Array([ 0.4551618 ,  0.9946741 ,  0.04011066, -0.07878903, -0.05297969,\n",
            "        0.36984658,  0.4935051 , -0.4643664 ,  0.6144154 ,  0.5564935 ,\n",
            "        1.09604   , -0.6138563 , -0.11352897,  1.0501469 , -1.2712358 ,\n",
            "       -4.5356703 ,  7.945536  ,  0.4909487 ], dtype=float32), 'agent_2': Array([ 0.4551618 ,  0.9946741 ,  0.04011066, -0.07878903, -0.05297969,\n",
            "        0.36984658,  0.4935051 ,  0.6144154 , -0.462025  ,  0.5564935 ,\n",
            "        1.09604   , -0.6138563 , -0.11352897,  1.0501469 , -1.2712358 ,\n",
            "       -4.5356703 ,  2.3009236 ,  1.0731242 ], dtype=float32), 'agent_3': Array([ 0.4551618 ,  0.9946741 ,  0.04011066, -0.07878903, -0.05297969,\n",
            "        0.36984658,  0.4935051 ,  0.6144154 ,  0.5564935 ,  1.1277391 ,\n",
            "        1.09604   , -0.6138563 , -0.11352897,  1.0501469 , -1.2712358 ,\n",
            "       -4.5356703 ,  6.647622  ,  6.565976  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.25386995 -0.6994791   0.25167954 -0.7024789   0.25462627 -0.7031264\n",
            "  0.25275344 -0.69793093]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.8710685, dtype=float32), 'agent_0': Array(-4.8710685, dtype=float32), 'agent_1': Array(-4.8710685, dtype=float32), 'agent_2': Array(-4.8710685, dtype=float32), 'agent_3': Array(-4.8710685, dtype=float32)}\n",
            "step: 97\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49778935,  0.9966099 ,  0.03425335, -0.06114934, -0.04308262,\n",
            "        0.47024858,  1.0664608 ,  0.55416715,  0.49758947,  0.54575133,\n",
            "        0.7208228 , -1.0769367 ,  1.1105537 , -0.38156676,  0.9425554 ,\n",
            "        0.63484025,  1.8632393 , -4.0071836 ], dtype=float32), 'agent_1': Array([ 0.49778935,  0.9966099 ,  0.03425335, -0.06114934, -0.04308262,\n",
            "        0.47024858,  0.55416715, -0.66819686,  0.49758947,  0.54575133,\n",
            "        0.7208228 , -1.0769367 ,  1.1105537 , -0.38156676,  0.9425554 ,\n",
            "        0.63484025, -0.20277499, -6.16308   ], dtype=float32), 'agent_2': Array([ 0.49778935,  0.9966099 ,  0.03425335, -0.06114934, -0.04308262,\n",
            "        0.47024858,  0.55416715,  0.49758947, -0.6160405 ,  0.54575133,\n",
            "        0.7208228 , -1.0769367 ,  1.1105537 , -0.38156676,  0.9425554 ,\n",
            "        0.63484025, -2.877158  , -4.094302  ], dtype=float32), 'agent_3': Array([ 0.49778935,  0.9966099 ,  0.03425335, -0.06114934, -0.04308262,\n",
            "        0.47024858,  0.55416715,  0.49758947,  0.54575133,  0.98371994,\n",
            "        0.7208228 , -1.0769367 ,  1.1105537 , -0.38156676,  0.9425554 ,\n",
            "        0.63484025, -1.2501891 , -4.98186   ], dtype=float32)}\n",
            "ctrl action chosen: [0.6437884  0.35297015 0.64297915 0.35457146 0.6440337  0.35042673\n",
            " 0.6417376  0.35236672]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9425311, dtype=float32), 'agent_0': Array(0.9425311, dtype=float32), 'agent_1': Array(0.9425311, dtype=float32), 'agent_2': Array(0.9425311, dtype=float32), 'agent_3': Array(0.9425311, dtype=float32)}\n",
            "step: 98\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5365896 ,  0.9958836 ,  0.04489595, -0.06831033, -0.0391665 ,\n",
            "        0.578159  ,  1.1441181 ,  0.5369966 ,  0.47931075,  0.5266284 ,\n",
            "        0.76304674, -0.74260235,  0.7493496 ,  0.34803602, -0.5188064 ,\n",
            "       -0.09165031,  1.1785599 ,  2.1793091 ], dtype=float32), 'agent_1': Array([ 0.5365896 ,  0.9958836 ,  0.04489595, -0.06831033, -0.0391665 ,\n",
            "        0.578159  ,  0.5369966 , -0.7203432 ,  0.47931075,  0.5266284 ,\n",
            "        0.76304674, -0.74260235,  0.7493496 ,  0.34803602, -0.5188064 ,\n",
            "       -0.09165031, -0.25599864,  1.229687  ], dtype=float32), 'agent_2': Array([ 0.5365896 ,  0.9958836 ,  0.04489595, -0.06831033, -0.0391665 ,\n",
            "        0.578159  ,  0.5369966 ,  0.47931075, -0.60547197,  0.5266284 ,\n",
            "        0.76304674, -0.74260235,  0.7493496 ,  0.34803602, -0.5188064 ,\n",
            "       -0.09165031,  1.5436257 ,  2.055555  ], dtype=float32), 'agent_3': Array([ 0.5365896 ,  0.9958836 ,  0.04489595, -0.06831033, -0.0391665 ,\n",
            "        0.578159  ,  0.5369966 ,  0.47931075,  0.5266284 ,  1.021715  ,\n",
            "        0.76304674, -0.74260235,  0.7493496 ,  0.34803602, -0.5188064 ,\n",
            "       -0.09165031,  0.34680873,  1.9286606 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7784014   0.93495804 -0.780311    0.93660384 -0.7759068   0.93117505\n",
            " -0.78052384  0.9353699 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7976303, dtype=float32), 'agent_0': Array(0.7976303, dtype=float32), 'agent_1': Array(0.7976303, dtype=float32), 'agent_2': Array(0.7976303, dtype=float32), 'agent_3': Array(0.7976303, dtype=float32)}\n",
            "step: 99\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5634154 ,   0.9838641 ,   0.03125994,  -0.10630023,\n",
            "         0.14047949,   0.19072144,   1.2717898 ,   0.06913487,\n",
            "         0.06156942,   0.0786382 ,   0.731802  ,  -0.9751797 ,\n",
            "         0.32835007,  -0.95062053,  -0.67699814,   9.992623  ,\n",
            "       -11.581975  ,  -0.19064556], dtype=float32), 'agent_1': Array([  0.5634154 ,   0.9838641 ,   0.03125994,  -0.10630023,\n",
            "         0.14047949,   0.19072144,   0.06913487,  -0.46830574,\n",
            "         0.06156942,   0.0786382 ,   0.731802  ,  -0.9751797 ,\n",
            "         0.32835007,  -0.95062053,  -0.67699814,   9.992623  ,\n",
            "       -12.774005  ,   3.0545526 ], dtype=float32), 'agent_2': Array([  0.5634154 ,   0.9838641 ,   0.03125994,  -0.10630023,\n",
            "         0.14047949,   0.19072144,   0.06913487,   0.06156942,\n",
            "        -0.4706338 ,   0.0786382 ,   0.731802  ,  -0.9751797 ,\n",
            "         0.32835007,  -0.95062053,  -0.67699814,   9.992623  ,\n",
            "       -11.582886  ,  -0.5841727 ], dtype=float32), 'agent_3': Array([  0.5634154 ,   0.9838641 ,   0.03125994,  -0.10630023,\n",
            "         0.14047949,   0.19072144,   0.06913487,   0.06156942,\n",
            "         0.0786382 ,   1.272244  ,   0.731802  ,  -0.9751797 ,\n",
            "         0.32835007,  -0.95062053,  -0.67699814,   9.992623  ,\n",
            "       -12.335674  ,   3.8751278 ], dtype=float32)}\n",
            "ctrl action chosen: [1.4330144  0.43898547 1.433211   0.439558   1.4310485  0.43817425\n",
            " 1.4344599  0.43834627]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1889398, dtype=float32), 'agent_0': Array(-1.1889398, dtype=float32), 'agent_1': Array(-1.1889398, dtype=float32), 'agent_2': Array(-1.1889398, dtype=float32), 'agent_3': Array(-1.1889398, dtype=float32)}\n",
            "step: 100\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5675043 ,  0.994833  ,  0.04378179, -0.08963351,  0.018878  ,\n",
            "        0.5219929 ,  1.2507658 ,  0.34544814,  0.39809528,  0.37416035,\n",
            "        0.54137707, -0.63369274, -0.1601696 ,  0.46476912, -0.13639157,\n",
            "       -9.670786  , 12.468502  ,  0.10447547], dtype=float32), 'agent_1': Array([ 0.5675043 ,  0.994833  ,  0.04378179, -0.08963351,  0.018878  ,\n",
            "        0.5219929 ,  0.34544814, -0.49119407,  0.39809528,  0.37416035,\n",
            "        0.54137707, -0.63369274, -0.1601696 ,  0.46476912, -0.13639157,\n",
            "       -9.670786  , 11.841389  ,  0.19293019], dtype=float32), 'agent_2': Array([ 0.5675043 ,  0.994833  ,  0.04378179, -0.08963351,  0.018878  ,\n",
            "        0.5219929 ,  0.34544814,  0.39809528, -0.49705496,  0.37416035,\n",
            "        0.54137707, -0.63369274, -0.1601696 ,  0.46476912, -0.13639157,\n",
            "       -9.670786  , 13.100584  ,  0.29171887], dtype=float32), 'agent_3': Array([ 0.5675043 ,  0.994833  ,  0.04378179, -0.08963351,  0.018878  ,\n",
            "        0.5219929 ,  0.34544814,  0.39809528,  0.37416035,  1.2539479 ,\n",
            "        0.54137707, -0.63369274, -0.1601696 ,  0.46476912, -0.13639157,\n",
            "       -9.670786  , 12.139347  ,  0.08528575], dtype=float32)}\n",
            "ctrl action chosen: [ 1.2873267  -0.6404428   1.2872038  -0.639833    1.2871431  -0.64102376\n",
            "  1.2868909  -0.6410223 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0175905, dtype=float32), 'agent_0': Array(-3.0175905, dtype=float32), 'agent_1': Array(-3.0175905, dtype=float32), 'agent_2': Array(-3.0175905, dtype=float32), 'agent_3': Array(-3.0175905, dtype=float32)}\n",
            "step: 101\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5489589 ,  0.9968835 ,  0.03806447, -0.06105496, -0.03235457,\n",
            "        0.5569716 ,  1.0569556 ,  0.5541735 ,  0.57914317,  0.5659705 ,\n",
            "        0.29484034, -0.782156  , -0.5189657 , -0.9622084 ,  1.6744748 ,\n",
            "        0.85117114, -2.5083325 , -5.880335  ], dtype=float32), 'agent_1': Array([ 0.5489589 ,  0.9968835 ,  0.03806447, -0.06105496, -0.03235457,\n",
            "        0.5569716 ,  0.5541735 , -0.68281746,  0.57914317,  0.5659705 ,\n",
            "        0.29484034, -0.782156  , -0.5189657 , -0.9622084 ,  1.6744748 ,\n",
            "        0.85117114,  0.24588147, -6.1554255 ], dtype=float32), 'agent_2': Array([ 0.5489589 ,  0.9968835 ,  0.03806447, -0.06105496, -0.03235457,\n",
            "        0.5569716 ,  0.5541735 ,  0.57914317, -0.6933755 ,  0.5659705 ,\n",
            "        0.29484034, -0.782156  , -0.5189657 , -0.9622084 ,  1.6744748 ,\n",
            "        0.85117114, -0.47283223, -5.5189023 ], dtype=float32), 'agent_3': Array([ 0.5489589 ,  0.9968835 ,  0.03806447, -0.06105496, -0.03235457,\n",
            "        0.5569716 ,  0.5541735 ,  0.57914317,  0.5659705 ,  1.056067  ,\n",
            "        0.29484034, -0.782156  , -0.5189657 , -0.9622084 ,  1.6744748 ,\n",
            "        0.85117114, -0.15625696, -6.009914  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8300007  -1.1727029   0.8301323  -1.170129    0.83296126 -1.1742742\n",
            "  0.83070034 -1.1723334 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8238246, dtype=float32), 'agent_0': Array(-2.8238246, dtype=float32), 'agent_1': Array(-2.8238246, dtype=float32), 'agent_2': Array(-2.8238246, dtype=float32), 'agent_3': Array(-2.8238246, dtype=float32)}\n",
            "step: 102\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5116862e-01,  9.9948823e-01, -7.9772454e-03,  2.8266210e-02,\n",
            "       -1.2675961e-02,  4.7785014e-01,  5.0194091e-01,  5.4639500e-01,\n",
            "        5.4478258e-01,  5.4036677e-01,  1.3279915e-02, -9.8211765e-01,\n",
            "        1.0148287e-01, -2.1674573e+00,  4.6801605e+00,  2.3967646e-02,\n",
            "        8.6601245e-01, -1.2779343e+01], dtype=float32), 'agent_1': Array([ 5.5116862e-01,  9.9948823e-01, -7.9772454e-03,  2.8266210e-02,\n",
            "       -1.2675961e-02,  4.7785014e-01,  5.4639500e-01, -1.1711382e+00,\n",
            "        5.4478258e-01,  5.4036677e-01,  1.3279915e-02, -9.8211765e-01,\n",
            "        1.0148287e-01, -2.1674573e+00,  4.6801605e+00,  2.3967646e-02,\n",
            "        6.7612469e-02, -1.1520114e+01], dtype=float32), 'agent_2': Array([ 5.5116862e-01,  9.9948823e-01, -7.9772454e-03,  2.8266210e-02,\n",
            "       -1.2675961e-02,  4.7785014e-01,  5.4639500e-01,  5.4478258e-01,\n",
            "       -1.1290970e+00,  5.4036677e-01,  1.3279915e-02, -9.8211765e-01,\n",
            "        1.0148287e-01, -2.1674573e+00,  4.6801605e+00,  2.3967646e-02,\n",
            "        2.5268441e-01, -9.9297600e+00], dtype=float32), 'agent_3': Array([ 5.5116862e-01,  9.9948823e-01, -7.9772454e-03,  2.8266210e-02,\n",
            "       -1.2675961e-02,  4.7785014e-01,  5.4639500e-01,  5.4478258e-01,\n",
            "        5.4036677e-01,  5.1473975e-01,  1.3279915e-02, -9.8211765e-01,\n",
            "        1.0148287e-01, -2.1674573e+00,  4.6801605e+00,  2.3967646e-02,\n",
            "        2.8245881e-01, -1.3449689e+01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.7709631  -0.00164732  0.770445    0.0011474   0.7714856  -0.00286403\n",
            "  0.77147436 -0.00131384]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0731654, dtype=float32), 'agent_0': Array(-3.0731654, dtype=float32), 'agent_1': Array(-3.0731654, dtype=float32), 'agent_2': Array(-3.0731654, dtype=float32), 'agent_3': Array(-3.0731654, dtype=float32)}\n",
            "step: 103\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.556109  ,  0.998218  , -0.01692684,  0.05518205, -0.01514486,\n",
            "        0.5687623 ,  0.5045983 ,  0.5336348 ,  0.54836327,  0.5406119 ,\n",
            "        0.6277561 , -0.6017685 ,  0.4173875 , -0.12582678,  0.5324249 ,\n",
            "        0.18306628,  0.84038055,  0.63615763], dtype=float32), 'agent_1': Array([ 0.556109  ,  0.998218  , -0.01692684,  0.05518205, -0.01514486,\n",
            "        0.5687623 ,  0.5336348 , -1.222507  ,  0.54836327,  0.5406119 ,\n",
            "        0.6277561 , -0.6017685 ,  0.4173875 , -0.12582678,  0.5324249 ,\n",
            "        0.18306628, -0.25525346,  0.7951685 ], dtype=float32), 'agent_2': Array([ 0.556109  ,  0.998218  , -0.01692684,  0.05518205, -0.01514486,\n",
            "        0.5687623 ,  0.5336348 ,  0.54836327, -1.2365432 ,  0.5406119 ,\n",
            "        0.6277561 , -0.6017685 ,  0.4173875 , -0.12582678,  0.5324249 ,\n",
            "        0.18306628, -0.44871378,  0.4553031 ], dtype=float32), 'agent_3': Array([ 0.556109  ,  0.998218  , -0.01692684,  0.05518205, -0.01514486,\n",
            "        0.5687623 ,  0.5336348 ,  0.54836327,  0.5406119 ,  0.5047256 ,\n",
            "        0.6277561 , -0.6017685 ,  0.4173875 , -0.12582678,  0.5324249 ,\n",
            "        0.18306628, -0.31526   ,  0.9020334 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.06002133 -0.3346712  -0.06067202 -0.3299358  -0.05635958 -0.33989206\n",
            " -0.06212583 -0.332692  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.33307087, dtype=float32), 'agent_0': Array(0.33307087, dtype=float32), 'agent_1': Array(0.33307087, dtype=float32), 'agent_2': Array(0.33307087, dtype=float32), 'agent_3': Array(0.33307087, dtype=float32)}\n",
            "step: 104\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5699064 ,  0.9950874 , -0.02264878,  0.09142008,  0.03050384,\n",
            "        0.5047387 ,  0.5259821 ,  0.4293248 ,  0.422404  ,  0.42453417,\n",
            "        0.4327178 , -0.49581528, -0.15484095,  0.00907997,  0.93086785,\n",
            "        1.8103226 , -1.6831042 ,  0.64003307], dtype=float32), 'agent_1': Array([ 0.5699064 ,  0.9950874 , -0.02264878,  0.09142008,  0.03050384,\n",
            "        0.5047387 ,  0.4293248 , -1.2412801 ,  0.422404  ,  0.42453417,\n",
            "        0.4327178 , -0.49581528, -0.15484095,  0.00907997,  0.93086785,\n",
            "        1.8103226 , -1.8746886 ,  0.59284735], dtype=float32), 'agent_2': Array([ 0.5699064 ,  0.9950874 , -0.02264878,  0.09142008,  0.03050384,\n",
            "        0.5047387 ,  0.4293248 ,  0.422404  , -1.2475905 ,  0.42453417,\n",
            "        0.4327178 , -0.49581528, -0.15484095,  0.00907997,  0.93086785,\n",
            "        1.8103226 , -2.6269453 ,  1.0575594 ], dtype=float32), 'agent_3': Array([ 0.5699064 ,  0.9950874 , -0.02264878,  0.09142008,  0.03050384,\n",
            "        0.5047387 ,  0.4293248 ,  0.422404  ,  0.42453417,  0.52346206,\n",
            "        0.4327178 , -0.49581528, -0.15484095,  0.00907997,  0.93086785,\n",
            "        1.8103226 , -2.1692529 ,  0.81677556], dtype=float32)}\n",
            "ctrl action chosen: [-0.5906183   0.71988624 -0.59044856  0.7221166  -0.58622134  0.71616334\n",
            " -0.5912432   0.7202458 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1801442, dtype=float32), 'agent_0': Array(1.1801442, dtype=float32), 'agent_1': Array(1.1801442, dtype=float32), 'agent_2': Array(1.1801442, dtype=float32), 'agent_3': Array(1.1801442, dtype=float32)}\n",
            "step: 105\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.56223452e-01,  9.78802025e-01,  1.70597516e-03,  7.33725652e-02,\n",
            "        1.91207379e-01,  1.22304164e-01,  8.40060353e-01,  4.46132384e-02,\n",
            "        1.25717195e-02,  2.71232035e-02,  9.59575176e-01, -4.48989868e-01,\n",
            "        1.16229057e-02,  2.72745211e-02, -1.95638084e+00,  7.73612690e+00,\n",
            "       -9.23153591e+00,  7.62715769e+00], dtype=float32), 'agent_1': Array([ 5.56223452e-01,  9.78802025e-01,  1.70597516e-03,  7.33725652e-02,\n",
            "        1.91207379e-01,  1.22304164e-01,  4.46132384e-02, -9.59351540e-01,\n",
            "        1.25717195e-02,  2.71232035e-02,  9.59575176e-01, -4.48989868e-01,\n",
            "        1.16229057e-02,  2.72745211e-02, -1.95638084e+00,  7.73612690e+00,\n",
            "       -9.37457848e+00,  8.68600464e+00], dtype=float32), 'agent_2': Array([ 5.56223452e-01,  9.78802025e-01,  1.70597516e-03,  7.33725652e-02,\n",
            "        1.91207379e-01,  1.22304164e-01,  4.46132384e-02,  1.25717195e-02,\n",
            "       -9.43330050e-01,  2.71232035e-02,  9.59575176e-01, -4.48989868e-01,\n",
            "        1.16229057e-02,  2.72745211e-02, -1.95638084e+00,  7.73612690e+00,\n",
            "       -9.84298134e+00,  9.12480354e+00], dtype=float32), 'agent_3': Array([ 5.56223452e-01,  9.78802025e-01,  1.70597516e-03,  7.33725652e-02,\n",
            "        1.91207379e-01,  1.22304164e-01,  4.46132384e-02,  1.25717195e-02,\n",
            "        2.71232035e-02,  7.82995522e-01,  9.59575176e-01, -4.48989868e-01,\n",
            "        1.16229057e-02,  2.72745211e-02, -1.95638084e+00,  7.73612690e+00,\n",
            "       -9.84540367e+00,  5.74711323e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 2.575531  -2.1267385  2.5766523 -2.1259987  2.5764556 -2.1274862\n",
            "  2.572978  -2.1277704]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.0008595, dtype=float32), 'agent_0': Array(-0.0008595, dtype=float32), 'agent_1': Array(-0.0008595, dtype=float32), 'agent_2': Array(-0.0008595, dtype=float32), 'agent_3': Array(-0.0008595, dtype=float32)}\n",
            "step: 106\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.55902386,   0.99424803,  -0.02648652,   0.09786133,\n",
            "         0.03453473,   0.5215849 ,   0.7193042 ,   0.4352763 ,\n",
            "         0.38443798,   0.37512144,  -0.02146959,  -0.69231987,\n",
            "         0.15296936,  -0.904304  ,   2.3538477 , -10.412847  ,\n",
            "        13.345109  ,  -6.843106  ], dtype=float32), 'agent_1': Array([  0.55902386,   0.99424803,  -0.02648652,   0.09786133,\n",
            "         0.03453473,   0.5215849 ,   0.4352763 ,  -0.9905285 ,\n",
            "         0.38443798,   0.37512144,  -0.02146959,  -0.69231987,\n",
            "         0.15296936,  -0.904304  ,   2.3538477 , -10.412847  ,\n",
            "        13.165019  ,  -5.147838  ], dtype=float32), 'agent_2': Array([  0.55902386,   0.99424803,  -0.02648652,   0.09786133,\n",
            "         0.03453473,   0.5215849 ,   0.4352763 ,   0.38443798,\n",
            "        -0.97346294,   0.37512144,  -0.02146959,  -0.69231987,\n",
            "         0.15296936,  -0.904304  ,   2.3538477 , -10.412847  ,\n",
            "        12.883529  ,  -5.1091323 ], dtype=float32), 'agent_3': Array([  0.55902386,   0.99424803,  -0.02648652,   0.09786133,\n",
            "         0.03453473,   0.5215849 ,   0.4352763 ,   0.38443798,\n",
            "         0.37512144,   0.5629997 ,  -0.02146959,  -0.69231987,\n",
            "         0.15296936,  -0.904304  ,   2.3538477 , -10.412847  ,\n",
            "        12.699291  ,  -8.18199   ], dtype=float32)}\n",
            "ctrl action chosen: [0.8555838  1.8758003  0.85754114 1.8769174  0.8588938  1.8760495\n",
            " 0.8531464  1.8754408 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-20.888592, dtype=float32), 'agent_0': Array(-20.888592, dtype=float32), 'agent_1': Array(-20.888592, dtype=float32), 'agent_2': Array(-20.888592, dtype=float32), 'agent_3': Array(-20.888592, dtype=float32)}\n",
            "step: 107\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5584605 ,  0.9965721 , -0.01481432,  0.08109468, -0.00695465,\n",
            "        0.5642623 ,  0.8353435 ,  0.5591371 ,  0.5582949 ,  0.5497338 ,\n",
            "        0.16210079, -0.36177635, -0.14158487,  1.0961659 , -1.6323565 ,\n",
            "        0.8526781 , -2.4702134 ,  5.4591513 ], dtype=float32), 'agent_1': Array([ 0.5584605 ,  0.9965721 , -0.01481432,  0.08109468, -0.00695465,\n",
            "        0.5642623 ,  0.5591371 , -0.7958012 ,  0.5582949 ,  0.5497338 ,\n",
            "        0.16210079, -0.36177635, -0.14158487,  1.0961659 , -1.6323565 ,\n",
            "        0.8526781 , -0.48358303,  6.888491  ], dtype=float32), 'agent_2': Array([ 5.5846047e-01,  9.9657208e-01, -1.4814323e-02,  8.1094682e-02,\n",
            "       -6.9546499e-03,  5.6426227e-01,  5.5913711e-01,  5.5829489e-01,\n",
            "       -7.4371636e-01,  5.4973382e-01,  1.6210079e-01, -3.6177635e-01,\n",
            "       -1.4158487e-01,  1.0961659e+00, -1.6323565e+00,  8.5267812e-01,\n",
            "       -2.6869336e-01,  7.6094360e+00], dtype=float32), 'agent_3': Array([ 0.5584605 ,  0.9965721 , -0.01481432,  0.08109468, -0.00695465,\n",
            "        0.5642623 ,  0.5591371 ,  0.5582949 ,  0.5497338 ,  0.6794842 ,\n",
            "        0.16210079, -0.36177635, -0.14158487,  1.0961659 , -1.6323565 ,\n",
            "        0.8526781 ,  0.18757008,  6.3552904 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.02211668  0.4347639  -0.02098786  0.43633395 -0.02046472  0.43231404\n",
            " -0.02101579  0.43508983]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.461109, dtype=float32), 'agent_0': Array(-7.461109, dtype=float32), 'agent_1': Array(-7.461109, dtype=float32), 'agent_2': Array(-7.461109, dtype=float32), 'agent_3': Array(-7.461109, dtype=float32)}\n",
            "step: 108\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55818963,  0.99733967,  0.00594552,  0.05008378,  0.05263009,\n",
            "        0.33282274,  1.0297256 ,  0.43327188,  0.45187354,  0.46018246,\n",
            "       -0.10495186, -0.5311012 ,  0.7601857 ,  0.56675273, -1.8672811 ,\n",
            "        2.6780708 , -3.9237363 ,  3.0826755 ], dtype=float32), 'agent_1': Array([ 5.5818963e-01,  9.9733967e-01,  5.9455219e-03,  5.0083779e-02,\n",
            "        5.2630089e-02,  3.3282274e-01,  4.3327188e-01, -5.2097023e-01,\n",
            "        4.5187354e-01,  4.6018246e-01, -1.0495186e-01, -5.3110123e-01,\n",
            "        7.6018572e-01,  5.6675273e-01, -1.8672811e+00,  2.6780708e+00,\n",
            "       -2.8539398e+00,  6.2553883e+00], dtype=float32), 'agent_2': Array([ 0.55818963,  0.99733967,  0.00594552,  0.05008378,  0.05263009,\n",
            "        0.33282274,  0.43327188,  0.45187354, -0.47956428,  0.46018246,\n",
            "       -0.10495186, -0.5311012 ,  0.7601857 ,  0.56675273, -1.8672811 ,\n",
            "        2.6780708 , -2.1188731 ,  2.6419253 ], dtype=float32), 'agent_3': Array([ 0.55818963,  0.99733967,  0.00594552,  0.05008378,  0.05263009,\n",
            "        0.33282274,  0.43327188,  0.45187354,  0.46018246,  0.8793759 ,\n",
            "       -0.10495186, -0.5311012 ,  0.7601857 ,  0.56675273, -1.8672811 ,\n",
            "        2.6780708 , -2.719859  ,  2.7885382 ], dtype=float32)}\n",
            "ctrl action chosen: [0.24630353 1.8717501  0.24984877 1.8729814  0.24936993 1.869923\n",
            " 0.2466178  1.8712853 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.63773274, dtype=float32), 'agent_0': Array(0.63773274, dtype=float32), 'agent_1': Array(0.63773274, dtype=float32), 'agent_2': Array(0.63773274, dtype=float32), 'agent_3': Array(0.63773274, dtype=float32)}\n",
            "step: 109\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1136287e-01,  9.9922806e-01,  2.4048710e-02,  1.3207522e-03,\n",
            "        3.1035030e-02,  3.9788452e-01,  1.2738183e+00,  4.9549934e-01,\n",
            "        5.5550063e-01,  5.0122297e-01,  2.2464991e-01, -3.8142204e-01,\n",
            "        1.3768911e+00,  4.0668631e-01, -1.5618896e+00, -1.1410356e+00,\n",
            "        2.1071315e+00,  1.7066649e+00], dtype=float32), 'agent_1': Array([ 6.1136287e-01,  9.9922806e-01,  2.4048710e-02,  1.3207522e-03,\n",
            "        3.1035030e-02,  3.9788452e-01,  4.9549934e-01, -4.4723800e-01,\n",
            "        5.5550063e-01,  5.0122297e-01,  2.2464991e-01, -3.8142204e-01,\n",
            "        1.3768911e+00,  4.0668631e-01, -1.5618896e+00, -1.1410356e+00,\n",
            "        1.9718431e+00, -5.8510286e-01], dtype=float32), 'agent_2': Array([ 6.1136287e-01,  9.9922806e-01,  2.4048710e-02,  1.3207522e-03,\n",
            "        3.1035030e-02,  3.9788452e-01,  4.9549934e-01,  5.5550063e-01,\n",
            "       -4.5187578e-01,  5.0122297e-01,  2.2464991e-01, -3.8142204e-01,\n",
            "        1.3768911e+00,  4.0668631e-01, -1.5618896e+00, -1.1410356e+00,\n",
            "        1.5091412e+00, -4.7722995e-01], dtype=float32), 'agent_3': Array([ 6.1136287e-01,  9.9922806e-01,  2.4048710e-02,  1.3207522e-03,\n",
            "        3.1035030e-02,  3.9788452e-01,  4.9549934e-01,  5.5550063e-01,\n",
            "        5.0122297e-01,  1.1759390e+00,  2.2464991e-01, -3.8142204e-01,\n",
            "        1.3768911e+00,  4.0668631e-01, -1.5618896e+00, -1.1410356e+00,\n",
            "        1.4066955e+00,  6.8631124e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.44101247 -0.78298885 -0.4415715  -0.78602785 -0.43923217 -0.78819185\n",
            " -0.4424218  -0.7783303 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.0473948, dtype=float32), 'agent_0': Array(-6.0473948, dtype=float32), 'agent_1': Array(-6.0473948, dtype=float32), 'agent_2': Array(-6.0473948, dtype=float32), 'agent_3': Array(-6.0473948, dtype=float32)}\n",
            "step: 110\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.8396300e-01,  9.9181211e-01,  9.4340537e-03,  4.1793836e-03,\n",
            "        1.2728851e-01,  1.8396857e-01,  1.1198292e+00,  2.8656948e-01,\n",
            "        3.4388614e-01,  2.7939159e-01, -5.8436394e-02, -6.3028336e-01,\n",
            "        9.4420910e-01, -4.6201980e-01,  5.8261436e-01,  5.3797441e+00,\n",
            "       -6.4796553e+00, -3.2789392e+00], dtype=float32), 'agent_1': Array([ 6.8396300e-01,  9.9181211e-01,  9.4340537e-03,  4.1793836e-03,\n",
            "        1.2728851e-01,  1.8396857e-01,  2.8656948e-01, -7.4338859e-01,\n",
            "        3.4388614e-01,  2.7939159e-01, -5.8436394e-02, -6.3028336e-01,\n",
            "        9.4420910e-01, -4.6201980e-01,  5.8261436e-01,  5.3797441e+00,\n",
            "       -6.2609239e+00, -9.1736031e+00], dtype=float32), 'agent_2': Array([ 6.8396300e-01,  9.9181211e-01,  9.4340537e-03,  4.1793836e-03,\n",
            "        1.2728851e-01,  1.8396857e-01,  2.8656948e-01,  3.4388614e-01,\n",
            "       -7.8179836e-01,  2.7939159e-01, -5.8436394e-02, -6.3028336e-01,\n",
            "        9.4420910e-01, -4.6201980e-01,  5.8261436e-01,  5.3797441e+00,\n",
            "       -6.4296322e+00, -9.7319994e+00], dtype=float32), 'agent_3': Array([ 6.8396300e-01,  9.9181211e-01,  9.4340537e-03,  4.1793836e-03,\n",
            "        1.2728851e-01,  1.8396857e-01,  2.8656948e-01,  3.4388614e-01,\n",
            "        2.7939159e-01,  1.1573815e+00, -5.8436394e-02, -6.3028336e-01,\n",
            "        9.4420910e-01, -4.6201980e-01,  5.8261436e-01,  5.3797441e+00,\n",
            "       -6.0668750e+00, -1.1183221e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.1785097  -1.3557949  -0.17699769 -1.3665453  -0.17458817 -1.3689277\n",
            " -0.17916322 -1.3555454 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.57181466, dtype=float32), 'agent_0': Array(-0.57181466, dtype=float32), 'agent_1': Array(-0.57181466, dtype=float32), 'agent_2': Array(-0.57181466, dtype=float32), 'agent_3': Array(-0.57181466, dtype=float32)}\n",
            "step: 111\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.9818705e-01,  9.7162509e-01, -1.0621971e-02,  4.6408929e-02,\n",
            "        2.3168544e-01, -7.1199320e-02,  6.9168574e-01,  2.3534831e-02,\n",
            "        1.1716411e-01,  3.9311372e-02, -4.2179823e-01, -6.8907738e-01,\n",
            "        2.9110909e-02, -1.1741954e-01,  2.0651436e+00,  3.8764923e+00,\n",
            "       -4.3982863e+00, -1.2533114e+01], dtype=float32), 'agent_1': Array([ 0.69818705,  0.9716251 , -0.01062197,  0.04640893,  0.23168544,\n",
            "       -0.07119932,  0.02353483, -1.3263807 ,  0.11716411,  0.03931137,\n",
            "       -0.42179823, -0.6890774 ,  0.02911091, -0.11741954,  2.0651436 ,\n",
            "        3.8764923 , -5.126077  , -6.009317  ], dtype=float32), 'agent_2': Array([ 0.69818705,  0.9716251 , -0.01062197,  0.04640893,  0.23168544,\n",
            "       -0.07119932,  0.02353483,  0.11716411, -1.3331211 ,  0.03931137,\n",
            "       -0.42179823, -0.6890774 ,  0.02911091, -0.11741954,  2.0651436 ,\n",
            "        3.8764923 , -3.5881157 , -3.7936585 ], dtype=float32), 'agent_3': Array([  0.69818705,   0.9716251 ,  -0.01062197,   0.04640893,\n",
            "         0.23168544,  -0.07119932,   0.02353483,   0.11716411,\n",
            "         0.03931137,   0.87704086,  -0.42179823,  -0.6890774 ,\n",
            "         0.02911091,  -0.11741954,   2.0651436 ,   3.8764923 ,\n",
            "        -4.488781  , -10.013732  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.22414018  0.89765584 -0.22729553  0.9041379  -0.22505805  0.90492797\n",
            " -0.2250408   0.8981091 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0759022, dtype=float32), 'agent_0': Array(-3.0759022, dtype=float32), 'agent_1': Array(-3.0759022, dtype=float32), 'agent_2': Array(-3.0759022, dtype=float32), 'agent_3': Array(-3.0759022, dtype=float32)}\n",
            "step: 112\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.7258322e-01,  9.4702852e-01, -1.4723154e-03,  7.8753466e-03,\n",
            "        3.2104951e-01, -2.6904026e-01,  6.3332611e-01, -1.9579259e-01,\n",
            "       -9.1387585e-02, -1.8604875e-01,  2.4482012e-01, -3.8471222e-01,\n",
            "       -1.0496259e+00, -3.1906721e-01, -1.8179586e+00,  3.6983461e+00,\n",
            "       -3.9467800e+00,  3.1516066e+00], dtype=float32), 'agent_1': Array([ 6.7258322e-01,  9.4702852e-01, -1.4723154e-03,  7.8753466e-03,\n",
            "        3.2104951e-01, -2.6904026e-01, -1.9579259e-01, -1.1854357e+00,\n",
            "       -9.1387585e-02, -1.8604875e-01,  2.4482012e-01, -3.8471222e-01,\n",
            "       -1.0496259e+00, -3.1906721e-01, -1.8179586e+00,  3.6983461e+00,\n",
            "       -4.0184379e+00,  3.1127229e+00], dtype=float32), 'agent_2': Array([ 6.7258322e-01,  9.4702852e-01, -1.4723154e-03,  7.8753466e-03,\n",
            "        3.2104951e-01, -2.6904026e-01, -1.9579259e-01, -9.1387585e-02,\n",
            "       -1.1655216e+00, -1.8604875e-01,  2.4482012e-01, -3.8471222e-01,\n",
            "       -1.0496259e+00, -3.1906721e-01, -1.8179586e+00,  3.6983461e+00,\n",
            "       -4.4649668e+00,  3.8069222e+00], dtype=float32), 'agent_3': Array([ 6.7258322e-01,  9.4702852e-01, -1.4723154e-03,  7.8753466e-03,\n",
            "        3.2104951e-01, -2.6904026e-01, -1.9579259e-01, -9.1387585e-02,\n",
            "       -1.8604875e-01,  8.5877872e-01,  2.4482012e-01, -3.8471222e-01,\n",
            "       -1.0496259e+00, -3.1906721e-01, -1.8179586e+00,  3.6983461e+00,\n",
            "       -4.5435681e+00,  3.2918801e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.30214217 -1.1864477  -0.30203483 -1.1856124  -0.3011534  -1.187437\n",
            " -0.3030342  -1.1874416 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5492077, dtype=float32), 'agent_0': Array(-0.5492077, dtype=float32), 'agent_1': Array(-0.5492077, dtype=float32), 'agent_2': Array(-0.5492077, dtype=float32), 'agent_3': Array(-0.5492077, dtype=float32)}\n",
            "step: 113\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2321180e-01,  9.0525478e-01,  2.8224564e-03,  1.7160805e-02,\n",
            "        4.2451301e-01, -5.1195520e-01,  4.5275941e-01, -4.4889224e-01,\n",
            "       -3.5876080e-01, -4.5903209e-01, -7.1358681e-02, -4.9681664e-01,\n",
            "       -1.0266304e+00,  3.2729077e-01, -4.0637702e-01,  4.6832461e+00,\n",
            "       -5.4389334e+00,  8.6285192e-01], dtype=float32), 'agent_1': Array([ 6.2321180e-01,  9.0525478e-01,  2.8224564e-03,  1.7160805e-02,\n",
            "        4.2451301e-01, -5.1195520e-01, -4.4889224e-01, -1.2411139e+00,\n",
            "       -3.5876080e-01, -4.5903209e-01, -7.1358681e-02, -4.9681664e-01,\n",
            "       -1.0266304e+00,  3.2729077e-01, -4.0637702e-01,  4.6832461e+00,\n",
            "       -5.3538747e+00, -1.0634025e-01], dtype=float32), 'agent_2': Array([ 6.2321180e-01,  9.0525478e-01,  2.8224564e-03,  1.7160805e-02,\n",
            "        4.2451301e-01, -5.1195520e-01, -4.4889224e-01, -3.5876080e-01,\n",
            "       -1.2382352e+00, -4.5903209e-01, -7.1358681e-02, -4.9681664e-01,\n",
            "       -1.0266304e+00,  3.2729077e-01, -4.0637702e-01,  4.6832461e+00,\n",
            "       -5.5829334e+00, -1.0840081e+00], dtype=float32), 'agent_3': Array([ 6.2321180e-01,  9.0525478e-01,  2.8224564e-03,  1.7160805e-02,\n",
            "        4.2451301e-01, -5.1195520e-01, -4.4889224e-01, -3.5876080e-01,\n",
            "       -4.5903209e-01,  5.3683186e-01, -7.1358681e-02, -4.9681664e-01,\n",
            "       -1.0266304e+00,  3.2729077e-01, -4.0637702e-01,  4.6832461e+00,\n",
            "       -5.2380996e+00, -8.6079922e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.14531529  0.2564224  -0.14747187  0.25664845 -0.14747281  0.25382754\n",
            " -0.14846948  0.2463513 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0833762, dtype=float32), 'agent_0': Array(-2.0833762, dtype=float32), 'agent_1': Array(-2.0833762, dtype=float32), 'agent_2': Array(-2.0833762, dtype=float32), 'agent_3': Array(-2.0833762, dtype=float32)}\n",
            "step: 114\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58340925,  0.8892496 ,  0.00568883, -0.03226658,  0.45624736,\n",
            "       -0.5336246 ,  0.64176774, -0.5373934 , -0.45524904, -0.53495157,\n",
            "        0.71891546, -0.32525063,  0.5778074 , -0.83532435, -0.90890664,\n",
            "        0.31655857,  0.9009251 ,  3.8542087 ], dtype=float32), 'agent_1': Array([ 0.58340925,  0.8892496 ,  0.00568883, -0.03226658,  0.45624736,\n",
            "       -0.5336246 , -0.5373934 , -1.0962427 , -0.45524904, -0.53495157,\n",
            "        0.71891546, -0.32525063,  0.5778074 , -0.83532435, -0.90890664,\n",
            "        0.31655857, -0.16713192,  3.665146  ], dtype=float32), 'agent_2': Array([ 0.58340925,  0.8892496 ,  0.00568883, -0.03226658,  0.45624736,\n",
            "       -0.5336246 , -0.5373934 , -0.45524904, -1.0897987 , -0.53495157,\n",
            "        0.71891546, -0.32525063,  0.5778074 , -0.83532435, -0.90890664,\n",
            "        0.31655857, -0.84116626,  2.4040787 ], dtype=float32), 'agent_3': Array([ 0.58340925,  0.8892496 ,  0.00568883, -0.03226658,  0.45624736,\n",
            "       -0.5336246 , -0.5373934 , -0.45524904, -0.53495157,  0.56255037,\n",
            "        0.71891546, -0.32525063,  0.5778074 , -0.83532435, -0.90890664,\n",
            "        0.31655857, -0.00415792,  1.0982243 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3457627   0.32414693 -0.34804592  0.32419607 -0.3471178   0.32202545\n",
            " -0.34462357  0.32248187]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1935554, dtype=float32), 'agent_0': Array(1.1935554, dtype=float32), 'agent_1': Array(1.1935554, dtype=float32), 'agent_2': Array(1.1935554, dtype=float32), 'agent_3': Array(1.1935554, dtype=float32)}\n",
            "step: 115\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.3150066e-01,  8.8086611e-01, -3.1996032e-04, -5.0390936e-02,\n",
            "        4.7067565e-01, -5.0387907e-01,  8.4499693e-01, -5.3057861e-01,\n",
            "       -5.4327136e-01, -5.3795481e-01,  8.5996389e-01, -4.9781799e-02,\n",
            "        6.5602064e-01, -5.9513867e-01, -8.9640170e-01,  1.6849199e-01,\n",
            "        6.6925019e-01,  4.8491826e+00], dtype=float32), 'agent_1': Array([ 6.3150066e-01,  8.8086611e-01, -3.1996032e-04, -5.0390936e-02,\n",
            "        4.7067565e-01, -5.0387907e-01, -5.3057861e-01, -9.1879219e-01,\n",
            "       -5.4327136e-01, -5.3795481e-01,  8.5996389e-01, -4.9781799e-02,\n",
            "        6.5602064e-01, -5.9513867e-01, -8.9640170e-01,  1.6849199e-01,\n",
            "        7.2515881e-01,  3.8174245e+00], dtype=float32), 'agent_2': Array([ 6.3150066e-01,  8.8086611e-01, -3.1996032e-04, -5.0390936e-02,\n",
            "        4.7067565e-01, -5.0387907e-01, -5.3057861e-01, -5.4327136e-01,\n",
            "       -9.9161452e-01, -5.3795481e-01,  8.5996389e-01, -4.9781799e-02,\n",
            "        6.5602064e-01, -5.9513867e-01, -8.9640170e-01,  1.6849199e-01,\n",
            "       -9.5424831e-01,  3.1550078e+00], dtype=float32), 'agent_3': Array([ 6.3150066e-01,  8.8086611e-01, -3.1996032e-04, -5.0390936e-02,\n",
            "        4.7067565e-01, -5.0387907e-01, -5.3057861e-01, -5.4327136e-01,\n",
            "       -5.3795481e-01,  6.1381966e-01,  8.5996389e-01, -4.9781799e-02,\n",
            "        6.5602064e-01, -5.9513867e-01, -8.9640170e-01,  1.6849199e-01,\n",
            "        5.6885028e-01,  1.8381618e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.12999262 -0.47665474 -0.12967396 -0.47776812 -0.13134998 -0.4778048\n",
            " -0.12747145 -0.47787136]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.4726849, dtype=float32), 'agent_0': Array(1.4726849, dtype=float32), 'agent_1': Array(1.4726849, dtype=float32), 'agent_2': Array(1.4726849, dtype=float32), 'agent_3': Array(1.4726849, dtype=float32)}\n",
            "step: 116\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6468758 ,  0.88017184, -0.0044584 , -0.0463648 ,  0.47236422,\n",
            "       -0.48050186,  0.8733851 , -0.50270116, -0.54212165, -0.5035531 ,\n",
            "        0.51819086, -0.17523766,  0.04149675,  0.08407792,  0.7900137 ,\n",
            "        0.38432813, -0.33733457, -1.60067   ], dtype=float32), 'agent_1': Array([ 0.6468758 ,  0.88017184, -0.0044584 , -0.0463648 ,  0.47236422,\n",
            "       -0.48050186, -0.50270116, -0.9364452 , -0.54212165, -0.5035531 ,\n",
            "        0.51819086, -0.17523766,  0.04149675,  0.08407792,  0.7900137 ,\n",
            "        0.38432813,  0.04940673, -1.8834165 ], dtype=float32), 'agent_2': Array([ 0.6468758 ,  0.88017184, -0.0044584 , -0.0463648 ,  0.47236422,\n",
            "       -0.48050186, -0.50270116, -0.54212165, -1.0246034 , -0.5035531 ,\n",
            "        0.51819086, -0.17523766,  0.04149675,  0.08407792,  0.7900137 ,\n",
            "        0.38432813,  0.41007408, -2.4712915 ], dtype=float32), 'agent_3': Array([ 0.6468758 ,  0.88017184, -0.0044584 , -0.0463648 ,  0.47236422,\n",
            "       -0.48050186, -0.50270116, -0.54212165, -0.5035531 ,  0.52891546,\n",
            "        0.51819086, -0.17523766,  0.04149675,  0.08407792,  0.7900137 ,\n",
            "        0.38432813,  0.48645258, -2.8566623 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.24259152  0.17266463 -0.24421118  0.1726629  -0.24391076  0.16958283\n",
            " -0.2454273   0.17130989]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.140259, dtype=float32), 'agent_0': Array(1.140259, dtype=float32), 'agent_1': Array(1.140259, dtype=float32), 'agent_2': Array(1.140259, dtype=float32), 'agent_3': Array(1.140259, dtype=float32)}\n",
            "step: 117\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63792616,  0.8699857 , -0.01527278, -0.05361573,  0.48991537,\n",
            "       -0.5360572 ,  0.90957403, -0.535234  , -0.5216126 , -0.52986014,\n",
            "        0.65363646, -0.03490448, -0.36901236, -0.47253317, -0.2506079 ,\n",
            "        0.4521344 , -0.48923865,  1.2042745 ], dtype=float32), 'agent_1': Array([ 0.63792616,  0.8699857 , -0.01527278, -0.05361573,  0.48991537,\n",
            "       -0.5360572 , -0.535234  , -0.8920476 , -0.5216126 , -0.52986014,\n",
            "        0.65363646, -0.03490448, -0.36901236, -0.47253317, -0.2506079 ,\n",
            "        0.4521344 , -0.06263183,  1.2954793 ], dtype=float32), 'agent_2': Array([ 0.63792616,  0.8699857 , -0.01527278, -0.05361573,  0.48991537,\n",
            "       -0.5360572 , -0.535234  , -0.5216126 , -1.0198479 , -0.52986014,\n",
            "        0.65363646, -0.03490448, -0.36901236, -0.47253317, -0.2506079 ,\n",
            "        0.4521344 ,  0.56414664,  0.6075372 ], dtype=float32), 'agent_3': Array([ 0.63792616,  0.8699857 , -0.01527278, -0.05361573,  0.48991537,\n",
            "       -0.5360572 , -0.535234  , -0.5216126 , -0.52986014,  0.54860246,\n",
            "        0.65363646, -0.03490448, -0.36901236, -0.47253317, -0.2506079 ,\n",
            "        0.4521344 , -0.24163191,  0.7111884 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5875966   1.26535    -0.5888812   1.2645363  -0.58671623  1.2603917\n",
            " -0.58808285  1.2646662 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.4359456, dtype=float32), 'agent_0': Array(1.4359456, dtype=float32), 'agent_1': Array(1.4359456, dtype=float32), 'agent_2': Array(1.4359456, dtype=float32), 'agent_3': Array(1.4359456, dtype=float32)}\n",
            "step: 118\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6067018 ,  0.85916394, -0.02364232, -0.10161412,  0.5009521 ,\n",
            "       -0.54645735,  1.2239681 , -0.5330137 , -0.531729  , -0.5421276 ,\n",
            "        0.95512867,  0.11029243, -0.8912802 , -1.6335169 , -2.2553384 ,\n",
            "        0.43119407,  0.3989274 ,  8.552694  ], dtype=float32), 'agent_1': Array([ 0.6067018 ,  0.85916394, -0.02364232, -0.10161412,  0.5009521 ,\n",
            "       -0.54645735, -0.5330137 , -0.58379686, -0.531729  , -0.5421276 ,\n",
            "        0.95512867,  0.11029243, -0.8912802 , -1.6335169 , -2.2553384 ,\n",
            "        0.43119407,  0.22828911,  8.68362   ], dtype=float32), 'agent_2': Array([ 0.6067018 ,  0.85916394, -0.02364232, -0.10161412,  0.5009521 ,\n",
            "       -0.54645735, -0.5330137 , -0.531729  , -0.72870994, -0.5421276 ,\n",
            "        0.95512867,  0.11029243, -0.8912802 , -1.6335169 , -2.2553384 ,\n",
            "        0.43119407, -0.41289145,  8.499621  ], dtype=float32), 'agent_3': Array([ 0.6067018 ,  0.85916394, -0.02364232, -0.10161412,  0.5009521 ,\n",
            "       -0.54645735, -0.5330137 , -0.531729  , -0.5421276 ,  0.83791953,\n",
            "        0.95512867,  0.11029243, -0.8912802 , -1.6335169 , -2.2553384 ,\n",
            "        0.43119407, -0.04647316,  8.457157  ], dtype=float32)}\n",
            "ctrl action chosen: [0.77037096 0.8489367  0.76803815 0.84843457 0.7681833  0.84837496\n",
            " 0.76801735 0.84944445]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0510051, dtype=float32), 'agent_0': Array(-2.0510051, dtype=float32), 'agent_1': Array(-2.0510051, dtype=float32), 'agent_2': Array(-2.0510051, dtype=float32), 'agent_3': Array(-2.0510051, dtype=float32)}\n",
            "step: 119\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5435686 ,  0.92770743, -0.01352585, -0.14408691,  0.34411463,\n",
            "       -0.06134083,  1.2903513 , -0.08596547, -0.08951329, -0.12238166,\n",
            "        0.76134205, -0.19073486, -1.2830973 , -0.843066  , -0.1075239 ,\n",
            "       -9.280402  , 12.769734  , -0.42576677], dtype=float32), 'agent_1': Array([ 0.5435686 ,  0.92770743, -0.01352585, -0.14408691,  0.34411463,\n",
            "       -0.06134083, -0.08596547, -0.45198292, -0.08951329, -0.12238166,\n",
            "        0.76134205, -0.19073486, -1.2830973 , -0.843066  , -0.1075239 ,\n",
            "       -9.280402  , 11.851344  , -0.3437766 ], dtype=float32), 'agent_2': Array([ 0.5435686 ,  0.92770743, -0.01352585, -0.14408691,  0.34411463,\n",
            "       -0.06134083, -0.08596547, -0.08951329, -0.4486086 , -0.12238166,\n",
            "        0.76134205, -0.19073486, -1.2830973 , -0.843066  , -0.1075239 ,\n",
            "       -9.280402  , 12.265472  , -0.64358795], dtype=float32), 'agent_3': Array([ 0.5435686 ,  0.92770743, -0.01352585, -0.14408691,  0.34411463,\n",
            "       -0.06134083, -0.08596547, -0.08951329, -0.12238166,  1.2938905 ,\n",
            "        0.76134205, -0.19073486, -1.2830973 , -0.843066  , -0.1075239 ,\n",
            "       -9.280402  , 11.183889  ,  4.9107437 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2785339 -0.6445272 -1.2791513 -0.6438743 -1.27946   -0.6446624\n",
            " -1.2781432 -0.6449333]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.7514579, dtype=float32), 'agent_0': Array(-0.7514579, dtype=float32), 'agent_1': Array(-0.7514579, dtype=float32), 'agent_2': Array(-0.7514579, dtype=float32), 'agent_3': Array(-0.7514579, dtype=float32)}\n",
            "step: 120\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5221923 ,   0.87132275,  -0.03130106,  -0.10434966,\n",
            "         0.47846437,  -0.3674495 ,   1.0303118 ,  -0.43065625,\n",
            "        -0.41012302,  -0.45007616,  -0.03957748,  -0.13847351,\n",
            "        -0.2037406 ,   0.7182404 ,   1.3938949 ,  10.070558  ,\n",
            "       -12.00352   ,  -7.5464773 ], dtype=float32), 'agent_1': Array([  0.5221923 ,   0.87132275,  -0.03130106,  -0.10434966,\n",
            "         0.47846437,  -0.3674495 ,  -0.43065625,  -0.55152094,\n",
            "        -0.41012302,  -0.45007616,  -0.03957748,  -0.13847351,\n",
            "        -0.2037406 ,   0.7182404 ,   1.3938949 ,  10.070558  ,\n",
            "       -13.44804   ,  -1.5891623 ], dtype=float32), 'agent_2': Array([  0.5221923 ,   0.87132275,  -0.03130106,  -0.10434966,\n",
            "         0.47846437,  -0.3674495 ,  -0.43065625,  -0.41012302,\n",
            "        -0.5676495 ,  -0.45007616,  -0.03957748,  -0.13847351,\n",
            "        -0.2037406 ,   0.7182404 ,   1.3938949 ,  10.070558  ,\n",
            "       -11.893193  ,  -2.9884431 ], dtype=float32), 'agent_3': Array([  0.5221923 ,   0.87132275,  -0.03130106,  -0.10434966,\n",
            "         0.47846437,  -0.3674495 ,  -0.43065625,  -0.41012302,\n",
            "        -0.45007616,   1.1836097 ,  -0.03957748,  -0.13847351,\n",
            "        -0.2037406 ,   0.7182404 ,   1.3938949 ,  10.070558  ,\n",
            "       -11.976089  ,  -2.151756  ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.5799392  -0.7698906   1.580805   -0.7687552   1.579314   -0.76932704\n",
            "  1.5805811  -0.76984495]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.053992, dtype=float32), 'agent_0': Array(-3.053992, dtype=float32), 'agent_1': Array(-3.053992, dtype=float32), 'agent_2': Array(-3.053992, dtype=float32), 'agent_3': Array(-3.053992, dtype=float32)}\n",
            "step: 121\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5168435 ,   0.9315061 ,  -0.02077146,  -0.02612069,\n",
            "         0.36219165,  -0.01774193,   0.5305486 ,  -0.22167188,\n",
            "        -0.05364501,  -0.14870708,  -0.34952164,  -0.13947487,\n",
            "         0.34546852,   1.4698269 ,   4.2242355 ,  -9.412887  ,\n",
            "        13.547057  , -11.351809  ], dtype=float32), 'agent_1': Array([ 0.5168435 ,  0.9315061 , -0.02077146, -0.02612069,  0.36219165,\n",
            "       -0.01774193, -0.22167188, -0.725788  , -0.05364501, -0.14870708,\n",
            "       -0.34952164, -0.13947487,  0.34546852,  1.4698269 ,  4.2242355 ,\n",
            "       -9.412887  ,  9.972319  , -5.9829617 ], dtype=float32), 'agent_2': Array([ 0.5168435 ,  0.9315061 , -0.02077146, -0.02612069,  0.36219165,\n",
            "       -0.01774193, -0.22167188, -0.05364501, -0.9580559 , -0.14870708,\n",
            "       -0.34952164, -0.13947487,  0.34546852,  1.4698269 ,  4.2242355 ,\n",
            "       -9.412887  , 13.655712  , -8.668536  ], dtype=float32), 'agent_3': Array([  0.5168435 ,   0.9315061 ,  -0.02077146,  -0.02612069,\n",
            "         0.36219165,  -0.01774193,  -0.22167188,  -0.05364501,\n",
            "        -0.14870708,   0.8569968 ,  -0.34952164,  -0.13947487,\n",
            "         0.34546852,   1.4698269 ,   4.2242355 ,  -9.412887  ,\n",
            "        11.35216   , -10.275098  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.0580565   0.35320735 -0.05709422  0.35373697 -0.05619677  0.35335803\n",
            " -0.05916483  0.35182154]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.517686, dtype=float32), 'agent_0': Array(-5.517686, dtype=float32), 'agent_1': Array(-5.517686, dtype=float32), 'agent_2': Array(-5.517686, dtype=float32), 'agent_3': Array(-5.517686, dtype=float32)}\n",
            "step: 122\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52661127,  0.95902646, -0.0119999 ,  0.03725922,  0.28059924,\n",
            "        0.2986478 ,  0.50705713, -0.0753436 ,  0.28302136,  0.0515261 ,\n",
            "        0.04963875, -0.04997253,  0.27207136,  1.1586535 ,  1.8264786 ,\n",
            "       -1.7424029 ,  3.562072  ,  0.7334047 ], dtype=float32), 'agent_1': Array([ 0.52661127,  0.95902646, -0.0119999 ,  0.03725922,  0.28059924,\n",
            "        0.2986478 , -0.0753436 , -0.8064867 ,  0.28302136,  0.0515261 ,\n",
            "        0.04963875, -0.04997253,  0.27207136,  1.1586535 ,  1.8264786 ,\n",
            "       -1.7424029 ,  0.7645516 , -0.35147864], dtype=float32), 'agent_2': Array([ 0.52661127,  0.95902646, -0.0119999 ,  0.03725922,  0.28059924,\n",
            "        0.2986478 , -0.0753436 ,  0.28302136, -1.0535828 ,  0.0515261 ,\n",
            "        0.04963875, -0.04997253,  0.27207136,  1.1586535 ,  1.8264786 ,\n",
            "       -1.7424029 ,  4.243247  ,  1.7143712 ], dtype=float32), 'agent_3': Array([ 0.52661127,  0.95902646, -0.0119999 ,  0.03725922,  0.28059924,\n",
            "        0.2986478 , -0.0753436 ,  0.28302136,  0.0515261 ,  0.5896238 ,\n",
            "        0.04963875, -0.04997253,  0.27207136,  1.1586535 ,  1.8264786 ,\n",
            "       -1.7424029 ,  1.5175076 , -2.6485841 ], dtype=float32)}\n",
            "ctrl action chosen: [0.19400169 1.3411487  0.18951976 1.3411332  0.19522448 1.3383225\n",
            " 0.18870279 1.3352649 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7023684, dtype=float32), 'agent_0': Array(0.7023684, dtype=float32), 'agent_1': Array(0.7023684, dtype=float32), 'agent_2': Array(0.7023684, dtype=float32), 'agent_3': Array(0.7023684, dtype=float32)}\n",
            "step: 123\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2723128e-01,  9.6904778e-01,  5.1383623e-03,  6.0091678e-02,\n",
            "        2.3939313e-01,  4.7658902e-01,  8.1118715e-01, -1.2907816e-02,\n",
            "        4.7355801e-01,  1.4073710e-01,  1.6845465e-01,  9.4270706e-02,\n",
            "       -3.1192303e-01,  1.1225682e+00, -1.8943170e-01, -1.8346584e+00,\n",
            "        3.7587881e+00,  1.0250508e+01], dtype=float32), 'agent_1': Array([ 5.2723128e-01,  9.6904778e-01,  5.1383623e-03,  6.0091678e-02,\n",
            "        2.3939313e-01,  4.7658902e-01, -1.2907816e-02, -5.6083810e-01,\n",
            "        4.7355801e-01,  1.4073710e-01,  1.6845465e-01,  9.4270706e-02,\n",
            "       -3.1192303e-01,  1.1225682e+00, -1.8943170e-01, -1.8346584e+00,\n",
            "        1.7847271e+00,  7.9953632e+00], dtype=float32), 'agent_2': Array([ 5.2723128e-01,  9.6904778e-01,  5.1383623e-03,  6.0091678e-02,\n",
            "        2.3939313e-01,  4.7658902e-01, -1.2907816e-02,  4.7355801e-01,\n",
            "       -7.5651544e-01,  1.4073710e-01,  1.6845465e-01,  9.4270706e-02,\n",
            "       -3.1192303e-01,  1.1225682e+00, -1.8943170e-01, -1.8346584e+00,\n",
            "        3.6672676e+00,  7.8920097e+00], dtype=float32), 'agent_3': Array([ 5.2723128e-01,  9.6904778e-01,  5.1383623e-03,  6.0091678e-02,\n",
            "        2.3939313e-01,  4.7658902e-01, -1.2907816e-02,  4.7355801e-01,\n",
            "        1.4073710e-01,  7.6951313e-01,  1.6845465e-01,  9.4270706e-02,\n",
            "       -3.1192303e-01,  1.1225682e+00, -1.8943170e-01, -1.8346584e+00,\n",
            "        2.2140746e+00,  5.7678261e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.03393395 -1.7537006   0.03279817 -1.7532974   0.03577307 -1.7558777\n",
            "  0.03445672 -1.754692  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.5145907, dtype=float32), 'agent_0': Array(-2.5145907, dtype=float32), 'agent_1': Array(-2.5145907, dtype=float32), 'agent_2': Array(-2.5145907, dtype=float32), 'agent_3': Array(-2.5145907, dtype=float32)}\n",
            "step: 124\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6000084e-01,  9.6702665e-01,  1.2772403e-03,  9.7803667e-02,\n",
            "        2.3514315e-01,  5.3407586e-01,  8.1352043e-01, -1.4040777e-02,\n",
            "        5.3529310e-01,  1.4849135e-01, -3.8228035e-01, -8.4114075e-02,\n",
            "        1.0092974e+00, -5.0288565e-02,  2.0537417e+00,  8.0146939e-01,\n",
            "       -5.3976876e-01, -3.2860186e+00], dtype=float32), 'agent_1': Array([ 5.6000084e-01,  9.6702665e-01,  1.2772403e-03,  9.7803667e-02,\n",
            "        2.3514315e-01,  5.3407586e-01, -1.4040777e-02, -5.6881273e-01,\n",
            "        5.3529310e-01,  1.4849135e-01, -3.8228035e-01, -8.4114075e-02,\n",
            "        1.0092974e+00, -5.0288565e-02,  2.0537417e+00,  8.0146939e-01,\n",
            "       -9.3209422e-01, -2.2632372e+00], dtype=float32), 'agent_2': Array([ 5.6000084e-01,  9.6702665e-01,  1.2772403e-03,  9.7803667e-02,\n",
            "        2.3514315e-01,  5.3407586e-01, -1.4040777e-02,  5.3529310e-01,\n",
            "       -7.9348218e-01,  1.4849135e-01, -3.8228035e-01, -8.4114075e-02,\n",
            "        1.0092974e+00, -5.0288565e-02,  2.0537417e+00,  8.0146939e-01,\n",
            "       -2.3915312e-01, -3.0443103e+00], dtype=float32), 'agent_3': Array([ 5.6000084e-01,  9.6702665e-01,  1.2772403e-03,  9.7803667e-02,\n",
            "        2.3514315e-01,  5.3407586e-01, -1.4040777e-02,  5.3529310e-01,\n",
            "        1.4849135e-01,  5.2806270e-01, -3.8228035e-01, -8.4114075e-02,\n",
            "        1.0092974e+00, -5.0288565e-02,  2.0537417e+00,  8.0146939e-01,\n",
            "       -7.8099036e-01, -7.9320292e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.36548662 -1.3641695  -0.3672654  -1.3613507  -0.36357498 -1.3685949\n",
            " -0.36143407 -1.3669436 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.207695, dtype=float32), 'agent_0': Array(-5.207695, dtype=float32), 'agent_1': Array(-5.207695, dtype=float32), 'agent_2': Array(-5.207695, dtype=float32), 'agent_3': Array(-5.207695, dtype=float32)}\n",
            "step: 125\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.59629476,  0.9325459 , -0.01776582,  0.13426009,  0.33468908,\n",
            "        0.30239487,  0.48116863, -0.2715067 ,  0.33110842, -0.09589915,\n",
            "       -0.07605553, -0.18200874,  0.62098503, -1.3165568 ,  2.090381  ,\n",
            "        5.2611    , -5.917034  , -8.061522  ], dtype=float32), 'agent_1': Array([ 0.59629476,  0.9325459 , -0.01776582,  0.13426009,  0.33468908,\n",
            "        0.30239487, -0.2715067 , -0.8200385 ,  0.33110842, -0.09589915,\n",
            "       -0.07605553, -0.18200874,  0.62098503, -1.3165568 ,  2.090381  ,\n",
            "        5.2611    , -6.629257  , -6.923568  ], dtype=float32), 'agent_2': Array([  0.59629476,   0.9325459 ,  -0.01776582,   0.13426009,\n",
            "         0.33468908,   0.30239487,  -0.2715067 ,   0.33110842,\n",
            "        -1.128237  ,  -0.09589915,  -0.07605553,  -0.18200874,\n",
            "         0.62098503,  -1.3165568 ,   2.090381  ,   5.2611    ,\n",
            "        -5.5195947 , -10.277071  ], dtype=float32), 'agent_3': Array([ 0.59629476,  0.9325459 , -0.01776582,  0.13426009,  0.33468908,\n",
            "        0.30239487, -0.2715067 ,  0.33110842, -0.09589915,  0.46658912,\n",
            "       -0.07605553, -0.18200874,  0.62098503, -1.3165568 ,  2.090381  ,\n",
            "        5.2611    , -6.2444057 ,  0.0850182 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.37092048 -2.2243426   0.3691929  -2.2211185   0.3744913  -2.229516\n",
            "  0.36975047 -2.2165124 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.1514375, dtype=float32), 'agent_0': Array(-3.1514375, dtype=float32), 'agent_1': Array(-3.1514375, dtype=float32), 'agent_2': Array(-3.1514375, dtype=float32), 'agent_3': Array(-3.1514375, dtype=float32)}\n",
            "step: 126\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6225506 ,  0.93608445, -0.0193641 ,  0.176666  ,  0.30357894,\n",
            "        0.40891764,  0.45723763, -0.23651464,  0.45904317, -0.02401663,\n",
            "       -0.28207302,  0.25048256,  0.4960537 ,  1.485378  ,  1.2916173 ,\n",
            "       -3.0957127 ,  4.548748  ,  1.1013992 ], dtype=float32), 'agent_1': Array([ 0.6225506 ,  0.93608445, -0.0193641 ,  0.176666  ,  0.30357894,\n",
            "        0.40891764, -0.23651464, -1.3195332 ,  0.45904317, -0.02401663,\n",
            "       -0.28207302,  0.25048256,  0.4960537 ,  1.485378  ,  1.2916173 ,\n",
            "       -3.0957127 ,  2.942989  , -8.276805  ], dtype=float32), 'agent_2': Array([ 0.6225506 ,  0.93608445, -0.0193641 ,  0.176666  ,  0.30357894,\n",
            "        0.40891764, -0.23651464,  0.45904317, -1.2950712 , -0.02401663,\n",
            "       -0.28207302,  0.25048256,  0.4960537 ,  1.485378  ,  1.2916173 ,\n",
            "       -3.0957127 ,  5.0011134 ,  0.9093831 ], dtype=float32), 'agent_3': Array([ 0.6225506 ,  0.93608445, -0.0193641 ,  0.176666  ,  0.30357894,\n",
            "        0.40891764, -0.23651464,  0.45904317, -0.02401663,  0.46254545,\n",
            "       -0.28207302,  0.25048256,  0.4960537 ,  1.485378  ,  1.2916173 ,\n",
            "       -3.0957127 ,  3.839331  , -0.03737629], dtype=float32)}\n",
            "ctrl action chosen: [-0.431685   -0.3528725  -0.43847847 -0.3557408  -0.43249765 -0.3557686\n",
            " -0.43519187 -0.35395384]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.363021, dtype=float32), 'agent_0': Array(-9.363021, dtype=float32), 'agent_1': Array(-9.363021, dtype=float32), 'agent_2': Array(-9.363021, dtype=float32), 'agent_3': Array(-9.363021, dtype=float32)}\n",
            "step: 127\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6431301 ,  0.9124332 , -0.01956855,  0.17997484,  0.36700386,\n",
            "        0.28020686,  0.5162752 , -0.40183154,  0.34350583, -0.19857652,\n",
            "        0.13828278, -0.10070801,  0.04417896, -0.603259  ,  0.17698705,\n",
            "        4.2066317 , -4.7295732 ,  0.51142895], dtype=float32), 'agent_1': Array([ 0.6431301 ,  0.9124332 , -0.01956855,  0.17997484,  0.36700386,\n",
            "        0.28020686, -0.40183154, -1.2661474 ,  0.34350583, -0.19857652,\n",
            "        0.13828278, -0.10070801,  0.04417896, -0.603259  ,  0.17698705,\n",
            "        4.2066317 , -5.332592  ,  1.7324964 ], dtype=float32), 'agent_2': Array([ 0.6431301 ,  0.9124332 , -0.01956855,  0.17997484,  0.36700386,\n",
            "        0.28020686, -0.40183154,  0.34350583, -1.2480519 , -0.19857652,\n",
            "        0.13828278, -0.10070801,  0.04417896, -0.603259  ,  0.17698705,\n",
            "        4.2066317 , -4.596446  ,  0.9927601 ], dtype=float32), 'agent_3': Array([ 0.6431301 ,  0.9124332 , -0.01956855,  0.17997484,  0.36700386,\n",
            "        0.28020686, -0.40183154,  0.34350583, -0.19857652,  0.53017265,\n",
            "        0.13828278, -0.10070801,  0.04417896, -0.603259  ,  0.17698705,\n",
            "        4.2066317 , -6.1496234 ,  0.83755255], dtype=float32)}\n",
            "ctrl action chosen: [0.14300324 0.4425515  0.14122589 0.4437269  0.14571744 0.43983984\n",
            " 0.14216353 0.44105297]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.47925347, dtype=float32), 'agent_0': Array(0.47925347, dtype=float32), 'agent_1': Array(0.47925347, dtype=float32), 'agent_2': Array(0.47925347, dtype=float32), 'agent_3': Array(0.47925347, dtype=float32)}\n",
            "step: 128\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6344043 ,  0.90931   , -0.02419195,  0.16181883,  0.3826027 ,\n",
            "        0.26783982,  0.74764055, -0.4501257 ,  0.32860395, -0.2897304 ,\n",
            "        0.31633377,  0.0603199 , -0.18440485, -0.6773863 , -1.0162898 ,\n",
            "       -0.44661248,  1.2076398 ,  5.557157  ], dtype=float32), 'agent_1': Array([ 0.6344043 ,  0.90931   , -0.02419195,  0.16181883,  0.3826027 ,\n",
            "        0.26783982, -0.4501257 , -0.97099113,  0.32860395, -0.2897304 ,\n",
            "        0.31633377,  0.0603199 , -0.18440485, -0.6773863 , -1.0162898 ,\n",
            "       -0.44661248,  0.43486467,  8.682782  ], dtype=float32), 'agent_2': Array([ 0.6344043 ,  0.90931   , -0.02419195,  0.16181883,  0.3826027 ,\n",
            "        0.26783982, -0.4501257 ,  0.32860395, -1.0055124 , -0.2897304 ,\n",
            "        0.31633377,  0.0603199 , -0.18440485, -0.6773863 , -1.0162898 ,\n",
            "       -0.44661248,  1.1000617 ,  7.082813  ], dtype=float32), 'agent_3': Array([ 0.6344043 ,  0.90931   , -0.02419195,  0.16181883,  0.3826027 ,\n",
            "        0.26783982, -0.4501257 ,  0.32860395, -0.2897304 ,  0.66502285,\n",
            "        0.31633377,  0.0603199 , -0.18440485, -0.6773863 , -1.0162898 ,\n",
            "       -0.44661248, -0.17999011,  2.5025098 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8094056  -0.940625   -0.8125422  -0.9416356  -0.8095946  -0.9443373\n",
            " -0.8089867  -0.94348305]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7612733, dtype=float32), 'agent_0': Array(0.7612733, dtype=float32), 'agent_1': Array(0.7612733, dtype=float32), 'agent_2': Array(0.7612733, dtype=float32), 'agent_3': Array(0.7612733, dtype=float32)}\n",
            "step: 129\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1516500e-01,  8.6356020e-01, -2.9487001e-02,  1.7344940e-01,\n",
            "        4.7255653e-01,  4.3744184e-03,  6.4563203e-01, -5.9419340e-01,\n",
            "        6.9400623e-02, -5.7209623e-01,  2.4092197e-01,  5.0258636e-02,\n",
            "       -7.1606636e-01, -7.0255744e-01,  1.5073271e+00,  1.9358877e+00,\n",
            "       -4.5021062e+00, -4.5815592e+00], dtype=float32), 'agent_1': Array([ 0.615165  ,  0.8635602 , -0.029487  ,  0.1734494 ,  0.47255653,\n",
            "        0.00437442, -0.5941934 , -0.9153182 ,  0.06940062, -0.5720962 ,\n",
            "        0.24092197,  0.05025864, -0.71606636, -0.70255744,  1.5073271 ,\n",
            "        1.9358877 ,  0.78430206, -2.153023  ], dtype=float32), 'agent_2': Array([ 0.615165  ,  0.8635602 , -0.029487  ,  0.1734494 ,  0.47255653,\n",
            "        0.00437442, -0.5941934 ,  0.06940062, -1.038198  , -0.5720962 ,\n",
            "        0.24092197,  0.05025864, -0.71606636, -0.70255744,  1.5073271 ,\n",
            "        1.9358877 , -4.2502227 , -4.020347  ], dtype=float32), 'agent_3': Array([ 0.615165  ,  0.8635602 , -0.029487  ,  0.1734494 ,  0.47255653,\n",
            "        0.00437442, -0.5941934 ,  0.06940062, -0.5720962 ,  0.4895965 ,\n",
            "        0.24092197,  0.05025864, -0.71606636, -0.70255744,  1.5073271 ,\n",
            "        1.9358877 , -2.4161997 , -2.2809243 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0297036   0.554158   -1.0286922   0.5569554  -1.0288849   0.55336684\n",
            " -1.0290784   0.5552388 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8552401, dtype=float32), 'agent_0': Array(-1.8552401, dtype=float32), 'agent_1': Array(-1.8552401, dtype=float32), 'agent_2': Array(-1.8552401, dtype=float32), 'agent_3': Array(-1.8552401, dtype=float32)}\n",
            "step: 130\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57409877,  0.83019125, -0.04375093,  0.15737125,  0.5330128 ,\n",
            "       -0.3162844 ,  0.6836659 , -0.54088193, -0.25115833, -0.6089479 ,\n",
            "        0.1847148 , -0.02069473, -0.62924623, -0.92309827, -0.71853906,\n",
            "        3.138035  , -7.668118  ,  1.3036137 ], dtype=float32), 'agent_1': Array([ 0.57409877,  0.83019125, -0.04375093,  0.15737125,  0.5330128 ,\n",
            "       -0.3162844 , -0.54088193, -0.7509891 , -0.25115833, -0.6089479 ,\n",
            "        0.1847148 , -0.02069473, -0.62924623, -0.92309827, -0.71853906,\n",
            "        3.138035  ,  1.0722277 ,  3.5559647 ], dtype=float32), 'agent_2': Array([ 0.57409877,  0.83019125, -0.04375093,  0.15737125,  0.5330128 ,\n",
            "       -0.3162844 , -0.54088193, -0.25115833, -0.97212064, -0.6089479 ,\n",
            "        0.1847148 , -0.02069473, -0.62924623, -0.92309827, -0.71853906,\n",
            "        3.138035  , -8.234558  ,  2.6624982 ], dtype=float32), 'agent_3': Array([ 0.57409877,  0.83019125, -0.04375093,  0.15737125,  0.5330128 ,\n",
            "       -0.3162844 , -0.54088193, -0.25115833, -0.6089479 ,  0.6336686 ,\n",
            "        0.1847148 , -0.02069473, -0.62924623, -0.92309827, -0.71853906,\n",
            "        3.138035  ,  0.7925786 ,  2.710326  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.3747317   0.7149454  -1.3703328   0.7161193  -1.3769541   0.7153188\n",
            " -1.3676366   0.71478087]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3964226, dtype=float32), 'agent_0': Array(-1.3964226, dtype=float32), 'agent_1': Array(-1.3964226, dtype=float32), 'agent_2': Array(-1.3964226, dtype=float32), 'agent_3': Array(-1.3964226, dtype=float32)}\n",
            "step: 131\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58082974,  0.799527  , -0.02974152,  0.1159201 ,  0.588587  ,\n",
            "       -0.57249796,  0.78214955, -0.5010041 , -0.61736286, -0.5222745 ,\n",
            "       -0.48006773, -0.4948616 ,  1.0516286 , -1.4038352 , -2.3335047 ,\n",
            "        0.36827016, -0.13438764,  2.136418  ], dtype=float32), 'agent_1': Array([ 0.58082974,  0.799527  , -0.02974152,  0.1159201 ,  0.588587  ,\n",
            "       -0.57249796, -0.5010041 , -0.5199618 , -0.61736286, -0.5222745 ,\n",
            "       -0.48006773, -0.4948616 ,  1.0516286 , -1.4038352 , -2.3335047 ,\n",
            "        0.36827016,  0.94171035,  6.11534   ], dtype=float32), 'agent_2': Array([ 0.58082974,  0.799527  , -0.02974152,  0.1159201 ,  0.588587  ,\n",
            "       -0.57249796, -0.5010041 , -0.61736286, -0.67780244, -0.5222745 ,\n",
            "       -0.48006773, -0.4948616 ,  1.0516286 , -1.4038352 , -2.3335047 ,\n",
            "        0.36827016, -2.1702938 ,  8.374525  ], dtype=float32), 'agent_3': Array([ 0.58082974,  0.799527  , -0.02974152,  0.1159201 ,  0.588587  ,\n",
            "       -0.57249796, -0.5010041 , -0.61736286, -0.5222745 ,  0.7944567 ,\n",
            "       -0.48006773, -0.4948616 ,  1.0516286 , -1.4038352 , -2.3335047 ,\n",
            "        0.36827016,  1.4348944 ,  3.2973707 ], dtype=float32)}\n",
            "ctrl action chosen: [0.7808994  0.5831591  0.7784639  0.58511156 0.776359   0.5860028\n",
            " 0.7798187  0.5835544 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.0451307, dtype=float32), 'agent_0': Array(-4.0451307, dtype=float32), 'agent_1': Array(-4.0451307, dtype=float32), 'agent_2': Array(-4.0451307, dtype=float32), 'agent_3': Array(-4.0451307, dtype=float32)}\n",
            "step: 132\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6352642 ,   0.90344286,  -0.03507003,   0.05840427,\n",
            "         0.4232612 ,  -0.074789  ,   0.9455573 ,   0.07249454,\n",
            "        -0.22585416,   0.04124153,  -0.5150676 ,  -0.45809746,\n",
            "         1.1623502 ,  -0.22439454,  -1.294651  , -10.41996   ,\n",
            "        13.7855425 ,   4.607004  ], dtype=float32), 'agent_1': Array([  0.6352642 ,   0.90344286,  -0.03507003,   0.05840427,\n",
            "         0.4232612 ,  -0.074789  ,   0.07249454,  -0.46806097,\n",
            "        -0.22585416,   0.04124153,  -0.5150676 ,  -0.45809746,\n",
            "         1.1623502 ,  -0.22439454,  -1.294651  , -10.41996   ,\n",
            "        14.129492  ,  -0.23005025], dtype=float32), 'agent_2': Array([  0.6352642 ,   0.90344286,  -0.03507003,   0.05840427,\n",
            "         0.4232612 ,  -0.074789  ,   0.07249454,  -0.22585416,\n",
            "        -0.46247905,   0.04124153,  -0.5150676 ,  -0.45809746,\n",
            "         1.1623502 ,  -0.22439454,  -1.294651  , -10.41996   ,\n",
            "        12.201336  ,  -0.76646525], dtype=float32), 'agent_3': Array([  0.6352642 ,   0.90344286,  -0.03507003,   0.05840427,\n",
            "         0.4232612 ,  -0.074789  ,   0.07249454,  -0.22585416,\n",
            "         0.04124153,   1.0079374 ,  -0.5150676 ,  -0.45809746,\n",
            "         1.1623502 ,  -0.22439454,  -1.294651  , -10.41996   ,\n",
            "        13.877496  ,   4.7060905 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.267485   -0.17712858  0.2627091  -0.17589584  0.2634511  -0.17616458\n",
            "  0.26693013 -0.17792384]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4337294, dtype=float32), 'agent_0': Array(-1.4337294, dtype=float32), 'agent_1': Array(-1.4337294, dtype=float32), 'agent_2': Array(-1.4337294, dtype=float32), 'agent_3': Array(-1.4337294, dtype=float32)}\n",
            "step: 133\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.70029426,  0.9611575 , -0.03266362,  0.03384406,  0.27196327,\n",
            "        0.36475295,  1.0371494 ,  0.53629774,  0.14275032,  0.50174034,\n",
            "       -0.573194  , -0.41384697,  1.0437489 ,  0.33968362, -0.9274029 ,\n",
            "       -4.943895  ,  6.6754584 ,  1.7868706 ], dtype=float32), 'agent_1': Array([ 0.70029426,  0.9611575 , -0.03266362,  0.03384406,  0.27196327,\n",
            "        0.36475295,  0.53629774, -0.58151644,  0.14275032,  0.50174034,\n",
            "       -0.573194  , -0.41384697,  1.0437489 ,  0.33968362, -0.9274029 ,\n",
            "       -4.943895  ,  7.0102944 , -3.3736165 ], dtype=float32), 'agent_2': Array([ 0.70029426,  0.9611575 , -0.03266362,  0.03384406,  0.27196327,\n",
            "        0.36475295,  0.53629774,  0.14275032, -0.52656454,  0.50174034,\n",
            "       -0.573194  , -0.41384697,  1.0437489 ,  0.33968362, -0.9274029 ,\n",
            "       -4.943895  ,  5.3788996 , -1.276415  ], dtype=float32), 'agent_3': Array([ 0.70029426,  0.9611575 , -0.03266362,  0.03384406,  0.27196327,\n",
            "        0.36475295,  0.53629774,  0.14275032,  0.50174034,  1.086663  ,\n",
            "       -0.573194  , -0.41384697,  1.0437489 ,  0.33968362, -0.9274029 ,\n",
            "       -4.943895  ,  7.409554  ,  1.6129004 ], dtype=float32)}\n",
            "ctrl action chosen: [0.9136691  0.4630455  0.9101366  0.46145895 0.91268176 0.46128657\n",
            " 0.91218877 0.46297184]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.24997564, dtype=float32), 'agent_0': Array(0.24997564, dtype=float32), 'agent_1': Array(0.24997564, dtype=float32), 'agent_2': Array(0.24997564, dtype=float32), 'agent_3': Array(0.24997564, dtype=float32)}\n",
            "step: 134\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.2159505e-01,  9.7128040e-01, -6.9355574e-03,  9.8802242e-04,\n",
            "        2.3783475e-01,  5.5808395e-01,  1.2523556e+00,  5.7004863e-01,\n",
            "        3.1324589e-01,  5.7238996e-01, -7.4833632e-01, -4.8532486e-01,\n",
            "        1.9037724e-01,  5.8186257e-01, -1.0651459e+00,  1.9839075e-01,\n",
            "        1.4729447e+00,  2.1100376e+00], dtype=float32), 'agent_1': Array([ 7.2159505e-01,  9.7128040e-01, -6.9355574e-03,  9.8802242e-04,\n",
            "        2.3783475e-01,  5.5808395e-01,  5.7004863e-01, -6.2799442e-01,\n",
            "        3.1324589e-01,  5.7238996e-01, -7.4833632e-01, -4.8532486e-01,\n",
            "        1.9037724e-01,  5.8186257e-01, -1.0651459e+00,  1.9839075e-01,\n",
            "       -1.4001849e+00,  6.3484389e-01], dtype=float32), 'agent_2': Array([ 7.2159505e-01,  9.7128040e-01, -6.9355574e-03,  9.8802242e-04,\n",
            "        2.3783475e-01,  5.5808395e-01,  5.7004863e-01,  3.1324589e-01,\n",
            "       -5.2077216e-01,  5.7238996e-01, -7.4833632e-01, -4.8532486e-01,\n",
            "        1.9037724e-01,  5.8186257e-01, -1.0651459e+00,  1.9839075e-01,\n",
            "        2.6150186e+00,  1.3506304e-01], dtype=float32), 'agent_3': Array([ 7.2159505e-01,  9.7128040e-01, -6.9355574e-03,  9.8802242e-04,\n",
            "        2.3783475e-01,  5.5808395e-01,  5.7004863e-01,  3.1324589e-01,\n",
            "        5.7238996e-01,  1.2625079e+00, -7.4833632e-01, -4.8532486e-01,\n",
            "        1.9037724e-01,  5.8186257e-01, -1.0651459e+00,  1.9839075e-01,\n",
            "       -1.0225616e+00, -7.3767170e-02], dtype=float32)}\n",
            "ctrl action chosen: [ 0.64284074 -0.90742886  0.6374799  -0.9040586   0.6469207  -0.9149556\n",
            "  0.6364374  -0.9067477 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6829534, dtype=float32), 'agent_0': Array(-1.6829534, dtype=float32), 'agent_1': Array(-1.6829534, dtype=float32), 'agent_2': Array(-1.6829534, dtype=float32), 'agent_3': Array(-1.6829534, dtype=float32)}\n",
            "step: 135\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7167464 ,  0.97167635, -0.02976337,  0.01811582,  0.23373277,\n",
            "        0.5802447 ,  1.0039485 ,  0.5145214 ,  0.5167943 ,  0.52306974,\n",
            "       -1.3382673 , -0.9996414 , -0.38717985, -0.8015972 ,  1.2245018 ,\n",
            "       -0.6804934 , -0.79050446, -7.019272  ], dtype=float32), 'agent_1': Array([ 0.7167464 ,  0.97167635, -0.02976337,  0.01811582,  0.23373277,\n",
            "        0.5802447 ,  0.5145214 , -0.9459617 ,  0.5167943 ,  0.52306974,\n",
            "       -1.3382673 , -0.9996414 , -0.38717985, -0.8015972 ,  1.2245018 ,\n",
            "       -0.6804934 ,  0.16009067, -8.209581  ], dtype=float32), 'agent_2': Array([ 0.7167464 ,  0.97167635, -0.02976337,  0.01811582,  0.23373277,\n",
            "        0.5802447 ,  0.5145214 ,  0.5167943 , -0.8585099 ,  0.52306974,\n",
            "       -1.3382673 , -0.9996414 , -0.38717985, -0.8015972 ,  1.2245018 ,\n",
            "       -0.6804934 ,  5.502878  , -8.590075  ], dtype=float32), 'agent_3': Array([ 0.7167464 ,  0.97167635, -0.02976337,  0.01811582,  0.23373277,\n",
            "        0.5802447 ,  0.5145214 ,  0.5167943 ,  0.52306974,  0.9866607 ,\n",
            "       -1.3382673 , -0.9996414 , -0.38717985, -0.8015972 ,  1.2245018 ,\n",
            "       -0.6804934 ,  0.11866106, -7.733254  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.0795013  -1.2493912   0.07894606 -1.248459    0.08294509 -1.2522079\n",
            "  0.07967536 -1.2491795 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.5923073, dtype=float32), 'agent_0': Array(-2.5923073, dtype=float32), 'agent_1': Array(-2.5923073, dtype=float32), 'agent_2': Array(-2.5923073, dtype=float32), 'agent_3': Array(-2.5923073, dtype=float32)}\n",
            "step: 136\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6813649 ,   0.9581839 ,  -0.06114713,   0.04741189,\n",
            "         0.27549395,   0.41399598,   0.52846146,   0.3995735 ,\n",
            "         0.56603974,   0.42798036,  -0.9289026 ,  -0.8835316 ,\n",
            "        -0.98581314,  -1.2229133 ,   1.0051267 ,   2.1666012 ,\n",
            "        -3.6000576 , -11.533787  ], dtype=float32), 'agent_1': Array([ 0.6813649 ,  0.9581839 , -0.06114713,  0.04741189,  0.27549395,\n",
            "        0.41399598,  0.3995735 , -1.3142707 ,  0.56603974,  0.42798036,\n",
            "       -0.9289026 , -0.8835316 , -0.98581314, -1.2229133 ,  1.0051267 ,\n",
            "        2.1666012 , -2.6522167 , -1.4148334 ], dtype=float32), 'agent_2': Array([ 0.6813649 ,  0.9581839 , -0.06114713,  0.04741189,  0.27549395,\n",
            "        0.41399598,  0.3995735 ,  0.56603974, -1.3017112 ,  0.42798036,\n",
            "       -0.9289026 , -0.8835316 , -0.98581314, -1.2229133 ,  1.0051267 ,\n",
            "        2.1666012 , -0.40231952, -5.1547604 ], dtype=float32), 'agent_3': Array([ 0.6813649 ,  0.9581839 , -0.06114713,  0.04741189,  0.27549395,\n",
            "        0.41399598,  0.3995735 ,  0.56603974,  0.42798036,  0.47641337,\n",
            "       -0.9289026 , -0.8835316 , -0.98581314, -1.2229133 ,  1.0051267 ,\n",
            "        2.1666012 , -2.1759725 , -9.615311  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.9022964  -0.18040848 -1.9040073  -0.16891448 -1.9002041  -0.17986266\n",
            " -1.9018989  -0.17990379]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.3223171, dtype=float32), 'agent_0': Array(-3.3223171, dtype=float32), 'agent_1': Array(-3.3223171, dtype=float32), 'agent_2': Array(-3.3223171, dtype=float32), 'agent_3': Array(-3.3223171, dtype=float32)}\n",
            "step: 137\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.0912180e-01,  8.5225856e-01, -3.7256446e-02,  2.6247211e-02,\n",
            "        5.2113187e-01, -2.6203877e-01,  4.9220404e-01, -2.4207433e-01,\n",
            "       -9.5607160e-05, -2.2031571e-01, -8.0332756e-01, -4.0369034e-01,\n",
            "       -1.3646841e+00,  1.1594770e-01, -9.6135288e-01,  1.3387835e+01,\n",
            "       -1.6599026e+01, -6.1606172e-02], dtype=float32), 'agent_1': Array([ 6.0912180e-01,  8.5225856e-01, -3.7256446e-02,  2.6247211e-02,\n",
            "        5.2113187e-01, -2.6203877e-01, -2.4207433e-01, -1.2480093e+00,\n",
            "       -9.5607160e-05, -2.2031571e-01, -8.0332756e-01, -4.0369034e-01,\n",
            "       -1.3646841e+00,  1.1594770e-01, -9.6135288e-01,  1.3387835e+01,\n",
            "       -1.5794216e+01,  7.8675896e-01], dtype=float32), 'agent_2': Array([ 6.0912180e-01,  8.5225856e-01, -3.7256446e-02,  2.6247211e-02,\n",
            "        5.2113187e-01, -2.6203877e-01, -2.4207433e-01, -9.5607160e-05,\n",
            "       -1.2561448e+00, -2.2031571e-01, -8.0332756e-01, -4.0369034e-01,\n",
            "       -1.3646841e+00,  1.1594770e-01, -9.6135288e-01,  1.3387835e+01,\n",
            "       -1.5648454e+01,  1.1008173e+00], dtype=float32), 'agent_3': Array([ 6.0912180e-01,  8.5225856e-01, -3.7256446e-02,  2.6247211e-02,\n",
            "        5.2113187e-01, -2.6203877e-01, -2.4207433e-01, -9.5607160e-05,\n",
            "       -2.2031571e-01,  4.8156199e-01, -8.0332756e-01, -4.0369034e-01,\n",
            "       -1.3646841e+00,  1.1594770e-01, -9.6135288e-01,  1.3387835e+01,\n",
            "       -1.6303297e+01, -5.1033276e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.81396955  2.018639   -0.8136302   2.0200396  -0.8122763   2.0187464\n",
            " -0.8149819   2.0176365 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.056763, dtype=float32), 'agent_0': Array(-7.056763, dtype=float32), 'agent_1': Array(-7.056763, dtype=float32), 'agent_2': Array(-7.056763, dtype=float32), 'agent_3': Array(-7.056763, dtype=float32)}\n",
            "step: 138\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55116636,  0.7643594 , -0.01846018, -0.02620674,  0.64399314,\n",
            "       -0.5819624 ,  0.74105954, -0.5755256 , -0.43071944, -0.5820487 ,\n",
            "        0.01130104, -0.21123886, -1.3616562 , -2.0718493 , -3.4416664 ,\n",
            "        0.473682  ,  1.3238864 ,  9.4072895 ], dtype=float32), 'agent_1': Array([ 5.5116636e-01,  7.6435941e-01, -1.8460182e-02, -2.6206739e-02,\n",
            "        6.4399314e-01, -5.8196241e-01, -5.7552558e-01, -8.7254316e-01,\n",
            "       -4.3071944e-01, -5.8204871e-01,  1.1301041e-02, -2.1123886e-01,\n",
            "       -1.3616562e+00, -2.0718493e+00, -3.4416664e+00,  4.7368199e-01,\n",
            "        5.1585387e-02,  1.1678081e+01], dtype=float32), 'agent_2': Array([ 0.55116636,  0.7643594 , -0.01846018, -0.02620674,  0.64399314,\n",
            "       -0.5819624 , -0.5755256 , -0.43071944, -0.87872493, -0.5820487 ,\n",
            "        0.01130104, -0.21123886, -1.3616562 , -2.0718493 , -3.4416664 ,\n",
            "        0.473682  , -3.0346496 , 11.060501  ], dtype=float32), 'agent_3': Array([ 0.55116636,  0.7643594 , -0.01846018, -0.02620674,  0.64399314,\n",
            "       -0.5819624 , -0.5755256 , -0.43071944, -0.5820487 ,  0.73090166,\n",
            "        0.01130104, -0.21123886, -1.3616562 , -2.0718493 , -3.4416664 ,\n",
            "        0.473682  , -0.1536599 ,  9.716662  ], dtype=float32)}\n",
            "ctrl action chosen: [0.33455625 0.518857   0.33236855 0.51796675 0.33333576 0.5178253\n",
            " 0.3331005  0.518915  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.896551, dtype=float32), 'agent_0': Array(-8.896551, dtype=float32), 'agent_1': Array(-8.896551, dtype=float32), 'agent_2': Array(-8.896551, dtype=float32), 'agent_3': Array(-8.896551, dtype=float32)}\n",
            "step: 139\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.47840875,  0.81183255,  0.01585915, -0.12384452,  0.570385  ,\n",
            "       -0.23861557,  1.1896517 , -0.34340462, -0.24817008, -0.36680686,\n",
            "        0.01838207,  0.24652481, -1.0856032 ,  0.07589836, -3.284773  ,\n",
            "       -5.916897  ,  9.749223  ,  7.2741885 ], dtype=float32), 'agent_1': Array([ 0.47840875,  0.81183255,  0.01585915, -0.12384452,  0.570385  ,\n",
            "       -0.23861557, -0.34340462, -0.41866142, -0.24817008, -0.36680686,\n",
            "        0.01838207,  0.24652481, -1.0856032 ,  0.07589836, -3.284773  ,\n",
            "       -5.916897  ,  7.096475  ,  0.6490483 ], dtype=float32), 'agent_2': Array([ 0.47840875,  0.81183255,  0.01585915, -0.12384452,  0.570385  ,\n",
            "       -0.23861557, -0.34340462, -0.24817008, -0.4264612 , -0.36680686,\n",
            "        0.01838207,  0.24652481, -1.0856032 ,  0.07589836, -3.284773  ,\n",
            "       -5.916897  ,  6.1309776 ,  2.648555  ], dtype=float32), 'agent_3': Array([ 0.47840875,  0.81183255,  0.01585915, -0.12384452,  0.570385  ,\n",
            "       -0.23861557, -0.34340462, -0.24817008, -0.36680686,  1.2870821 ,\n",
            "        0.01838207,  0.24652481, -1.0856032 ,  0.07589836, -3.284773  ,\n",
            "       -5.916897  ,  6.812997  ,  7.441169  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.37235102 -0.7948344   0.3714515  -0.79573673  0.37223542 -0.7963801\n",
            "  0.3696824  -0.7951927 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3116598, dtype=float32), 'agent_0': Array(0.3116598, dtype=float32), 'agent_1': Array(0.3116598, dtype=float32), 'agent_2': Array(0.3116598, dtype=float32), 'agent_3': Array(0.3116598, dtype=float32)}\n",
            "step: 140\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.48328066,  0.8776488 ,  0.06495226, -0.0929192 ,  0.4657037 ,\n",
            "        0.20110035,  1.0676365 ,  0.02181073,  0.02792423, -0.03787538,\n",
            "       -0.42066574, -0.7390499 ,  1.0137379 ,  1.1989185 ,  0.57885814,\n",
            "       -4.6288514 ,  7.9437056 , -5.493659  ], dtype=float32), 'agent_1': Array([ 0.48328066,  0.8776488 ,  0.06495226, -0.0929192 ,  0.4657037 ,\n",
            "        0.20110035,  0.02181073, -0.59013534,  0.02792423, -0.03787538,\n",
            "       -0.42066574, -0.7390499 ,  1.0137379 ,  1.1989185 ,  0.57885814,\n",
            "       -4.6288514 ,  7.124676  , -3.3801856 ], dtype=float32), 'agent_2': Array([ 0.48328066,  0.8776488 ,  0.06495226, -0.0929192 ,  0.4657037 ,\n",
            "        0.20110035,  0.02181073,  0.02792423, -0.5367111 , -0.03787538,\n",
            "       -0.42066574, -0.7390499 ,  1.0137379 ,  1.1989185 ,  0.57885814,\n",
            "       -4.6288514 ,  5.921151  , -0.987966  ], dtype=float32), 'agent_3': Array([ 0.48328066,  0.8776488 ,  0.06495226, -0.0929192 ,  0.4657037 ,\n",
            "        0.20110035,  0.02181073,  0.02792423, -0.03787538,  1.0982609 ,\n",
            "       -0.42066574, -0.7390499 ,  1.0137379 ,  1.1989185 ,  0.57885814,\n",
            "       -4.6288514 ,  6.5065928 , -4.955633  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.04383178 -1.3996944   0.04412235 -1.3989724   0.0468639  -1.3985811\n",
            "  0.0422266  -1.3999507 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9482621, dtype=float32), 'agent_0': Array(-0.9482621, dtype=float32), 'agent_1': Array(-0.9482621, dtype=float32), 'agent_2': Array(-0.9482621, dtype=float32), 'agent_3': Array(-0.9482621, dtype=float32)}\n",
            "step: 141\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.550024  ,   0.89720184,   0.04806395,  -0.02953509,\n",
            "         0.4380028 ,   0.402249  ,   0.6557478 ,   0.13563943,\n",
            "         0.24876726,   0.10163424,  -0.12930632,  -1.272583  ,\n",
            "         1.3525724 ,  -0.18273368,   3.7118313 ,  -0.3401791 ,\n",
            "         2.8610468 , -11.137186  ], dtype=float32), 'agent_1': Array([ 0.550024  ,  0.89720184,  0.04806395, -0.02953509,  0.4380028 ,\n",
            "        0.402249  ,  0.13563943, -0.9173277 ,  0.24876726,  0.10163424,\n",
            "       -0.12930632, -1.272583  ,  1.3525724 , -0.18273368,  3.7118313 ,\n",
            "       -0.3401791 ,  0.33155254, -9.009217  ], dtype=float32), 'agent_2': Array([ 0.550024  ,  0.89720184,  0.04806395, -0.02953509,  0.4380028 ,\n",
            "        0.402249  ,  0.13563943,  0.24876726, -0.7887376 ,  0.10163424,\n",
            "       -0.12930632, -1.272583  ,  1.3525724 , -0.18273368,  3.7118313 ,\n",
            "       -0.3401791 ,  3.8700416 , -6.4658604 ], dtype=float32), 'agent_3': Array([  0.550024  ,   0.89720184,   0.04806395,  -0.02953509,\n",
            "         0.4380028 ,   0.402249  ,   0.13563943,   0.24876726,\n",
            "         0.10163424,   0.6554332 ,  -0.12930632,  -1.272583  ,\n",
            "         1.3525724 ,  -0.18273368,   3.7118313 ,  -0.3401791 ,\n",
            "         1.2034147 , -11.719533  ], dtype=float32)}\n",
            "ctrl action chosen: [0.9364085  0.22896059 0.9344248  0.23014322 0.9343717  0.22721955\n",
            " 0.936458   0.22866936]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0450742, dtype=float32), 'agent_0': Array(-3.0450742, dtype=float32), 'agent_1': Array(-3.0450742, dtype=float32), 'agent_2': Array(-3.0450742, dtype=float32), 'agent_3': Array(-3.0450742, dtype=float32)}\n",
            "step: 142\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6082007 ,  0.9288431 ,  0.03318866,  0.01338667,  0.3687408 ,\n",
            "        0.61189973,  0.4834149 ,  0.38606703,  0.59435785,  0.37602848,\n",
            "       -0.1809001 , -1.2203693 ,  1.2124538 ,  0.26163954,  0.6557822 ,\n",
            "        0.31035322, -1.1265607 ,  1.1036528 ], dtype=float32), 'agent_1': Array([ 0.6082007 ,  0.9288431 ,  0.03318866,  0.01338667,  0.3687408 ,\n",
            "        0.61189973,  0.38606703, -1.119807  ,  0.59435785,  0.37602848,\n",
            "       -0.1809001 , -1.2203693 ,  1.2124538 ,  0.26163954,  0.6557822 ,\n",
            "        0.31035322,  2.7885606 , -2.4108682 ], dtype=float32), 'agent_2': Array([ 0.6082007 ,  0.9288431 ,  0.03318866,  0.01338667,  0.3687408 ,\n",
            "        0.61189973,  0.38606703,  0.59435785, -0.8424917 ,  0.37602848,\n",
            "       -0.1809001 , -1.2203693 ,  1.2124538 ,  0.26163954,  0.6557822 ,\n",
            "        0.31035322,  1.3913466 , -0.24545997], dtype=float32), 'agent_3': Array([ 0.6082007 ,  0.9288431 ,  0.03318866,  0.01338667,  0.3687408 ,\n",
            "        0.61189973,  0.38606703,  0.59435785,  0.37602848,  0.4875201 ,\n",
            "       -0.1809001 , -1.2203693 ,  1.2124538 ,  0.26163954,  0.6557822 ,\n",
            "        0.31035322,  3.148565  ,  0.97007746], dtype=float32)}\n",
            "ctrl action chosen: [ 0.35787073 -1.5502687   0.36391354 -1.5585433   0.3669871  -1.5608506\n",
            "  0.36824998 -1.5561626 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9702941, dtype=float32), 'agent_0': Array(-0.9702941, dtype=float32), 'agent_1': Array(-0.9702941, dtype=float32), 'agent_2': Array(-0.9702941, dtype=float32), 'agent_3': Array(-0.9702941, dtype=float32)}\n",
            "step: 143\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.7220336e-01,  9.1549033e-01,  2.1422338e-03,  3.8686156e-02,\n",
            "        4.0047005e-01,  4.7981745e-01,  4.7311723e-01,  4.8506168e-01,\n",
            "        5.5037719e-01,  4.7770709e-01,  2.5272369e-01, -1.3539791e+00,\n",
            "        1.2571812e+00, -1.0028664e+00,  4.9515623e-01,  7.2011274e-01,\n",
            "       -2.5800989e+00,  1.2435205e+00], dtype=float32), 'agent_1': Array([ 6.7220336e-01,  9.1549033e-01,  2.1422338e-03,  3.8686156e-02,\n",
            "        4.0047005e-01,  4.7981745e-01,  4.8506168e-01, -1.2835882e+00,\n",
            "        5.5037719e-01,  4.7770709e-01,  2.5272369e-01, -1.3539791e+00,\n",
            "        1.2571812e+00, -1.0028664e+00,  4.9515623e-01,  7.2011274e-01,\n",
            "        3.3795166e+00,  1.1112975e+00], dtype=float32), 'agent_2': Array([ 6.7220336e-01,  9.1549033e-01,  2.1422338e-03,  3.8686156e-02,\n",
            "        4.0047005e-01,  4.7981745e-01,  4.8506168e-01,  5.5037719e-01,\n",
            "       -1.2177036e+00,  4.7770709e-01,  2.5272369e-01, -1.3539791e+00,\n",
            "        1.2571812e+00, -1.0028664e+00,  4.9515623e-01,  7.2011274e-01,\n",
            "       -1.5108883e+00, -9.2990894e+00], dtype=float32), 'agent_3': Array([ 6.7220336e-01,  9.1549033e-01,  2.1422338e-03,  3.8686156e-02,\n",
            "        4.0047005e-01,  4.7981745e-01,  4.8506168e-01,  5.5037719e-01,\n",
            "        4.7770709e-01,  4.8369342e-01,  2.5272369e-01, -1.3539791e+00,\n",
            "        1.2571812e+00, -1.0028664e+00,  4.9515623e-01,  7.2011274e-01,\n",
            "        3.4657490e+00,  1.6771518e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.347645    0.68898964 -1.3332317   0.6875651  -1.3366814   0.6756693\n",
            " -1.3338939   0.68612105]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.1520314, dtype=float32), 'agent_0': Array(-4.1520314, dtype=float32), 'agent_1': Array(-4.1520314, dtype=float32), 'agent_2': Array(-4.1520314, dtype=float32), 'agent_3': Array(-4.1520314, dtype=float32)}\n",
            "step: 144\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.1499407e-01,  7.7101362e-01,  3.1117972e-02,  1.4914295e-02,\n",
            "        6.3588303e-01, -2.5246745e-01,  8.5065395e-01,  1.0965670e-02,\n",
            "       -1.5387934e-01,  7.7811410e-03,  1.4257431e-01, -7.1620941e-01,\n",
            "        3.4807920e-01,  2.3039924e-01, -1.7729669e+00,  1.3589159e+01,\n",
            "       -1.7342402e+01,  1.0925321e+01], dtype=float32), 'agent_1': Array([ 7.1499407e-01,  7.7101362e-01,  3.1117972e-02,  1.4914295e-02,\n",
            "        6.3588303e-01, -2.5246745e-01,  1.0965670e-02, -1.0650036e+00,\n",
            "       -1.5387934e-01,  7.7811410e-03,  1.4257431e-01, -7.1620941e-01,\n",
            "        3.4807920e-01,  2.3039924e-01, -1.7729669e+00,  1.3589159e+01,\n",
            "       -1.2877226e+01,  5.9409676e+00], dtype=float32), 'agent_2': Array([ 7.1499407e-01,  7.7101362e-01,  3.1117972e-02,  1.4914295e-02,\n",
            "        6.3588303e-01, -2.5246745e-01,  1.0965670e-02, -1.5387934e-01,\n",
            "       -1.1702622e+00,  7.7811410e-03,  1.4257431e-01, -7.1620941e-01,\n",
            "        3.4807920e-01,  2.3039924e-01, -1.7729669e+00,  1.3589159e+01,\n",
            "       -1.7600761e+01,  2.4278519e+00], dtype=float32), 'agent_3': Array([ 7.1499407e-01,  7.7101362e-01,  3.1117972e-02,  1.4914295e-02,\n",
            "        6.3588303e-01, -2.5246745e-01,  1.0965670e-02, -1.5387934e-01,\n",
            "        7.7811410e-03,  8.7261426e-01,  1.4257431e-01, -7.1620941e-01,\n",
            "        3.4807920e-01,  2.3039924e-01, -1.7729669e+00,  1.3589159e+01,\n",
            "       -1.2994075e+01,  9.8131790e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.07525017  2.1159692  -0.07784009  2.1166086  -0.07949752  2.1120484\n",
            " -0.0730407   2.1171093 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.3278334, dtype=float32), 'agent_0': Array(-3.3278334, dtype=float32), 'agent_1': Array(-3.3278334, dtype=float32), 'agent_2': Array(-3.3278334, dtype=float32), 'agent_3': Array(-3.3278334, dtype=float32)}\n",
            "step: 145\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7140137 ,  0.67270714,  0.06495066, -0.04667341,  0.7355734 ,\n",
            "       -0.58396006,  1.3367522 , -0.19127081, -0.54520786, -0.20228948,\n",
            "        0.3533244 , -0.67858696, -0.16589165, -0.5543793 , -1.5620381 ,\n",
            "        1.079872  ,  1.1326952 ,  0.5019681 ], dtype=float32), 'agent_1': Array([ 0.7140137 ,  0.67270714,  0.06495066, -0.04667341,  0.7355734 ,\n",
            "       -0.58396006, -0.19127081, -0.50531065, -0.54520786, -0.20228948,\n",
            "        0.3533244 , -0.67858696, -0.16589165, -0.5543793 , -1.5620381 ,\n",
            "        1.079872  ,  0.69272095, 13.051928  ], dtype=float32), 'agent_2': Array([ 0.7140137 ,  0.67270714,  0.06495066, -0.04667341,  0.7355734 ,\n",
            "       -0.58396006, -0.19127081, -0.54520786, -0.7996034 , -0.20228948,\n",
            "        0.3533244 , -0.67858696, -0.16589165, -0.5543793 , -1.5620381 ,\n",
            "        1.079872  , -1.386256  , 10.326535  ], dtype=float32), 'agent_3': Array([ 0.7140137 ,  0.67270714,  0.06495066, -0.04667341,  0.7355734 ,\n",
            "       -0.58396006, -0.19127081, -0.54520786, -0.20228948,  1.3305157 ,\n",
            "        0.3533244 , -0.67858696, -0.16589165, -0.5543793 , -1.5620381 ,\n",
            "        1.079872  ,  0.4290787 ,  1.4669964 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.6037222   0.5279629  -0.6117481   0.53153205 -0.6114013   0.5316218\n",
            " -0.606362    0.5320151 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.686131, dtype=float32), 'agent_0': Array(-7.686131, dtype=float32), 'agent_1': Array(-7.686131, dtype=float32), 'agent_2': Array(-7.686131, dtype=float32), 'agent_3': Array(-7.686131, dtype=float32)}\n",
            "step: 146\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6657892 ,  0.63456106,  0.07930746, -0.0256228 ,  0.76836586,\n",
            "       -0.5421496 ,  1.2589061 , -0.26978695, -0.5618007 , -0.27540907,\n",
            "        0.07675886, -1.0755539 , -1.4344215 ,  0.9188538 ,  0.07176053,\n",
            "        2.3340352 ,  0.9518816 , -1.2938826 ], dtype=float32), 'agent_1': Array([ 0.6657892 ,  0.63456106,  0.07930746, -0.0256228 ,  0.76836586,\n",
            "       -0.5421496 , -0.26978695, -0.48677164, -0.5618007 , -0.27540907,\n",
            "        0.07675886, -1.0755539 , -1.4344215 ,  0.9188538 ,  0.07176053,\n",
            "        2.3340352 , -2.9054418 ,  0.10699413], dtype=float32), 'agent_2': Array([ 0.6657892 ,  0.63456106,  0.07930746, -0.0256228 ,  0.76836586,\n",
            "       -0.5421496 , -0.26978695, -0.5618007 , -0.4692098 , -0.27540907,\n",
            "        0.07675886, -1.0755539 , -1.4344215 ,  0.9188538 ,  0.07176053,\n",
            "        2.3340352 ,  0.0140671 ,  3.024404  ], dtype=float32), 'agent_3': Array([ 0.6657892 ,  0.63456106,  0.07930746, -0.0256228 ,  0.76836586,\n",
            "       -0.5421496 , -0.26978695, -0.5618007 , -0.27540907,  1.2489672 ,\n",
            "        0.07675886, -1.0755539 , -1.4344215 ,  0.9188538 ,  0.07176053,\n",
            "        2.3340352 , -2.5179627 , -1.4752582 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.46954072 -0.4449123  -0.47582793 -0.4410471  -0.4713165  -0.4377884\n",
            " -0.47467482 -0.44267532]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.23262167, dtype=float32), 'agent_0': Array(-0.23262167, dtype=float32), 'agent_1': Array(-0.23262167, dtype=float32), 'agent_2': Array(-0.23262167, dtype=float32), 'agent_3': Array(-0.23262167, dtype=float32)}\n",
            "step: 147\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60689926,  0.57461363,  0.06583914,  0.01930834,  0.81554365,\n",
            "       -0.5352801 ,  0.93309885, -0.48928043, -0.5522507 , -0.47217417,\n",
            "       -0.03116131, -1.3325691 , -1.0541677 ,  1.7815763 ,  1.9306754 ,\n",
            "        3.5838923 , -0.4582922 , -9.079197  ], dtype=float32), 'agent_1': Array([ 0.60689926,  0.57461363,  0.06583914,  0.01930834,  0.81554365,\n",
            "       -0.5352801 , -0.48928043, -0.62347466, -0.5522507 , -0.47217417,\n",
            "       -0.03116131, -1.3325691 , -1.0541677 ,  1.7815763 ,  1.9306754 ,\n",
            "        3.5838923 , -5.667621  , -4.809435  ], dtype=float32), 'agent_2': Array([ 0.60689926,  0.57461363,  0.06583914,  0.01930834,  0.81554365,\n",
            "       -0.5352801 , -0.48928043, -0.5522507 , -0.5214959 , -0.47217417,\n",
            "       -0.03116131, -1.3325691 , -1.0541677 ,  1.7815763 ,  1.9306754 ,\n",
            "        3.5838923 ,  0.45149237, -1.0475005 ], dtype=float32), 'agent_3': Array([ 0.60689926,  0.57461363,  0.06583914,  0.01930834,  0.81554365,\n",
            "       -0.5352801 , -0.48928043, -0.5522507 , -0.47217417,  0.9443425 ,\n",
            "       -0.03116131, -1.3325691 , -1.0541677 ,  1.7815763 ,  1.9306754 ,\n",
            "        3.5838923 , -5.339862  , -8.097497  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.13477024  1.672397   -0.1347118   1.6740756  -0.13657252  1.6764973\n",
            " -0.13529463  1.6701818 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.20323479, dtype=float32), 'agent_0': Array(0.20323479, dtype=float32), 'agent_1': Array(0.20323479, dtype=float32), 'agent_2': Array(0.20323479, dtype=float32), 'agent_3': Array(0.20323479, dtype=float32)}\n",
            "step: 148\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4241884e-01,  5.5817908e-01,  6.5794177e-02,  2.7732877e-02,\n",
            "        8.2664281e-01, -4.2865610e-01,  9.3617845e-01, -5.4810911e-01,\n",
            "       -4.0642235e-01, -5.4116219e-01,  1.0740757e-02, -6.2694550e-01,\n",
            "       -1.1235952e+00, -6.2580687e-01, -4.1479486e-01, -3.0381065e-03,\n",
            "        2.5813041e+00,  3.6645701e+00], dtype=float32), 'agent_1': Array([ 5.4241884e-01,  5.5817908e-01,  6.5794177e-02,  2.7732877e-02,\n",
            "        8.2664281e-01, -4.2865610e-01, -5.4810911e-01, -5.3159529e-01,\n",
            "       -4.0642235e-01, -5.4116219e-01,  1.0740757e-02, -6.2694550e-01,\n",
            "       -1.1235952e+00, -6.2580687e-01, -4.1479486e-01, -3.0381065e-03,\n",
            "        5.0331891e-01,  5.2127061e+00], dtype=float32), 'agent_2': Array([ 5.4241884e-01,  5.5817908e-01,  6.5794177e-02,  2.7732877e-02,\n",
            "        8.2664281e-01, -4.2865610e-01, -5.4810911e-01, -4.0642235e-01,\n",
            "       -4.9263850e-01, -5.4116219e-01,  1.0740757e-02, -6.2694550e-01,\n",
            "       -1.1235952e+00, -6.2580687e-01, -4.1479486e-01, -3.0381065e-03,\n",
            "        3.4796474e+00, -1.7722545e-03], dtype=float32), 'agent_3': Array([ 0.54241884,  0.5581791 ,  0.06579418,  0.02773288,  0.8266428 ,\n",
            "       -0.4286561 , -0.5481091 , -0.40642235, -0.5411622 ,  0.9562836 ,\n",
            "        0.01074076, -0.6269455 , -1.1235952 , -0.62580687, -0.41479486,\n",
            "       -0.00303811,  0.43788868,  2.6826372 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8969897   1.2789927  -0.90164465  1.2788336  -0.8948849   1.271156\n",
            " -0.8988577   1.2800531 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.6666594, dtype=float32), 'agent_0': Array(-4.6666594, dtype=float32), 'agent_1': Array(-4.6666594, dtype=float32), 'agent_2': Array(-4.6666594, dtype=float32), 'agent_3': Array(-4.6666594, dtype=float32)}\n",
            "step: 149\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.1379806e-01,  5.1239020e-01,  7.6179437e-02, -4.7464380e-03,\n",
            "        8.5535401e-01, -5.1838291e-01,  1.2666099e+00, -5.6582189e-01,\n",
            "       -4.7840267e-01, -5.7550246e-01,  7.9689026e-01, -6.0362816e-01,\n",
            "        1.3887882e-02, -1.1259563e+00, -1.1703647e+00,  1.9468045e+00,\n",
            "       -2.2893877e+00,  6.7970490e+00], dtype=float32), 'agent_1': Array([ 0.51379806,  0.5123902 ,  0.07617944, -0.00474644,  0.855354  ,\n",
            "       -0.5183829 , -0.5658219 , -0.44741684, -0.47840267, -0.57550246,\n",
            "        0.79689026, -0.60362816,  0.01388788, -1.1259563 , -1.1703647 ,\n",
            "        1.9468045 ,  0.4876834 ,  0.2649981 ], dtype=float32), 'agent_2': Array([ 0.51379806,  0.5123902 ,  0.07617944, -0.00474644,  0.855354  ,\n",
            "       -0.5183829 , -0.5658219 , -0.47840267, -0.47650915, -0.57550246,\n",
            "        0.79689026, -0.60362816,  0.01388788, -1.1259563 , -1.1703647 ,\n",
            "        1.9468045 , -2.6170824 ,  0.13435641], dtype=float32), 'agent_3': Array([ 0.51379806,  0.5123902 ,  0.07617944, -0.00474644,  0.855354  ,\n",
            "       -0.5183829 , -0.5658219 , -0.47840267, -0.57550246,  1.0624948 ,\n",
            "        0.79689026, -0.60362816,  0.01388788, -1.1259563 , -1.1703647 ,\n",
            "        1.9468045 ,  0.04030152,  1.6296909 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.79824674 -0.29278678  0.79910326 -0.29700455  0.7956264  -0.2971056\n",
            "  0.801156   -0.29268178]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.4459636, dtype=float32), 'agent_0': Array(-3.4459636, dtype=float32), 'agent_1': Array(-3.4459636, dtype=float32), 'agent_2': Array(-3.4459636, dtype=float32), 'agent_3': Array(-3.4459636, dtype=float32)}\n",
            "step: 150\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54972625,  0.6432937 ,  0.06183685, -0.01094492,  0.7630397 ,\n",
            "       -0.11945778,  1.238039  , -0.03893224, -0.08260431, -0.08826557,\n",
            "        1.0388017 , -1.0870934 ,  0.3802061 , -0.8699215 , -0.24252738,\n",
            "       -8.782761  , 10.732335  , -0.29787147], dtype=float32), 'agent_1': Array([ 5.4972625e-01,  6.4329368e-01,  6.1836846e-02, -1.0944915e-02,\n",
            "        7.6303971e-01, -1.1945778e-01, -3.8932241e-02, -5.7585156e-01,\n",
            "       -8.2604311e-02, -8.8265568e-02,  1.0388017e+00, -1.0870934e+00,\n",
            "        3.8020611e-01, -8.6992151e-01, -2.4252738e-01, -8.7827606e+00,\n",
            "        1.3965516e+01, -3.5555043e+00], dtype=float32), 'agent_2': Array([ 0.54972625,  0.6432937 ,  0.06183685, -0.01094492,  0.7630397 ,\n",
            "       -0.11945778, -0.03893224, -0.08260431, -0.63863665, -0.08826557,\n",
            "        1.0388017 , -1.0870934 ,  0.3802061 , -0.8699215 , -0.24252738,\n",
            "       -8.782761  , 10.867653  , -4.3533525 ], dtype=float32), 'agent_3': Array([ 5.4972625e-01,  6.4329368e-01,  6.1836846e-02, -1.0944915e-02,\n",
            "        7.6303971e-01, -1.1945778e-01, -3.8932241e-02, -8.2604311e-02,\n",
            "       -8.8265568e-02,  9.4211531e-01,  1.0388017e+00, -1.0870934e+00,\n",
            "        3.8020611e-01, -8.6992151e-01, -2.4252738e-01, -8.7827606e+00,\n",
            "        1.3363018e+01, -1.7100070e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.53715277 0.34669346 0.53381294 0.34526575 0.53401285 0.34435773\n",
            " 0.5335756  0.34539583]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.6426109, dtype=float32), 'agent_0': Array(0.6426109, dtype=float32), 'agent_1': Array(0.6426109, dtype=float32), 'agent_2': Array(0.6426109, dtype=float32), 'agent_3': Array(0.6426109, dtype=float32)}\n",
            "step: 151\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.543963  ,  0.7820924 ,  0.07051517, -0.03626253,  0.6180973 ,\n",
            "        0.38529772,  1.2148434 ,  0.5799272 ,  0.43286   ,  0.52153397,\n",
            "        0.9898186 , -0.7555008 , -0.14923811, -0.8953935 , -1.6043417 ,\n",
            "       -5.988171  ,  8.113578  , -0.749464  ], dtype=float32), 'agent_1': Array([ 0.543963  ,  0.7820924 ,  0.07051517, -0.03626253,  0.6180973 ,\n",
            "        0.38529772,  0.5799272 , -0.63967836,  0.43286   ,  0.52153397,\n",
            "        0.9898186 , -0.7555008 , -0.14923811, -0.8953935 , -1.6043417 ,\n",
            "       -5.988171  ,  8.631118  ,  1.0978905 ], dtype=float32), 'agent_2': Array([ 0.543963  ,  0.7820924 ,  0.07051517, -0.03626253,  0.6180973 ,\n",
            "        0.38529772,  0.5799272 ,  0.43286   , -0.6683717 ,  0.52153397,\n",
            "        0.9898186 , -0.7555008 , -0.14923811, -0.8953935 , -1.6043417 ,\n",
            "       -5.988171  ,  8.473182  ,  1.1612531 ], dtype=float32), 'agent_3': Array([ 0.543963  ,  0.7820924 ,  0.07051517, -0.03626253,  0.6180973 ,\n",
            "        0.38529772,  0.5799272 ,  0.43286   ,  0.52153397,  1.0608679 ,\n",
            "        0.9898186 , -0.7555008 , -0.14923811, -0.8953935 , -1.6043417 ,\n",
            "       -5.988171  ,  9.840049  ,  2.8142703 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.69458604 -1.0308946   0.69398475 -1.0285488   0.69488835 -1.0296291\n",
            "  0.6921675  -1.0290657 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2384808, dtype=float32), 'agent_0': Array(1.2384808, dtype=float32), 'agent_1': Array(1.2384808, dtype=float32), 'agent_2': Array(1.2384808, dtype=float32), 'agent_3': Array(1.2384808, dtype=float32)}\n",
            "step: 152\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.55639726,   0.7872626 ,   0.01620724,  -0.0462659 ,\n",
            "         0.61466604,   0.52573717,   0.8022779 ,   0.54994124,\n",
            "         0.54142743,   0.56558925,   0.8803487 ,  -1.6038418 ,\n",
            "         0.2967    ,  -2.3381934 ,   1.999954  ,   1.1967828 ,\n",
            "         1.0899326 , -10.536557  ], dtype=float32), 'agent_1': Array([ 0.55639726,  0.7872626 ,  0.01620724, -0.0462659 ,  0.61466604,\n",
            "        0.52573717,  0.54994124, -0.894667  ,  0.54142743,  0.56558925,\n",
            "        0.8803487 , -1.6038418 ,  0.2967    , -2.3381934 ,  1.999954  ,\n",
            "        1.1967828 , -2.42006   , -6.816538  ], dtype=float32), 'agent_2': Array([ 0.55639726,  0.7872626 ,  0.01620724, -0.0462659 ,  0.61466604,\n",
            "        0.52573717,  0.54994124,  0.54142743, -0.9539739 ,  0.56558925,\n",
            "        0.8803487 , -1.6038418 ,  0.2967    , -2.3381934 ,  1.999954  ,\n",
            "        1.1967828 ,  0.11322775, -8.510013  ], dtype=float32), 'agent_3': Array([ 0.55639726,  0.7872626 ,  0.01620724, -0.0462659 ,  0.61466604,\n",
            "        0.52573717,  0.54994124,  0.54142743,  0.56558925,  0.77570087,\n",
            "        0.8803487 , -1.6038418 ,  0.2967    , -2.3381934 ,  1.999954  ,\n",
            "        1.1967828 , -1.2512045 , -8.876303  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3130605  -1.0136107  -0.31655475 -1.0123192  -0.3132056  -1.0160345\n",
            " -0.31515008 -1.0146099 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.208812, dtype=float32), 'agent_0': Array(-1.208812, dtype=float32), 'agent_1': Array(-1.208812, dtype=float32), 'agent_2': Array(-1.208812, dtype=float32), 'agent_3': Array(-1.208812, dtype=float32)}\n",
            "step: 153\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57770246,  0.7146015 , -0.04565484, -0.02828704,  0.697467  ,\n",
            "        0.38051534,  0.43522352,  0.1623245 ,  0.37518406,  0.27776182,\n",
            "       -0.1587987 , -1.2337685 ,  0.6560087 ,  0.737709  ,  0.8354811 ,\n",
            "        4.967746  , -3.0589764 ,  0.7374727 ], dtype=float32), 'agent_1': Array([ 0.57770246,  0.7146015 , -0.04565484, -0.02828704,  0.697467  ,\n",
            "        0.38051534,  0.1623245 , -1.1901586 ,  0.37518406,  0.27776182,\n",
            "       -0.1587987 , -1.2337685 ,  0.6560087 ,  0.737709  ,  0.8354811 ,\n",
            "        4.967746  , -9.186546  , -5.283361  ], dtype=float32), 'agent_2': Array([ 0.57770246,  0.7146015 , -0.04565484, -0.02828704,  0.697467  ,\n",
            "        0.38051534,  0.1623245 ,  0.37518406, -1.3085864 ,  0.27776182,\n",
            "       -0.1587987 , -1.2337685 ,  0.6560087 ,  0.737709  ,  0.8354811 ,\n",
            "        4.967746  , -3.667848  , -0.11482517], dtype=float32), 'agent_3': Array([ 0.57770246,  0.7146015 , -0.04565484, -0.02828704,  0.697467  ,\n",
            "        0.38051534,  0.1623245 ,  0.37518406,  0.27776182,  0.43333137,\n",
            "       -0.1587987 , -1.2337685 ,  0.6560087 ,  0.737709  ,  0.8354811 ,\n",
            "        4.967746  , -7.09748   , -0.33027926], dtype=float32)}\n",
            "ctrl action chosen: [-0.37990037 -0.24042445 -0.37940317 -0.24331963 -0.37656263 -0.24362886\n",
            " -0.37932324 -0.2406396 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.8172431, dtype=float32), 'agent_0': Array(-0.8172431, dtype=float32), 'agent_1': Array(-0.8172431, dtype=float32), 'agent_2': Array(-0.8172431, dtype=float32), 'agent_3': Array(-0.8172431, dtype=float32)}\n",
            "step: 154\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.43486142e-01,  6.16468966e-01, -3.62457745e-02,  7.24981597e-04,\n",
            "        7.86544263e-01,  1.78077057e-01,  5.05342603e-01, -3.26183140e-01,\n",
            "        1.47009477e-01, -1.02152035e-01, -7.55238533e-01, -1.22556686e+00,\n",
            "        1.41236782e+00,  6.35334969e-01,  1.01794577e+00,  5.70394850e+00,\n",
            "       -4.74906254e+00,  1.72251806e-01], dtype=float32), 'agent_1': Array([ 6.43486142e-01,  6.16468966e-01, -3.62457745e-02,  7.24981597e-04,\n",
            "        7.86544263e-01,  1.78077057e-01, -3.26183140e-01, -1.24389923e+00,\n",
            "        1.47009477e-01, -1.02152035e-01, -7.55238533e-01, -1.22556686e+00,\n",
            "        1.41236782e+00,  6.35334969e-01,  1.01794577e+00,  5.70394850e+00,\n",
            "       -1.00006618e+01, -6.74142122e-01], dtype=float32), 'agent_2': Array([ 6.43486142e-01,  6.16468966e-01, -3.62457745e-02,  7.24981597e-04,\n",
            "        7.86544263e-01,  1.78077057e-01, -3.26183140e-01,  1.47009477e-01,\n",
            "       -1.24371433e+00, -1.02152035e-01, -7.55238533e-01, -1.22556686e+00,\n",
            "        1.41236782e+00,  6.35334969e-01,  1.01794577e+00,  5.70394850e+00,\n",
            "       -5.36637545e+00, -3.19464616e-02], dtype=float32), 'agent_3': Array([ 6.43486142e-01,  6.16468966e-01, -3.62457745e-02,  7.24981597e-04,\n",
            "        7.86544263e-01,  1.78077057e-01, -3.26183140e-01,  1.47009477e-01,\n",
            "       -1.02152035e-01,  4.84701365e-01, -7.55238533e-01, -1.22556686e+00,\n",
            "        1.41236782e+00,  6.35334969e-01,  1.01794577e+00,  5.70394850e+00,\n",
            "       -8.03931808e+00,  1.20410264e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.34478068  2.030729   -0.34319752  2.0333936  -0.34432954  2.0290024\n",
            " -0.34734833  2.0313935 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.08559743, dtype=float32), 'agent_0': Array(-0.08559743, dtype=float32), 'agent_1': Array(-0.08559743, dtype=float32), 'agent_2': Array(-0.08559743, dtype=float32), 'agent_3': Array(-0.08559743, dtype=float32)}\n",
            "step: 155\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.9297367e-01,  5.4111844e-01, -7.9883868e-03,  6.8975030e-03,\n",
            "        8.4088022e-01,  2.2904744e-02,  8.4125829e-01, -6.0412252e-01,\n",
            "       -4.7016710e-02, -4.0375519e-01, -9.3363523e-01, -6.7567825e-01,\n",
            "        5.7947636e-01,  5.4424942e-01, -1.7896547e+00,  8.7815160e-01,\n",
            "       -3.8717917e-01,  9.7000103e+00], dtype=float32), 'agent_1': Array([ 0.6929737 ,  0.54111844, -0.00798839,  0.0068975 ,  0.8408802 ,\n",
            "        0.02290474, -0.6041225 , -1.0526578 , -0.04701671, -0.4037552 ,\n",
            "       -0.93363523, -0.67567825,  0.57947636,  0.5442494 , -1.7896547 ,\n",
            "        0.8781516 ,  0.30425507,  6.0166235 ], dtype=float32), 'agent_2': Array([ 6.9297367e-01,  5.4111844e-01, -7.9883868e-03,  6.8975030e-03,\n",
            "        8.4088022e-01,  2.2904744e-02, -6.0412252e-01, -4.7016710e-02,\n",
            "       -9.2864209e-01, -4.0375519e-01, -9.3363523e-01, -6.7567825e-01,\n",
            "        5.7947636e-01,  5.4424942e-01, -1.7896547e+00,  8.7815160e-01,\n",
            "       -1.3472846e+00,  9.8673267e+00], dtype=float32), 'agent_3': Array([ 6.9297367e-01,  5.4111844e-01, -7.9883868e-03,  6.8975030e-03,\n",
            "        8.4088022e-01,  2.2904744e-02, -6.0412252e-01, -4.7016710e-02,\n",
            "       -4.0375519e-01,  8.7680644e-01, -9.3363523e-01, -6.7567825e-01,\n",
            "        5.7947636e-01,  5.4424942e-01, -1.7896547e+00,  8.7815160e-01,\n",
            "       -3.5231683e+00,  1.1687260e+01], dtype=float32)}\n",
            "ctrl action chosen: [1.03342    0.5156765  1.0328193  0.51642454 1.0328585  0.51450413\n",
            " 1.0329736  0.51463205]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.309825, dtype=float32), 'agent_0': Array(-8.309825, dtype=float32), 'agent_1': Array(-8.309825, dtype=float32), 'agent_2': Array(-8.309825, dtype=float32), 'agent_3': Array(-8.309825, dtype=float32)}\n",
            "step: 156\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.9969821e-01,  7.0994908e-01,  3.2890826e-02,  6.8728370e-03,\n",
            "        7.0345098e-01,  6.0678077e-01,  1.2784088e+00, -3.4360632e-02,\n",
            "        5.1105165e-01,  2.7545737e-02, -1.0110378e+00, -8.3994865e-01,\n",
            "       -1.3420582e-01,  1.5394844e+00, -6.3453943e-01, -9.7818708e+00,\n",
            "        1.0968345e+01,  6.0532889e+00], dtype=float32), 'agent_1': Array([ 6.9969821e-01,  7.0994908e-01,  3.2890826e-02,  6.8728370e-03,\n",
            "        7.0345098e-01,  6.0678077e-01, -3.4360632e-02, -6.9553113e-01,\n",
            "        5.1105165e-01,  2.7545737e-02, -1.0110378e+00, -8.3994865e-01,\n",
            "       -1.3420582e-01,  1.5394844e+00, -6.3453943e-01, -9.7818708e+00,\n",
            "        1.4195274e+01,  8.9241314e+00], dtype=float32), 'agent_2': Array([ 6.9969821e-01,  7.0994908e-01,  3.2890826e-02,  6.8728370e-03,\n",
            "        7.0345098e-01,  6.0678077e-01, -3.4360632e-02,  5.1105165e-01,\n",
            "       -4.5623919e-01,  2.7545737e-02, -1.0110378e+00, -8.3994865e-01,\n",
            "       -1.3420582e-01,  1.5394844e+00, -6.3453943e-01, -9.7818708e+00,\n",
            "        1.3129221e+01,  6.0261335e+00], dtype=float32), 'agent_3': Array([ 6.9969821e-01,  7.0994908e-01,  3.2890826e-02,  6.8728370e-03,\n",
            "        7.0345098e-01,  6.0678077e-01, -3.4360632e-02,  5.1105165e-01,\n",
            "        2.7545737e-02,  1.3177232e+00, -1.0110378e+00, -8.3994865e-01,\n",
            "       -1.3420582e-01,  1.5394844e+00, -6.3453943e-01, -9.7818708e+00,\n",
            "        1.0525809e+01,  1.1717274e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.36459306 -0.9188992   0.363665   -0.9199531   0.36342546 -0.921682\n",
            "  0.36135742 -0.92110205]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.571795, dtype=float32), 'agent_0': Array(-2.571795, dtype=float32), 'agent_1': Array(-2.571795, dtype=float32), 'agent_2': Array(-2.571795, dtype=float32), 'agent_3': Array(-2.571795, dtype=float32)}\n",
            "step: 157\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6844065 ,  0.73200727,  0.00554975,  0.0359551 ,  0.68032485,\n",
            "        0.54272306,  1.1630784 ,  0.18789816,  0.5679586 ,  0.15537645,\n",
            "       -0.9424448 , -1.3873577 , -0.32496452,  0.02241336,  1.6929756 ,\n",
            "       -0.6975205 , -2.9519355 , -3.4050202 ], dtype=float32), 'agent_1': Array([ 0.6844065 ,  0.73200727,  0.00554975,  0.0359551 ,  0.68032485,\n",
            "        0.54272306,  0.18789816, -0.6727013 ,  0.5679586 ,  0.15537645,\n",
            "       -0.9424448 , -1.3873577 , -0.32496452,  0.02241336,  1.6929756 ,\n",
            "       -0.6975205 ,  3.4016175 , -2.7839053 ], dtype=float32), 'agent_2': Array([ 0.6844065 ,  0.73200727,  0.00554975,  0.0359551 ,  0.68032485,\n",
            "        0.54272306,  0.18789816,  0.5679586 , -0.61100674,  0.15537645,\n",
            "       -0.9424448 , -1.3873577 , -0.32496452,  0.02241336,  1.6929756 ,\n",
            "       -0.6975205 , -0.73567796, -4.299988  ], dtype=float32), 'agent_3': Array([ 0.6844065 ,  0.73200727,  0.00554975,  0.0359551 ,  0.68032485,\n",
            "        0.54272306,  0.18789816,  0.5679586 ,  0.15537645,  1.1590084 ,\n",
            "       -0.9424448 , -1.3873577 , -0.32496452,  0.02241336,  1.6929756 ,\n",
            "       -0.6975205 ,  2.2608693 , -4.300071  ], dtype=float32)}\n",
            "ctrl action chosen: [1.4271951 1.1546184 1.4274658 1.1505171 1.4296265 1.149156  1.427322\n",
            " 1.1484342]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8563128, dtype=float32), 'agent_0': Array(-1.8563128, dtype=float32), 'agent_1': Array(-1.8563128, dtype=float32), 'agent_2': Array(-1.8563128, dtype=float32), 'agent_3': Array(-1.8563128, dtype=float32)}\n",
            "step: 158\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6518512 ,  0.78160614,  0.01904928,  0.04402707,  0.621925  ,\n",
            "        0.53663385,  1.250893  ,  0.5724506 ,  0.5712144 ,  0.4963158 ,\n",
            "       -0.85998774, -0.92635155, -0.9620547 ,  0.23019172, -0.20836584,\n",
            "       -2.3727598 , -0.13130309, -0.09130254], dtype=float32), 'agent_1': Array([ 0.6518512 ,  0.78160614,  0.01904928,  0.04402707,  0.621925  ,\n",
            "        0.53663385,  0.5724506 , -0.46076685,  0.5712144 ,  0.4963158 ,\n",
            "       -0.85998774, -0.92635155, -0.9620547 ,  0.23019172, -0.20836584,\n",
            "       -2.3727598 ,  6.7369485 ,  0.8187523 ], dtype=float32), 'agent_2': Array([ 0.6518512 ,  0.78160614,  0.01904928,  0.04402707,  0.621925  ,\n",
            "        0.53663385,  0.5724506 ,  0.5712144 , -0.49200365,  0.4963158 ,\n",
            "       -0.85998774, -0.92635155, -0.9620547 ,  0.23019172, -0.20836584,\n",
            "       -2.3727598 , -1.71475   ,  0.6171056 ], dtype=float32), 'agent_3': Array([ 0.6518512 ,  0.78160614,  0.01904928,  0.04402707,  0.621925  ,\n",
            "        0.53663385,  0.5724506 ,  0.5712144 ,  0.4963158 ,  1.2336203 ,\n",
            "       -0.85998774, -0.92635155, -0.9620547 ,  0.23019172, -0.20836584,\n",
            "       -2.3727598 ,  7.349321  ,  2.371095  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1720185   0.75987595 -1.1712441   0.75358045 -1.1758368   0.7596815\n",
            " -1.172239    0.7525412 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.685482, dtype=float32), 'agent_0': Array(-6.685482, dtype=float32), 'agent_1': Array(-6.685482, dtype=float32), 'agent_2': Array(-6.685482, dtype=float32), 'agent_3': Array(-6.685482, dtype=float32)}\n",
            "step: 159\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.62586886,   0.6386327 ,   0.02154824,   0.05189875,\n",
            "         0.7674571 ,  -0.08639571,   1.2501462 ,   0.24576852,\n",
            "        -0.15015563,   0.16515198,   0.235641  ,  -1.1862278 ,\n",
            "         0.2198577 ,  -0.46848342,  -0.39310902,  11.361537  ,\n",
            "       -16.464771  ,   0.05106202], dtype=float32), 'agent_1': Array([  0.62586886,   0.6386327 ,   0.02154824,   0.05189875,\n",
            "         0.7674571 ,  -0.08639571,   0.24576852,  -0.48468193,\n",
            "        -0.15015563,   0.16515198,   0.235641  ,  -1.1862278 ,\n",
            "         0.2198577 ,  -0.46848342,  -0.39310902,  11.361537  ,\n",
            "       -11.3010435 ,   0.39282936], dtype=float32), 'agent_2': Array([  0.62586886,   0.6386327 ,   0.02154824,   0.05189875,\n",
            "         0.7674571 ,  -0.08639571,   0.24576852,  -0.15015563,\n",
            "        -0.49505362,   0.16515198,   0.235641  ,  -1.1862278 ,\n",
            "         0.2198577 ,  -0.46848342,  -0.39310902,  11.361537  ,\n",
            "       -18.966764  ,   0.693373  ], dtype=float32), 'agent_3': Array([  0.62586886,   0.6386327 ,   0.02154824,   0.05189875,\n",
            "         0.7674571 ,  -0.08639571,   0.24576852,  -0.15015563,\n",
            "         0.16515198,   1.2519485 ,   0.235641  ,  -1.1862278 ,\n",
            "         0.2198577 ,  -0.46848342,  -0.39310902,  11.361537  ,\n",
            "       -11.508856  ,   0.9022957 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0005721   0.29309776 -1.0025196   0.29336828 -1.0003204   0.29256025\n",
            " -1.0018045   0.29255816]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.3174548, dtype=float32), 'agent_0': Array(-3.3174548, dtype=float32), 'agent_1': Array(-3.3174548, dtype=float32), 'agent_2': Array(-3.3174548, dtype=float32), 'agent_3': Array(-3.3174548, dtype=float32)}\n",
            "step: 160\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6527287 ,  0.49841368,  0.01108384,  0.03021766,  0.86634165,\n",
            "       -0.60905004,  1.2376108 , -0.18252072, -0.65484875, -0.31526592,\n",
            "        0.5919099 , -1.8445969 ,  0.5113244 , -1.0327032 ,  0.1566981 ,\n",
            "       -0.39647463, -0.24033052,  0.41627133], dtype=float32), 'agent_1': Array([ 0.6527287 ,  0.49841368,  0.01108384,  0.03021766,  0.86634165,\n",
            "       -0.60905004, -0.18252072, -0.50929755, -0.65484875, -0.31526592,\n",
            "        0.5919099 , -1.8445969 ,  0.5113244 , -1.0327032 ,  0.1566981 ,\n",
            "       -0.39647463, -2.2138276 , -0.34621516], dtype=float32), 'agent_2': Array([ 0.6527287 ,  0.49841368,  0.01108384,  0.03021766,  0.86634165,\n",
            "       -0.60905004, -0.18252072, -0.65484875, -0.5115156 , -0.31526592,\n",
            "        0.5919099 , -1.8445969 ,  0.5113244 , -1.0327032 ,  0.1566981 ,\n",
            "       -0.39647463,  1.59435   , -0.14263536], dtype=float32), 'agent_3': Array([ 0.6527287 ,  0.49841368,  0.01108384,  0.03021766,  0.86634165,\n",
            "       -0.60905004, -0.18252072, -0.65484875, -0.31526592,  1.2211531 ,\n",
            "        0.5919099 , -1.8445969 ,  0.5113244 , -1.0327032 ,  0.1566981 ,\n",
            "       -0.39647463, -3.686559  , -0.52231836], dtype=float32)}\n",
            "ctrl action chosen: [1.5698575  0.33590105 1.5616428  0.33324343 1.5707104  0.33559301\n",
            " 1.5609878  0.333286  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5402658, dtype=float32), 'agent_0': Array(-0.5402658, dtype=float32), 'agent_1': Array(-0.5402658, dtype=float32), 'agent_2': Array(-0.5402658, dtype=float32), 'agent_3': Array(-0.5402658, dtype=float32)}\n",
            "step: 161\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.6692102e-01,  7.0418835e-01, -8.3005084e-03,  7.5367498e-03,\n",
            "        7.0992476e-01, -3.6626883e-02,  1.2343045e+00,  3.7941840e-01,\n",
            "        2.1368399e-02,  1.6966859e-01,  5.1014423e-01, -1.9008636e+00,\n",
            "        4.7278404e-02, -1.0889502e+00, -2.4584416e-01, -1.4656153e+01,\n",
            "        1.7540180e+01, -4.2686704e-01], dtype=float32), 'agent_1': Array([ 6.6692102e-01,  7.0418835e-01, -8.3005084e-03,  7.5367498e-03,\n",
            "        7.0992476e-01, -3.6626883e-02,  3.7941840e-01, -5.1956105e-01,\n",
            "        2.1368399e-02,  1.6966859e-01,  5.1014423e-01, -1.9008636e+00,\n",
            "        4.7278404e-02, -1.0889502e+00, -2.4584416e-01, -1.4656153e+01,\n",
            "        1.5801508e+01,  6.2990688e-02], dtype=float32), 'agent_2': Array([ 6.6692102e-01,  7.0418835e-01, -8.3005084e-03,  7.5367498e-03,\n",
            "        7.0992476e-01, -3.6626883e-02,  3.7941840e-01,  2.1368399e-02,\n",
            "       -5.1595223e-01,  1.6966859e-01,  5.1014423e-01, -1.9008636e+00,\n",
            "        4.7278404e-02, -1.0889502e+00, -2.4584416e-01, -1.4656153e+01,\n",
            "        2.0261400e+01, -6.4033076e-02], dtype=float32), 'agent_3': Array([ 6.6692102e-01,  7.0418835e-01, -8.3005084e-03,  7.5367498e-03,\n",
            "        7.0992476e-01, -3.6626883e-02,  3.7941840e-01,  2.1368399e-02,\n",
            "        1.6966859e-01,  1.2339779e+00,  5.1014423e-01, -1.9008636e+00,\n",
            "        4.7278404e-02, -1.0889502e+00, -2.4584416e-01, -1.4656153e+01,\n",
            "        1.4440018e+01,  3.8009992e-01], dtype=float32)}\n",
            "ctrl action chosen: [-2.89279   -1.6032455 -2.891156  -1.6030495 -2.8940976 -1.6037625\n",
            " -2.8910458 -1.6047999]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6161587, dtype=float32), 'agent_0': Array(-3.6161587, dtype=float32), 'agent_1': Array(-3.6161587, dtype=float32), 'agent_2': Array(-3.6161587, dtype=float32), 'agent_3': Array(-3.6161587, dtype=float32)}\n",
            "step: 162\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.65376806,   0.6470987 ,  -0.06606871,   0.0214465 ,\n",
            "         0.75923544,  -0.25640443,   0.8680913 ,   0.1033975 ,\n",
            "        -0.09512651,  -0.1469801 ,   0.72695017,  -2.2181988 ,\n",
            "        -0.48792362,  -1.2173868 ,   3.0391724 ,   8.825358  ,\n",
            "       -12.301543  , -10.74148   ], dtype=float32), 'agent_1': Array([  0.65376806,   0.6470987 ,  -0.06606871,   0.0214465 ,\n",
            "         0.75923544,  -0.25640443,   0.1033975 ,  -0.86293143,\n",
            "        -0.09512651,  -0.1469801 ,   0.72695017,  -2.2181988 ,\n",
            "        -0.48792362,  -1.2173868 ,   3.0391724 ,   8.825358  ,\n",
            "       -12.685706  ,  -9.237789  ], dtype=float32), 'agent_2': Array([  0.65376806,   0.6470987 ,  -0.06606871,   0.0214465 ,\n",
            "         0.75923544,  -0.25640443,   0.1033975 ,  -0.09512651,\n",
            "        -0.86023444,  -0.1469801 ,   0.72695017,  -2.2181988 ,\n",
            "        -0.48792362,  -1.2173868 ,   3.0391724 ,   8.825358  ,\n",
            "       -10.298452  ,  -9.874818  ], dtype=float32), 'agent_3': Array([  0.65376806,   0.6470987 ,  -0.06606871,   0.0214465 ,\n",
            "         0.75923544,  -0.25640443,   0.1033975 ,  -0.09512651,\n",
            "        -0.1469801 ,   0.9548171 ,   0.72695017,  -2.2181988 ,\n",
            "        -0.48792362,  -1.2173868 ,   3.0391724 ,   8.825358  ,\n",
            "       -13.488464  ,  -8.217388  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8090596  -0.5515104  -0.80935544 -0.54998136 -0.8079771  -0.5534519\n",
            " -0.8094721  -0.5503738 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-20.21526, dtype=float32), 'agent_0': Array(-20.21526, dtype=float32), 'agent_1': Array(-20.21526, dtype=float32), 'agent_2': Array(-20.21526, dtype=float32), 'agent_3': Array(-20.21526, dtype=float32)}\n",
            "step: 163\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60942984,  0.5232828 , -0.11455555,  0.06561267,  0.84187126,\n",
            "       -0.6050241 ,  0.45005485, -0.443444  , -0.49855292, -0.6171847 ,\n",
            "        1.1639357 , -2.0351887 , -1.2210965 ,  0.6704696 ,  1.7714458 ,\n",
            "       -0.21959962,  2.4475408 , -2.3384845 ], dtype=float32), 'agent_1': Array([ 0.60942984,  0.5232828 , -0.11455555,  0.06561267,  0.84187126,\n",
            "       -0.6050241 , -0.443444  , -1.2538822 , -0.49855292, -0.6171847 ,\n",
            "        1.1639357 , -2.0351887 , -1.2210965 ,  0.6704696 ,  1.7714458 ,\n",
            "       -0.21959962, -5.5463343 , -7.155936  ], dtype=float32), 'agent_2': Array([ 0.60942984,  0.5232828 , -0.11455555,  0.06561267,  0.84187126,\n",
            "       -0.6050241 , -0.443444  , -0.49855292, -1.2755507 , -0.6171847 ,\n",
            "        1.1639357 , -2.0351887 , -1.2210965 ,  0.6704696 ,  1.7714458 ,\n",
            "       -0.21959962, -2.2568421 , -4.928166  ], dtype=float32), 'agent_3': Array([ 0.60942984,  0.5232828 , -0.11455555,  0.06561267,  0.84187126,\n",
            "       -0.6050241 , -0.443444  , -0.49855292, -0.6171847 ,  0.5638574 ,\n",
            "        1.1639357 , -2.0351887 , -1.2210965 ,  0.6704696 ,  1.7714458 ,\n",
            "       -0.21959962,  0.01487547, -8.679985  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.6529994  -0.5873147  -1.6593889  -0.59180677 -1.656582   -0.5921071\n",
            " -1.6574333  -0.5930013 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.10788405, dtype=float32), 'agent_0': Array(-0.10788405, dtype=float32), 'agent_1': Array(-0.10788405, dtype=float32), 'agent_2': Array(-0.10788405, dtype=float32), 'agent_3': Array(-0.10788405, dtype=float32)}\n",
            "step: 164\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54860824,  0.5513991 , -0.12336028,  0.04799296,  0.8236734 ,\n",
            "       -0.45574948,  0.48388854, -0.60374653, -0.55975825, -0.52462363,\n",
            "        1.1868954 , -1.733017  , -1.035881  , -1.2150762 ,  0.13213098,\n",
            "       -1.9671553 ,  2.8495443 , -0.8964595 ], dtype=float32), 'agent_1': Array([ 0.54860824,  0.5513991 , -0.12336028,  0.04799296,  0.8236734 ,\n",
            "       -0.45574948, -0.60374653, -1.271821  , -0.55975825, -0.52462363,\n",
            "        1.1868954 , -1.733017  , -1.035881  , -1.2150762 ,  0.13213098,\n",
            "       -1.9671553 , -0.72505414,  0.6265041 ], dtype=float32), 'agent_2': Array([ 0.54860824,  0.5513991 , -0.12336028,  0.04799296,  0.8236734 ,\n",
            "       -0.45574948, -0.60374653, -0.55975825, -1.2652146 , -0.52462363,\n",
            "        1.1868954 , -1.733017  , -1.035881  , -1.2150762 ,  0.13213098,\n",
            "       -1.9671553 , -0.9033042 ,  0.17005052], dtype=float32), 'agent_3': Array([ 0.54860824,  0.5513991 , -0.12336028,  0.04799296,  0.8236734 ,\n",
            "       -0.45574948, -0.60374653, -0.55975825, -0.52462363,  0.47702935,\n",
            "        1.1868954 , -1.733017  , -1.035881  , -1.2150762 ,  0.13213098,\n",
            "       -1.9671553 ,  2.2013595 ,  1.0560496 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.39878827 -0.67074543  0.3899101  -0.66887385  0.39005652 -0.6711743\n",
            "  0.3972382  -0.66906494]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.961746, dtype=float32), 'agent_0': Array(-3.961746, dtype=float32), 'agent_1': Array(-3.961746, dtype=float32), 'agent_2': Array(-3.961746, dtype=float32), 'agent_3': Array(-3.961746, dtype=float32)}\n",
            "step: 165\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56085235,  0.65732247, -0.11964591,  0.02503313,  0.7436298 ,\n",
            "       -0.05320066,  0.47739375, -0.39105946, -0.3933618 , -0.1725849 ,\n",
            "        1.369524  , -1.0053635 ,  0.7653475 ,  0.25466618, -0.8382794 ,\n",
            "       -5.046723  ,  8.054162  ,  0.54995614], dtype=float32), 'agent_1': Array([ 0.56085235,  0.65732247, -0.11964591,  0.02503313,  0.7436298 ,\n",
            "       -0.05320066, -0.39105946, -1.2516617 , -0.3933618 , -0.1725849 ,\n",
            "        1.369524  , -1.0053635 ,  0.7653475 ,  0.25466618, -0.8382794 ,\n",
            "       -5.046723  ,  5.599841  ,  0.5125711 ], dtype=float32), 'agent_2': Array([ 0.56085235,  0.65732247, -0.11964591,  0.02503313,  0.7436298 ,\n",
            "       -0.05320066, -0.39105946, -0.3933618 , -1.2309561 , -0.1725849 ,\n",
            "        1.369524  , -1.0053635 ,  0.7653475 ,  0.25466618, -0.8382794 ,\n",
            "       -5.046723  ,  3.7320406 ,  0.6911334 ], dtype=float32), 'agent_3': Array([ 0.56085235,  0.65732247, -0.11964591,  0.02503313,  0.7436298 ,\n",
            "       -0.05320066, -0.39105946, -0.3933618 , -0.1725849 ,  0.5016606 ,\n",
            "        1.369524  , -1.0053635 ,  0.7653475 ,  0.25466618, -0.8382794 ,\n",
            "       -5.046723  ,  6.7615914 ,  1.0107882 ], dtype=float32)}\n",
            "ctrl action chosen: [0.06771914 0.5120804  0.06932835 0.512833   0.0710154  0.51125556\n",
            " 0.06741817 0.5115839 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0042027, dtype=float32), 'agent_0': Array(1.0042027, dtype=float32), 'agent_1': Array(1.0042027, dtype=float32), 'agent_2': Array(1.0042027, dtype=float32), 'agent_3': Array(1.0042027, dtype=float32)}\n",
            "step: 166\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6060608 ,  0.70901346, -0.09094636, -0.01500913,  0.6991449 ,\n",
            "        0.2070536 ,  0.64127445, -0.23440036, -0.32394466,  0.0221781 ,\n",
            "        1.697576  , -0.6799698 ,  0.7745385 , -0.06789518, -2.180834  ,\n",
            "       -2.1034758 ,  3.9785337 ,  4.9849687 ], dtype=float32), 'agent_1': Array([ 0.6060608 ,  0.70901346, -0.09094636, -0.01500913,  0.6991449 ,\n",
            "        0.2070536 , -0.23440036, -1.0282794 , -0.32394466,  0.0221781 ,\n",
            "        1.697576  , -0.6799698 ,  0.7745385 , -0.06789518, -2.180834  ,\n",
            "       -2.1034758 ,  2.1578155 ,  5.837111  ], dtype=float32), 'agent_2': Array([ 0.6060608 ,  0.70901346, -0.09094636, -0.01500913,  0.6991449 ,\n",
            "        0.2070536 , -0.23440036, -0.32394466, -0.97646326,  0.0221781 ,\n",
            "        1.697576  , -0.6799698 ,  0.7745385 , -0.06789518, -2.180834  ,\n",
            "       -2.1034758 ,  0.540018  ,  6.3353815 ], dtype=float32), 'agent_3': Array([ 0.6060608 ,  0.70901346, -0.09094636, -0.01500913,  0.6991449 ,\n",
            "        0.2070536 , -0.23440036, -0.32394466,  0.0221781 ,  0.79550093,\n",
            "        1.697576  , -0.6799698 ,  0.7745385 , -0.06789518, -2.180834  ,\n",
            "       -2.1034758 ,  2.8765717 ,  7.5612907 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.754312   -0.34776205 -0.757452   -0.34705693 -0.75869024 -0.34819594\n",
            " -0.7590665  -0.34614474]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(2.0635135, dtype=float32), 'agent_0': Array(2.0635135, dtype=float32), 'agent_1': Array(2.0635135, dtype=float32), 'agent_2': Array(2.0635135, dtype=float32), 'agent_3': Array(2.0635135, dtype=float32)}\n",
            "step: 167\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6233907 ,  0.6274785 , -0.07345596, -0.01360952,  0.77504176,\n",
            "       -0.02270614,  0.7432288 , -0.5472722 , -0.62110007, -0.26040646,\n",
            "        1.2988806 , -1.2804985 ,  0.04246235,  0.45669156, -0.21401648,\n",
            "        2.0643344 , -3.3546948 ,  0.7310262 ], dtype=float32), 'agent_1': Array([ 0.6233907 ,  0.6274785 , -0.07345596, -0.01360952,  0.77504176,\n",
            "       -0.02270614, -0.5472722 , -0.9667387 , -0.62110007, -0.26040646,\n",
            "        1.2988806 , -1.2804985 ,  0.04246235,  0.45669156, -0.21401648,\n",
            "        2.0643344 , -3.801061  , -0.57765967], dtype=float32), 'agent_2': Array([ 0.6233907 ,  0.6274785 , -0.07345596, -0.01360952,  0.77504176,\n",
            "       -0.02270614, -0.5472722 , -0.62110007, -0.89831793, -0.26040646,\n",
            "        1.2988806 , -1.2804985 ,  0.04246235,  0.45669156, -0.21401648,\n",
            "        2.0643344 , -0.4000579 , -0.3366924 ], dtype=float32), 'agent_3': Array([ 0.6233907 ,  0.6274785 , -0.07345596, -0.01360952,  0.77504176,\n",
            "       -0.02270614, -0.5472722 , -0.62110007, -0.26040646,  0.8964605 ,\n",
            "        1.2988806 , -1.2804985 ,  0.04246235,  0.45669156, -0.21401648,\n",
            "        2.0643344 , -4.268904  , -0.561646  ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1286849  -0.3443696   1.1268626  -0.34655526  1.1308556  -0.35044798\n",
            "  1.1265181  -0.34569225]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1787628, dtype=float32), 'agent_0': Array(1.1787628, dtype=float32), 'agent_1': Array(1.1787628, dtype=float32), 'agent_2': Array(1.1787628, dtype=float32), 'agent_3': Array(1.1787628, dtype=float32)}\n",
            "step: 168\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6128339 ,   0.77656615,  -0.06382998,  -0.01518825,\n",
            "         0.6266101 ,   0.4786009 ,   0.6938776 ,  -0.09647617,\n",
            "        -0.05452233,   0.20407951,   1.2502432 ,  -1.1329651 ,\n",
            "        -0.41463375,   0.4494263 ,   0.52906334, -12.178618  ,\n",
            "        14.675662  ,  -2.363913  ], dtype=float32), 'agent_1': Array([  0.6128339 ,   0.77656615,  -0.06382998,  -0.01518825,\n",
            "         0.6266101 ,   0.4786009 ,  -0.09647617,  -1.0792446 ,\n",
            "        -0.05452233,   0.20407951,   1.2502432 ,  -1.1329651 ,\n",
            "        -0.41463375,   0.4494263 ,   0.52906334, -12.178618  ,\n",
            "        13.910364  ,  -3.265537  ], dtype=float32), 'agent_2': Array([ 6.1283392e-01,  7.7656615e-01, -6.3829981e-02, -1.5188247e-02,\n",
            "        6.2661010e-01,  4.7860089e-01, -9.6476175e-02, -5.4522332e-02,\n",
            "       -9.9267310e-01,  2.0407951e-01,  1.2502432e+00, -1.1329651e+00,\n",
            "       -4.1463375e-01,  4.4942629e-01,  5.2906334e-01, -1.2178618e+01,\n",
            "        1.7256828e+01, -2.8523691e+00], dtype=float32), 'agent_3': Array([  0.6128339 ,   0.77656615,  -0.06382998,  -0.01518825,\n",
            "         0.6266101 ,   0.4786009 ,  -0.09647617,  -0.05452233,\n",
            "         0.20407951,   0.80966574,   1.2502432 ,  -1.1329651 ,\n",
            "        -0.41463375,   0.4494263 ,   0.52906334, -12.178618  ,\n",
            "        14.093058  ,  -2.571429  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1285882  1.6231905 -1.1300361  1.6244214 -1.1284326  1.6225948\n",
            " -1.1298132  1.623128 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.547277, dtype=float32), 'agent_0': Array(-0.547277, dtype=float32), 'agent_1': Array(-0.547277, dtype=float32), 'agent_2': Array(-0.547277, dtype=float32), 'agent_3': Array(-0.547277, dtype=float32)}\n",
            "step: 169\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.59384423,   0.7089497 ,  -0.03254842,  -0.02587483,\n",
            "         0.7040323 ,   0.21665844,   0.9084504 ,  -0.37558603,\n",
            "        -0.22214212,  -0.07664364,   1.4736652 ,  -0.8401871 ,\n",
            "        -0.44705868,   0.63047   ,  -2.0536714 ,   9.481816  ,\n",
            "       -12.219781  ,   6.781199  ], dtype=float32), 'agent_1': Array([  0.59384423,   0.7089497 ,  -0.03254842,  -0.02587483,\n",
            "         0.7040323 ,   0.21665844,  -0.37558603,  -0.8765317 ,\n",
            "        -0.22214212,  -0.07664364,   1.4736652 ,  -0.8401871 ,\n",
            "        -0.44705868,   0.63047   ,  -2.0536714 ,   9.481816  ,\n",
            "       -12.417468  ,   6.5296416 ], dtype=float32), 'agent_2': Array([  0.59384423,   0.7089497 ,  -0.03254842,  -0.02587483,\n",
            "         0.7040323 ,   0.21665844,  -0.37558603,  -0.22214212,\n",
            "        -0.77979356,  -0.07664364,   1.4736652 ,  -0.8401871 ,\n",
            "        -0.44705868,   0.63047   ,  -2.0536714 ,   9.481816  ,\n",
            "       -11.015951  ,   6.9979773 ], dtype=float32), 'agent_3': Array([  0.59384423,   0.7089497 ,  -0.03254842,  -0.02587483,\n",
            "         0.7040323 ,   0.21665844,  -0.37558603,  -0.22214212,\n",
            "        -0.07664364,   1.0348697 ,   1.4736652 ,  -0.8401871 ,\n",
            "        -0.44705868,   0.63047   ,  -2.0536714 ,   9.481816  ,\n",
            "       -12.420758  ,   6.7519293 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.84819585 -0.5892151   0.84616274 -0.58828074  0.8485825  -0.58849233\n",
            "  0.84668547 -0.58910424]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.4290633, dtype=float32), 'agent_0': Array(-5.4290633, dtype=float32), 'agent_1': Array(-5.4290633, dtype=float32), 'agent_2': Array(-5.4290633, dtype=float32), 'agent_3': Array(-5.4290633, dtype=float32)}\n",
            "step: 170\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5621688 ,  0.7679664 , -0.01900278, -0.01354362,  0.6400651 ,\n",
            "        0.41678494,  0.88996387, -0.21091107,  0.02340606,  0.08420707,\n",
            "        1.0836124 , -1.2266159 , -0.43574572,  1.0263829 ,  0.46056658,\n",
            "       -7.465433  ,  9.525915  , -2.807098  ], dtype=float32), 'agent_1': Array([ 0.5621688 ,  0.7679664 , -0.01900278, -0.01354362,  0.6400651 ,\n",
            "        0.41678494, -0.21091107, -0.88857883,  0.02340606,  0.08420707,\n",
            "        1.0836124 , -1.2266159 , -0.43574572,  1.0263829 ,  0.46056658,\n",
            "       -7.465433  ,  8.7881155 , -1.673899  ], dtype=float32), 'agent_2': Array([ 0.5621688 ,  0.7679664 , -0.01900278, -0.01354362,  0.6400651 ,\n",
            "        0.41678494, -0.21091107,  0.02340606, -0.8039126 ,  0.08420707,\n",
            "        1.0836124 , -1.2266159 , -0.43574572,  1.0263829 ,  0.46056658,\n",
            "       -7.465433  , 10.265807  , -2.091945  ], dtype=float32), 'agent_3': Array([ 0.5621688 ,  0.7679664 , -0.01900278, -0.01354362,  0.6400651 ,\n",
            "        0.41678494, -0.21091107,  0.02340606,  0.08420707,  1.0204122 ,\n",
            "        1.0836124 , -1.2266159 , -0.43574572,  1.0263829 ,  0.46056658,\n",
            "       -7.465433  ,  8.706426  , -2.2589302 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.92317575 -1.4317545   0.922436   -1.4303873   0.9229689  -1.4320158\n",
            "  0.9210053  -1.4323852 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.22735071, dtype=float32), 'agent_0': Array(0.22735071, dtype=float32), 'agent_1': Array(0.22735071, dtype=float32), 'agent_2': Array(0.22735071, dtype=float32), 'agent_3': Array(0.22735071, dtype=float32)}\n",
            "step: 171\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53927594,  0.86339986, -0.02121292,  0.01796401,  0.50375384,\n",
            "        0.6445413 ,  0.5573071 ,  0.2502775 ,  0.55013525,  0.55538154,\n",
            "        0.5503416 , -1.8595695 , -0.73292255,  0.06643708,  2.023399  ,\n",
            "       -1.8337314 , -3.916243  , -9.033138  ], dtype=float32), 'agent_1': Array([ 0.53927594,  0.86339986, -0.02121292,  0.01796401,  0.50375384,\n",
            "        0.6445413 ,  0.2502775 , -1.1687592 ,  0.55013525,  0.55538154,\n",
            "        0.5503416 , -1.8595695 , -0.73292255,  0.06643708,  2.023399  ,\n",
            "       -1.8337314 ,  4.7738967 , -7.2735286 ], dtype=float32), 'agent_2': Array([ 0.53927594,  0.86339986, -0.02121292,  0.01796401,  0.50375384,\n",
            "        0.6445413 ,  0.2502775 ,  0.55013525, -1.0408418 ,  0.55538154,\n",
            "        0.5503416 , -1.8595695 , -0.73292255,  0.06643708,  2.023399  ,\n",
            "       -1.8337314 ,  5.039154  , -7.549991  ], dtype=float32), 'agent_3': Array([ 0.53927594,  0.86339986, -0.02121292,  0.01796401,  0.50375384,\n",
            "        0.6445413 ,  0.2502775 ,  0.55013525,  0.55538154,  0.7096004 ,\n",
            "        0.5503416 , -1.8595695 , -0.73292255,  0.06643708,  2.023399  ,\n",
            "       -1.8337314 ,  3.760267  , -9.230525  ], dtype=float32)}\n",
            "ctrl action chosen: [0.6415784  1.9493618  0.63998604 1.9520464  0.64348537 1.9484622\n",
            " 0.6411212  1.9487767 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.996017, dtype=float32), 'agent_0': Array(-3.996017, dtype=float32), 'agent_1': Array(-3.996017, dtype=float32), 'agent_2': Array(-3.996017, dtype=float32), 'agent_3': Array(-3.996017, dtype=float32)}\n",
            "step: 172\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5553599 ,  0.8559822 ,  0.00800055,  0.04047816,  0.51535624,\n",
            "        0.37045076,  0.58898443,  0.38206095,  0.5824946 ,  0.55066085,\n",
            "        0.26233196, -0.12054443,  0.72609186,  1.6202726 , -0.77275133,\n",
            "        0.70877695, -5.757351  ,  3.508904  ], dtype=float32), 'agent_1': Array([ 0.5553599 ,  0.8559822 ,  0.00800055,  0.04047816,  0.51535624,\n",
            "        0.37045076,  0.38206095, -1.0648644 ,  0.5824946 ,  0.55066085,\n",
            "        0.26233196, -0.12054443,  0.72609186,  1.6202726 , -0.77275133,\n",
            "        0.70877695,  3.659139  ,  5.2553163 ], dtype=float32), 'agent_2': Array([ 0.5553599 ,  0.8559822 ,  0.00800055,  0.04047816,  0.51535624,\n",
            "        0.37045076,  0.38206095,  0.5824946 , -0.9379754 ,  0.55066085,\n",
            "        0.26233196, -0.12054443,  0.72609186,  1.6202726 , -0.77275133,\n",
            "        0.70877695, -0.93179923,  4.8542676 ], dtype=float32), 'agent_3': Array([ 0.5553599 ,  0.8559822 ,  0.00800055,  0.04047816,  0.51535624,\n",
            "        0.37045076,  0.38206095,  0.5824946 ,  0.55066085,  0.6836644 ,\n",
            "        0.26233196, -0.12054443,  0.72609186,  1.6202726 , -0.77275133,\n",
            "        0.70877695, -0.63863456,  2.8263097 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.3090917  -0.5783829   1.3219172  -0.5774643   1.3194593  -0.58174014\n",
            "  1.3175637  -0.5790163 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.113317, dtype=float32), 'agent_0': Array(-7.113317, dtype=float32), 'agent_1': Array(-7.113317, dtype=float32), 'agent_2': Array(-7.113317, dtype=float32), 'agent_3': Array(-7.113317, dtype=float32)}\n",
            "step: 173\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58286893,  0.8611761 ,  0.00177686,  0.07362317,  0.50294375,\n",
            "        0.33068946,  0.4896283 ,  0.620243  ,  0.5375597 ,  0.5455416 ,\n",
            "        0.4528284 , -0.12073517,  0.26085377,  0.8365318 ,  1.6237172 ,\n",
            "       -0.05115704,  0.7305878 ,  0.04814284], dtype=float32), 'agent_1': Array([ 5.8286893e-01,  8.6117607e-01,  1.7768587e-03,  7.3623173e-02,\n",
            "        5.0294375e-01,  3.3068946e-01,  6.2024301e-01, -1.1264203e+00,\n",
            "        5.3755969e-01,  5.4554158e-01,  4.5282841e-01, -1.2073517e-01,\n",
            "        2.6085377e-01,  8.3653182e-01,  1.6237172e+00, -5.1157042e-02,\n",
            "        1.8709654e+00, -2.9259562e+00], dtype=float32), 'agent_2': Array([ 5.8286893e-01,  8.6117607e-01,  1.7768587e-03,  7.3623173e-02,\n",
            "        5.0294375e-01,  3.3068946e-01,  6.2024301e-01,  5.3755969e-01,\n",
            "       -1.0119921e+00,  5.4554158e-01,  4.5282841e-01, -1.2073517e-01,\n",
            "        2.6085377e-01,  8.3653182e-01,  1.6237172e+00, -5.1157042e-02,\n",
            "       -1.3725661e+00, -2.6644266e+00], dtype=float32), 'agent_3': Array([ 5.82868934e-01,  8.61176074e-01,  1.77685870e-03,  7.36231729e-02,\n",
            "        5.02943754e-01,  3.30689460e-01,  6.20243013e-01,  5.37559688e-01,\n",
            "        5.45541584e-01,  5.38397372e-01,  4.52828407e-01, -1.20735168e-01,\n",
            "        2.60853767e-01,  8.36531818e-01,  1.62371719e+00, -5.11570424e-02,\n",
            "       -1.22384235e-01, -4.10761404e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.18337943 1.2675846  0.18350577 1.2641445  0.18576927 1.2569753\n",
            " 0.18237716 1.2598215 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.850246, dtype=float32), 'agent_0': Array(-2.850246, dtype=float32), 'agent_1': Array(-2.850246, dtype=float32), 'agent_2': Array(-2.850246, dtype=float32), 'agent_3': Array(-2.850246, dtype=float32)}\n",
            "step: 174\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5909429 ,  0.8449557 ,  0.06856389,  0.06977766,  0.52581376,\n",
            "        0.29954043,  0.8613822 ,  0.53670454,  0.39905554,  0.4696528 ,\n",
            "        0.8220196 ,  0.3276825 , -0.08962154,  2.1718993 , -2.630359  ,\n",
            "        0.43101326,  0.82668674, 10.735006  ], dtype=float32), 'agent_1': Array([ 0.5909429 ,  0.8449557 ,  0.06856389,  0.06977766,  0.52581376,\n",
            "        0.29954043,  0.53670454, -0.8099198 ,  0.39905554,  0.4696528 ,\n",
            "        0.8220196 ,  0.3276825 , -0.08962154,  2.1718993 , -2.630359  ,\n",
            "        0.43101326, -1.6973076 ,  9.959405  ], dtype=float32), 'agent_2': Array([ 0.5909429 ,  0.8449557 ,  0.06856389,  0.06977766,  0.52581376,\n",
            "        0.29954043,  0.53670454,  0.39905554, -0.6919794 ,  0.4696528 ,\n",
            "        0.8220196 ,  0.3276825 , -0.08962154,  2.1718993 , -2.630359  ,\n",
            "        0.43101326, -1.7902347 ,  9.139604  ], dtype=float32), 'agent_3': Array([ 0.5909429 ,  0.8449557 ,  0.06856389,  0.06977766,  0.52581376,\n",
            "        0.29954043,  0.53670454,  0.39905554,  0.4696528 ,  0.80412835,\n",
            "        0.8220196 ,  0.3276825 , -0.08962154,  2.1718993 , -2.630359  ,\n",
            "        0.43101326, -0.30997515,  8.887223  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.82430124  1.5283583  -0.8247247   1.5301703  -0.8235996   1.5272019\n",
            " -0.82415867  1.5287615 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5681849, dtype=float32), 'agent_0': Array(-1.5681849, dtype=float32), 'agent_1': Array(-1.5681849, dtype=float32), 'agent_2': Array(-1.5681849, dtype=float32), 'agent_3': Array(-1.5681849, dtype=float32)}\n",
            "step: 175\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.58274436,   0.7172877 ,   0.13661112,   0.01253264,\n",
            "         0.6831388 ,  -0.15797302,   1.320754  ,  -0.04155425,\n",
            "        -0.16778503,  -0.03363762,   1.257205  ,  -0.01955032,\n",
            "        -0.02456903,  -0.39759234,  -0.7330701 ,  10.192584  ,\n",
            "       -11.188731  ,   0.36061597], dtype=float32), 'agent_1': Array([ 5.8274436e-01,  7.1728772e-01,  1.3661112e-01,  1.2532642e-02,\n",
            "        6.8313879e-01, -1.5797302e-01, -4.1554250e-02, -4.3264878e-01,\n",
            "       -1.6778503e-01, -3.3637621e-02,  1.2572050e+00, -1.9550323e-02,\n",
            "       -2.4569035e-02, -3.9759234e-01, -7.3307008e-01,  1.0192584e+01,\n",
            "       -1.4328069e+01,  1.3621731e-01], dtype=float32), 'agent_2': Array([ 5.8274436e-01,  7.1728772e-01,  1.3661112e-01,  1.2532642e-02,\n",
            "        6.8313879e-01, -1.5797302e-01, -4.1554250e-02, -1.6778503e-01,\n",
            "       -4.4439211e-01, -3.3637621e-02,  1.2572050e+00, -1.9550323e-02,\n",
            "       -2.4569035e-02, -3.9759234e-01, -7.3307008e-01,  1.0192584e+01,\n",
            "       -1.3453836e+01, -9.8008591e-01], dtype=float32), 'agent_3': Array([ 5.8274436e-01,  7.1728772e-01,  1.3661112e-01,  1.2532642e-02,\n",
            "        6.8313879e-01, -1.5797302e-01, -4.1554250e-02, -1.6778503e-01,\n",
            "       -3.3637621e-02,  1.2524900e+00,  1.2572050e+00, -1.9550323e-02,\n",
            "       -2.4569035e-02, -3.9759234e-01, -7.3307008e-01,  1.0192584e+01,\n",
            "       -1.2987314e+01,  6.9499078e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.64336216 0.4000487  0.64193314 0.40087667 0.6408349  0.40059963\n",
            " 0.64577997 0.4029342 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.1274195, dtype=float32), 'agent_0': Array(-4.1274195, dtype=float32), 'agent_1': Array(-4.1274195, dtype=float32), 'agent_2': Array(-4.1274195, dtype=float32), 'agent_3': Array(-4.1274195, dtype=float32)}\n",
            "step: 176\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6110728 ,  0.75153697,  0.13470244,  0.02079847,  0.6454572 ,\n",
            "        0.01875759,  1.2604922 , -0.01061097, -0.08336948,  0.05813821,\n",
            "        1.3080359 , -0.03967285,  0.8156657 ,  0.19899668, -1.2903798 ,\n",
            "       -5.427248  ,  7.6533966 ,  0.11183582], dtype=float32), 'agent_1': Array([ 0.6110728 ,  0.75153697,  0.13470244,  0.02079847,  0.6454572 ,\n",
            "        0.01875759, -0.01061097, -0.48969647, -0.08336948,  0.05813821,\n",
            "        1.3080359 , -0.03967285,  0.8156657 ,  0.19899668, -1.2903798 ,\n",
            "       -5.427248  ,  5.289303  , -0.6280258 ], dtype=float32), 'agent_2': Array([ 0.6110728 ,  0.75153697,  0.13470244,  0.02079847,  0.6454572 ,\n",
            "        0.01875759, -0.01061097, -0.08336948, -0.5140864 ,  0.05813821,\n",
            "        1.3080359 , -0.03967285,  0.8156657 ,  0.19899668, -1.2903798 ,\n",
            "       -5.427248  ,  6.5087786 ,  0.01506681], dtype=float32), 'agent_3': Array([ 0.6110728 ,  0.75153697,  0.13470244,  0.02079847,  0.6454572 ,\n",
            "        0.01875759, -0.01061097, -0.08336948,  0.05813821,  1.2466782 ,\n",
            "        1.3080359 , -0.03967285,  0.8156657 ,  0.19899668, -1.2903798 ,\n",
            "       -5.427248  ,  6.8313828 ,  1.1674997 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7160927  -0.8684954  -0.71635187 -0.868256   -0.7167971  -0.8684133\n",
            " -0.7168899  -0.8681995 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2480896, dtype=float32), 'agent_0': Array(1.2480896, dtype=float32), 'agent_1': Array(1.2480896, dtype=float32), 'agent_2': Array(1.2480896, dtype=float32), 'agent_3': Array(1.2480896, dtype=float32)}\n",
            "step: 177\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.65296394,  0.67534494,  0.12292518,  0.02307743,  0.7268191 ,\n",
            "       -0.21076079,  0.98499954, -0.33300093, -0.33847362, -0.16831188,\n",
            "        1.2945652 , -0.55122375,  0.7326126 ,  0.20901404,  2.2107208 ,\n",
            "        6.88879   , -8.130684  , -9.387138  ], dtype=float32), 'agent_1': Array([  0.65296394,   0.67534494,   0.12292518,   0.02307743,\n",
            "         0.7268191 ,  -0.21076079,  -0.33300093,  -0.81134754,\n",
            "        -0.33847362,  -0.16831188,   1.2945652 ,  -0.55122375,\n",
            "         0.7326126 ,   0.20901404,   2.2107208 ,   6.88879   ,\n",
            "       -10.136665  ,  -9.793895  ], dtype=float32), 'agent_2': Array([ 0.65296394,  0.67534494,  0.12292518,  0.02307743,  0.7268191 ,\n",
            "       -0.21076079, -0.33300093, -0.33847362, -0.755761  , -0.16831188,\n",
            "        1.2945652 , -0.55122375,  0.7326126 ,  0.20901404,  2.2107208 ,\n",
            "        6.88879   , -8.48551   , -6.415498  ], dtype=float32), 'agent_3': Array([ 0.65296394,  0.67534494,  0.12292518,  0.02307743,  0.7268191 ,\n",
            "       -0.21076079, -0.33300093, -0.33847362, -0.16831188,  1.0325763 ,\n",
            "        1.2945652 , -0.55122375,  0.7326126 ,  0.20901404,  2.2107208 ,\n",
            "        6.88879   , -8.038704  , -7.5866613 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3551862  -0.2651069  -0.35752368 -0.26391    -0.3566667  -0.2602831\n",
            " -0.35679442 -0.26321965]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.2396934, dtype=float32), 'agent_0': Array(-0.2396934, dtype=float32), 'agent_1': Array(-0.2396934, dtype=float32), 'agent_2': Array(-0.2396934, dtype=float32), 'agent_3': Array(-0.2396934, dtype=float32)}\n",
            "step: 178\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6778644 ,  0.6017171 ,  0.10064952,  0.05021572,  0.7907495 ,\n",
            "       -0.44585174,  0.52867216, -0.58807254, -0.55668926, -0.43514127,\n",
            "        0.89571476, -0.33226013,  0.3194332 ,  0.7957092 ,  1.7184663 ,\n",
            "        0.11880265, -0.81745124, -8.6122265 ], dtype=float32), 'agent_1': Array([ 0.6778644 ,  0.6017171 ,  0.10064952,  0.05021572,  0.7907495 ,\n",
            "       -0.44585174, -0.58807254, -1.2422812 , -0.55668926, -0.43514127,\n",
            "        0.89571476, -0.33226013,  0.3194332 ,  0.7957092 ,  1.7184663 ,\n",
            "        0.11880265,  0.87275004, -7.95973   ], dtype=float32), 'agent_2': Array([ 0.6778644 ,  0.6017171 ,  0.10064952,  0.05021572,  0.7907495 ,\n",
            "       -0.44585174, -0.58807254, -0.55668926, -0.98516095, -0.43514127,\n",
            "        0.89571476, -0.33226013,  0.3194332 ,  0.7957092 ,  1.7184663 ,\n",
            "        0.11880265,  0.59868467, -4.70332   ], dtype=float32), 'agent_3': Array([ 0.6778644 ,  0.6017171 ,  0.10064952,  0.05021572,  0.7907495 ,\n",
            "       -0.44585174, -0.58807254, -0.55668926, -0.43514127,  0.6860866 ,\n",
            "        0.89571476, -0.33226013,  0.3194332 ,  0.7957092 ,  1.7184663 ,\n",
            "        0.11880265, -2.1036136 , -7.3075604 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.5444962  -0.38330933 -1.5464483  -0.3813354  -1.5460875  -0.38317257\n",
            " -1.5453322  -0.3840013 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.718801, dtype=float32), 'agent_0': Array(1.718801, dtype=float32), 'agent_1': Array(1.718801, dtype=float32), 'agent_2': Array(1.718801, dtype=float32), 'agent_3': Array(1.718801, dtype=float32)}\n",
            "step: 179\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.688525  ,  0.59069043,  0.08490866,  0.05767221,  0.8003433 ,\n",
            "       -0.55497164,  0.48513308, -0.5224027 , -0.5384027 , -0.57413286,\n",
            "        1.0358334 , -0.2585411 ,  0.10052919, -1.026416  ,  0.05521776,\n",
            "       -0.1991455 , -1.4712726 ,  0.541282  ], dtype=float32), 'agent_1': Array([ 0.688525  ,  0.59069043,  0.08490866,  0.05767221,  0.8003433 ,\n",
            "       -0.55497164, -0.5224027 , -1.2609936 , -0.5384027 , -0.57413286,\n",
            "        1.0358334 , -0.2585411 ,  0.10052919, -1.026416  ,  0.05521776,\n",
            "       -0.1991455 ,  1.9030471 ,  1.1346216 ], dtype=float32), 'agent_2': Array([ 0.688525  ,  0.59069043,  0.08490866,  0.05767221,  0.8003433 ,\n",
            "       -0.55497164, -0.5224027 , -0.5384027 , -1.2294443 , -0.57413286,\n",
            "        1.0358334 , -0.2585411 ,  0.10052919, -1.026416  ,  0.05521776,\n",
            "       -0.1991455 ,  0.7509612 , -3.2851682 ], dtype=float32), 'agent_3': Array([ 0.688525  ,  0.59069043,  0.08490866,  0.05767221,  0.8003433 ,\n",
            "       -0.55497164, -0.5224027 , -0.5384027 , -0.57413286,  0.48415172,\n",
            "        1.0358334 , -0.2585411 ,  0.10052919, -1.026416  ,  0.05521776,\n",
            "       -0.1991455 , -1.340674  ,  1.5387748 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.9731785 -1.9086071 -1.9667665 -1.909383  -1.973322  -1.9176965\n",
            " -1.9740314 -1.9070436]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.1785092, dtype=float32), 'agent_0': Array(-3.1785092, dtype=float32), 'agent_1': Array(-3.1785092, dtype=float32), 'agent_2': Array(-3.1785092, dtype=float32), 'agent_3': Array(-3.1785092, dtype=float32)}\n",
            "step: 180\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.69731903,  0.59733975,  0.07226141,  0.05294811,  0.7969693 ,\n",
            "       -0.5733767 ,  0.49516666, -0.5123554 , -0.54006153, -0.5679242 ,\n",
            "        1.2173891 , -0.68998337,  0.15002489, -0.48827544,  0.18006787,\n",
            "       -0.4391109 ,  0.55314046,  0.8335063 ], dtype=float32), 'agent_1': Array([ 0.69731903,  0.59733975,  0.07226141,  0.05294811,  0.7969693 ,\n",
            "       -0.5733767 , -0.5123554 , -1.2425189 , -0.54006153, -0.5679242 ,\n",
            "        1.2173891 , -0.68998337,  0.15002489, -0.48827544,  0.18006787,\n",
            "       -0.4391109 , -1.1711065 ,  0.21635452], dtype=float32), 'agent_2': Array([ 0.69731903,  0.59733975,  0.07226141,  0.05294811,  0.7969693 ,\n",
            "       -0.5733767 , -0.5123554 , -0.54006153, -1.281939  , -0.5679242 ,\n",
            "        1.2173891 , -0.68998337,  0.15002489, -0.48827544,  0.18006787,\n",
            "       -0.4391109 , -0.67962426, -0.39697838], dtype=float32), 'agent_3': Array([ 0.69731903,  0.59733975,  0.07226141,  0.05294811,  0.7969693 ,\n",
            "       -0.5733767 , -0.5123554 , -0.54006153, -0.5679242 ,  0.4762303 ,\n",
            "        1.2173891 , -0.68998337,  0.15002489, -0.48827544,  0.18006787,\n",
            "       -0.4391109 ,  1.2073497 ,  0.50437766], dtype=float32)}\n",
            "ctrl action chosen: [1.2084011  0.61100775 1.2001767  0.61029065 1.2035139  0.60629326\n",
            " 1.2075118  0.61060804]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.889233, dtype=float32), 'agent_0': Array(-12.889233, dtype=float32), 'agent_1': Array(-12.889233, dtype=float32), 'agent_2': Array(-12.889233, dtype=float32), 'agent_3': Array(-12.889233, dtype=float32)}\n",
            "step: 181\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.9885957e-01,  7.8020716e-01,  6.9008946e-02,  2.8863238e-02,\n",
            "        6.2103271e-01,  4.8832670e-02,  8.0460739e-01,  2.2580706e-02,\n",
            "        1.7524852e-03,  8.5669570e-02,  1.2308359e+00, -2.1629333e-01,\n",
            "       -2.0904541e-01, -6.6906017e-01, -1.9556541e+00, -1.3089572e+01,\n",
            "        1.6715899e+01,  7.4978199e+00], dtype=float32), 'agent_1': Array([ 6.9885957e-01,  7.8020716e-01,  6.9008946e-02,  2.8863238e-02,\n",
            "        6.2103271e-01,  4.8832670e-02,  2.2580706e-02, -9.8963612e-01,\n",
            "        1.7524852e-03,  8.5669570e-02,  1.2308359e+00, -2.1629333e-01,\n",
            "       -2.0904541e-01, -6.6906017e-01, -1.9556541e+00, -1.3089572e+01,\n",
            "        1.4412620e+01,  6.2148094e+00], dtype=float32), 'agent_2': Array([ 6.9885957e-01,  7.8020716e-01,  6.9008946e-02,  2.8863238e-02,\n",
            "        6.2103271e-01,  4.8832670e-02,  2.2580706e-02,  1.7524852e-03,\n",
            "       -1.1111548e+00,  8.5669570e-02,  1.2308359e+00, -2.1629333e-01,\n",
            "       -2.0904541e-01, -6.6906017e-01, -1.9556541e+00, -1.3089572e+01,\n",
            "        1.4739277e+01,  4.9550228e+00], dtype=float32), 'agent_3': Array([ 6.9885957e-01,  7.8020716e-01,  6.9008946e-02,  2.8863238e-02,\n",
            "        6.2103271e-01,  4.8832670e-02,  2.2580706e-02,  1.7524852e-03,\n",
            "        8.5669570e-02,  7.3924971e-01,  1.2308359e+00, -2.1629333e-01,\n",
            "       -2.0904541e-01, -6.6906017e-01, -1.9556541e+00, -1.3089572e+01,\n",
            "        1.7133900e+01,  7.1309581e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.2161812  -0.16152228 -1.216606   -0.16159071 -1.2161107  -0.16138415\n",
            " -1.2173316  -0.16172722]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4276905, dtype=float32), 'agent_0': Array(-1.4276905, dtype=float32), 'agent_1': Array(-1.4276905, dtype=float32), 'agent_2': Array(-1.4276905, dtype=float32), 'agent_3': Array(-1.4276905, dtype=float32)}\n",
            "step: 182\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.7103219e-01,  7.1896476e-01,  7.2032385e-02, -2.0146678e-04,\n",
            "        6.9130385e-01, -1.5428792e-01,  9.5541048e-01, -2.7703249e-01,\n",
            "       -2.7658805e-01, -1.1094258e-01,  1.0183334e+00, -4.7664642e-01,\n",
            "       -8.0109835e-01, -5.1599252e-01, -3.1612724e-01,  8.9795675e+00,\n",
            "       -1.0959066e+01,  1.7756094e+00], dtype=float32), 'agent_1': Array([ 6.7103219e-01,  7.1896476e-01,  7.2032385e-02, -2.0146678e-04,\n",
            "        6.9130385e-01, -1.5428792e-01, -2.7703249e-01, -8.6970532e-01,\n",
            "       -2.7658805e-01, -1.1094258e-01,  1.0183334e+00, -4.7664642e-01,\n",
            "       -8.0109835e-01, -5.1599252e-01, -3.1612724e-01,  8.9795675e+00,\n",
            "       -1.2829956e+01,  1.2884910e+00], dtype=float32), 'agent_2': Array([ 6.7103219e-01,  7.1896476e-01,  7.2032385e-02, -2.0146678e-04,\n",
            "        6.9130385e-01, -1.5428792e-01, -2.7703249e-01, -2.7658805e-01,\n",
            "       -9.6242249e-01, -1.1094258e-01,  1.0183334e+00, -4.7664642e-01,\n",
            "       -8.0109835e-01, -5.1599252e-01, -3.1612724e-01,  8.9795675e+00,\n",
            "       -1.2153802e+01,  2.3174109e+00], dtype=float32), 'agent_3': Array([ 6.7103219e-01,  7.1896476e-01,  7.2032385e-02, -2.0146678e-04,\n",
            "        6.9130385e-01, -1.5428792e-01, -2.7703249e-01, -2.7658805e-01,\n",
            "       -1.1094258e-01,  9.1741502e-01,  1.0183334e+00, -4.7664642e-01,\n",
            "       -8.0109835e-01, -5.1599252e-01, -3.1612724e-01,  8.9795675e+00,\n",
            "       -1.0869780e+01,  2.0648072e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.20067845 -1.7428668  -0.20332927 -1.7419928  -0.20179304 -1.7420486\n",
            " -0.2023628  -1.7427607 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9173567, dtype=float32), 'agent_0': Array(-0.9173567, dtype=float32), 'agent_1': Array(-0.9173567, dtype=float32), 'agent_2': Array(-0.9173567, dtype=float32), 'agent_3': Array(-0.9173567, dtype=float32)}\n",
            "step: 183\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6223544 ,  0.64425725,  0.04436227,  0.01963373,  0.7632687 ,\n",
            "       -0.44233412,  0.7515783 , -0.5762322 , -0.5637935 , -0.37236363,\n",
            "        0.73678493, -0.8514404 , -0.9140253 ,  0.56249225,  2.6643252 ,\n",
            "       -0.7213704 , -0.9751688 , -7.384731  ], dtype=float32), 'agent_1': Array([ 0.6223544 ,  0.64425725,  0.04436227,  0.01963373,  0.7632687 ,\n",
            "       -0.44233412, -0.5762322 , -1.0896293 , -0.5637935 , -0.37236363,\n",
            "        0.73678493, -0.8514404 , -0.9140253 ,  0.56249225,  2.6643252 ,\n",
            "       -0.7213704 ,  1.2654308 , -7.32171   ], dtype=float32), 'agent_2': Array([ 0.6223544 ,  0.64425725,  0.04436227,  0.01963373,  0.7632687 ,\n",
            "       -0.44233412, -0.5762322 , -0.5637935 , -1.1553445 , -0.37236363,\n",
            "        0.73678493, -0.8514404 , -0.9140253 ,  0.56249225,  2.6643252 ,\n",
            "       -0.7213704 ,  1.0711645 , -6.5417395 ], dtype=float32), 'agent_3': Array([ 0.6223544 ,  0.64425725,  0.04436227,  0.01963373,  0.7632687 ,\n",
            "       -0.44233412, -0.5762322 , -0.5637935 , -0.37236363,  0.7061474 ,\n",
            "        0.73678493, -0.8514404 , -0.9140253 ,  0.56249225,  2.6643252 ,\n",
            "       -0.7213704 , -0.09672449, -7.510892  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3273447  -0.51947665 -0.32980525 -0.5187716  -0.3287778  -0.5201435\n",
            " -0.3290766  -0.5204273 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.248906, dtype=float32), 'agent_0': Array(-4.248906, dtype=float32), 'agent_1': Array(-4.248906, dtype=float32), 'agent_2': Array(-4.248906, dtype=float32), 'agent_3': Array(-4.248906, dtype=float32)}\n",
            "step: 184\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7920039e-01,  6.4552426e-01,  1.3623000e-04,  5.3170368e-02,\n",
            "        7.6188666e-01, -5.0886911e-01,  4.5609960e-01, -5.3994823e-01,\n",
            "       -5.1988101e-01, -4.2932555e-01,  1.1001825e+00, -1.4925003e-01,\n",
            "       -7.2333813e-01, -1.4026803e+00,  1.1895500e+00,  9.5241743e-01,\n",
            "       -2.5157781e+00, -1.0599887e+00], dtype=float32), 'agent_1': Array([ 5.7920039e-01,  6.4552426e-01,  1.3623000e-04,  5.3170368e-02,\n",
            "        7.6188666e-01, -5.0886911e-01, -5.3994823e-01, -1.2846189e+00,\n",
            "       -5.1988101e-01, -4.2932555e-01,  1.1001825e+00, -1.4925003e-01,\n",
            "       -7.2333813e-01, -1.4026803e+00,  1.1895500e+00,  9.5241743e-01,\n",
            "        2.0974997e-01,  5.9705460e-01], dtype=float32), 'agent_2': Array([ 5.7920039e-01,  6.4552426e-01,  1.3623000e-04,  5.3170368e-02,\n",
            "        7.6188666e-01, -5.0886911e-01, -5.3994823e-01, -5.1988101e-01,\n",
            "       -1.2632929e+00, -4.2932555e-01,  1.1001825e+00, -1.4925003e-01,\n",
            "       -7.2333813e-01, -1.4026803e+00,  1.1895500e+00,  9.5241743e-01,\n",
            "       -1.5763223e-02, -5.6161705e-02], dtype=float32), 'agent_3': Array([ 5.7920039e-01,  6.4552426e-01,  1.3623000e-04,  5.3170368e-02,\n",
            "        7.6188666e-01, -5.0886911e-01, -5.3994823e-01, -5.1988101e-01,\n",
            "       -4.2932555e-01,  4.6434006e-01,  1.1001825e+00, -1.4925003e-01,\n",
            "       -7.2333813e-01, -1.4026803e+00,  1.1895500e+00,  9.5241743e-01,\n",
            "       -3.1629941e+00,  6.0040778e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.08685543  1.5751685  -0.08315258  1.5771636  -0.08252879  1.5738654\n",
            " -0.09020817  1.5779551 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1965898, dtype=float32), 'agent_0': Array(1.1965898, dtype=float32), 'agent_1': Array(1.1965898, dtype=float32), 'agent_2': Array(1.1965898, dtype=float32), 'agent_3': Array(1.1965898, dtype=float32)}\n",
            "step: 185\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5640771 ,  0.6478273 , -0.02057047,  0.01876876,  0.76127803,\n",
            "       -0.54272974,  0.67028415, -0.4642184 , -0.49775267, -0.53221756,\n",
            "        1.1583567 ,  0.54445267, -0.27798414, -1.4700699 , -0.5754102 ,\n",
            "       -0.7104182 ,  0.7200218 ,  6.115978  ], dtype=float32), 'agent_1': Array([ 0.5640771 ,  0.6478273 , -0.02057047,  0.01876876,  0.76127803,\n",
            "       -0.54272974, -0.4642184 , -1.0209222 , -0.49775267, -0.53221756,\n",
            "        1.1583567 ,  0.54445267, -0.27798414, -1.4700699 , -0.5754102 ,\n",
            "       -0.7104182 ,  2.041953  ,  7.677434  ], dtype=float32), 'agent_2': Array([ 0.5640771 ,  0.6478273 , -0.02057047,  0.01876876,  0.76127803,\n",
            "       -0.54272974, -0.4642184 , -0.49775267, -0.97731715, -0.53221756,\n",
            "        1.1583567 ,  0.54445267, -0.27798414, -1.4700699 , -0.5754102 ,\n",
            "       -0.7104182 ,  0.3524877 ,  8.556585  ], dtype=float32), 'agent_3': Array([ 0.5640771 ,  0.6478273 , -0.02057047,  0.01876876,  0.76127803,\n",
            "       -0.54272974, -0.4642184 , -0.49775267, -0.53221756,  0.73265857,\n",
            "        1.1583567 ,  0.54445267, -0.27798414, -1.4700699 , -0.5754102 ,\n",
            "       -0.7104182 , -1.0994412 ,  7.0273714 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7103616  -0.5598136  -0.71115255 -0.5603263  -0.71180356 -0.560141\n",
            " -0.7122438  -0.55753696]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.9227805, dtype=float32), 'agent_0': Array(-2.9227805, dtype=float32), 'agent_1': Array(-2.9227805, dtype=float32), 'agent_2': Array(-2.9227805, dtype=float32), 'agent_3': Array(-2.9227805, dtype=float32)}\n",
            "step: 186\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5379735 ,  0.64160675, -0.05251164,  0.01827926,  0.76501584,\n",
            "       -0.53475183,  0.6863724 , -0.52066505, -0.5425257 , -0.57088935,\n",
            "        1.1159897 , -0.14505386, -0.18305779, -0.58679605,  1.0558149 ,\n",
            "       -0.07355361,  0.34595296, -2.4851522 ], dtype=float32), 'agent_1': Array([ 0.5379735 ,  0.64160675, -0.05251164,  0.01827926,  0.76501584,\n",
            "       -0.53475183, -0.52066505, -0.90266204, -0.5425257 , -0.57088935,\n",
            "        1.1159897 , -0.14505386, -0.18305779, -0.58679605,  1.0558149 ,\n",
            "       -0.07355361, -1.8171322 ,  1.1164426 ], dtype=float32), 'agent_2': Array([ 0.5379735 ,  0.64160675, -0.05251164,  0.01827926,  0.76501584,\n",
            "       -0.53475183, -0.52066505, -0.5425257 , -0.9036337 , -0.57088935,\n",
            "        1.1159897 , -0.14505386, -0.18305779, -0.58679605,  1.0558149 ,\n",
            "       -0.07355361, -0.40591797, -0.4628216 ], dtype=float32), 'agent_3': Array([ 0.5379735 ,  0.64160675, -0.05251164,  0.01827926,  0.76501584,\n",
            "       -0.53475183, -0.52066505, -0.5425257 , -0.57088935,  0.80031294,\n",
            "        1.1159897 , -0.14505386, -0.18305779, -0.58679605,  1.0558149 ,\n",
            "       -0.07355361,  0.5858401 , -0.21334068], dtype=float32)}\n",
            "ctrl action chosen: [ 1.3430835  -0.48473513  1.3381859  -0.47806254  1.3432444  -0.4824556\n",
            "  1.345287   -0.48040697]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5608413, dtype=float32), 'agent_0': Array(0.5608413, dtype=float32), 'agent_1': Array(0.5608413, dtype=float32), 'agent_2': Array(0.5608413, dtype=float32), 'agent_3': Array(0.5608413, dtype=float32)}\n",
            "step: 187\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3247589e-01,  8.0298096e-01, -8.0695763e-02,  5.1325862e-03,\n",
            "        5.9049428e-01,  7.3400505e-02,  4.9656188e-01, -3.1539228e-02,\n",
            "        2.0169465e-02,  4.8850123e-02,  1.1243343e+00, -2.3517609e-01,\n",
            "       -2.9610395e-01, -7.7482605e-01,  1.3700267e+00, -1.2942429e+01,\n",
            "        1.6478355e+01, -4.6340885e+00], dtype=float32), 'agent_1': Array([ 5.3247589e-01,  8.0298096e-01, -8.0695763e-02,  5.1325862e-03,\n",
            "        5.9049428e-01,  7.3400505e-02, -3.1539228e-02, -9.5051730e-01,\n",
            "        2.0169465e-02,  4.8850123e-02,  1.1243343e+00, -2.3517609e-01,\n",
            "       -2.9610395e-01, -7.7482605e-01,  1.3700267e+00, -1.2942429e+01,\n",
            "        1.3886476e+01, -2.4992774e+00], dtype=float32), 'agent_2': Array([ 5.3247589e-01,  8.0298096e-01, -8.0695763e-02,  5.1325862e-03,\n",
            "        5.9049428e-01,  7.3400505e-02, -3.1539228e-02,  2.0169465e-02,\n",
            "       -9.5047116e-01,  4.8850123e-02,  1.1243343e+00, -2.3517609e-01,\n",
            "       -2.9610395e-01, -7.7482605e-01,  1.3700267e+00, -1.2942429e+01,\n",
            "        1.5702521e+01, -2.8615551e+00], dtype=float32), 'agent_3': Array([ 5.3247589e-01,  8.0298096e-01, -8.0695763e-02,  5.1325862e-03,\n",
            "        5.9049428e-01,  7.3400505e-02, -3.1539228e-02,  2.0169465e-02,\n",
            "        4.8850123e-02,  7.3183626e-01,  1.1243343e+00, -2.3517609e-01,\n",
            "       -2.9610395e-01, -7.7482605e-01,  1.3700267e+00, -1.2942429e+01,\n",
            "        1.7118273e+01, -3.3175416e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.052683   0.35330582 1.0537605  0.35649368 1.0533994  0.35405922\n",
            " 1.0522789  0.3538985 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.960218, dtype=float32), 'agent_0': Array(-1.960218, dtype=float32), 'agent_1': Array(-1.960218, dtype=float32), 'agent_2': Array(-1.960218, dtype=float32), 'agent_3': Array(-1.960218, dtype=float32)}\n",
            "step: 188\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52799004,  0.9092764 , -0.09641707, -0.00842944,  0.40478298,\n",
            "        0.5957041 ,  0.52373624,  0.52278084,  0.566442  ,  0.59191567,\n",
            "        0.5938053 , -0.2327919 , -0.15882254, -0.68604517,  0.31027666,\n",
            "        0.60550207, -1.6570591 ,  0.628121  ], dtype=float32), 'agent_1': Array([ 0.52799004,  0.9092764 , -0.09641707, -0.00842944,  0.40478298,\n",
            "        0.5957041 ,  0.52278084, -0.8676438 ,  0.566442  ,  0.59191567,\n",
            "        0.5938053 , -0.2327919 , -0.15882254, -0.68604517,  0.31027666,\n",
            "        0.60550207,  2.440523  ,  3.337879  ], dtype=float32), 'agent_2': Array([ 0.52799004,  0.9092764 , -0.09641707, -0.00842944,  0.40478298,\n",
            "        0.5957041 ,  0.52278084,  0.566442  , -0.95295084,  0.59191567,\n",
            "        0.5938053 , -0.2327919 , -0.15882254, -0.68604517,  0.31027666,\n",
            "        0.60550207, -0.06095417,  0.6952582 ], dtype=float32), 'agent_3': Array([ 0.52799004,  0.9092764 , -0.09641707, -0.00842944,  0.40478298,\n",
            "        0.5957041 ,  0.52278084,  0.566442  ,  0.59191567,  0.6528096 ,\n",
            "        0.5938053 , -0.2327919 , -0.15882254, -0.68604517,  0.31027666,\n",
            "        0.60550207, -1.2833654 , -1.084666  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.11854939 -0.5053942   0.1251376  -0.50557345  0.12681238 -0.5103398\n",
            "  0.1184255  -0.5097552 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5975034, dtype=float32), 'agent_0': Array(-0.5975034, dtype=float32), 'agent_1': Array(-0.5975034, dtype=float32), 'agent_2': Array(-0.5975034, dtype=float32), 'agent_3': Array(-0.5975034, dtype=float32)}\n",
            "step: 189\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.529495  ,  0.89298594, -0.12153472,  0.01768932,  0.43300408,\n",
            "        0.4778008 ,  0.48568806,  0.5368597 ,  0.50223345,  0.47225198,\n",
            "        0.572443  , -0.81357956,  0.48402548,  0.5310825 ,  0.9840854 ,\n",
            "        2.0762107 , -3.0153995 ,  0.33304787], dtype=float32), 'agent_1': Array([ 0.529495  ,  0.89298594, -0.12153472,  0.01768932,  0.43300408,\n",
            "        0.4778008 ,  0.5368597 , -0.9524296 ,  0.50223345,  0.47225198,\n",
            "        0.572443  , -0.81357956,  0.48402548,  0.5310825 ,  0.9840854 ,\n",
            "        2.0762107 , -0.6332493 , -3.4473097 ], dtype=float32), 'agent_2': Array([ 0.529495  ,  0.89298594, -0.12153472,  0.01768932,  0.43300408,\n",
            "        0.4778008 ,  0.5368597 ,  0.50223345, -1.1431634 ,  0.47225198,\n",
            "        0.572443  , -0.81357956,  0.48402548,  0.5310825 ,  0.9840854 ,\n",
            "        2.0762107 , -2.0271816 , -3.5220912 ], dtype=float32), 'agent_3': Array([ 0.529495  ,  0.89298594, -0.12153472,  0.01768932,  0.43300408,\n",
            "        0.4778008 ,  0.5368597 ,  0.50223345,  0.47225198,  0.49189082,\n",
            "        0.572443  , -0.81357956,  0.48402548,  0.5310825 ,  0.9840854 ,\n",
            "        2.0762107 , -3.2557118 , -1.0334969 ], dtype=float32)}\n",
            "ctrl action chosen: [0.25291926 0.45763475 0.25528678 0.4510989  0.26001745 0.44531518\n",
            " 0.25396696 0.4553703 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9144136, dtype=float32), 'agent_0': Array(0.9144136, dtype=float32), 'agent_1': Array(0.9144136, dtype=float32), 'agent_2': Array(0.9144136, dtype=float32), 'agent_3': Array(0.9144136, dtype=float32)}\n",
            "step: 190\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56928   ,  0.89303875, -0.08566466,  0.01726676,  0.44141287,\n",
            "        0.4687045 ,  0.57787377,  0.55835646,  0.52449673,  0.4567416 ,\n",
            "        0.749588  , -0.61473846,  0.6519079 ,  1.2172769 , -0.8767199 ,\n",
            "       -0.703567  ,  1.2738622 ,  2.724823  ], dtype=float32), 'agent_1': Array([ 0.56928   ,  0.89303875, -0.08566466,  0.01726676,  0.44141287,\n",
            "        0.4687045 ,  0.55835646, -0.86233884,  0.52449673,  0.4567416 ,\n",
            "        0.749588  , -0.61473846,  0.6519079 ,  1.2172769 , -0.8767199 ,\n",
            "       -0.703567  ,  0.47456318,  3.1692576 ], dtype=float32), 'agent_2': Array([ 0.56928   ,  0.89303875, -0.08566466,  0.01726676,  0.44141287,\n",
            "        0.4687045 ,  0.55835646,  0.52449673, -1.0123273 ,  0.4567416 ,\n",
            "        0.749588  , -0.61473846,  0.6519079 ,  1.2172769 , -0.8767199 ,\n",
            "       -0.703567  ,  1.6890894 ,  3.3792121 ], dtype=float32), 'agent_3': Array([ 0.56928   ,  0.89303875, -0.08566466,  0.01726676,  0.44141287,\n",
            "        0.4687045 ,  0.55835646,  0.52449673,  0.4567416 ,  0.634559  ,\n",
            "        0.749588  , -0.61473846,  0.6519079 ,  1.2172769 , -0.8767199 ,\n",
            "       -0.703567  ,  1.2080427 ,  3.8301985 ], dtype=float32)}\n",
            "ctrl action chosen: [1.9374473  0.10323202 1.9376905  0.10639735 1.9401782  0.10005736\n",
            " 1.9372156  0.10455271]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1386168, dtype=float32), 'agent_0': Array(1.1386168, dtype=float32), 'agent_1': Array(1.1386168, dtype=float32), 'agent_2': Array(1.1386168, dtype=float32), 'agent_3': Array(1.1386168, dtype=float32)}\n",
            "step: 191\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5810342 ,  0.90045613, -0.05889519,  0.01860299,  0.43053943,\n",
            "        0.5586754 ,  0.7038609 ,  0.54007274,  0.55675423,  0.5521655 ,\n",
            "        0.9404659 , -0.81653595, -0.03355742,  1.1650256 , -0.34982634,\n",
            "        0.4199949 ,  0.7539667 ,  2.8625255 ], dtype=float32), 'agent_1': Array([ 0.5810342 ,  0.90045613, -0.05889519,  0.01860299,  0.43053943,\n",
            "        0.5586754 ,  0.54007274, -0.7821885 ,  0.55675423,  0.5521655 ,\n",
            "        0.9404659 , -0.81653595, -0.03355742,  1.1650256 , -0.34982634,\n",
            "        0.4199949 , -1.2395421 ,  1.7250367 ], dtype=float32), 'agent_2': Array([ 0.5810342 ,  0.90045613, -0.05889519,  0.01860299,  0.43053943,\n",
            "        0.5586754 ,  0.54007274,  0.55675423, -0.9534658 ,  0.5521655 ,\n",
            "        0.9404659 , -0.81653595, -0.03355742,  1.1650256 , -0.34982634,\n",
            "        0.4199949 , -0.3941855 ,  1.2283993 ], dtype=float32), 'agent_3': Array([ 0.5810342 ,  0.90045613, -0.05889519,  0.01860299,  0.43053943,\n",
            "        0.5586754 ,  0.54007274,  0.55675423,  0.5521655 ,  0.7705073 ,\n",
            "        0.9404659 , -0.81653595, -0.03355742,  1.1650256 , -0.34982634,\n",
            "        0.4199949 ,  0.86574966,  2.4932332 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.5000994   0.47122264 -1.5019219   0.4739363  -1.4983314   0.46537113\n",
            " -1.4999532   0.4707443 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.616541, dtype=float32), 'agent_0': Array(-5.616541, dtype=float32), 'agent_1': Array(-5.616541, dtype=float32), 'agent_2': Array(-5.616541, dtype=float32), 'agent_3': Array(-5.616541, dtype=float32)}\n",
            "step: 192\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6981981e-01,  7.6960093e-01, -7.4960962e-03,  1.0847394e-02,\n",
            "        6.3838911e-01,  2.5088459e-02,  9.7108608e-01, -1.3275678e-01,\n",
            "       -5.3996764e-02,  1.9743612e-02,  1.0321140e+00, -6.9122314e-01,\n",
            "       -2.2301674e-01,  6.3852298e-01, -2.3127255e+00,  1.3086059e+01,\n",
            "       -1.5054735e+01,  6.2567453e+00], dtype=float32), 'agent_1': Array([ 5.6981981e-01,  7.6960093e-01, -7.4960962e-03,  1.0847394e-02,\n",
            "        6.3838911e-01,  2.5088459e-02, -1.3275678e-01, -5.6155115e-01,\n",
            "       -5.3996764e-02,  1.9743612e-02,  1.0321140e+00, -6.9122314e-01,\n",
            "       -2.2301674e-01,  6.3852298e-01, -2.3127255e+00,  1.3086059e+01,\n",
            "       -1.7445148e+01,  5.4692655e+00], dtype=float32), 'agent_2': Array([ 5.6981981e-01,  7.6960093e-01, -7.4960962e-03,  1.0847394e-02,\n",
            "        6.3838911e-01,  2.5088459e-02, -1.3275678e-01, -5.3996764e-02,\n",
            "       -7.2580010e-01,  1.9743612e-02,  1.0321140e+00, -6.9122314e-01,\n",
            "       -2.2301674e-01,  6.3852298e-01, -2.3127255e+00,  1.3086059e+01,\n",
            "       -1.6425665e+01,  6.1381888e+00], dtype=float32), 'agent_3': Array([ 5.6981981e-01,  7.6960093e-01, -7.4960962e-03,  1.0847394e-02,\n",
            "        6.3838911e-01,  2.5088459e-02, -1.3275678e-01, -5.3996764e-02,\n",
            "        1.9743612e-02,  1.0242252e+00,  1.0321140e+00, -6.9122314e-01,\n",
            "       -2.2301674e-01,  6.3852298e-01, -2.3127255e+00,  1.3086059e+01,\n",
            "       -1.5211707e+01,  5.7455168e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.1416366  0.13896559 1.1389325  0.1396629  1.1400359  0.1396334\n",
            " 1.1401013  0.1388383 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.9963207, dtype=float32), 'agent_0': Array(-2.9963207, dtype=float32), 'agent_1': Array(-2.9963207, dtype=float32), 'agent_2': Array(-2.9963207, dtype=float32), 'agent_3': Array(-2.9963207, dtype=float32)}\n",
            "step: 193\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5594379e-01,  8.3232826e-01,  3.0199474e-02, -9.0828212e-03,\n",
            "        5.5338526e-01,  3.2168970e-01,  1.1902363e+00,  5.5908926e-02,\n",
            "        1.8706918e-01,  2.8161827e-01,  1.0828972e+00, -6.8435669e-01,\n",
            "       -7.2789192e-02,  9.6139222e-01, -1.1849147e+00, -9.4760609e+00,\n",
            "        1.2763921e+01,  3.3064830e+00], dtype=float32), 'agent_1': Array([ 5.5594379e-01,  8.3232826e-01,  3.0199474e-02, -9.0828212e-03,\n",
            "        5.5338526e-01,  3.2168970e-01,  5.5908926e-02, -4.9754566e-01,\n",
            "        1.8706918e-01,  2.8161827e-01,  1.0828972e+00, -6.8435669e-01,\n",
            "       -7.2789192e-02,  9.6139222e-01, -1.1849147e+00, -9.4760609e+00,\n",
            "        1.0832297e+01, -3.5966116e-01], dtype=float32), 'agent_2': Array([ 5.5594379e-01,  8.3232826e-01,  3.0199474e-02, -9.0828212e-03,\n",
            "        5.5338526e-01,  3.2168970e-01,  5.5908926e-02,  1.8706918e-01,\n",
            "       -5.1022369e-01,  2.8161827e-01,  1.0828972e+00, -6.8435669e-01,\n",
            "       -7.2789192e-02,  9.6139222e-01, -1.1849147e+00, -9.4760609e+00,\n",
            "        1.1928428e+01,  2.7749038e+00], dtype=float32), 'agent_3': Array([ 5.5594379e-01,  8.3232826e-01,  3.0199474e-02, -9.0828212e-03,\n",
            "        5.5338526e-01,  3.2168970e-01,  5.5908926e-02,  1.8706918e-01,\n",
            "        2.8161827e-01,  1.1806753e+00,  1.0828972e+00, -6.8435669e-01,\n",
            "       -7.2789192e-02,  9.6139222e-01, -1.1849147e+00, -9.4760609e+00,\n",
            "        1.1926675e+01,  8.0371177e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 1.4777263 -1.201832   1.4746908 -1.2007602  1.4771159 -1.2027444\n",
            "  1.4750603 -1.2018212]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.5290735, dtype=float32), 'agent_0': Array(-0.5290735, dtype=float32), 'agent_1': Array(-0.5290735, dtype=float32), 'agent_2': Array(-0.5290735, dtype=float32), 'agent_3': Array(-0.5290735, dtype=float32)}\n",
            "step: 194\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5594106 ,  0.8965987 ,  0.02885491,  0.01361119,  0.44169322,\n",
            "        0.598204  ,  1.01175   ,  0.46179056,  0.5666167 ,  0.6017531 ,\n",
            "        0.4333496 , -0.81892014, -0.12956858, -0.17840607,  1.4563212 ,\n",
            "        0.16148797, -1.9641964 , -6.091994  ], dtype=float32), 'agent_1': Array([ 0.5594106 ,  0.8965987 ,  0.02885491,  0.01361119,  0.44169322,\n",
            "        0.598204  ,  0.46179056, -0.7868368 ,  0.5666167 ,  0.6017531 ,\n",
            "        0.4333496 , -0.81892014, -0.12956858, -0.17840607,  1.4563212 ,\n",
            "        0.16148797,  3.5507193 , -9.672106  ], dtype=float32), 'agent_2': Array([ 0.5594106 ,  0.8965987 ,  0.02885491,  0.01361119,  0.44169322,\n",
            "        0.598204  ,  0.46179056,  0.5666167 , -0.7092304 ,  0.6017531 ,\n",
            "        0.4333496 , -0.81892014, -0.12956858, -0.17840607,  1.4563212 ,\n",
            "        0.16148797,  0.85329616, -6.711202  ], dtype=float32), 'agent_3': Array([ 0.5594106 ,  0.8965987 ,  0.02885491,  0.01361119,  0.44169322,\n",
            "        0.598204  ,  0.46179056,  0.5666167 ,  0.6017531 ,  0.8632959 ,\n",
            "        0.4333496 , -0.81892014, -0.12956858, -0.17840607,  1.4563212 ,\n",
            "        0.16148797, -0.65912265, -8.579175  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.20953502 -1.2399805  -0.209458   -1.2376883  -0.20680314 -1.2418996\n",
            " -0.20867    -1.2397194 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.5353446, dtype=float32), 'agent_0': Array(-5.5353446, dtype=float32), 'agent_1': Array(-5.5353446, dtype=float32), 'agent_2': Array(-5.5353446, dtype=float32), 'agent_3': Array(-5.5353446, dtype=float32)}\n",
            "step: 195\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4571593e-01,  8.5174000e-01, -8.6406739e-03,  4.9857352e-02,\n",
            "        5.2151567e-01,  2.6469311e-01,  5.4779738e-01,  3.8847411e-01,\n",
            "        4.2933476e-01,  3.3068705e-01,  6.1607361e-01, -1.0477066e+00,\n",
            "        5.1677227e-01, -1.6173279e+00,  2.2980173e+00,  5.3901029e+00,\n",
            "       -8.7499580e+00, -1.2609839e+01], dtype=float32), 'agent_1': Array([ 0.5457159 ,  0.85174   , -0.00864067,  0.04985735,  0.52151567,\n",
            "        0.2646931 ,  0.3884741 , -1.3171597 ,  0.42933476,  0.33068705,\n",
            "        0.6160736 , -1.0477066 ,  0.5167723 , -1.6173279 ,  2.2980173 ,\n",
            "        5.390103  , -3.4341173 , -4.2132816 ], dtype=float32), 'agent_2': Array([ 5.4571593e-01,  8.5174000e-01, -8.6406739e-03,  4.9857352e-02,\n",
            "        5.2151567e-01,  2.6469311e-01,  3.8847411e-01,  4.2933476e-01,\n",
            "       -1.1687721e+00,  3.3068705e-01,  6.1607361e-01, -1.0477066e+00,\n",
            "        5.1677227e-01, -1.6173279e+00,  2.2980173e+00,  5.3901029e+00,\n",
            "       -4.5032196e+00, -9.5547009e+00], dtype=float32), 'agent_3': Array([ 0.5457159 ,  0.85174   , -0.00864067,  0.04985735,  0.52151567,\n",
            "        0.2646931 ,  0.3884741 ,  0.42933476,  0.33068705,  0.42749685,\n",
            "        0.6160736 , -1.0477066 ,  0.5167723 , -1.6173279 ,  2.2980173 ,\n",
            "        5.390103  , -8.282468  , -3.3746214 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.44224355  1.3146061  -0.44264174  1.3262151  -0.43872315  1.3129689\n",
            " -0.44253534  1.3265675 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7255793, dtype=float32), 'agent_0': Array(-1.7255793, dtype=float32), 'agent_1': Array(-1.7255793, dtype=float32), 'agent_2': Array(-1.7255793, dtype=float32), 'agent_3': Array(-1.7255793, dtype=float32)}\n",
            "step: 196\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.93182445e-01,  7.63018191e-01, -7.18568685e-04,  1.79373175e-02,\n",
            "        6.46127701e-01, -1.71362862e-01,  5.77799976e-01,  1.21314324e-01,\n",
            "        1.36082694e-01, -1.03598565e-01,  5.48934937e-01, -1.42955780e-01,\n",
            "        1.36305094e+00,  1.97713926e-01, -1.25507534e+00,  5.48502016e+00,\n",
            "       -8.13621521e+00,  4.06097841e+00], dtype=float32), 'agent_1': Array([ 5.93182445e-01,  7.63018191e-01, -7.18568685e-04,  1.79373175e-02,\n",
            "        6.46127701e-01, -1.71362862e-01,  1.21314324e-01, -1.07003188e+00,\n",
            "        1.36082694e-01, -1.03598565e-01,  5.48934937e-01, -1.42955780e-01,\n",
            "        1.36305094e+00,  1.97713926e-01, -1.25507534e+00,  5.48502016e+00,\n",
            "       -4.94694042e+00,  6.34955645e+00], dtype=float32), 'agent_2': Array([ 5.93182445e-01,  7.63018191e-01, -7.18568685e-04,  1.79373175e-02,\n",
            "        6.46127701e-01, -1.71362862e-01,  1.21314324e-01,  1.36082694e-01,\n",
            "       -1.09919071e+00, -1.03598565e-01,  5.48934937e-01, -1.42955780e-01,\n",
            "        1.36305094e+00,  1.97713926e-01, -1.25507534e+00,  5.48502016e+00,\n",
            "       -6.14662504e+00,  5.84940195e+00], dtype=float32), 'agent_3': Array([ 5.93182445e-01,  7.63018191e-01, -7.18568685e-04,  1.79373175e-02,\n",
            "        6.46127701e-01, -1.71362862e-01,  1.21314324e-01,  1.36082694e-01,\n",
            "       -1.03598565e-01,  6.53838634e-01,  5.48934937e-01, -1.42955780e-01,\n",
            "        1.36305094e+00,  1.97713926e-01, -1.25507534e+00,  5.48502016e+00,\n",
            "       -7.97390461e+00,  5.38326836e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.32276526  0.22808717 -0.31572285  0.22958697 -0.31542143  0.22765934\n",
            " -0.32116395  0.22738533]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.036833, dtype=float32), 'agent_0': Array(-2.036833, dtype=float32), 'agent_1': Array(-2.036833, dtype=float32), 'agent_2': Array(-2.036833, dtype=float32), 'agent_3': Array(-2.036833, dtype=float32)}\n",
            "step: 197\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.3498998e-01,  6.6975462e-01,  8.6589903e-03, -1.7893334e-03,\n",
            "        7.4252987e-01, -5.4285634e-01,  7.3806345e-01, -1.2649135e-01,\n",
            "       -1.6456844e-01, -5.0468320e-01,  7.3266029e-01, -3.1137466e-01,\n",
            "        4.4102669e-01, -8.8975722e-01, -1.0132606e+00,  4.9211888e+00,\n",
            "       -6.0848851e+00,  4.0531802e+00], dtype=float32), 'agent_1': Array([ 6.3498998e-01,  6.6975462e-01,  8.6589903e-03, -1.7893334e-03,\n",
            "        7.4252987e-01, -5.4285634e-01, -1.2649135e-01, -8.0266899e-01,\n",
            "       -1.6456844e-01, -5.0468320e-01,  7.3266029e-01, -3.1137466e-01,\n",
            "        4.4102669e-01, -8.8975722e-01, -1.0132606e+00,  4.9211888e+00,\n",
            "       -4.8306556e+00,  6.3326402e+00], dtype=float32), 'agent_2': Array([ 6.3498998e-01,  6.6975462e-01,  8.6589903e-03, -1.7893334e-03,\n",
            "        7.4252987e-01, -5.4285634e-01, -1.2649135e-01, -1.6456844e-01,\n",
            "       -9.2620808e-01, -5.0468320e-01,  7.3266029e-01, -3.1137466e-01,\n",
            "        4.4102669e-01, -8.8975722e-01, -1.0132606e+00,  4.9211888e+00,\n",
            "       -5.2324800e+00,  3.5691729e+00], dtype=float32), 'agent_3': Array([ 6.3498998e-01,  6.6975462e-01,  8.6589903e-03, -1.7893334e-03,\n",
            "        7.4252987e-01, -5.4285634e-01, -1.2649135e-01, -1.6456844e-01,\n",
            "       -5.0468320e-01,  8.8944602e-01,  7.3266029e-01, -3.1137466e-01,\n",
            "        4.4102669e-01, -8.8975722e-01, -1.0132606e+00,  4.9211888e+00,\n",
            "       -7.5414643e+00,  6.3210354e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.6689175  -0.84923047  1.6714462  -0.8480202   1.6704501  -0.8498535\n",
            "  1.668975   -0.8507973 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.3297831, dtype=float32), 'agent_0': Array(1.3297831, dtype=float32), 'agent_1': Array(1.3297831, dtype=float32), 'agent_2': Array(1.3297831, dtype=float32), 'agent_3': Array(1.3297831, dtype=float32)}\n",
            "step: 198\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.4341450e-01,  7.9967046e-01, -5.5733351e-03,  1.3154302e-03,\n",
            "        6.0041177e-01, -1.0007943e-01,  6.5933490e-01,  3.8896295e-01,\n",
            "        3.4593803e-01, -1.0326172e-01,  6.9904327e-01, -6.8740845e-01,\n",
            "        2.3651123e-02, -2.8384039e-01,  1.2448715e+00, -1.1511599e+01,\n",
            "        1.3783754e+01, -4.1782246e+00], dtype=float32), 'agent_1': Array([ 6.4341450e-01,  7.9967046e-01, -5.5733351e-03,  1.3154302e-03,\n",
            "        6.0041177e-01, -1.0007943e-01,  3.8896295e-01, -7.7649552e-01,\n",
            "        3.4593803e-01, -1.0326172e-01,  6.9904327e-01, -6.8740845e-01,\n",
            "        2.3651123e-02, -2.8384039e-01,  1.2448715e+00, -1.1511599e+01,\n",
            "        1.5132579e+01, -2.7294660e+00], dtype=float32), 'agent_2': Array([ 6.4341450e-01,  7.9967046e-01, -5.5733351e-03,  1.3154302e-03,\n",
            "        6.0041177e-01, -1.0007943e-01,  3.8896295e-01,  3.4593803e-01,\n",
            "       -1.0026050e+00, -1.0326172e-01,  6.9904327e-01, -6.8740845e-01,\n",
            "        2.3651123e-02, -2.8384039e-01,  1.2448715e+00, -1.1511599e+01,\n",
            "        1.5116987e+01, -3.4143972e+00], dtype=float32), 'agent_3': Array([ 6.4341450e-01,  7.9967046e-01, -5.5733351e-03,  1.3154302e-03,\n",
            "        6.0041177e-01, -1.0007943e-01,  3.8896295e-01,  3.4593803e-01,\n",
            "       -1.0326172e-01,  9.2728055e-01,  6.9904327e-01, -6.8740845e-01,\n",
            "        2.3651123e-02, -2.8384039e-01,  1.2448715e+00, -1.1511599e+01,\n",
            "        1.3383172e+01, -2.2429688e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5995285  -1.0313193   0.6004674  -1.0290897   0.6013833  -1.0313586\n",
            "  0.60108215 -1.0305513 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.289286, dtype=float32), 'agent_0': Array(-5.289286, dtype=float32), 'agent_1': Array(-5.289286, dtype=float32), 'agent_2': Array(-5.289286, dtype=float32), 'agent_3': Array(-5.289286, dtype=float32)}\n",
            "step: 199\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.62504655,  0.85484034, -0.04610618,  0.03892873,  0.5153705 ,\n",
            "        0.23402461,  0.43867925,  0.58087426,  0.59541494,  0.20574327,\n",
            "        1.1550426 , -0.84400177, -0.6637573 ,  0.23337613,  2.6861322 ,\n",
            "       -0.4954603 ,  3.4105673 , -0.32823062], dtype=float32), 'agent_1': Array([  0.62504655,   0.85484034,  -0.04610618,   0.03892873,\n",
            "         0.5153705 ,   0.23402461,   0.58087426,  -1.1737808 ,\n",
            "         0.59541494,   0.20574327,   1.1550426 ,  -0.84400177,\n",
            "        -0.6637573 ,   0.23337613,   2.6861322 ,  -0.4954603 ,\n",
            "        -1.7657675 , -11.81183   ], dtype=float32), 'agent_2': Array([ 0.62504655,  0.85484034, -0.04610618,  0.03892873,  0.5153705 ,\n",
            "        0.23402461,  0.58087426,  0.59541494, -1.3000369 ,  0.20574327,\n",
            "        1.1550426 , -0.84400177, -0.6637573 ,  0.23337613,  2.6861322 ,\n",
            "       -0.4954603 , -0.42279133, -3.233708  ], dtype=float32), 'agent_3': Array([  0.62504655,   0.85484034,  -0.04610618,   0.03892873,\n",
            "         0.5153705 ,   0.23402461,   0.58087426,   0.59541494,\n",
            "         0.20574327,   0.5582484 ,   1.1550426 ,  -0.84400177,\n",
            "        -0.6637573 ,   0.23337613,   2.6861322 ,  -0.4954603 ,\n",
            "         2.2598557 , -10.955629  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.8534545  -0.29252857 -1.8560226  -0.2983967  -1.8527061  -0.3008121\n",
            " -1.8562655  -0.29933995]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.91980886, dtype=float32), 'agent_0': Array(-0.91980886, dtype=float32), 'agent_1': Array(-0.91980886, dtype=float32), 'agent_2': Array(-0.91980886, dtype=float32), 'agent_3': Array(-0.91980886, dtype=float32)}\n",
            "step: 200\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5934368 ,   0.70151514,  -0.02811864,   0.06204777,\n",
            "         0.70939124,  -0.26463935,   0.51119167,  -0.14797409,\n",
            "        -0.06722862,  -0.36844656,   1.2225628 ,  -0.4087448 ,\n",
            "        -0.7980108 ,  -0.4716457 ,  -0.09762544,  13.583209  ,\n",
            "       -14.0922    ,   1.0912716 ], dtype=float32), 'agent_1': Array([  0.5934368 ,   0.70151514,  -0.02811864,   0.06204777,\n",
            "         0.70939124,  -0.26463935,  -0.14797409,  -1.2641343 ,\n",
            "        -0.06722862,  -0.36844656,   1.2225628 ,  -0.4087448 ,\n",
            "        -0.7980108 ,  -0.4716457 ,  -0.09762544,  13.583209  ,\n",
            "       -19.163187  ,   1.14129   ], dtype=float32), 'agent_2': Array([  0.5934368 ,   0.70151514,  -0.02811864,   0.06204777,\n",
            "         0.70939124,  -0.26463935,  -0.14797409,  -0.06722862,\n",
            "        -1.260691  ,  -0.36844656,   1.2225628 ,  -0.4087448 ,\n",
            "        -0.7980108 ,  -0.4716457 ,  -0.09762544,  13.583209  ,\n",
            "       -18.51486   ,   0.51195425], dtype=float32), 'agent_3': Array([  0.5934368 ,   0.70151514,  -0.02811864,   0.06204777,\n",
            "         0.70939124,  -0.26463935,  -0.14797409,  -0.06722862,\n",
            "        -0.36844656,   0.48305544,   1.2225628 ,  -0.4087448 ,\n",
            "        -0.7980108 ,  -0.4716457 ,  -0.09762544,  13.583209  ,\n",
            "       -15.418561  ,   1.2646956 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.28144255 -0.63949573  0.2804205  -0.6384166   0.28140065 -0.6393634\n",
            "  0.28186896 -0.63979983]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.933345, dtype=float32), 'agent_0': Array(-4.933345, dtype=float32), 'agent_1': Array(-4.933345, dtype=float32), 'agent_2': Array(-4.933345, dtype=float32), 'agent_3': Array(-4.933345, dtype=float32)}\n",
            "step: 201\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53650427,  0.65578747, -0.03002272,  0.07166589,  0.75093645,\n",
            "       -0.32533318,  0.51963603, -0.41555265, -0.30822897, -0.49060318,\n",
            "        0.9927273 , -0.56381226, -1.4635801 , -0.1231097 ,  0.25202978,\n",
            "       -0.54553556,  2.5595603 , -0.11606117], dtype=float32), 'agent_1': Array([ 0.53650427,  0.65578747, -0.03002272,  0.07166589,  0.75093645,\n",
            "       -0.32533318, -0.41555265, -1.2354894 , -0.30822897, -0.49060318,\n",
            "        0.9927273 , -0.56381226, -1.4635801 , -0.1231097 ,  0.25202978,\n",
            "       -0.54553556, -1.2882717 ,  0.8396535 ], dtype=float32), 'agent_2': Array([ 0.53650427,  0.65578747, -0.03002272,  0.07166589,  0.75093645,\n",
            "       -0.32533318, -0.41555265, -0.30822897, -1.2291623 , -0.49060318,\n",
            "        0.9927273 , -0.56381226, -1.4635801 , -0.1231097 ,  0.25202978,\n",
            "       -0.54553556, -0.7041374 ,  0.54317445], dtype=float32), 'agent_3': Array([ 0.53650427,  0.65578747, -0.03002272,  0.07166589,  0.75093645,\n",
            "       -0.32533318, -0.41555265, -0.30822897, -0.49060318,  0.5069747 ,\n",
            "        0.9927273 , -0.56381226, -1.4635801 , -0.1231097 ,  0.25202978,\n",
            "       -0.54553556,  1.4810417 ,  0.7894411 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5026988  -0.29862452  0.4926421  -0.29365298  0.49491775 -0.29879966\n",
            "  0.5006918  -0.2958357 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0320622, dtype=float32), 'agent_0': Array(1.0320622, dtype=float32), 'agent_1': Array(1.0320622, dtype=float32), 'agent_2': Array(1.0320622, dtype=float32), 'agent_3': Array(1.0320622, dtype=float32)}\n",
            "step: 202\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4888992 ,  0.7463447 , -0.05220284,  0.0620802 ,  0.6605987 ,\n",
            "        0.07638162,  0.5037327 , -0.17914261, -0.03049675, -0.13032563,\n",
            "        0.80604553,  0.2530098 , -0.10858178, -0.959006  ,  0.5797094 ,\n",
            "       -6.58614   ,  9.538594  , -0.71130455], dtype=float32), 'agent_1': Array([ 0.4888992 ,  0.7463447 , -0.05220284,  0.0620802 ,  0.6605987 ,\n",
            "        0.07638162, -0.17914261, -1.1852676 , -0.03049675, -0.13032563,\n",
            "        0.80604553,  0.2530098 , -0.10858178, -0.959006  ,  0.5797094 ,\n",
            "       -6.58614   ,  6.861719  ,  1.0046552 ], dtype=float32), 'agent_2': Array([ 0.4888992 ,  0.7463447 , -0.05220284,  0.0620802 ,  0.6605987 ,\n",
            "        0.07638162, -0.17914261, -0.03049675, -1.2206986 , -0.13032563,\n",
            "        0.80604553,  0.2530098 , -0.10858178, -0.959006  ,  0.5797094 ,\n",
            "       -6.58614   ,  7.895364  , -1.3247013 ], dtype=float32), 'agent_3': Array([ 0.4888992 ,  0.7463447 , -0.05220284,  0.0620802 ,  0.6605987 ,\n",
            "        0.07638162, -0.17914261, -0.03049675, -0.13032563,  0.5226354 ,\n",
            "        0.80604553,  0.2530098 , -0.10858178, -0.959006  ,  0.5797094 ,\n",
            "       -6.58614   ,  8.969281  , -0.13735245], dtype=float32)}\n",
            "ctrl action chosen: [-0.01204905  0.31867203 -0.00918991  0.31936586 -0.01024882  0.31705362\n",
            " -0.01215058  0.31865716]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2058809, dtype=float32), 'agent_0': Array(1.2058809, dtype=float32), 'agent_1': Array(1.2058809, dtype=float32), 'agent_2': Array(1.2058809, dtype=float32), 'agent_3': Array(1.2058809, dtype=float32)}\n",
            "step: 203\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49726966,  0.7712817 , -0.07844554,  0.04751278,  0.62985194,\n",
            "        0.26396427,  0.54421544, -0.08454379,  0.10002741,  0.02744158,\n",
            "        1.0307789 ,  0.3938675 ,  0.14283061, -1.0039582 ,  0.24713744,\n",
            "       -0.5664857 ,  2.1935434 ,  0.6578244 ], dtype=float32), 'agent_1': Array([ 0.49726966,  0.7712817 , -0.07844554,  0.04751278,  0.62985194,\n",
            "        0.26396427, -0.08454379, -1.0259721 ,  0.10002741,  0.02744158,\n",
            "        1.0307789 ,  0.3938675 ,  0.14283061, -1.0039582 ,  0.24713744,\n",
            "       -0.5664857 ,  0.91962624,  3.5474539 ], dtype=float32), 'agent_2': Array([ 0.49726966,  0.7712817 , -0.07844554,  0.04751278,  0.62985194,\n",
            "        0.26396427, -0.08454379,  0.10002741, -1.1783899 ,  0.02744158,\n",
            "        1.0307789 ,  0.3938675 ,  0.14283061, -1.0039582 ,  0.24713744,\n",
            "       -0.5664857 ,  1.2367139 ,  1.3418953 ], dtype=float32), 'agent_3': Array([ 0.49726966,  0.7712817 , -0.07844554,  0.04751278,  0.62985194,\n",
            "        0.26396427, -0.08454379,  0.10002741,  0.02744158,  0.60474616,\n",
            "        1.0307789 ,  0.3938675 ,  0.14283061, -1.0039582 ,  0.24713744,\n",
            "       -0.5664857 ,  1.610183  ,  2.1004658 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.3241186  -1.2533276   0.31995824 -1.2502759   0.32555035 -1.2551429\n",
            "  0.32173437 -1.2517872 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.812249, dtype=float32), 'agent_0': Array(1.812249, dtype=float32), 'agent_1': Array(1.812249, dtype=float32), 'agent_2': Array(1.812249, dtype=float32), 'agent_3': Array(1.812249, dtype=float32)}\n",
            "step: 204\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5041596 ,  0.81406426, -0.10903125,  0.06688538,  0.56651396,\n",
            "        0.51149184,  0.46749896,  0.10975647,  0.30777934,  0.25108877,\n",
            "        0.5931854 ,  0.53663254,  0.15414953,  0.7746712 ,  0.8754786 ,\n",
            "       -3.574608  ,  5.6177344 ,  0.46760187], dtype=float32), 'agent_1': Array([ 0.5041596 ,  0.81406426, -0.10903125,  0.06688538,  0.56651396,\n",
            "        0.51149184,  0.10975647, -1.2170899 ,  0.30777934,  0.25108877,\n",
            "        0.5931854 ,  0.53663254,  0.15414953,  0.7746712 ,  0.8754786 ,\n",
            "       -3.574608  ,  4.652254  , -6.696588  ], dtype=float32), 'agent_2': Array([ 0.5041596 ,  0.81406426, -0.10903125,  0.06688538,  0.56651396,\n",
            "        0.51149184,  0.10975647,  0.30777934, -1.2607886 ,  0.25108877,\n",
            "        0.5931854 ,  0.53663254,  0.15414953,  0.7746712 ,  0.8754786 ,\n",
            "       -3.574608  ,  4.967842  ,  0.9898836 ], dtype=float32), 'agent_3': Array([ 0.5041596 ,  0.81406426, -0.10903125,  0.06688538,  0.56651396,\n",
            "        0.51149184,  0.10975647,  0.30777934,  0.25108877,  0.46194446,\n",
            "        0.5931854 ,  0.53663254,  0.15414953,  0.7746712 ,  0.8754786 ,\n",
            "       -3.574608  ,  5.3019905 , -0.18527524], dtype=float32)}\n",
            "ctrl action chosen: [ 0.43777546 -1.2125263   0.43013343 -1.2135898   0.43890437 -1.2139266\n",
            "  0.43634143 -1.2126782 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5513654, dtype=float32), 'agent_0': Array(-1.5513654, dtype=float32), 'agent_1': Array(-1.5513654, dtype=float32), 'agent_2': Array(-1.5513654, dtype=float32), 'agent_3': Array(-1.5513654, dtype=float32)}\n",
            "step: 205\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5162017 ,  0.8442767 , -0.11768208,  0.06599269,  0.51864505,\n",
            "        0.5844599 ,  0.4739115 ,  0.30791458,  0.5216331 ,  0.47215828,\n",
            "        0.5223751 ,  0.36506653,  0.37671328, -0.22850129,  0.399573  ,\n",
            "       -1.4446049 , -0.8544467 ,  0.3323362 ], dtype=float32), 'agent_1': Array([ 0.5162017 ,  0.8442767 , -0.11768208,  0.06599269,  0.51864505,\n",
            "        0.5844599 ,  0.30791458, -1.2770207 ,  0.5216331 ,  0.47215828,\n",
            "        0.5223751 ,  0.36506653,  0.37671328, -0.22850129,  0.399573  ,\n",
            "       -1.4446049 ,  3.5713854 ,  0.12253205], dtype=float32), 'agent_2': Array([ 0.5162017 ,  0.8442767 , -0.11768208,  0.06599269,  0.51864505,\n",
            "        0.5844599 ,  0.30791458,  0.5216331 , -1.2634687 ,  0.47215828,\n",
            "        0.5223751 ,  0.36506653,  0.37671328, -0.22850129,  0.399573  ,\n",
            "       -1.4446049 ,  3.6914566 , -0.4150659 ], dtype=float32), 'agent_3': Array([ 0.5162017 ,  0.8442767 , -0.11768208,  0.06599269,  0.51864505,\n",
            "        0.5844599 ,  0.30791458,  0.5216331 ,  0.47215828,  0.48396105,\n",
            "        0.5223751 ,  0.36506653,  0.37671328, -0.22850129,  0.399573  ,\n",
            "       -1.4446049 ,  3.7995791 ,  0.6422004 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2343918 -1.1603919 -1.2300192 -1.1622092 -1.2285991 -1.1665702\n",
            " -1.2319934 -1.1648725]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7002668, dtype=float32), 'agent_0': Array(-1.7002668, dtype=float32), 'agent_1': Array(-1.7002668, dtype=float32), 'agent_2': Array(-1.7002668, dtype=float32), 'agent_3': Array(-1.7002668, dtype=float32)}\n",
            "step: 206\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5361209 ,   0.6969276 ,  -0.0945097 ,   0.10929843,\n",
            "         0.70243424,  -0.08974034,   0.4856726 ,  -0.19778958,\n",
            "         0.03152234,  -0.02410188,   0.22740364,  -0.12960434,\n",
            "         0.5273342 ,   0.620465  ,   0.07785667,  13.269054  ,\n",
            "       -17.842983  ,   0.07758273], dtype=float32), 'agent_1': Array([  0.5361209 ,   0.6969276 ,  -0.0945097 ,   0.10929843,\n",
            "         0.70243424,  -0.08974034,  -0.19778958,  -1.2642134 ,\n",
            "         0.03152234,  -0.02410188,   0.22740364,  -0.12960434,\n",
            "         0.5273342 ,   0.620465  ,   0.07785667,  13.269054  ,\n",
            "       -14.690177  ,   0.72928435], dtype=float32), 'agent_2': Array([  0.5361209 ,   0.6969276 ,  -0.0945097 ,   0.10929843,\n",
            "         0.70243424,  -0.08974034,  -0.19778958,   0.03152234,\n",
            "        -1.2678533 ,  -0.02410188,   0.22740364,  -0.12960434,\n",
            "         0.5273342 ,   0.620465  ,   0.07785667,  13.269054  ,\n",
            "       -14.327728  ,   0.21485506], dtype=float32), 'agent_3': Array([  0.5361209 ,   0.6969276 ,  -0.0945097 ,   0.10929843,\n",
            "         0.70243424,  -0.08974034,  -0.19778958,   0.03152234,\n",
            "        -0.02410188,   0.4792634 ,   0.22740364,  -0.12960434,\n",
            "         0.5273342 ,   0.620465  ,   0.07785667,  13.269054  ,\n",
            "       -14.910635  ,  -0.18965515], dtype=float32)}\n",
            "ctrl action chosen: [ 0.31290007 -0.8005829   0.31189823 -0.79983556  0.31209537 -0.80204076\n",
            "  0.31085336 -0.802009  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.462928, dtype=float32), 'agent_0': Array(-4.462928, dtype=float32), 'agent_1': Array(-4.462928, dtype=float32), 'agent_2': Array(-4.462928, dtype=float32), 'agent_3': Array(-4.462928, dtype=float32)}\n",
            "step: 207\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55923456,  0.65131235, -0.08168428,  0.1212355 ,  0.74459517,\n",
            "       -0.31566697,  0.48793936, -0.3023485 , -0.05124157, -0.17664674,\n",
            "        0.5296707 , -0.25815964,  0.37425756,  0.27781484,  0.15634039,\n",
            "       -0.5243364 , -0.262798  ,  0.03077883], dtype=float32), 'agent_1': Array([ 0.55923456,  0.65131235, -0.08168428,  0.1212355 ,  0.74459517,\n",
            "       -0.31566697, -0.3023485 , -1.2394472 , -0.05124157, -0.17664674,\n",
            "        0.5296707 , -0.25815964,  0.37425756,  0.27781484,  0.15634039,\n",
            "       -0.5243364 ,  1.8384222 , -0.03964372], dtype=float32), 'agent_2': Array([ 0.55923456,  0.65131235, -0.08168428,  0.1212355 ,  0.74459517,\n",
            "       -0.31566697, -0.3023485 , -0.05124157, -1.2481261 , -0.17664674,\n",
            "        0.5296707 , -0.25815964,  0.37425756,  0.27781484,  0.15634039,\n",
            "       -0.5243364 ,  2.2334223 , -0.00961742], dtype=float32), 'agent_3': Array([ 0.55923456,  0.65131235, -0.08168428,  0.1212355 ,  0.74459517,\n",
            "       -0.31566697, -0.3023485 , -0.05124157, -0.17664674,  0.4819805 ,\n",
            "        0.5296707 , -0.25815964,  0.37425756,  0.27781484,  0.15634039,\n",
            "       -0.5243364 ,  0.85482764, -0.18470363], dtype=float32)}\n",
            "ctrl action chosen: [0.17677885 2.1851265  0.1807629  2.1860228  0.18181789 2.1803195\n",
            " 0.17804459 2.1830347 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.06476176, dtype=float32), 'agent_0': Array(-0.06476176, dtype=float32), 'agent_1': Array(-0.06476176, dtype=float32), 'agent_2': Array(-0.06476176, dtype=float32), 'agent_3': Array(-0.06476176, dtype=float32)}\n",
            "step: 208\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58245134,  0.69435513, -0.0495501 ,  0.07587703,  0.71390367,\n",
            "       -0.22653261,  0.8277642 , -0.10890676,  0.14403751, -0.0275179 ,\n",
            "        0.64044   ,  0.45719147,  0.46924353, -0.16876934, -3.2440405 ,\n",
            "       -2.8232176 ,  2.7790103 ,  9.173401  ], dtype=float32), 'agent_1': Array([ 0.58245134,  0.69435513, -0.0495501 ,  0.07587703,  0.71390367,\n",
            "       -0.22653261, -0.10890676, -0.87713325,  0.14403751, -0.0275179 ,\n",
            "        0.64044   ,  0.45719147,  0.46924353, -0.16876934, -3.2440405 ,\n",
            "       -2.8232176 ,  4.782336  ,  9.656444  ], dtype=float32), 'agent_2': Array([ 0.58245134,  0.69435513, -0.0495501 ,  0.07587703,  0.71390367,\n",
            "       -0.22653261, -0.10890676,  0.14403751, -0.9246577 , -0.0275179 ,\n",
            "        0.64044   ,  0.45719147,  0.46924353, -0.16876934, -3.2440405 ,\n",
            "       -2.8232176 ,  4.319502  ,  8.631443  ], dtype=float32), 'agent_3': Array([ 0.58245134,  0.69435513, -0.0495501 ,  0.07587703,  0.71390367,\n",
            "       -0.22653261, -0.10890676,  0.14403751, -0.0275179 ,  0.75482416,\n",
            "        0.64044   ,  0.45719147,  0.46924353, -0.16876934, -3.2440405 ,\n",
            "       -2.8232176 ,  3.6429129 ,  7.6012444 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.48751315  1.8847467  -0.48754984  1.8852844  -0.48550344  1.8835604\n",
            " -0.4868319   1.8834226 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.9976063, dtype=float32), 'agent_0': Array(-7.9976063, dtype=float32), 'agent_1': Array(-7.9976063, dtype=float32), 'agent_2': Array(-7.9976063, dtype=float32), 'agent_3': Array(-7.9976063, dtype=float32)}\n",
            "step: 209\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5985744 ,  0.62757015,  0.02141995,  0.00889204,  0.7782145 ,\n",
            "       -0.44382992,  1.3051622 , -0.29477   , -0.03951136, -0.2693356 ,\n",
            "        0.6672859 ,  0.7154465 ,  0.16531944, -0.4559872 , -3.362742  ,\n",
            "        5.6156588 , -6.027646  ,  4.7725587 ], dtype=float32), 'agent_1': Array([ 0.5985744 ,  0.62757015,  0.02141995,  0.00889204,  0.7782145 ,\n",
            "       -0.44382992, -0.29477   , -0.42177528, -0.03951136, -0.2693356 ,\n",
            "        0.6672859 ,  0.7154465 ,  0.16531944, -0.4559872 , -3.362742  ,\n",
            "        5.6156588 , -6.8531203 ,  2.6610787 ], dtype=float32), 'agent_2': Array([ 0.5985744 ,  0.62757015,  0.02141995,  0.00889204,  0.7782145 ,\n",
            "       -0.44382992, -0.29477   , -0.03951136, -0.4264854 , -0.2693356 ,\n",
            "        0.6672859 ,  0.7154465 ,  0.16531944, -0.4559872 , -3.362742  ,\n",
            "        5.6156588 , -5.6564026 ,  5.470834  ], dtype=float32), 'agent_3': Array([ 5.9857440e-01,  6.2757015e-01,  2.1419946e-02,  8.8920426e-03,\n",
            "        7.7821451e-01, -4.4382992e-01, -2.9477000e-01, -3.9511364e-02,\n",
            "       -2.6933560e-01,  1.1934987e+00,  6.6728592e-01,  7.1544647e-01,\n",
            "        1.6531944e-01, -4.5598719e-01, -3.3627419e+00,  5.6156588e+00,\n",
            "       -7.6692562e+00,  9.4633570e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.05602507 -0.8204457   0.05211818 -0.8230836   0.05550146 -0.8197931\n",
            "  0.05531695 -0.8204139 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.9869156, dtype=float32), 'agent_0': Array(-5.9869156, dtype=float32), 'agent_1': Array(-5.9869156, dtype=float32), 'agent_2': Array(-5.9869156, dtype=float32), 'agent_3': Array(-5.9869156, dtype=float32)}\n",
            "step: 210\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.636032  ,  0.5867562 ,  0.01241725,  0.00509009,  0.8096525 ,\n",
            "       -0.5386375 ,  1.1005127 , -0.42045984, -0.10168178, -0.44006762,\n",
            "        0.8759022 ,  0.11005402,  1.1011481 , -0.3893693 , -0.39932713,\n",
            "        0.802855  , -0.23497948, -4.6208076 ], dtype=float32), 'agent_1': Array([ 0.636032  ,  0.5867562 ,  0.01241725,  0.00509009,  0.8096525 ,\n",
            "       -0.5386375 , -0.42045984, -0.56352884, -0.10168178, -0.44006762,\n",
            "        0.8759022 ,  0.11005402,  1.1011481 , -0.3893693 , -0.39932713,\n",
            "        0.802855  , -0.97872335, -2.8733945 ], dtype=float32), 'agent_2': Array([ 0.636032  ,  0.5867562 ,  0.01241725,  0.00509009,  0.8096525 ,\n",
            "       -0.5386375 , -0.42045984, -0.10168178, -0.5844673 , -0.44006762,\n",
            "        0.8759022 ,  0.11005402,  1.1011481 , -0.3893693 , -0.39932713,\n",
            "        0.802855  ,  0.2848119 , -3.15148   ], dtype=float32), 'agent_3': Array([ 0.636032  ,  0.5867562 ,  0.01241725,  0.00509009,  0.8096525 ,\n",
            "       -0.5386375 , -0.42045984, -0.10168178, -0.44006762,  1.147205  ,\n",
            "        0.8759022 ,  0.11005402,  1.1011481 , -0.3893693 , -0.39932713,\n",
            "        0.802855  , -1.5337235 , -2.4413273 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.77434874 -0.01854904  0.7727806  -0.01705708  0.774389   -0.01901455\n",
            "  0.77362275 -0.01672388]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5466548, dtype=float32), 'agent_0': Array(0.5466548, dtype=float32), 'agent_1': Array(0.5466548, dtype=float32), 'agent_2': Array(0.5466548, dtype=float32), 'agent_3': Array(0.5466548, dtype=float32)}\n",
            "step: 211\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.5440273e-01,  7.1820486e-01,  2.2083364e-02, -1.2943588e-02,\n",
            "        6.9536072e-01, -9.0871193e-02,  9.9588472e-01,  5.8222208e-03,\n",
            "        3.9424708e-01, -3.0774722e-02,  8.5663795e-01,  1.6994476e-01,\n",
            "       -6.6411495e-02, -3.8326973e-01, -3.4898853e-01, -9.5140800e+00,\n",
            "        1.2335358e+01, -3.0960100e+00], dtype=float32), 'agent_1': Array([ 6.5440273e-01,  7.1820486e-01,  2.2083364e-02, -1.2943588e-02,\n",
            "        6.9536072e-01, -9.0871193e-02,  5.8222208e-03, -7.1751446e-01,\n",
            "        3.9424708e-01, -3.0774722e-02,  8.5663795e-01,  1.6994476e-01,\n",
            "       -6.6411495e-02, -3.8326973e-01, -3.4898853e-01, -9.5140800e+00,\n",
            "        1.1841573e+01, -4.1408253e+00], dtype=float32), 'agent_2': Array([ 6.5440273e-01,  7.1820486e-01,  2.2083364e-02, -1.2943588e-02,\n",
            "        6.9536072e-01, -9.0871193e-02,  5.8222208e-03,  3.9424708e-01,\n",
            "       -7.2424084e-01, -3.0774722e-02,  8.5663795e-01,  1.6994476e-01,\n",
            "       -6.6411495e-02, -3.8326973e-01, -3.4898853e-01, -9.5140800e+00,\n",
            "        1.3072039e+01, -4.1995530e+00], dtype=float32), 'agent_3': Array([ 6.5440273e-01,  7.1820486e-01,  2.2083364e-02, -1.2943588e-02,\n",
            "        6.9536072e-01, -9.0871193e-02,  5.8222208e-03,  3.9424708e-01,\n",
            "       -3.0774722e-02,  1.1773633e+00,  8.5663795e-01,  1.6994476e-01,\n",
            "       -6.6411495e-02, -3.8326973e-01, -3.4898853e-01, -9.5140800e+00,\n",
            "        1.1541307e+01, -5.1188880e-01], dtype=float32)}\n",
            "ctrl action chosen: [0.23522508 1.6003221  0.23422009 1.6009034  0.23540235 1.5995896\n",
            " 0.23478675 1.6008695 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.64256144, dtype=float32), 'agent_0': Array(0.64256144, dtype=float32), 'agent_1': Array(0.64256144, dtype=float32), 'agent_2': Array(0.64256144, dtype=float32), 'agent_3': Array(0.64256144, dtype=float32)}\n",
            "step: 212\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.64004314,  0.77720714,  0.05271283, -0.04021642,  0.62574214,\n",
            "        0.19854552,  1.079441  ,  0.29113084,  0.5865966 ,  0.22469714,\n",
            "        0.8933544 ,  0.6196976 , -0.49512386,  0.82387537, -2.0725634 ,\n",
            "       -1.1567333 ,  3.1550405 ,  4.88336   ], dtype=float32), 'agent_1': Array([ 0.64004314,  0.77720714,  0.05271283, -0.04021642,  0.62574214,\n",
            "        0.19854552,  0.29113084, -0.59528553,  0.5865966 ,  0.22469714,\n",
            "        0.8933544 ,  0.6196976 , -0.49512386,  0.82387537, -2.0725634 ,\n",
            "       -1.1567333 ,  3.0279417 ,  5.519546  ], dtype=float32), 'agent_2': Array([ 0.64004314,  0.77720714,  0.05271283, -0.04021642,  0.62574214,\n",
            "        0.19854552,  0.29113084,  0.5865966 , -0.6342192 ,  0.22469714,\n",
            "        0.8933544 ,  0.6196976 , -0.49512386,  0.82387537, -2.0725634 ,\n",
            "       -1.1567333 , -1.0640277 ,  4.758838  ], dtype=float32), 'agent_3': Array([ 0.64004314,  0.77720714,  0.05271283, -0.04021642,  0.62574214,\n",
            "        0.19854552,  0.29113084,  0.5865966 ,  0.22469714,  1.262606  ,\n",
            "        0.8933544 ,  0.6196976 , -0.49512386,  0.82387537, -2.0725634 ,\n",
            "       -1.1567333 ,  2.312075  ,  0.46472806], dtype=float32)}\n",
            "ctrl action chosen: [-0.3820722  -0.8268641  -0.38315898 -0.8255868  -0.38447103 -0.82903063\n",
            " -0.37728468 -0.8358392 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.3317814, dtype=float32), 'agent_0': Array(-3.3317814, dtype=float32), 'agent_1': Array(-3.3317814, dtype=float32), 'agent_2': Array(-3.3317814, dtype=float32), 'agent_3': Array(-3.3317814, dtype=float32)}\n",
            "step: 213\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.59685624,  0.71283084,  0.05113859, -0.04840738,  0.69779205,\n",
            "        0.04080806,  0.9995499 ,  0.11369829,  0.24879777,  0.02802395,\n",
            "        0.982666  ,  0.28715134, -1.0104418 , -0.15686841,  0.19492492,\n",
            "        5.7699738 , -5.602442  , -3.2829564 ], dtype=float32), 'agent_1': Array([ 0.59685624,  0.71283084,  0.05113859, -0.04840738,  0.69779205,\n",
            "        0.04080806,  0.11369829, -0.71547997,  0.24879777,  0.02802395,\n",
            "        0.982666  ,  0.28715134, -1.0104418 , -0.15686841,  0.19492492,\n",
            "        5.7699738 , -5.6371126 , -3.6979806 ], dtype=float32), 'agent_2': Array([ 0.59685624,  0.71283084,  0.05113859, -0.04840738,  0.69779205,\n",
            "        0.04080806,  0.11369829,  0.24879777, -0.73829204,  0.02802395,\n",
            "        0.982666  ,  0.28715134, -1.0104418 , -0.15686841,  0.19492492,\n",
            "        5.7699738 , -9.551596  , -3.473413  ], dtype=float32), 'agent_3': Array([ 0.59685624,  0.71283084,  0.05113859, -0.04840738,  0.69779205,\n",
            "        0.04080806,  0.11369829,  0.24879777,  0.02802395,  1.0743303 ,\n",
            "        0.982666  ,  0.28715134, -1.0104418 , -0.15686841,  0.19492492,\n",
            "        5.7699738 , -5.7464724 , -4.945994  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5079265  -0.27856234 -0.50905687 -0.2790009  -0.50769955 -0.27681288\n",
            " -0.5084766  -0.28147507]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.27339113, dtype=float32), 'agent_0': Array(0.27339113, dtype=float32), 'agent_1': Array(0.27339113, dtype=float32), 'agent_2': Array(0.27339113, dtype=float32), 'agent_3': Array(0.27339113, dtype=float32)}\n",
            "step: 214\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5499438 ,  0.5743655 ,  0.04465794, -0.06378121,  0.8148877 ,\n",
            "       -0.34972075,  0.879158  , -0.29702774, -0.28709817, -0.3620289 ,\n",
            "        0.71349144,  0.32234192,  0.11296272,  0.1523716 ,  0.66523564,\n",
            "        7.65816   , -8.363542  , -3.6829925 ], dtype=float32), 'agent_1': Array([ 0.5499438 ,  0.5743655 ,  0.04465794, -0.06378121,  0.8148877 ,\n",
            "       -0.34972075, -0.29702774, -0.76943076, -0.28709817, -0.3620289 ,\n",
            "        0.71349144,  0.32234192,  0.11296272,  0.1523716 ,  0.66523564,\n",
            "        7.65816   , -9.507812  ,  0.24387653], dtype=float32), 'agent_2': Array([  0.5499438 ,   0.5743655 ,   0.04465794,  -0.06378121,\n",
            "         0.8148877 ,  -0.34972075,  -0.29702774,  -0.28709817,\n",
            "        -0.8191106 ,  -0.3620289 ,   0.71349144,   0.32234192,\n",
            "         0.11296272,   0.1523716 ,   0.66523564,   7.65816   ,\n",
            "       -10.735065  ,  -0.8262492 ], dtype=float32), 'agent_3': Array([ 0.5499438 ,  0.5743655 ,  0.04465794, -0.06378121,  0.8148877 ,\n",
            "       -0.34972075, -0.29702774, -0.28709817, -0.3620289 ,  0.85004675,\n",
            "        0.71349144,  0.32234192,  0.11296272,  0.1523716 ,  0.66523564,\n",
            "        7.65816   , -8.434309  , -5.6372476 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1599003   0.79356456 -1.1595839   0.7954849  -1.1588312   0.79437286\n",
            " -1.1616428   0.79121953]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2579694, dtype=float32), 'agent_0': Array(1.2579694, dtype=float32), 'agent_1': Array(1.2579694, dtype=float32), 'agent_2': Array(1.2579694, dtype=float32), 'agent_3': Array(1.2579694, dtype=float32)}\n",
            "step: 215\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5576141 ,  0.49718818,  0.0492    , -0.07848457,  0.86268383,\n",
            "       -0.54622066,  0.9399296 , -0.57329404, -0.5792781 , -0.55277574,\n",
            "        0.40254593,  0.45223236, -0.08903742, -0.7078257 , -1.4922543 ,\n",
            "       -0.32115912,  0.12864317,  4.4176097 ], dtype=float32), 'agent_1': Array([ 0.5576141 ,  0.49718818,  0.0492    , -0.07848457,  0.86268383,\n",
            "       -0.54622066, -0.57329404, -0.5094451 , -0.5792781 , -0.55277574,\n",
            "        0.40254593,  0.45223236, -0.08903742, -0.7078257 , -1.4922543 ,\n",
            "       -0.32115912, -0.10128357,  6.5247245 ], dtype=float32), 'agent_2': Array([ 0.5576141 ,  0.49718818,  0.0492    , -0.07848457,  0.86268383,\n",
            "       -0.54622066, -0.57329404, -0.5792781 , -0.5908463 , -0.55277574,\n",
            "        0.40254593,  0.45223236, -0.08903742, -0.7078257 , -1.4922543 ,\n",
            "       -0.32115912, -0.63434416,  7.1458426 ], dtype=float32), 'agent_3': Array([ 0.5576141 ,  0.49718818,  0.0492    , -0.07848457,  0.86268383,\n",
            "       -0.54622066, -0.57329404, -0.5792781 , -0.55277574,  0.821899  ,\n",
            "        0.40254593,  0.45223236, -0.08903742, -0.7078257 , -1.4922543 ,\n",
            "       -0.32115912,  0.39356634,  2.5790637 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.88817066 -0.6446302  -0.89184785 -0.64526105 -0.89250267 -0.6450259\n",
            " -0.8868545  -0.6462368 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.4756317, dtype=float32), 'agent_0': Array(-2.4756317, dtype=float32), 'agent_1': Array(-2.4756317, dtype=float32), 'agent_2': Array(-2.4756317, dtype=float32), 'agent_3': Array(-2.4756317, dtype=float32)}\n",
            "step: 216\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5429386 ,  0.507178  ,  0.04473595, -0.05744042,  0.8587606 ,\n",
            "       -0.5371151 ,  0.8426032 , -0.5405924 , -0.5476359 , -0.5276853 ,\n",
            "        0.19960403,  0.02412796, -0.45386553,  0.70187956,  1.3242565 ,\n",
            "       -0.16138029, -0.719018  , -4.1447043 ], dtype=float32), 'agent_1': Array([ 0.5429386 ,  0.507178  ,  0.04473595, -0.05744042,  0.8587606 ,\n",
            "       -0.5371151 , -0.5405924 , -0.5936175 , -0.5476359 , -0.5276853 ,\n",
            "        0.19960403,  0.02412796, -0.45386553,  0.70187956,  1.3242565 ,\n",
            "       -0.16138029,  0.35565728, -2.9407625 ], dtype=float32), 'agent_2': Array([ 0.5429386 ,  0.507178  ,  0.04473595, -0.05744042,  0.8587606 ,\n",
            "       -0.5371151 , -0.5405924 , -0.5476359 , -0.6010011 , -0.5276853 ,\n",
            "        0.19960403,  0.02412796, -0.45386553,  0.70187956,  1.3242565 ,\n",
            "       -0.16138029,  0.5963988 , -2.8322954 ], dtype=float32), 'agent_3': Array([ 0.5429386 ,  0.507178  ,  0.04473595, -0.05744042,  0.8587606 ,\n",
            "       -0.5371151 , -0.5405924 , -0.5476359 , -0.5276853 ,  0.66350627,\n",
            "        0.19960403,  0.02412796, -0.45386553,  0.70187956,  1.3242565 ,\n",
            "       -0.16138029, -0.1731864 , -4.8640227 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.38721335 -0.23572665 -0.38826776 -0.23541117 -0.38800177 -0.23560755\n",
            " -0.38893163 -0.23618777]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.172301, dtype=float32), 'agent_0': Array(-1.172301, dtype=float32), 'agent_1': Array(-1.172301, dtype=float32), 'agent_2': Array(-1.172301, dtype=float32), 'agent_3': Array(-1.172301, dtype=float32)}\n",
            "step: 217\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50501245,  0.51179796,  0.03639219, -0.03981933,  0.85741067,\n",
            "       -0.5495242 ,  0.71162015, -0.532903  , -0.51853645, -0.5403837 ,\n",
            "        0.28715134,  0.27303696, -1.0056615 ,  0.61270106,  0.66043365,\n",
            "       -0.06136845,  0.2297613 , -2.810084  ], dtype=float32), 'agent_1': Array([ 0.50501245,  0.51179796,  0.03639219, -0.03981933,  0.85741067,\n",
            "       -0.5495242 , -0.532903  , -0.69749504, -0.51853645, -0.5403837 ,\n",
            "        0.28715134,  0.27303696, -1.0056615 ,  0.61270106,  0.66043365,\n",
            "       -0.06136845, -0.05011543, -1.5978494 ], dtype=float32), 'agent_2': Array([ 0.50501245,  0.51179796,  0.03639219, -0.03981933,  0.85741067,\n",
            "       -0.5495242 , -0.532903  , -0.51853645, -0.6801652 , -0.5403837 ,\n",
            "        0.28715134,  0.27303696, -1.0056615 ,  0.61270106,  0.66043365,\n",
            "       -0.06136845,  0.15947051, -1.413295  ], dtype=float32), 'agent_3': Array([ 0.50501245,  0.51179796,  0.03639219, -0.03981933,  0.85741067,\n",
            "       -0.5495242 , -0.532903  , -0.51853645, -0.5403837 ,  0.5142458 ,\n",
            "        0.28715134,  0.27303696, -1.0056615 ,  0.61270106,  0.66043365,\n",
            "       -0.06136845, -0.3053534 , -2.7200608 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1616753  -0.06503872 -1.1622419  -0.06383467 -1.161608   -0.0646271\n",
            " -1.1636153  -0.06478584]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.81831324, dtype=float32), 'agent_0': Array(0.81831324, dtype=float32), 'agent_1': Array(0.81831324, dtype=float32), 'agent_2': Array(0.81831324, dtype=float32), 'agent_3': Array(0.81831324, dtype=float32)}\n",
            "step: 218\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49207324,  0.5107089 ,  0.01362729, -0.01501107,  0.85951465,\n",
            "       -0.5383669 ,  0.5334985 , -0.5588692 , -0.54052275, -0.5585872 ,\n",
            "        0.28691292,  0.29182434, -0.24362803,  0.2333142 ,  1.4565878 ,\n",
            "       -0.08487367,  0.3114673 , -3.96694   ], dtype=float32), 'agent_1': Array([ 0.49207324,  0.5107089 ,  0.01362729, -0.01501107,  0.85951465,\n",
            "       -0.5383669 , -0.5588692 , -0.73908395, -0.54052275, -0.5585872 ,\n",
            "        0.28691292,  0.29182434, -0.24362803,  0.2333142 ,  1.4565878 ,\n",
            "       -0.08487367, -0.10800355, -0.49177992], dtype=float32), 'agent_2': Array([ 0.49207324,  0.5107089 ,  0.01362729, -0.01501107,  0.85951465,\n",
            "       -0.5383669 , -0.5588692 , -0.54052275, -0.72982246, -0.5585872 ,\n",
            "        0.28691292,  0.29182434, -0.24362803,  0.2333142 ,  1.4565878 ,\n",
            "       -0.08487367, -0.51886165, -1.3877579 ], dtype=float32), 'agent_3': Array([ 0.49207324,  0.5107089 ,  0.01362729, -0.01501107,  0.85951465,\n",
            "       -0.5383669 , -0.5588692 , -0.54052275, -0.5585872 ,  0.50070083,\n",
            "        0.28691292,  0.29182434, -0.24362803,  0.2333142 ,  1.4565878 ,\n",
            "       -0.08487367,  0.06922615,  0.43392462], dtype=float32)}\n",
            "ctrl action chosen: [-0.5961583  1.4152855 -0.5961244  1.41919   -0.5968701  1.4167638\n",
            " -0.5953321  1.4210904]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.442038, dtype=float32), 'agent_0': Array(-1.442038, dtype=float32), 'agent_1': Array(-1.442038, dtype=float32), 'agent_2': Array(-1.442038, dtype=float32), 'agent_3': Array(-1.442038, dtype=float32)}\n",
            "step: 219\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4703516 ,  0.51644254,  0.01673337, -0.0384853 ,  0.8552929 ,\n",
            "       -0.5322776 ,  0.7243084 , -0.53320193, -0.55044055, -0.53196925,\n",
            "        0.23298264,  0.5781174 , -0.8268237 , -1.0717546 , -1.4962076 ,\n",
            "       -0.09466089, -0.30815995,  7.600169  ], dtype=float32), 'agent_1': Array([ 0.4703516 ,  0.51644254,  0.01673337, -0.0384853 ,  0.8552929 ,\n",
            "       -0.5322776 , -0.53320193, -0.46960124, -0.55044055, -0.53196925,\n",
            "        0.23298264,  0.5781174 , -0.8268237 , -1.0717546 , -1.4962076 ,\n",
            "       -0.09466089,  0.4199348 ,  4.4310503 ], dtype=float32), 'agent_2': Array([ 0.4703516 ,  0.51644254,  0.01673337, -0.0384853 ,  0.8552929 ,\n",
            "       -0.5322776 , -0.53320193, -0.55044055, -0.47319162, -0.53196925,\n",
            "        0.23298264,  0.5781174 , -0.8268237 , -1.0717546 , -1.4962076 ,\n",
            "       -0.09466089, -0.13207449,  5.167334  ], dtype=float32), 'agent_3': Array([ 0.4703516 ,  0.51644254,  0.01673337, -0.0384853 ,  0.8552929 ,\n",
            "       -0.5322776 , -0.53320193, -0.55044055, -0.53196925,  0.8299037 ,\n",
            "        0.23298264,  0.5781174 , -0.8268237 , -1.0717546 , -1.4962076 ,\n",
            "       -0.09466089,  0.24390748, 10.402107  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.41850486 -0.03650217 -0.41762692 -0.0364449  -0.4190283  -0.03601151\n",
            " -0.42057943 -0.03634009]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.4828558, dtype=float32), 'agent_0': Array(-3.4828558, dtype=float32), 'agent_1': Array(-3.4828558, dtype=float32), 'agent_2': Array(-3.4828558, dtype=float32), 'agent_3': Array(-3.4828558, dtype=float32)}\n",
            "step: 220\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4607465 ,  0.52171624,  0.00797752, -0.03928429,  0.8521768 ,\n",
            "       -0.53187656,  0.8263898 , -0.52725977, -0.5330076 , -0.5374677 ,\n",
            "        0.21967888,  0.329113  ,  1.0847628 , -0.5592807 , -0.30727404,\n",
            "       -0.1336045 ,  0.2323924 , -0.4517354 ], dtype=float32), 'agent_1': Array([ 0.4607465 ,  0.52171624,  0.00797752, -0.03928429,  0.8521768 ,\n",
            "       -0.53187656, -0.52725977, -0.502504  , -0.5330076 , -0.5374677 ,\n",
            "        0.21967888,  0.329113  ,  1.0847628 , -0.5592807 , -0.30727404,\n",
            "       -0.1336045 , -0.29425135,  0.14748734], dtype=float32), 'agent_2': Array([ 0.4607465 ,  0.52171624,  0.00797752, -0.03928429,  0.8521768 ,\n",
            "       -0.53187656, -0.52725977, -0.5330076 , -0.50509715, -0.5374677 ,\n",
            "        0.21967888,  0.329113  ,  1.0847628 , -0.5592807 , -0.30727404,\n",
            "       -0.1336045 ,  0.29874003,  0.13626704], dtype=float32), 'agent_3': Array([ 0.4607465 ,  0.52171624,  0.00797752, -0.03928429,  0.8521768 ,\n",
            "       -0.53187656, -0.52725977, -0.5330076 , -0.5374677 ,  1.0120482 ,\n",
            "        0.21967888,  0.329113  ,  1.0847628 , -0.5592807 , -0.30727404,\n",
            "       -0.1336045 , -0.41768494,  0.3149047 ], dtype=float32)}\n",
            "ctrl action chosen: [0.5857769 1.1762834 0.5807882 1.176719  0.5822535 1.1766518 0.5820844\n",
            " 1.17931  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9710672, dtype=float32), 'agent_0': Array(0.9710672, dtype=float32), 'agent_1': Array(0.9710672, dtype=float32), 'agent_2': Array(0.9710672, dtype=float32), 'agent_3': Array(0.9710672, dtype=float32)}\n",
            "step: 221\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50679827,  0.6326289 ,  0.03828121, -0.07676993,  0.76968926,\n",
            "       -0.18098782,  1.1266237 , -0.20306648, -0.1791026 , -0.21545666,\n",
            "        0.08993149,  0.66051483,  0.7741809 , -0.32013366, -1.579044  ,\n",
            "       -7.5084214 ,  9.354434  ,  7.718106  ], dtype=float32), 'agent_1': Array([ 0.50679827,  0.6326289 ,  0.03828121, -0.07676993,  0.76968926,\n",
            "       -0.18098782, -0.20306648, -0.48783672, -0.1791026 , -0.21545666,\n",
            "        0.08993149,  0.66051483,  0.7741809 , -0.32013366, -1.579044  ,\n",
            "       -7.5084214 ,  9.066378  , -0.37332714], dtype=float32), 'agent_2': Array([ 0.50679827,  0.6326289 ,  0.03828121, -0.07676993,  0.76968926,\n",
            "       -0.18098782, -0.20306648, -0.1791026 , -0.48613518, -0.21545666,\n",
            "        0.08993149,  0.66051483,  0.7741809 , -0.32013366, -1.579044  ,\n",
            "       -7.5084214 ,  9.419587  , -0.42738277], dtype=float32), 'agent_3': Array([ 0.50679827,  0.6326289 ,  0.03828121, -0.07676993,  0.76968926,\n",
            "       -0.18098782, -0.20306648, -0.1791026 , -0.21545666,  1.2622416 ,\n",
            "        0.08993149,  0.66051483,  0.7741809 , -0.32013366, -1.579044  ,\n",
            "       -7.5084214 ,  9.056624  ,  4.0936265 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.02606437 -0.410438   -0.02980197 -0.41180417 -0.02994335 -0.41206077\n",
            " -0.02718299 -0.41315088]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3238401, dtype=float32), 'agent_0': Array(-2.3238401, dtype=float32), 'agent_1': Array(-2.3238401, dtype=float32), 'agent_2': Array(-2.3238401, dtype=float32), 'agent_3': Array(-2.3238401, dtype=float32)}\n",
            "step: 222\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5496118 ,  0.6859336 ,  0.04159021, -0.06476802,  0.7235817 ,\n",
            "        0.01276739,  1.186849  , -0.01630907,  0.00999577, -0.04644023,\n",
            "        0.18491745,  0.1660347 ,  0.46069622, -0.0818847 ,  0.40811327,\n",
            "       -1.3322474 ,  1.8121563 ,  0.37390772], dtype=float32), 'agent_1': Array([ 0.5496118 ,  0.6859336 ,  0.04159021, -0.06476802,  0.7235817 ,\n",
            "        0.01276739, -0.01630907, -0.6619046 ,  0.00999577, -0.04644023,\n",
            "        0.18491745,  0.1660347 ,  0.46069622, -0.0818847 ,  0.40811327,\n",
            "       -1.3322474 ,  1.9641899 , -4.563918  ], dtype=float32), 'agent_2': Array([ 0.5496118 ,  0.6859336 ,  0.04159021, -0.06476802,  0.7235817 ,\n",
            "        0.01276739, -0.01630907,  0.00999577, -0.67878425, -0.04644023,\n",
            "        0.18491745,  0.1660347 ,  0.46069622, -0.0818847 ,  0.40811327,\n",
            "       -1.3322474 ,  1.8215541 , -5.2790546 ], dtype=float32), 'agent_3': Array([ 0.5496118 ,  0.6859336 ,  0.04159021, -0.06476802,  0.7235817 ,\n",
            "        0.01276739, -0.01630907,  0.00999577, -0.04644023,  1.183904  ,\n",
            "        0.18491745,  0.1660347 ,  0.46069622, -0.0818847 ,  0.40811327,\n",
            "       -1.3322474 ,  1.6440896 , -1.0923702 ], dtype=float32)}\n",
            "ctrl action chosen: [1.0077099  0.69030064 0.99998105 0.6865334  1.001073   0.6840849\n",
            " 1.004851   0.6892593 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7590644, dtype=float32), 'agent_0': Array(0.7590644, dtype=float32), 'agent_1': Array(0.7590644, dtype=float32), 'agent_2': Array(0.7590644, dtype=float32), 'agent_3': Array(0.7590644, dtype=float32)}\n",
            "step: 223\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56217206,  0.8287477 ,  0.08009364, -0.06967629,  0.5494612 ,\n",
            "        0.56979907,  1.258     ,  0.5538096 ,  0.57084537,  0.51266867,\n",
            "        0.09112358,  0.37698746,  0.06728172,  0.3974406 , -0.91529626,\n",
            "       -6.2438955 ,  7.1978693 , -0.9817236 ], dtype=float32), 'agent_1': Array([ 0.56217206,  0.8287477 ,  0.08009364, -0.06967629,  0.5494612 ,\n",
            "        0.56979907,  0.5538096 , -0.54068184,  0.57084537,  0.51266867,\n",
            "        0.09112358,  0.37698746,  0.06728172,  0.3974406 , -0.91529626,\n",
            "       -6.2438955 ,  8.30615   ,  5.0731335 ], dtype=float32), 'agent_2': Array([ 0.56217206,  0.8287477 ,  0.08009364, -0.06967629,  0.5494612 ,\n",
            "        0.56979907,  0.5538096 ,  0.57084537, -0.6445745 ,  0.51266867,\n",
            "        0.09112358,  0.37698746,  0.06728172,  0.3974406 , -0.91529626,\n",
            "       -6.2438955 ,  7.2563963 ,  3.2267425 ], dtype=float32), 'agent_3': Array([ 0.56217206,  0.8287477 ,  0.08009364, -0.06967629,  0.5494612 ,\n",
            "        0.56979907,  0.5538096 ,  0.57084537,  0.51266867,  1.2550812 ,\n",
            "        0.09112358,  0.37698746,  0.06728172,  0.3974406 , -0.91529626,\n",
            "       -6.2438955 ,  8.692075  , -0.4449362 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.17276597  1.0388746  -0.17139612  1.0405561  -0.1704705   1.0394301\n",
            " -0.1741265   1.039292  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8472712, dtype=float32), 'agent_0': Array(-1.8472712, dtype=float32), 'agent_1': Array(-1.8472712, dtype=float32), 'agent_2': Array(-1.8472712, dtype=float32), 'agent_3': Array(-1.8472712, dtype=float32)}\n",
            "step: 224\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53776395,  0.81333   ,  0.10195152, -0.07447174,  0.5679386 ,\n",
            "        0.5110448 ,  1.2626216 ,  0.5181157 ,  0.50934476,  0.5230891 ,\n",
            "        0.32491684,  0.30002594, -0.7012129 ,  0.18335536, -0.2406976 ,\n",
            "        1.4249398 , -2.2466226 , -0.5585681 ], dtype=float32), 'agent_1': Array([ 0.53776395,  0.81333   ,  0.10195152, -0.07447174,  0.5679386 ,\n",
            "        0.5110448 ,  0.5181157 , -0.4736957 ,  0.50934476,  0.5230891 ,\n",
            "        0.32491684,  0.30002594, -0.7012129 ,  0.18335536, -0.2406976 ,\n",
            "        1.4249398 , -2.0243134 ,  0.2482327 ], dtype=float32), 'agent_2': Array([ 0.53776395,  0.81333   ,  0.10195152, -0.07447174,  0.5679386 ,\n",
            "        0.5110448 ,  0.5181157 ,  0.50934476, -0.461439  ,  0.5230891 ,\n",
            "        0.32491684,  0.30002594, -0.7012129 ,  0.18335536, -0.2406976 ,\n",
            "        1.4249398 , -2.39543   ,  0.16138127], dtype=float32), 'agent_3': Array([ 0.53776395,  0.81333   ,  0.10195152, -0.07447174,  0.5679386 ,\n",
            "        0.5110448 ,  0.5181157 ,  0.50934476,  0.5230891 ,  1.2598441 ,\n",
            "        0.32491684,  0.30002594, -0.7012129 ,  0.18335536, -0.2406976 ,\n",
            "        1.4249398 , -0.8333452 , -0.55901694], dtype=float32)}\n",
            "ctrl action chosen: [1.1268975  0.00599012 1.1272764  0.00828015 1.1276743  0.00409018\n",
            " 1.1280923  0.00510329]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.99886274, dtype=float32), 'agent_0': Array(-0.99886274, dtype=float32), 'agent_1': Array(-0.99886274, dtype=float32), 'agent_2': Array(-0.99886274, dtype=float32), 'agent_3': Array(-0.99886274, dtype=float32)}\n",
            "step: 225\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50600827,  0.81949896,  0.09983931, -0.07179418,  0.5597315 ,\n",
            "        0.54237914,  1.1448447 ,  0.5482024 ,  0.5460346 ,  0.56565154,\n",
            "        0.17023087,  0.28305054, -0.64496994,  0.3060971 , -0.26766616,\n",
            "       -0.10272777,  0.69516313, -1.6446943 ], dtype=float32), 'agent_1': Array([ 0.50600827,  0.81949896,  0.09983931, -0.07179418,  0.5597315 ,\n",
            "        0.54237914,  0.5482024 , -0.5094153 ,  0.5460346 ,  0.56565154,\n",
            "        0.17023087,  0.28305054, -0.64496994,  0.3060971 , -0.26766616,\n",
            "       -0.10272777,  0.4884021 ,  0.8977187 ], dtype=float32), 'agent_2': Array([ 0.50600827,  0.81949896,  0.09983931, -0.07179418,  0.5597315 ,\n",
            "        0.54237914,  0.5482024 ,  0.5460346 , -0.5078977 ,  0.56565154,\n",
            "        0.17023087,  0.28305054, -0.64496994,  0.3060971 , -0.26766616,\n",
            "       -0.10272777,  0.79884386, -0.2888453 ], dtype=float32), 'agent_3': Array([ 0.50600827,  0.81949896,  0.09983931, -0.07179418,  0.5597315 ,\n",
            "        0.54237914,  0.5482024 ,  0.5460346 ,  0.56565154,  1.1773933 ,\n",
            "        0.17023087,  0.28305054, -0.64496994,  0.3060971 , -0.26766616,\n",
            "       -0.10272777,  0.1463163 , -0.72342134], dtype=float32)}\n",
            "ctrl action chosen: [ 0.01396212 -0.7226438   0.01591909 -0.71534044  0.018492   -0.7233513\n",
            "  0.01342405 -0.7203081 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.2837305, dtype=float32), 'agent_0': Array(-1.2837305, dtype=float32), 'agent_1': Array(-1.2837305, dtype=float32), 'agent_2': Array(-1.2837305, dtype=float32), 'agent_3': Array(-1.2837305, dtype=float32)}\n",
            "step: 226\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50816035,  0.81457114,  0.06481981, -0.04568712,  0.5746172 ,\n",
            "        0.5243991 ,  0.8836245 ,  0.4912503 ,  0.52427864,  0.509677  ,\n",
            "       -0.01454353, -0.40550232,  0.26495457, -1.0247024 ,  2.7969882 ,\n",
            "        0.45090285, -0.3502947 , -7.2613206 ], dtype=float32), 'agent_1': Array([ 0.50816035,  0.81457114,  0.06481981, -0.04568712,  0.5746172 ,\n",
            "        0.5243991 ,  0.4912503 , -0.6447925 ,  0.52427864,  0.509677  ,\n",
            "       -0.01454353, -0.40550232,  0.26495457, -1.0247024 ,  2.7969882 ,\n",
            "        0.45090285, -1.6990325 , -4.409755  ], dtype=float32), 'agent_2': Array([ 0.50816035,  0.81457114,  0.06481981, -0.04568712,  0.5746172 ,\n",
            "        0.5243991 ,  0.4912503 ,  0.52427864, -0.6567436 ,  0.509677  ,\n",
            "       -0.01454353, -0.40550232,  0.26495457, -1.0247024 ,  2.7969882 ,\n",
            "        0.45090285, -0.4032588 , -4.7486377 ], dtype=float32), 'agent_3': Array([ 0.50816035,  0.81457114,  0.06481981, -0.04568712,  0.5746172 ,\n",
            "        0.5243991 ,  0.4912503 ,  0.52427864,  0.509677  ,  0.9104292 ,\n",
            "       -0.01454353, -0.40550232,  0.26495457, -1.0247024 ,  2.7969882 ,\n",
            "        0.45090285, -1.1835122 , -8.114251  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.8962325   0.30594337 -1.8993728   0.31074283 -1.8968683   0.3052867\n",
            " -1.8961997   0.3060377 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.01234376, dtype=float32), 'agent_0': Array(-0.01234376, dtype=float32), 'agent_1': Array(-0.01234376, dtype=float32), 'agent_2': Array(-0.01234376, dtype=float32), 'agent_3': Array(-0.01234376, dtype=float32)}\n",
            "step: 227\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5093105 ,   0.6463887 ,   0.03490444,  -0.03182336,\n",
            "         0.7615449 ,  -0.06290945,   0.7519817 ,  -0.1720923 ,\n",
            "        -0.0655295 ,  -0.13906701,  -0.03995895,  -0.13685226,\n",
            "        -0.1647234 ,   0.41399288,   0.7467312 ,  12.612073  ,\n",
            "       -15.064408  ,  -1.0396202 ], dtype=float32), 'agent_1': Array([  0.5093105 ,   0.6463887 ,   0.03490444,  -0.03182336,\n",
            "         0.7615449 ,  -0.06290945,  -0.1720923 ,  -0.65429205,\n",
            "        -0.0655295 ,  -0.13906701,  -0.03995895,  -0.13685226,\n",
            "        -0.1647234 ,   0.41399288,   0.7467312 ,  12.612073  ,\n",
            "       -16.426414  ,   0.8020282 ], dtype=float32), 'agent_2': Array([  0.5093105 ,   0.6463887 ,   0.03490444,  -0.03182336,\n",
            "         0.7615449 ,  -0.06290945,  -0.1720923 ,  -0.0655295 ,\n",
            "        -0.663352  ,  -0.13906701,  -0.03995895,  -0.13685226,\n",
            "        -0.1647234 ,   0.41399288,   0.7467312 ,  12.612073  ,\n",
            "       -15.337589  ,   1.284799  ], dtype=float32), 'agent_3': Array([  0.5093105 ,   0.6463887 ,   0.03490444,  -0.03182336,\n",
            "         0.7615449 ,  -0.06290945,  -0.1720923 ,  -0.0655295 ,\n",
            "        -0.13906701,   0.75904256,  -0.03995895,  -0.13685226,\n",
            "        -0.1647234 ,   0.41399288,   0.7467312 ,  12.612073  ,\n",
            "       -16.369793  ,  -1.2457108 ], dtype=float32)}\n",
            "ctrl action chosen: [1.5672635  0.3739982  1.5676693  0.37495    1.5685551  0.37430343\n",
            " 1.567011   0.3739845 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.414418, dtype=float32), 'agent_0': Array(-6.414418, dtype=float32), 'agent_1': Array(-6.414418, dtype=float32), 'agent_2': Array(-6.414418, dtype=float32), 'agent_3': Array(-6.414418, dtype=float32)}\n",
            "step: 228\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.86757666e-01,  7.24886298e-01,  3.17673646e-02, -1.09317731e-02,\n",
            "        6.88048959e-01,  2.17938468e-01,  7.69754589e-01,  4.94448692e-02,\n",
            "        1.94273859e-01,  7.70482644e-02, -7.59124756e-02, -1.21974945e-01,\n",
            "       -6.71398640e-01,  3.06900591e-01,  2.73715764e-01, -9.41725731e+00,\n",
            "        1.23998671e+01,  1.82496607e+00], dtype=float32), 'agent_1': Array([ 4.86757666e-01,  7.24886298e-01,  3.17673646e-02, -1.09317731e-02,\n",
            "        6.88048959e-01,  2.17938468e-01,  4.94448692e-02, -5.66148460e-01,\n",
            "        1.94273859e-01,  7.70482644e-02, -7.59124756e-02, -1.21974945e-01,\n",
            "       -6.71398640e-01,  3.06900591e-01,  2.73715764e-01, -9.41725731e+00,\n",
            "        1.13959122e+01,  2.81774902e+00], dtype=float32), 'agent_2': Array([ 4.86757666e-01,  7.24886298e-01,  3.17673646e-02, -1.09317731e-02,\n",
            "        6.88048959e-01,  2.17938468e-01,  4.94448692e-02,  1.94273859e-01,\n",
            "       -5.59279919e-01,  7.70482644e-02, -7.59124756e-02, -1.21974945e-01,\n",
            "       -6.71398640e-01,  3.06900591e-01,  2.73715764e-01, -9.41725731e+00,\n",
            "        1.20186710e+01,  3.11212635e+00], dtype=float32), 'agent_3': Array([ 4.86757666e-01,  7.24886298e-01,  3.17673646e-02, -1.09317731e-02,\n",
            "        6.88048959e-01,  2.17938468e-01,  4.94448692e-02,  1.94273859e-01,\n",
            "        7.70482644e-02,  7.68586755e-01, -7.59124756e-02, -1.21974945e-01,\n",
            "       -6.71398640e-01,  3.06900591e-01,  2.73715764e-01, -9.41725731e+00,\n",
            "        1.12062016e+01,  1.59522963e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.4129064  -0.19418138 -1.4120376  -0.19473067 -1.4124603  -0.1961329\n",
            " -1.4128692  -0.19447549]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.2515144, dtype=float32), 'agent_0': Array(-4.2515144, dtype=float32), 'agent_1': Array(-4.2515144, dtype=float32), 'agent_2': Array(-4.2515144, dtype=float32), 'agent_3': Array(-4.2515144, dtype=float32)}\n",
            "step: 229\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.51416582e-01,  6.35358751e-01,  2.36428007e-02,  4.68589948e-04,\n",
            "        7.71854937e-01, -4.65634838e-02,  7.85210967e-01, -2.62432158e-01,\n",
            "       -8.74866843e-02, -2.33669385e-01,  1.44481659e-02, -2.78472900e-01,\n",
            "       -5.37687540e-01, -1.16077356e-01,  4.64960605e-01,  9.39603710e+00,\n",
            "       -1.14959297e+01, -3.74574840e-01], dtype=float32), 'agent_1': Array([ 4.51416582e-01,  6.35358751e-01,  2.36428007e-02,  4.68589948e-04,\n",
            "        7.71854937e-01, -4.65634838e-02, -2.62432158e-01, -5.15272379e-01,\n",
            "       -8.74866843e-02, -2.33669385e-01,  1.44481659e-02, -2.78472900e-01,\n",
            "       -5.37687540e-01, -1.16077356e-01,  4.64960605e-01,  9.39603710e+00,\n",
            "       -1.23744373e+01,  7.75135875e-01], dtype=float32), 'agent_2': Array([ 4.51416582e-01,  6.35358751e-01,  2.36428007e-02,  4.68589948e-04,\n",
            "        7.71854937e-01, -4.65634838e-02, -2.62432158e-01, -8.74866843e-02,\n",
            "       -5.16179085e-01, -2.33669385e-01,  1.44481659e-02, -2.78472900e-01,\n",
            "       -5.37687540e-01, -1.16077356e-01,  4.64960605e-01,  9.39603710e+00,\n",
            "       -1.18219032e+01, -1.32254839e-01], dtype=float32), 'agent_3': Array([ 4.51416582e-01,  6.35358751e-01,  2.36428007e-02,  4.68589948e-04,\n",
            "        7.71854937e-01, -4.65634838e-02, -2.62432158e-01, -8.74866843e-02,\n",
            "       -2.33669385e-01,  7.34921575e-01,  1.44481659e-02, -2.78472900e-01,\n",
            "       -5.37687540e-01, -1.16077356e-01,  4.64960605e-01,  9.39603710e+00,\n",
            "       -1.22130461e+01, -1.50750542e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.07340988  0.07895175 -0.07387778  0.07969469 -0.07416774  0.07859568\n",
            " -0.07485325  0.07852822]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.120544, dtype=float32), 'agent_0': Array(-3.120544, dtype=float32), 'agent_1': Array(-3.120544, dtype=float32), 'agent_2': Array(-3.120544, dtype=float32), 'agent_3': Array(-3.120544, dtype=float32)}\n",
            "step: 230\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.3087697e-01,  5.4809749e-01,  1.9195719e-02,  1.3522111e-03,\n",
            "        8.3619314e-01, -3.4429789e-01,  7.9623044e-01, -5.5916023e-01,\n",
            "       -3.7258986e-01, -5.5020970e-01,  1.0600090e-01, -1.7518997e-01,\n",
            "       -4.2324662e-01,  2.0462291e-01,  3.2755533e-01,  7.1070373e-01,\n",
            "       -1.9453691e+00, -5.0757378e-01], dtype=float32), 'agent_1': Array([ 0.43087697,  0.5480975 ,  0.01919572,  0.00135221,  0.83619314,\n",
            "       -0.3442979 , -0.55916023, -0.51765597, -0.37258986, -0.5502097 ,\n",
            "        0.1060009 , -0.17518997, -0.42324662,  0.20462291,  0.32755533,\n",
            "        0.71070373, -0.28991345, -0.67389786], dtype=float32), 'agent_2': Array([ 4.3087697e-01,  5.4809749e-01,  1.9195719e-02,  1.3522111e-03,\n",
            "        8.3619314e-01, -3.4429789e-01, -5.5916023e-01, -3.7258986e-01,\n",
            "       -5.2131784e-01, -5.5020970e-01,  1.0600090e-01, -1.7518997e-01,\n",
            "       -4.2324662e-01,  2.0462291e-01,  3.2755533e-01,  7.1070373e-01,\n",
            "       -1.4921895e+00, -4.2495754e-01], dtype=float32), 'agent_3': Array([ 4.3087697e-01,  5.4809749e-01,  1.9195719e-02,  1.3522111e-03,\n",
            "        8.3619314e-01, -3.4429789e-01, -5.5916023e-01, -3.7258986e-01,\n",
            "       -5.5020970e-01,  6.7364866e-01,  1.0600090e-01, -1.7518997e-01,\n",
            "       -4.2324662e-01,  2.0462291e-01,  3.2755533e-01,  7.1070373e-01,\n",
            "       -1.1173906e+00, -1.7005342e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.4983395  -0.4135083   1.4980564  -0.41625783  1.4961227  -0.4152597\n",
            "  1.4976945  -0.41755223]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1219337, dtype=float32), 'agent_0': Array(1.1219337, dtype=float32), 'agent_1': Array(1.1219337, dtype=float32), 'agent_2': Array(1.1219337, dtype=float32), 'agent_3': Array(1.1219337, dtype=float32)}\n",
            "step: 231\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.0889579e-01,  7.3155648e-01, -3.5806382e-03,  2.6365800e-02,\n",
            "        6.8126154e-01,  2.1532448e-01,  6.1399639e-01,  2.0434616e-02,\n",
            "        1.9988683e-01,  9.2428429e-03,  1.8277168e-01, -2.6884079e-01,\n",
            "       -3.7816167e-01, -3.4797075e-01,  1.5162399e+00, -1.3087650e+01,\n",
            "        1.5735709e+01, -4.5997334e+00], dtype=float32), 'agent_1': Array([ 4.0889579e-01,  7.3155648e-01, -3.5806382e-03,  2.6365800e-02,\n",
            "        6.8126154e-01,  2.1532448e-01,  2.0434616e-02, -7.1306813e-01,\n",
            "        1.9988683e-01,  9.2428429e-03,  1.8277168e-01, -2.6884079e-01,\n",
            "       -3.7816167e-01, -3.4797075e-01,  1.5162399e+00, -1.3087650e+01,\n",
            "        1.6147827e+01, -5.4563155e+00], dtype=float32), 'agent_2': Array([ 4.0889579e-01,  7.3155648e-01, -3.5806382e-03,  2.6365800e-02,\n",
            "        6.8126154e-01,  2.1532448e-01,  2.0434616e-02,  1.9988683e-01,\n",
            "       -6.6887730e-01,  9.2428429e-03,  1.8277168e-01, -2.6884079e-01,\n",
            "       -3.7816167e-01, -3.4797075e-01,  1.5162399e+00, -1.3087650e+01,\n",
            "        1.6050354e+01, -3.4541321e+00], dtype=float32), 'agent_3': Array([ 4.0889579e-01,  7.3155648e-01, -3.5806382e-03,  2.6365800e-02,\n",
            "        6.8126154e-01,  2.1532448e-01,  2.0434616e-02,  1.9988683e-01,\n",
            "        9.2428429e-03,  4.9371457e-01,  1.8277168e-01, -2.6884079e-01,\n",
            "       -3.7816167e-01, -3.4797075e-01,  1.5162399e+00, -1.3087650e+01,\n",
            "        1.5840288e+01, -2.0815105e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.2075028   1.588929   -0.20893373  1.5891297  -0.2067551   1.5894626\n",
            " -0.20679894  1.5904391 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.706399, dtype=float32), 'agent_0': Array(-3.706399, dtype=float32), 'agent_1': Array(-3.706399, dtype=float32), 'agent_2': Array(-3.706399, dtype=float32), 'agent_3': Array(-3.706399, dtype=float32)}\n",
            "step: 232\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 3.9861241e-01,  7.7833873e-01,  1.3859570e-02,  1.0284446e-03,\n",
            "        6.2769079e-01,  4.0172002e-01,  7.3770893e-01,  2.2393529e-01,\n",
            "        4.0593547e-01,  2.0967771e-01, -1.3685226e-02,  2.0246506e-01,\n",
            "       -1.6828179e-01,  2.4802299e-01, -2.1380377e+00,  9.0665184e-02,\n",
            "        3.0999720e-02,  4.9965353e+00], dtype=float32), 'agent_1': Array([ 3.9861241e-01,  7.7833873e-01,  1.3859570e-02,  1.0284446e-03,\n",
            "        6.2769079e-01,  4.0172002e-01,  2.2393529e-01, -5.3022146e-01,\n",
            "        4.0593547e-01,  2.0967771e-01, -1.3685226e-02,  2.0246506e-01,\n",
            "       -1.6828179e-01,  2.4802299e-01, -2.1380377e+00,  9.0665184e-02,\n",
            "        4.5060316e-01,  7.2325554e+00], dtype=float32), 'agent_2': Array([ 3.9861241e-01,  7.7833873e-01,  1.3859570e-02,  1.0284446e-03,\n",
            "        6.2769079e-01,  4.0172002e-01,  2.2393529e-01,  4.0593547e-01,\n",
            "       -4.7065699e-01,  2.0967771e-01, -1.3685226e-02,  2.0246506e-01,\n",
            "       -1.6828179e-01,  2.4802299e-01, -2.1380377e+00,  9.0665184e-02,\n",
            "       -3.3978540e-02,  3.2513714e+00], dtype=float32), 'agent_3': Array([ 3.9861241e-01,  7.7833873e-01,  1.3859570e-02,  1.0284446e-03,\n",
            "        6.2769079e-01,  4.0172002e-01,  2.2393529e-01,  4.0593547e-01,\n",
            "        2.0967771e-01,  7.0213753e-01, -1.3685226e-02,  2.0246506e-01,\n",
            "       -1.6828179e-01,  2.4802299e-01, -2.1380377e+00,  9.0665184e-02,\n",
            "        4.6348557e-01,  5.4040599e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.5260659  -1.2396033  -0.52789426 -1.2392731  -0.5248197  -1.2428982\n",
            " -0.5268727  -1.2409627 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.088592, dtype=float32), 'agent_0': Array(-4.088592, dtype=float32), 'agent_1': Array(-4.088592, dtype=float32), 'agent_2': Array(-4.088592, dtype=float32), 'agent_3': Array(-4.088592, dtype=float32)}\n",
            "step: 233\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 3.9982224e-01,  6.8423659e-01, -1.6164202e-02,  5.6773173e-03,\n",
            "        7.2905892e-01,  7.9032443e-02,  4.9246782e-01, -9.3991935e-02,\n",
            "        7.0193052e-02, -1.2450223e-01,  2.4576187e-01, -5.5084229e-01,\n",
            "        1.0933280e-01, -4.3040577e-01,  1.6714483e+00,  7.4045968e+00,\n",
            "       -8.9531298e+00, -6.1166430e+00], dtype=float32), 'agent_1': Array([ 3.9982224e-01,  6.8423659e-01, -1.6164202e-02,  5.6773173e-03,\n",
            "        7.2905892e-01,  7.9032443e-02, -9.3991935e-02, -6.8693626e-01,\n",
            "        7.0193052e-02, -1.2450223e-01,  2.4576187e-01, -5.5084229e-01,\n",
            "        1.0933280e-01, -4.3040577e-01,  1.6714483e+00,  7.4045968e+00,\n",
            "       -8.5943193e+00, -5.8268189e+00], dtype=float32), 'agent_2': Array([ 3.9982224e-01,  6.8423659e-01, -1.6164202e-02,  5.6773173e-03,\n",
            "        7.2905892e-01,  7.9032443e-02, -9.3991935e-02,  7.0193052e-02,\n",
            "       -7.3959130e-01, -1.2450223e-01,  2.4576187e-01, -5.5084229e-01,\n",
            "        1.0933280e-01, -4.3040577e-01,  1.6714483e+00,  7.4045968e+00,\n",
            "       -9.0594110e+00, -7.4494848e+00], dtype=float32), 'agent_3': Array([ 3.9982224e-01,  6.8423659e-01, -1.6164202e-02,  5.6773173e-03,\n",
            "        7.2905892e-01,  7.9032443e-02, -9.3991935e-02,  7.0193052e-02,\n",
            "       -1.2450223e-01,  4.9473560e-01,  2.4576187e-01, -5.5084229e-01,\n",
            "        1.0933280e-01, -4.3040577e-01,  1.6714483e+00,  7.4045968e+00,\n",
            "       -8.9296207e+00, -5.1149774e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9153047  -0.2808038   0.91515046 -0.28059703  0.9159874  -0.28341678\n",
            "  0.91505724 -0.28093493]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.4685056, dtype=float32), 'agent_0': Array(-2.4685056, dtype=float32), 'agent_1': Array(-2.4685056, dtype=float32), 'agent_2': Array(-2.4685056, dtype=float32), 'agent_3': Array(-2.4685056, dtype=float32)}\n",
            "step: 234\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.3290275e-01,  7.8273469e-01, -2.3365844e-02, -1.0948852e-03,\n",
            "        6.2191594e-01,  4.2801297e-01,  4.9486396e-01,  2.4133587e-01,\n",
            "        4.3604803e-01,  2.3655804e-01,  4.1446686e-01, -2.4623871e-01,\n",
            "        1.6100943e+00, -4.7763902e-01,  5.8805674e-01, -9.6264448e+00,\n",
            "        1.1997475e+01, -5.4336107e-01], dtype=float32), 'agent_1': Array([ 4.3290275e-01,  7.8273469e-01, -2.3365844e-02, -1.0948852e-03,\n",
            "        6.2191594e-01,  4.2801297e-01,  2.4133587e-01, -7.6228482e-01,\n",
            "        4.3604803e-01,  2.3655804e-01,  4.1446686e-01, -2.4623871e-01,\n",
            "        1.6100943e+00, -4.7763902e-01,  5.8805674e-01, -9.6264448e+00,\n",
            "        1.1101938e+01,  4.1388458e-01], dtype=float32), 'agent_2': Array([ 4.3290275e-01,  7.8273469e-01, -2.3365844e-02, -1.0948852e-03,\n",
            "        6.2191594e-01,  4.2801297e-01,  2.4133587e-01,  4.3604803e-01,\n",
            "       -8.5953677e-01,  2.3655804e-01,  4.1446686e-01, -2.4623871e-01,\n",
            "        1.6100943e+00, -4.7763902e-01,  5.8805674e-01, -9.6264448e+00,\n",
            "        1.2991389e+01,  5.3429898e-02], dtype=float32), 'agent_3': Array([ 4.3290275e-01,  7.8273469e-01, -2.3365844e-02, -1.0948852e-03,\n",
            "        6.2191594e-01,  4.2801297e-01,  2.4133587e-01,  4.3604803e-01,\n",
            "        2.3655804e-01,  5.0076586e-01,  4.1446686e-01, -2.4623871e-01,\n",
            "        1.6100943e+00, -4.7763902e-01,  5.8805674e-01, -9.6264448e+00,\n",
            "        1.2349518e+01, -5.0734586e-01], dtype=float32)}\n",
            "ctrl action chosen: [-1.1110868   0.9643837  -1.1084738   0.9653087  -1.1101332   0.9634848\n",
            " -1.1113316   0.96399933]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.4634565, dtype=float32), 'agent_0': Array(-0.4634565, dtype=float32), 'agent_1': Array(-0.4634565, dtype=float32), 'agent_2': Array(-0.4634565, dtype=float32), 'agent_3': Array(-0.4634565, dtype=float32)}\n",
            "step: 235\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.02706826e-01,  6.87187314e-01, -1.07203396e-02, -1.95411779e-02,\n",
            "        7.26138294e-01,  1.02787465e-01,  7.69011259e-01, -1.03884660e-01,\n",
            "        1.63636014e-01, -7.92120546e-02,  4.23431396e-01, -1.01947784e-01,\n",
            "        1.01317167e+00,  5.65966815e-02, -1.66760623e+00,  1.00708666e+01,\n",
            "       -1.24608755e+01,  8.87047100e+00], dtype=float32), 'agent_1': Array([ 5.02706826e-01,  6.87187314e-01, -1.07203396e-02, -1.95411779e-02,\n",
            "        7.26138294e-01,  1.02787465e-01, -1.03884660e-01, -4.80728388e-01,\n",
            "        1.63636014e-01, -7.92120546e-02,  4.23431396e-01, -1.01947784e-01,\n",
            "        1.01317167e+00,  5.65966815e-02, -1.66760623e+00,  1.00708666e+01,\n",
            "       -1.25993576e+01,  4.31206751e+00], dtype=float32), 'agent_2': Array([ 5.02706826e-01,  6.87187314e-01, -1.07203396e-02, -1.95411779e-02,\n",
            "        7.26138294e-01,  1.02787465e-01, -1.03884660e-01,  1.63636014e-01,\n",
            "       -5.85470498e-01, -7.92120546e-02,  4.23431396e-01, -1.01947784e-01,\n",
            "        1.01317167e+00,  5.65966815e-02, -1.66760623e+00,  1.00708666e+01,\n",
            "       -1.18504934e+01,  6.91803026e+00], dtype=float32), 'agent_3': Array([ 5.02706826e-01,  6.87187314e-01, -1.07203396e-02, -1.95411779e-02,\n",
            "        7.26138294e-01,  1.02787465e-01, -1.03884660e-01,  1.63636014e-01,\n",
            "       -7.92120546e-02,  7.69175947e-01,  4.23431396e-01, -1.01947784e-01,\n",
            "        1.01317167e+00,  5.65966815e-02, -1.66760623e+00,  1.00708666e+01,\n",
            "       -1.23579845e+01,  8.25147724e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.1550301   0.50834423 -1.1605191   0.5074292  -1.1563934   0.50828373\n",
            " -1.1562605   0.50781894]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8716536, dtype=float32), 'agent_0': Array(-2.8716536, dtype=float32), 'agent_1': Array(-2.8716536, dtype=float32), 'agent_2': Array(-2.8716536, dtype=float32), 'agent_3': Array(-2.8716536, dtype=float32)}\n",
            "step: 236\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5372000e-01,  4.9908468e-01, -2.6742441e-03, -2.4508750e-02,\n",
            "        8.6620241e-01, -5.1430285e-01,  1.1036766e+00, -6.2700951e-01,\n",
            "       -4.4751334e-01, -6.1895853e-01,  2.6803017e-01,  1.5411377e-01,\n",
            "        1.3445258e+00, -4.2732856e-01, -4.4518647e-01,  1.3285940e+00,\n",
            "       -4.3418312e+00,  4.7341881e+00], dtype=float32), 'agent_1': Array([ 0.55372   ,  0.49908468, -0.00267424, -0.02450875,  0.8662024 ,\n",
            "       -0.51430285, -0.6270095 , -0.48049408, -0.44751334, -0.61895853,\n",
            "        0.26803017,  0.15411377,  1.3445258 , -0.42732856, -0.44518647,\n",
            "        1.328594  ,  1.6094478 ,  0.49210232], dtype=float32), 'agent_2': Array([ 5.5372000e-01,  4.9908468e-01, -2.6742441e-03, -2.4508750e-02,\n",
            "        8.6620241e-01, -5.1430285e-01, -6.2700951e-01, -4.4751334e-01,\n",
            "       -4.6818528e-01, -6.1895853e-01,  2.6803017e-01,  1.5411377e-01,\n",
            "        1.3445258e+00, -4.2732856e-01, -4.4518647e-01,  1.3285940e+00,\n",
            "       -4.6360321e+00,  1.6412401e-01], dtype=float32), 'agent_3': Array([ 5.5372000e-01,  4.9908468e-01, -2.6742441e-03, -2.4508750e-02,\n",
            "        8.6620241e-01, -5.1430285e-01, -6.2700951e-01, -4.4751334e-01,\n",
            "       -6.1895853e-01,  1.0982019e+00,  2.6803017e-01,  1.5411377e-01,\n",
            "        1.3445258e+00, -4.2732856e-01, -4.4518647e-01,  1.3285940e+00,\n",
            "        5.9078586e-01,  6.5029154e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.4301226   0.161175   -1.4261284   0.15298545 -1.4364575   0.16039643\n",
            " -1.4260445   0.16110654]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8320262, dtype=float32), 'agent_0': Array(-1.8320262, dtype=float32), 'agent_1': Array(-1.8320262, dtype=float32), 'agent_2': Array(-1.8320262, dtype=float32), 'agent_3': Array(-1.8320262, dtype=float32)}\n",
            "step: 237\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6430631 ,  0.5004448 ,  0.0043185 , -0.03177064,  0.86517453,\n",
            "       -0.5839685 ,  1.2514368 , -0.49922997, -0.57996184, -0.514926  ,\n",
            "        0.15525818,  0.21829605,  1.6641617 ,  0.6550405 , -0.12577718,\n",
            "       -0.10242791, -0.68078005,  1.4213964 ], dtype=float32), 'agent_1': Array([ 0.6430631 ,  0.5004448 ,  0.0043185 , -0.03177064,  0.86517453,\n",
            "       -0.5839685 , -0.49922997, -0.52482647, -0.57996184, -0.514926  ,\n",
            "        0.15525818,  0.21829605,  1.6641617 ,  0.6550405 , -0.12577718,\n",
            "       -0.10242791,  2.140317  , -1.1877612 ], dtype=float32), 'agent_2': Array([ 0.6430631 ,  0.5004448 ,  0.0043185 , -0.03177064,  0.86517453,\n",
            "       -0.5839685 , -0.49922997, -0.57996184, -0.51635265, -0.514926  ,\n",
            "        0.15525818,  0.21829605,  1.6641617 ,  0.6550405 , -0.12577718,\n",
            "       -0.10242791, -1.9096594 , -1.103189  ], dtype=float32), 'agent_3': Array([ 0.6430631 ,  0.5004448 ,  0.0043185 , -0.03177064,  0.86517453,\n",
            "       -0.5839685 , -0.49922997, -0.57996184, -0.514926  ,  1.274197  ,\n",
            "        0.15525818,  0.21829605,  1.6641617 ,  0.6550405 , -0.12577718,\n",
            "       -0.10242791,  2.1031303 , -1.1154894 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8935643  -0.7928184   0.8952297  -0.80026734  0.88937044 -0.7979778\n",
            "  0.8961273  -0.79746085]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8838158, dtype=float32), 'agent_0': Array(-2.8838158, dtype=float32), 'agent_1': Array(-2.8838158, dtype=float32), 'agent_2': Array(-2.8838158, dtype=float32), 'agent_3': Array(-2.8838158, dtype=float32)}\n",
            "step: 238\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.9106656e-01,  6.8750620e-01, -1.7326135e-02,  1.2516477e-02,\n",
            "        7.2586387e-01, -6.8099000e-02,  1.1034492e+00,  1.7970794e-01,\n",
            "       -1.4047475e-01,  1.7109920e-01,  2.0265579e-01, -3.2167435e-01,\n",
            "        5.4423809e-01,  4.1760018e-01,  2.8412187e+00, -1.1076322e+01,\n",
            "        1.3396892e+01, -5.4128513e+00], dtype=float32), 'agent_1': Array([ 6.9106656e-01,  6.8750620e-01, -1.7326135e-02,  1.2516477e-02,\n",
            "        7.2586387e-01, -6.8099000e-02,  1.7970794e-01, -9.3705565e-01,\n",
            "       -1.4047475e-01,  1.7109920e-01,  2.0265579e-01, -3.2167435e-01,\n",
            "        5.4423809e-01,  4.1760018e-01,  2.8412187e+00, -1.1076322e+01,\n",
            "        1.5141756e+01, -1.0470825e+01], dtype=float32), 'agent_2': Array([  0.69106656,   0.6875062 ,  -0.01732614,   0.01251648,\n",
            "         0.7258639 ,  -0.068099  ,   0.17970794,  -0.14047475,\n",
            "        -0.90644485,   0.1710992 ,   0.20265579,  -0.32167435,\n",
            "         0.5442381 ,   0.41760018,   2.8412187 , -11.076322  ,\n",
            "        12.374247  , -10.751126  ], dtype=float32), 'agent_3': Array([ 6.9106656e-01,  6.8750620e-01, -1.7326135e-02,  1.2516477e-02,\n",
            "        7.2586387e-01, -6.8099000e-02,  1.7970794e-01, -1.4047475e-01,\n",
            "        1.7109920e-01,  1.0401472e+00,  2.0265579e-01, -3.2167435e-01,\n",
            "        5.4423809e-01,  4.1760018e-01,  2.8412187e+00, -1.1076322e+01,\n",
            "        1.5531320e+01, -8.2172680e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.12413708 -0.8719732   0.12144647 -0.87268996  0.1198384  -0.87366855\n",
            "  0.12158674 -0.873085  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6834164, dtype=float32), 'agent_0': Array(-1.6834164, dtype=float32), 'agent_1': Array(-1.6834164, dtype=float32), 'agent_2': Array(-1.6834164, dtype=float32), 'agent_3': Array(-1.6834164, dtype=float32)}\n",
            "step: 239\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.7083678 ,   0.77220196,  -0.08696176,   0.05770906,\n",
            "         0.6267468 ,   0.24974373,   0.60185117,   0.5636379 ,\n",
            "         0.14942554,   0.5565808 ,   0.3432274 ,  -0.1537323 ,\n",
            "         0.1532197 ,  -0.8163185 ,   1.8269653 ,  -1.5190017 ,\n",
            "         2.2891314 , -12.392997  ], dtype=float32), 'agent_1': Array([ 0.7083678 ,  0.77220196, -0.08696176,  0.05770906,  0.6267468 ,\n",
            "        0.24974373,  0.5636379 , -1.3217409 ,  0.14942554,  0.5565808 ,\n",
            "        0.3432274 , -0.1537323 ,  0.1532197 , -0.8163185 ,  1.8269653 ,\n",
            "       -1.5190017 ,  1.9234818 ,  0.0804817 ], dtype=float32), 'agent_2': Array([ 0.7083678 ,  0.77220196, -0.08696176,  0.05770906,  0.6267468 ,\n",
            "        0.24974373,  0.5636379 ,  0.14942554, -1.3296973 ,  0.5565808 ,\n",
            "        0.3432274 , -0.1537323 ,  0.1532197 , -0.8163185 ,  1.8269653 ,\n",
            "       -1.5190017 ,  1.8584207 , -0.42800552], dtype=float32), 'agent_3': Array([ 0.7083678 ,  0.77220196, -0.08696176,  0.05770906,  0.6267468 ,\n",
            "        0.24974373,  0.5636379 ,  0.14942554,  0.5565808 ,  0.4593416 ,\n",
            "        0.3432274 , -0.1537323 ,  0.1532197 , -0.8163185 ,  1.8269653 ,\n",
            "       -1.5190017 ,  1.6209425 , -8.889907  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.43959716  0.03938372 -0.4361925   0.04868623 -0.43507123  0.04378714\n",
            " -0.44112572  0.04054369]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.23298132, dtype=float32), 'agent_0': Array(-0.23298132, dtype=float32), 'agent_1': Array(-0.23298132, dtype=float32), 'agent_2': Array(-0.23298132, dtype=float32), 'agent_3': Array(-0.23298132, dtype=float32)}\n",
            "step: 240\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.67937136,  0.70873004, -0.06764787,  0.05104831,  0.70037115,\n",
            "        0.03839248,  0.5129281 ,  0.35894927, -0.11197083,  0.327109  ,\n",
            "        0.09284019,  0.10900497, -0.75246096,  0.42318758, -0.11548255,\n",
            "        5.9028907 , -6.582942  , -0.0179377 ], dtype=float32), 'agent_1': Array([ 0.67937136,  0.70873004, -0.06764787,  0.05104831,  0.70037115,\n",
            "        0.03839248,  0.35894927, -1.2073538 , -0.11197083,  0.327109  ,\n",
            "        0.09284019,  0.10900497, -0.75246096,  0.42318758, -0.11548255,\n",
            "        5.9028907 , -6.7076063 ,  1.6151326 ], dtype=float32), 'agent_2': Array([ 0.67937136,  0.70873004, -0.06764787,  0.05104831,  0.70037115,\n",
            "        0.03839248,  0.35894927, -0.11197083, -1.2064738 ,  0.327109  ,\n",
            "        0.09284019,  0.10900497, -0.75246096,  0.42318758, -0.11548255,\n",
            "        5.9028907 , -7.782767  ,  2.412048  ], dtype=float32), 'agent_3': Array([ 0.67937136,  0.70873004, -0.06764787,  0.05104831,  0.70037115,\n",
            "        0.03839248,  0.35894927, -0.11197083,  0.327109  ,  0.5198305 ,\n",
            "        0.09284019,  0.10900497, -0.75246096,  0.42318758, -0.11548255,\n",
            "        5.9028907 , -7.327957  , -0.80807084], dtype=float32)}\n",
            "ctrl action chosen: [-0.83183616  0.9432761  -0.8301799   0.9458202  -0.82790595  0.9439315\n",
            " -0.833013    0.944371  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7962041, dtype=float32), 'agent_0': Array(0.7962041, dtype=float32), 'agent_1': Array(0.7962041, dtype=float32), 'agent_2': Array(0.7962041, dtype=float32), 'agent_3': Array(0.7962041, dtype=float32)}\n",
            "step: 241\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.64707106,  0.53324366, -0.01081004,  0.01792018,  0.8457028 ,\n",
            "       -0.5112893 ,  0.72790813, -0.1954172 , -0.6374363 , -0.26342493,\n",
            "        0.01173019,  0.40683746, -0.8857131 , -1.4471817 , -3.8060162 ,\n",
            "        6.287317  , -8.389156  ,  8.128764  ], dtype=float32), 'agent_1': Array([ 6.4707106e-01,  5.3324366e-01, -1.0810037e-02,  1.7920179e-02,\n",
            "        8.4570283e-01, -5.1128930e-01, -1.9541720e-01, -7.7176553e-01,\n",
            "       -6.3743627e-01, -2.6342493e-01,  1.1730194e-02,  4.0683746e-01,\n",
            "       -8.8571310e-01, -1.4471817e+00, -3.8060162e+00,  6.2873168e+00,\n",
            "       -8.9441938e+00,  1.2142205e+01], dtype=float32), 'agent_2': Array([ 6.4707106e-01,  5.3324366e-01, -1.0810037e-02,  1.7920179e-02,\n",
            "        8.4570283e-01, -5.1128930e-01, -1.9541720e-01, -6.3743627e-01,\n",
            "       -6.8555641e-01, -2.6342493e-01,  1.1730194e-02,  4.0683746e-01,\n",
            "       -8.8571310e-01, -1.4471817e+00, -3.8060162e+00,  6.2873168e+00,\n",
            "       -3.2332261e+00,  1.3759573e+01], dtype=float32), 'agent_3': Array([ 0.64707106,  0.53324366, -0.01081004,  0.01792018,  0.8457028 ,\n",
            "       -0.5112893 , -0.1954172 , -0.6374363 , -0.26342493,  0.7798336 ,\n",
            "        0.01173019,  0.40683746, -0.8857131 , -1.4471817 , -3.8060162 ,\n",
            "        6.287317  , -9.662213  ,  9.589492  ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.0713272 -1.0507731  1.072015  -1.048507   1.071757  -1.0465097\n",
            "  1.0716091 -1.0505921]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0663116, dtype=float32), 'agent_0': Array(-2.0663116, dtype=float32), 'agent_1': Array(-2.0663116, dtype=float32), 'agent_2': Array(-2.0663116, dtype=float32), 'agent_3': Array(-2.0663116, dtype=float32)}\n",
            "step: 242\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8442849e-01,  6.6813612e-01, -8.6998437e-03,  1.0673424e-02,\n",
            "        7.4391174e-01, -1.1023052e-01,  6.8646562e-01,  1.7707510e-01,\n",
            "       -7.4952267e-02,  8.2582645e-02, -1.7738342e-02, -3.4198761e-01,\n",
            "       -1.4000535e+00,  1.1076413e-01,  1.4032654e+00, -1.1238574e+01,\n",
            "        1.3377629e+01, -4.8548889e+00], dtype=float32), 'agent_1': Array([ 5.8442849e-01,  6.6813612e-01, -8.6998437e-03,  1.0673424e-02,\n",
            "        7.4391174e-01, -1.1023052e-01,  1.7707510e-01, -7.0023310e-01,\n",
            "       -7.4952267e-02,  8.2582645e-02, -1.7738342e-02, -3.4198761e-01,\n",
            "       -1.4000535e+00,  1.1076413e-01,  1.4032654e+00, -1.1238574e+01,\n",
            "        1.3239811e+01, -3.5585656e+00], dtype=float32), 'agent_2': Array([ 5.8442849e-01,  6.6813612e-01, -8.6998437e-03,  1.0673424e-02,\n",
            "        7.4391174e-01, -1.1023052e-01,  1.7707510e-01, -7.4952267e-02,\n",
            "       -6.1259335e-01,  8.2582645e-02, -1.7738342e-02, -3.4198761e-01,\n",
            "       -1.4000535e+00,  1.1076413e-01,  1.4032654e+00, -1.1238574e+01,\n",
            "        1.7699078e+01, -3.7110474e+00], dtype=float32), 'agent_3': Array([ 5.8442849e-01,  6.6813612e-01, -8.6998437e-03,  1.0673424e-02,\n",
            "        7.4391174e-01, -1.1023052e-01,  1.7707510e-01, -7.4952267e-02,\n",
            "        8.2582645e-02,  7.9712665e-01, -1.7738342e-02, -3.4198761e-01,\n",
            "       -1.4000535e+00,  1.1076413e-01,  1.4032654e+00, -1.1238574e+01,\n",
            "        1.3004747e+01, -4.2463307e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.4449006  -0.5799971  -0.44479764 -0.57836807 -0.4436412  -0.5802653\n",
            " -0.44552138 -0.57982326]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.5324912, dtype=float32), 'agent_0': Array(-3.5324912, dtype=float32), 'agent_1': Array(-3.5324912, dtype=float32), 'agent_2': Array(-3.5324912, dtype=float32), 'agent_3': Array(-3.5324912, dtype=float32)}\n",
            "step: 243\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5010749 ,  0.6823168 , -0.0341278 ,  0.03652857,  0.7293455 ,\n",
            "       -0.07884572,  0.46666822,  0.1923375 ,  0.14626272,  0.10172142,\n",
            "       -0.01115799, -0.27971268, -1.9641995 ,  0.30315802,  1.7767425 ,\n",
            "        2.81992   , -3.8530328 , -1.4604337 ], dtype=float32), 'agent_1': Array([ 0.5010749 ,  0.6823168 , -0.0341278 ,  0.03652857,  0.7293455 ,\n",
            "       -0.07884572,  0.1923375 , -0.94836944,  0.14626272,  0.10172142,\n",
            "       -0.01115799, -0.27971268, -1.9641995 ,  0.30315802,  1.7767425 ,\n",
            "        2.81992   , -4.5177774 , -6.97483   ], dtype=float32), 'agent_2': Array([ 0.5010749 ,  0.6823168 , -0.0341278 ,  0.03652857,  0.7293455 ,\n",
            "       -0.07884572,  0.1923375 ,  0.14626272, -0.8266005 ,  0.10172142,\n",
            "       -0.01115799, -0.27971268, -1.9641995 ,  0.30315802,  1.7767425 ,\n",
            "        2.81992   , -0.72630996, -5.9833198 ], dtype=float32), 'agent_3': Array([ 0.5010749 ,  0.6823168 , -0.0341278 ,  0.03652857,  0.7293455 ,\n",
            "       -0.07884572,  0.1923375 ,  0.14626272,  0.10172142,  0.5099626 ,\n",
            "       -0.01115799, -0.27971268, -1.9641995 ,  0.30315802,  1.7767425 ,\n",
            "        2.81992   , -4.5834174 , -6.896606  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.4674574  1.0166057 -1.4711708  1.010428  -1.4692352  1.0113512\n",
            " -1.470632   1.0100336]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.06364834, dtype=float32), 'agent_0': Array(-0.06364834, dtype=float32), 'agent_1': Array(-0.06364834, dtype=float32), 'agent_2': Array(-0.06364834, dtype=float32), 'agent_3': Array(-0.06364834, dtype=float32)}\n",
            "step: 244\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4424409 ,  0.48637223, -0.00883591,  0.03757589,  0.8728986 ,\n",
            "       -0.6469234 ,  0.6710451 , -0.47811893, -0.36580586, -0.56076926,\n",
            "       -0.16503334,  0.6913185 , -0.4231155 ,  0.0217456 , -0.6792962 ,\n",
            "        5.6386538 , -3.188774  ,  4.964947  ], dtype=float32), 'agent_1': Array([ 4.4244090e-01,  4.8637223e-01, -8.8359118e-03,  3.7575893e-02,\n",
            "        8.7289858e-01, -6.4692342e-01, -4.7811893e-01, -8.3559328e-01,\n",
            "       -3.6580586e-01, -5.6076926e-01, -1.6503334e-01,  6.9131851e-01,\n",
            "       -4.2311549e-01,  2.1745600e-02, -6.7929620e-01,  5.6386538e+00,\n",
            "       -1.0076429e+01,  5.7817807e+00], dtype=float32), 'agent_2': Array([ 0.4424409 ,  0.48637223, -0.00883591,  0.03757589,  0.8728986 ,\n",
            "       -0.6469234 , -0.47811893, -0.36580586, -0.67782164, -0.56076926,\n",
            "       -0.16503334,  0.6913185 , -0.4231155 ,  0.0217456 , -0.6792962 ,\n",
            "        5.6386538 , -8.264848  ,  6.3041105 ], dtype=float32), 'agent_3': Array([ 0.4424409 ,  0.48637223, -0.00883591,  0.03757589,  0.8728986 ,\n",
            "       -0.6469234 , -0.47811893, -0.36580586, -0.56076926,  0.6144795 ,\n",
            "       -0.16503334,  0.6913185 , -0.4231155 ,  0.0217456 , -0.6792962 ,\n",
            "        5.6386538 , -8.33476   ,  3.2099488 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.47770917 -1.0175911   0.46862873 -1.0196923   0.47214162 -1.0196795\n",
            "  0.46940228 -1.0215952 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.5379486, dtype=float32), 'agent_0': Array(-5.5379486, dtype=float32), 'agent_1': Array(-5.5379486, dtype=float32), 'agent_2': Array(-5.5379486, dtype=float32), 'agent_3': Array(-5.5379486, dtype=float32)}\n",
            "step: 245\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.4396690e-01,  5.5222541e-01, -2.6406795e-02,  7.1642600e-02,\n",
            "        8.3019102e-01, -3.5100964e-01,  5.1277304e-01, -4.0471873e-01,\n",
            "       -2.2633117e-01, -4.4692159e-01, -5.1021576e-03, -6.1321259e-02,\n",
            "        5.2900910e-01, -1.8521082e-01,  1.1352290e+00, -4.8826675e+00,\n",
            "        8.8467388e+00, -4.7953925e+00], dtype=float32), 'agent_1': Array([ 4.4396690e-01,  5.5222541e-01, -2.6406795e-02,  7.1642600e-02,\n",
            "        8.3019102e-01, -3.5100964e-01, -4.0471873e-01, -1.0103878e+00,\n",
            "       -2.2633117e-01, -4.4692159e-01, -5.1021576e-03, -6.1321259e-02,\n",
            "        5.2900910e-01, -1.8521082e-01,  1.1352290e+00, -4.8826675e+00,\n",
            "        4.1444125e+00, -5.5236511e+00], dtype=float32), 'agent_2': Array([ 4.4396690e-01,  5.5222541e-01, -2.6406795e-02,  7.1642600e-02,\n",
            "        8.3019102e-01, -3.5100964e-01, -4.0471873e-01, -2.2633117e-01,\n",
            "       -8.2734996e-01, -4.4692159e-01, -5.1021576e-03, -6.1321259e-02,\n",
            "        5.2900910e-01, -1.8521082e-01,  1.1352290e+00, -4.8826675e+00,\n",
            "        5.3236666e+00, -5.1300750e+00], dtype=float32), 'agent_3': Array([ 4.4396690e-01,  5.5222541e-01, -2.6406795e-02,  7.1642600e-02,\n",
            "        8.3019102e-01, -3.5100964e-01, -4.0471873e-01, -2.2633117e-01,\n",
            "       -4.4692159e-01,  4.6455386e-01, -5.1021576e-03, -6.1321259e-02,\n",
            "        5.2900910e-01, -1.8521082e-01,  1.1352290e+00, -4.8826675e+00,\n",
            "        5.6268730e+00,  4.2527750e-01], dtype=float32)}\n",
            "ctrl action chosen: [0.7482796  0.46888912 0.7434682  0.46620318 0.7447432  0.4664037\n",
            " 0.7506999  0.4710683 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.2454445, dtype=float32), 'agent_0': Array(-1.2454445, dtype=float32), 'agent_1': Array(-1.2454445, dtype=float32), 'agent_2': Array(-1.2454445, dtype=float32), 'agent_3': Array(-1.2454445, dtype=float32)}\n",
            "step: 246\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.4868856 ,   0.7339505 ,  -0.0190042 ,   0.03532889,\n",
            "         0.6780173 ,   0.3334287 ,   0.60657144,   0.08397364,\n",
            "         0.3372146 ,   0.15422021,  -0.3698349 ,   0.27399063,\n",
            "         0.7022083 ,   0.16793703,  -1.3314477 , -10.550934  ,\n",
            "        14.505414  ,   2.6126773 ], dtype=float32), 'agent_1': Array([  0.4868856 ,   0.7339505 ,  -0.0190042 ,   0.03532889,\n",
            "         0.6780173 ,   0.3334287 ,   0.08397364,  -0.8951845 ,\n",
            "         0.3372146 ,   0.15422021,  -0.3698349 ,   0.27399063,\n",
            "         0.7022083 ,   0.16793703,  -1.3314477 , -10.550934  ,\n",
            "        11.650721  ,   2.994066  ], dtype=float32), 'agent_2': Array([  0.4868856 ,   0.7339505 ,  -0.0190042 ,   0.03532889,\n",
            "         0.6780173 ,   0.3334287 ,   0.08397364,   0.3372146 ,\n",
            "        -0.75159955,   0.15422021,  -0.3698349 ,   0.27399063,\n",
            "         0.7022083 ,   0.16793703,  -1.3314477 , -10.550934  ,\n",
            "        12.536031  ,   2.44619   ], dtype=float32), 'agent_3': Array([  0.4868856 ,   0.7339505 ,  -0.0190042 ,   0.03532889,\n",
            "         0.6780173 ,   0.3334287 ,   0.08397364,   0.3372146 ,\n",
            "         0.15422021,   0.626781  ,  -0.3698349 ,   0.27399063,\n",
            "         0.7022083 ,   0.16793703,  -1.3314477 , -10.550934  ,\n",
            "        13.470861  ,   3.3898528 ], dtype=float32)}\n",
            "ctrl action chosen: [ 2.696108   -0.0985686   2.6986623  -0.09908947  2.6978512  -0.09899985\n",
            "  2.697258   -0.09915205]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.854887, dtype=float32), 'agent_0': Array(-0.854887, dtype=float32), 'agent_1': Array(-0.854887, dtype=float32), 'agent_2': Array(-0.854887, dtype=float32), 'agent_3': Array(-0.854887, dtype=float32)}\n",
            "step: 247\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5059989 ,  0.8144707 , -0.02296758,  0.02437391,  0.5792375 ,\n",
            "        0.61565787,  0.5859096 ,  0.46936426,  0.5788313 ,  0.5615253 ,\n",
            "       -0.4438877 , -0.08077621,  0.1354456 , -0.178468  , -0.09099402,\n",
            "       -0.28344023, -1.6266142 , -1.0140976 ], dtype=float32), 'agent_1': Array([ 0.5059989 ,  0.8144707 , -0.02296758,  0.02437391,  0.5792375 ,\n",
            "        0.61565787,  0.46936426, -0.9124055 ,  0.5788313 ,  0.5615253 ,\n",
            "       -0.4438877 , -0.08077621,  0.1354456 , -0.178468  , -0.09099402,\n",
            "       -0.28344023,  3.7210283 , -0.86434   ], dtype=float32), 'agent_2': Array([ 0.5059989 ,  0.8144707 , -0.02296758,  0.02437391,  0.5792375 ,\n",
            "        0.61565787,  0.46936426,  0.5788313 , -0.79987144,  0.5615253 ,\n",
            "       -0.4438877 , -0.08077621,  0.1354456 , -0.178468  , -0.09099402,\n",
            "       -0.28344023, -1.1881441 , -1.6256326 ], dtype=float32), 'agent_3': Array([ 0.5059989 ,  0.8144707 , -0.02296758,  0.02437391,  0.5792375 ,\n",
            "        0.61565787,  0.46936426,  0.5788313 ,  0.5615253 ,  0.6966604 ,\n",
            "       -0.4438877 , -0.08077621,  0.1354456 , -0.178468  , -0.09099402,\n",
            "       -0.28344023,  1.9361812 ,  0.9946076 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0654263  1.7704668 -1.0552361  1.7671742 -1.060891   1.7650309\n",
            " -1.0580553  1.7693053]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-13.926171, dtype=float32), 'agent_0': Array(-13.926171, dtype=float32), 'agent_1': Array(-13.926171, dtype=float32), 'agent_2': Array(-13.926171, dtype=float32), 'agent_3': Array(-13.926171, dtype=float32)}\n",
            "step: 248\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.1827884e-01,  6.5594065e-01,  2.8344840e-02, -1.7946299e-02,\n",
            "        7.5406659e-01, -8.4854454e-02,  9.1972280e-01,  4.6396665e-03,\n",
            "       -9.4410196e-02,  5.9313159e-02, -3.1757355e-01,  3.1232834e-01,\n",
            "        1.3056993e-01, -3.3721876e-01, -3.9795930e+00,  1.3500753e+01,\n",
            "       -1.9603163e+01,  1.0575445e+01], dtype=float32), 'agent_1': Array([ 5.18278837e-01,  6.55940652e-01,  2.83448398e-02, -1.79462992e-02,\n",
            "        7.54066586e-01, -8.48544538e-02,  4.63966653e-03, -5.82030535e-01,\n",
            "       -9.44101959e-02,  5.93131594e-02, -3.17573547e-01,  3.12328339e-01,\n",
            "        1.30569935e-01, -3.37218761e-01, -3.97959304e+00,  1.35007534e+01,\n",
            "       -1.37957201e+01,  1.00498495e+01], dtype=float32), 'agent_2': Array([ 5.1827884e-01,  6.5594065e-01,  2.8344840e-02, -1.7946299e-02,\n",
            "        7.5406659e-01, -8.4854454e-02,  4.6396665e-03, -9.4410196e-02,\n",
            "       -5.0175977e-01,  5.9313159e-02, -3.1757355e-01,  3.1232834e-01,\n",
            "        1.3056993e-01, -3.3721876e-01, -3.9795930e+00,  1.3500753e+01,\n",
            "       -1.8790264e+01,  8.7001314e+00], dtype=float32), 'agent_3': Array([ 5.1827884e-01,  6.5594065e-01,  2.8344840e-02, -1.7946299e-02,\n",
            "        7.5406659e-01, -8.4854454e-02,  4.6396665e-03, -9.4410196e-02,\n",
            "        5.9313159e-02,  1.0449727e+00, -3.1757355e-01,  3.1232834e-01,\n",
            "        1.3056993e-01, -3.3721876e-01, -3.9795930e+00,  1.3500753e+01,\n",
            "       -1.5419883e+01,  9.3530436e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.348244    0.3467316  -1.3455539   0.34937698 -1.349525    0.34679466\n",
            " -1.34791     0.34726396]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.9087963, dtype=float32), 'agent_0': Array(-7.9087963, dtype=float32), 'agent_1': Array(-7.9087963, dtype=float32), 'agent_2': Array(-7.9087963, dtype=float32), 'agent_3': Array(-7.9087963, dtype=float32)}\n",
            "step: 249\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5145998 ,  0.48736775,  0.03647868, -0.06367768,  0.87010753,\n",
            "       -0.628313  ,  1.2604674 , -0.4846594 , -0.6251832 , -0.5140371 ,\n",
            "       -0.16565323, -0.12464523,  0.26043653, -0.44818306, -0.42599967,\n",
            "        0.45725703,  0.8552434 ,  0.6656083 ], dtype=float32), 'agent_1': Array([ 0.5145998 ,  0.48736775,  0.03647868, -0.06367768,  0.87010753,\n",
            "       -0.628313  , -0.4846594 , -0.4799499 , -0.6251832 , -0.5140371 ,\n",
            "       -0.16565323, -0.12464523,  0.26043653, -0.44818306, -0.42599967,\n",
            "        0.45725703, -2.7968562 , -0.7350909 ], dtype=float32), 'agent_2': Array([ 0.5145998 ,  0.48736775,  0.03647868, -0.06367768,  0.87010753,\n",
            "       -0.628313  , -0.4846594 , -0.6251832 , -0.49255562, -0.5140371 ,\n",
            "       -0.16565323, -0.12464523,  0.26043653, -0.44818306, -0.42599967,\n",
            "        0.45725703,  0.74595076, -0.67131126], dtype=float32), 'agent_3': Array([ 0.5145998 ,  0.48736775,  0.03647868, -0.06367768,  0.87010753,\n",
            "       -0.628313  , -0.4846594 , -0.6251832 , -0.5140371 ,  1.2578199 ,\n",
            "       -0.16565323, -0.12464523,  0.26043653, -0.44818306, -0.42599967,\n",
            "        0.45725703, -4.198941  , -0.7416903 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.88220817  0.7589518  -0.8931651   0.7580109  -0.8868938   0.7554709\n",
            " -0.8932389   0.758935  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0418396, dtype=float32), 'agent_0': Array(-3.0418396, dtype=float32), 'agent_1': Array(-3.0418396, dtype=float32), 'agent_2': Array(-3.0418396, dtype=float32), 'agent_3': Array(-3.0418396, dtype=float32)}\n",
            "step: 250\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.552471  ,  0.5027554 ,  0.0529589 , -0.0950153 ,  0.85755736,\n",
            "       -0.5089344 ,  1.2708067 , -0.55696   , -0.50660145, -0.5825323 ,\n",
            "       -0.08792877,  0.050354  ,  0.31830072, -0.6772748 , -0.9985833 ,\n",
            "       -0.59989536,  1.9604203 , -0.47352526], dtype=float32), 'agent_1': Array([ 0.552471  ,  0.5027554 ,  0.0529589 , -0.0950153 ,  0.85755736,\n",
            "       -0.5089344 , -0.55696   , -0.50367814, -0.50660145, -0.5825323 ,\n",
            "       -0.08792877,  0.050354  ,  0.31830072, -0.6772748 , -0.9985833 ,\n",
            "       -0.59989536, -1.6485957 , -0.908255  ], dtype=float32), 'agent_2': Array([ 0.552471  ,  0.5027554 ,  0.0529589 , -0.0950153 ,  0.85755736,\n",
            "       -0.5089344 , -0.55696   , -0.50660145, -0.50812346, -0.5825323 ,\n",
            "       -0.08792877,  0.050354  ,  0.31830072, -0.6772748 , -0.9985833 ,\n",
            "       -0.59989536,  1.7907857 , -0.4865369 ], dtype=float32), 'agent_3': Array([ 0.552471  ,  0.5027554 ,  0.0529589 , -0.0950153 ,  0.85755736,\n",
            "       -0.5089344 , -0.55696   , -0.50660145, -0.5825323 ,  1.2680334 ,\n",
            "       -0.08792877,  0.050354  ,  0.31830072, -0.6772748 , -0.9985833 ,\n",
            "       -0.59989536, -0.60088754, -0.64124316], dtype=float32)}\n",
            "ctrl action chosen: [-1.1643734  -0.33697823 -1.1755916  -0.33863872 -1.168303   -0.3373732\n",
            " -1.1699655  -0.33786914]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.9403241, dtype=float32), 'agent_0': Array(-1.9403241, dtype=float32), 'agent_1': Array(-1.9403241, dtype=float32), 'agent_2': Array(-1.9403241, dtype=float32), 'agent_3': Array(-1.9403241, dtype=float32)}\n",
            "step: 251\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5546862 ,  0.505076  ,  0.05405817, -0.0941817 ,  0.856216  ,\n",
            "       -0.5299483 ,  1.1001203 , -0.5895733 , -0.5271967 , -0.5605936 ,\n",
            "       -0.25763512, -0.25978088,  0.04402399,  0.47869006,  0.23557954,\n",
            "       -0.16130908, -1.4156126 , -4.6505246 ], dtype=float32), 'agent_1': Array([ 0.5546862 ,  0.505076  ,  0.05405817, -0.0941817 ,  0.856216  ,\n",
            "       -0.5299483 , -0.5895733 , -0.6587632 , -0.5271967 , -0.5605936 ,\n",
            "       -0.25763512, -0.25978088,  0.04402399,  0.47869006,  0.23557954,\n",
            "       -0.16130908,  0.93489313, -2.7679338 ], dtype=float32), 'agent_2': Array([ 0.5546862 ,  0.505076  ,  0.05405817, -0.0941817 ,  0.856216  ,\n",
            "       -0.5299483 , -0.5895733 , -0.5271967 , -0.6921446 , -0.5605936 ,\n",
            "       -0.25763512, -0.25978088,  0.04402399,  0.47869006,  0.23557954,\n",
            "       -0.16130908, -1.3242784 , -4.037129  ], dtype=float32), 'agent_3': Array([ 0.5546862 ,  0.505076  ,  0.05405817, -0.0941817 ,  0.856216  ,\n",
            "       -0.5299483 , -0.5895733 , -0.5271967 , -0.5605936 ,  1.0731726 ,\n",
            "       -0.25763512, -0.25978088,  0.04402399,  0.47869006,  0.23557954,\n",
            "       -0.16130908,  1.2542787 , -5.8174033 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.68389827 -0.3410774  -0.68427676 -0.34110528 -0.6862785  -0.34164658\n",
            " -0.68515426 -0.3403411 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.0789542, dtype=float32), 'agent_0': Array(-2.0789542, dtype=float32), 'agent_1': Array(-2.0789542, dtype=float32), 'agent_2': Array(-2.0789542, dtype=float32), 'agent_3': Array(-2.0789542, dtype=float32)}\n",
            "step: 252\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57742745,  0.51729256,  0.0488564 , -0.07285195,  0.8513014 ,\n",
            "       -0.56425685,  0.81522334, -0.5281702 , -0.54721564, -0.5126602 ,\n",
            "       -0.13070107,  0.03433228,  0.63182116,  0.48700708,  0.9494918 ,\n",
            "       -0.34598833, -0.1931584 , -6.13232   ], dtype=float32), 'agent_1': Array([ 0.57742745,  0.51729256,  0.0488564 , -0.07285195,  0.8513014 ,\n",
            "       -0.56425685, -0.5281702 , -0.7619109 , -0.54721564, -0.5126602 ,\n",
            "       -0.13070107,  0.03433228,  0.63182116,  0.48700708,  0.9494918 ,\n",
            "       -0.34598833,  0.44638282, -2.1452758 ], dtype=float32), 'agent_2': Array([ 0.57742745,  0.51729256,  0.0488564 , -0.07285195,  0.8513014 ,\n",
            "       -0.56425685, -0.5281702 , -0.54721564, -0.8427595 , -0.5126602 ,\n",
            "       -0.13070107,  0.03433228,  0.63182116,  0.48700708,  0.9494918 ,\n",
            "       -0.34598833,  0.09804724, -2.579107  ], dtype=float32), 'agent_3': Array([ 0.57742745,  0.51729256,  0.0488564 , -0.07285195,  0.8513014 ,\n",
            "       -0.56425685, -0.5281702 , -0.54721564, -0.5126602 ,  0.73621714,\n",
            "       -0.13070107,  0.03433228,  0.63182116,  0.48700708,  0.9494918 ,\n",
            "       -0.34598833, -0.0554552 , -6.287419  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.10914798 -0.13656285  0.10849601 -0.13545856  0.10825668 -0.13700615\n",
            "  0.10781506 -0.13565466]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.41058588, dtype=float32), 'agent_0': Array(-0.41058588, dtype=float32), 'agent_1': Array(-0.41058588, dtype=float32), 'agent_2': Array(-0.41058588, dtype=float32), 'agent_3': Array(-0.41058588, dtype=float32)}\n",
            "step: 253\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6016223 ,  0.55866885,  0.03967972, -0.05714845,  0.8264677 ,\n",
            "       -0.46778592,  0.5678972 , -0.41711816, -0.429833  , -0.41836026,\n",
            "        0.04210472,  0.12865067,  0.3456235 ,  0.11626776,  0.6740207 ,\n",
            "       -1.7815523 ,  2.2657328 , -4.5531216 ], dtype=float32), 'agent_1': Array([ 0.6016223 ,  0.55866885,  0.03967972, -0.05714845,  0.8264677 ,\n",
            "       -0.46778592, -0.41711816, -0.856549  , -0.429833  , -0.41836026,\n",
            "        0.04210472,  0.12865067,  0.3456235 ,  0.11626776,  0.6740207 ,\n",
            "       -1.7815523 ,  1.9666709 , -1.9985573 ], dtype=float32), 'agent_2': Array([ 0.6016223 ,  0.55866885,  0.03967972, -0.05714845,  0.8264677 ,\n",
            "       -0.46778592, -0.41711816, -0.429833  , -0.90754783, -0.41836026,\n",
            "        0.04210472,  0.12865067,  0.3456235 ,  0.11626776,  0.6740207 ,\n",
            "       -1.7815523 ,  2.560939  , -1.0836412 ], dtype=float32), 'agent_3': Array([ 0.6016223 ,  0.55866885,  0.03967972, -0.05714845,  0.8264677 ,\n",
            "       -0.46778592, -0.41711816, -0.429833  , -0.41836026,  0.51381195,\n",
            "        0.04210472,  0.12865067,  0.3456235 ,  0.11626776,  0.6740207 ,\n",
            "       -1.7815523 ,  1.4968128 , -3.7042246 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9081203  -0.33999208  0.91075563 -0.3380764   0.9122629  -0.33827266\n",
            "  0.90859455 -0.33956638]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9353471, dtype=float32), 'agent_0': Array(0.9353471, dtype=float32), 'agent_1': Array(0.9353471, dtype=float32), 'agent_2': Array(0.9353471, dtype=float32), 'agent_3': Array(0.9353471, dtype=float32)}\n",
            "step: 254\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.61551934,   0.7403704 ,   0.03816378,  -0.04325308,\n",
            "         0.6697197 ,   0.11803775,   0.48853907,   0.16171654,\n",
            "         0.1718123 ,   0.14035596,   0.15473366,  -0.0210762 ,\n",
            "         0.45505762,  -0.21764597,   0.21297568, -11.874203  ,\n",
            "        14.617015  ,   0.5500517 ], dtype=float32), 'agent_1': Array([  0.61551934,   0.7403704 ,   0.03816378,  -0.04325308,\n",
            "         0.6697197 ,   0.11803775,   0.16171654,  -0.9974401 ,\n",
            "         0.1718123 ,   0.14035596,   0.15473366,  -0.0210762 ,\n",
            "         0.45505762,  -0.21764597,   0.21297568, -11.874203  ,\n",
            "        14.656641  ,  -2.4541926 ], dtype=float32), 'agent_2': Array([  0.61551934,   0.7403704 ,   0.03816378,  -0.04325308,\n",
            "         0.6697197 ,   0.11803775,   0.16171654,   0.1718123 ,\n",
            "        -1.046309  ,   0.14035596,   0.15473366,  -0.0210762 ,\n",
            "         0.45505762,  -0.21764597,   0.21297568, -11.874203  ,\n",
            "        15.008919  ,  -2.9806664 ], dtype=float32), 'agent_3': Array([  0.61551934,   0.7403704 ,   0.03816378,  -0.04325308,\n",
            "         0.6697197 ,   0.11803775,   0.16171654,   0.1718123 ,\n",
            "         0.14035596,   0.49210632,   0.15473366,  -0.0210762 ,\n",
            "         0.45505762,  -0.21764597,   0.21297568, -11.874203  ,\n",
            "        14.25826   ,   0.37407306], dtype=float32)}\n",
            "ctrl action chosen: [ 1.5705554  -0.8895203   1.5687553  -0.8901422   1.5699923  -0.8921273\n",
            "  1.5704194  -0.88969016]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.79295385, dtype=float32), 'agent_0': Array(-0.79295385, dtype=float32), 'agent_1': Array(-0.79295385, dtype=float32), 'agent_2': Array(-0.79295385, dtype=float32), 'agent_3': Array(-0.79295385, dtype=float32)}\n",
            "step: 255\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6426217 ,  0.8408837 ,  0.01851475, -0.02879944,  0.54013187,\n",
            "        0.55857337,  0.4856767 ,  0.57298726,  0.5803414 ,  0.5592934 ,\n",
            "        0.34618378, -0.26950836,  0.4911542 , -0.387086  ,  0.7919024 ,\n",
            "        0.5697763 ,  0.43488118,  0.78424335], dtype=float32), 'agent_1': Array([ 0.6426217 ,  0.8408837 ,  0.01851475, -0.02879944,  0.54013187,\n",
            "        0.55857337,  0.57298726, -1.2610357 ,  0.5803414 ,  0.5592934 ,\n",
            "        0.34618378, -0.26950836,  0.4911542 , -0.387086  ,  0.7919024 ,\n",
            "        0.5697763 , -0.35797364, -4.567902  ], dtype=float32), 'agent_2': Array([ 0.6426217 ,  0.8408837 ,  0.01851475, -0.02879944,  0.54013187,\n",
            "        0.55857337,  0.57298726,  0.5803414 , -1.2839427 ,  0.5592934 ,\n",
            "        0.34618378, -0.26950836,  0.4911542 , -0.387086  ,  0.7919024 ,\n",
            "        0.5697763 , -0.5993206 , -1.8034357 ], dtype=float32), 'agent_3': Array([ 0.6426217 ,  0.8408837 ,  0.01851475, -0.02879944,  0.54013187,\n",
            "        0.55857337,  0.57298726,  0.5803414 ,  0.5592934 ,  0.4921296 ,\n",
            "        0.34618378, -0.26950836,  0.4911542 , -0.387086  ,  0.7919024 ,\n",
            "        0.5697763 ,  0.21125218,  0.5832373 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.13941792 -0.80832565  0.13621089 -0.8136667   0.14131817 -0.8185239\n",
            "  0.13890584 -0.80853623]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.195361, dtype=float32), 'agent_0': Array(-5.195361, dtype=float32), 'agent_1': Array(-5.195361, dtype=float32), 'agent_2': Array(-5.195361, dtype=float32), 'agent_3': Array(-5.195361, dtype=float32)}\n",
            "step: 256\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.66245264,  0.827255  ,  0.01582695, -0.02413771,  0.5610846 ,\n",
            "        0.5226015 ,  0.51404256,  0.4978591 ,  0.49521145,  0.51509047,\n",
            "        0.05693436,  0.10643005,  0.11560917, -0.04370399,  0.51029795,\n",
            "        0.77021813, -0.4007411 , -0.18729925], dtype=float32), 'agent_1': Array([ 0.66245264,  0.827255  ,  0.01582695, -0.02413771,  0.5610846 ,\n",
            "        0.5226015 ,  0.4978591 , -1.2843008 ,  0.49521145,  0.51509047,\n",
            "        0.05693436,  0.10643005,  0.11560917, -0.04370399,  0.51029795,\n",
            "        0.77021813, -1.602603  , -0.40952095], dtype=float32), 'agent_2': Array([ 0.66245264,  0.827255  ,  0.01582695, -0.02413771,  0.5610846 ,\n",
            "        0.5226015 ,  0.4978591 ,  0.49521145, -1.2792628 ,  0.51509047,\n",
            "        0.05693436,  0.10643005,  0.11560917, -0.04370399,  0.51029795,\n",
            "        0.77021813, -1.747958  ,  0.37091726], dtype=float32), 'agent_3': Array([ 0.66245264,  0.827255  ,  0.01582695, -0.02413771,  0.5610846 ,\n",
            "        0.5226015 ,  0.4978591 ,  0.49521145,  0.51509047,  0.50474286,\n",
            "        0.05693436,  0.10643005,  0.11560917, -0.04370399,  0.51029795,\n",
            "        0.77021813, -0.60113066, -0.39302003], dtype=float32)}\n",
            "ctrl action chosen: [-0.23595469  0.19716576 -0.23689449  0.2004387  -0.23264503  0.19477586\n",
            " -0.23677503  0.19690542]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.22342336, dtype=float32), 'agent_0': Array(-0.22342336, dtype=float32), 'agent_1': Array(-0.22342336, dtype=float32), 'agent_2': Array(-0.22342336, dtype=float32), 'agent_3': Array(-0.22342336, dtype=float32)}\n",
            "step: 257\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.65053374,  0.78730077,  0.0243207 , -0.02409524,  0.615618  ,\n",
            "        0.39156845,  0.614022  ,  0.31210336,  0.2920216 ,  0.3678048 ,\n",
            "        0.1364708 ,  0.2825737 , -0.37463903,  0.38277334, -0.16909769,\n",
            "        2.44533   , -2.6593773 ,  1.4488921 ], dtype=float32), 'agent_1': Array([ 0.65053374,  0.78730077,  0.0243207 , -0.02409524,  0.615618  ,\n",
            "        0.39156845,  0.31210336, -1.1685399 ,  0.2920216 ,  0.3678048 ,\n",
            "        0.1364708 ,  0.2825737 , -0.37463903,  0.38277334, -0.16909769,\n",
            "        2.44533   , -3.3910935 ,  2.9959126 ], dtype=float32), 'agent_2': Array([ 0.65053374,  0.78730077,  0.0243207 , -0.02409524,  0.615618  ,\n",
            "        0.39156845,  0.31210336,  0.2920216 , -1.1283152 ,  0.3678048 ,\n",
            "        0.1364708 ,  0.2825737 , -0.37463903,  0.38277334, -0.16909769,\n",
            "        2.44533   , -3.8581123 ,  4.026743  ], dtype=float32), 'agent_3': Array([ 0.65053374,  0.78730077,  0.0243207 , -0.02409524,  0.615618  ,\n",
            "        0.39156845,  0.31210336,  0.2920216 ,  0.3678048 ,  0.5747342 ,\n",
            "        0.1364708 ,  0.2825737 , -0.37463903,  0.38277334, -0.16909769,\n",
            "        2.44533   , -2.9384258 ,  1.0871419 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8754411  -1.3804531   0.87493485 -1.37792     0.8777846  -1.3811064\n",
            "  0.8740684  -1.3806944 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9735745, dtype=float32), 'agent_0': Array(0.9735745, dtype=float32), 'agent_1': Array(0.9735745, dtype=float32), 'agent_2': Array(0.9735745, dtype=float32), 'agent_3': Array(0.9735745, dtype=float32)}\n",
            "step: 258\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6209666 ,  0.8387552 , -0.00123926, -0.00551411,  0.5444795 ,\n",
            "        0.57470894,  0.4639154 ,  0.53884655,  0.5142769 ,  0.5703578 ,\n",
            "        0.01916885, -0.05149841, -0.803113  , -0.46100205,  0.5692661 ,\n",
            "       -0.34299612, -0.6571645 ,  0.36640906], dtype=float32), 'agent_1': Array([ 6.2096661e-01,  8.3875519e-01, -1.2392561e-03, -5.5141062e-03,\n",
            "        5.4447949e-01,  5.7470894e-01,  5.3884655e-01, -1.2587861e+00,\n",
            "        5.1427692e-01,  5.7035780e-01,  1.9168854e-02, -5.1498413e-02,\n",
            "       -8.0311298e-01, -4.6100205e-01,  5.6926608e-01, -3.4299612e-01,\n",
            "        1.3351808e+00, -8.7939286e-01], dtype=float32), 'agent_2': Array([ 6.2096661e-01,  8.3875519e-01, -1.2392561e-03, -5.5141062e-03,\n",
            "        5.4447949e-01,  5.7470894e-01,  5.3884655e-01,  5.1427692e-01,\n",
            "       -1.2421796e+00,  5.7035780e-01,  1.9168854e-02, -5.1498413e-02,\n",
            "       -8.0311298e-01, -4.6100205e-01,  5.6926608e-01, -3.4299612e-01,\n",
            "        2.3520575e+00, -3.9710333e+00], dtype=float32), 'agent_3': Array([ 0.6209666 ,  0.8387552 , -0.00123926, -0.00551411,  0.5444795 ,\n",
            "        0.57470894,  0.53884655,  0.5142769 ,  0.5703578 ,  0.47150242,\n",
            "        0.01916885, -0.05149841, -0.803113  , -0.46100205,  0.5692661 ,\n",
            "       -0.34299612,  0.0028452 ,  0.60121673], dtype=float32)}\n",
            "ctrl action chosen: [-0.46435997  2.267413   -0.45934096  2.265591   -0.45861527  2.256321\n",
            " -0.4633032   2.267167  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.211904, dtype=float32), 'agent_0': Array(-4.211904, dtype=float32), 'agent_1': Array(-4.211904, dtype=float32), 'agent_2': Array(-4.211904, dtype=float32), 'agent_3': Array(-4.211904, dtype=float32)}\n",
            "step: 259\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6121148 ,  0.79079735,  0.03829889, -0.02301731,  0.610445  ,\n",
            "        0.3152941 ,  0.7999439 ,  0.3773792 ,  0.36660194,  0.34747908,\n",
            "       -0.47636032,  1.0634422 ,  0.7224202 ,  0.9403636 , -1.3056971 ,\n",
            "        4.681903  , -7.798861  ,  9.313128  ], dtype=float32), 'agent_1': Array([ 0.6121148 ,  0.79079735,  0.03829889, -0.02301731,  0.610445  ,\n",
            "        0.3152941 ,  0.3773792 , -0.97722507,  0.36660194,  0.34747908,\n",
            "       -0.47636032,  1.0634422 ,  0.7224202 ,  0.9403636 , -1.3056971 ,\n",
            "        4.681903  , -5.285026  ,  6.1491127 ], dtype=float32), 'agent_2': Array([ 0.6121148 ,  0.79079735,  0.03829889, -0.02301731,  0.610445  ,\n",
            "        0.3152941 ,  0.3773792 ,  0.36660194, -0.9955103 ,  0.34747908,\n",
            "       -0.47636032,  1.0634422 ,  0.7224202 ,  0.9403636 , -1.3056971 ,\n",
            "        4.681903  , -5.461467  ,  6.1092534 ], dtype=float32), 'agent_3': Array([ 0.6121148 ,  0.79079735,  0.03829889, -0.02301731,  0.610445  ,\n",
            "        0.3152941 ,  0.3773792 ,  0.36660194,  0.34747908,  0.8164132 ,\n",
            "       -0.47636032,  1.0634422 ,  0.7224202 ,  0.9403636 , -1.3056971 ,\n",
            "        4.681903  , -7.012192  ,  8.930246  ], dtype=float32)}\n",
            "ctrl action chosen: [1.4382452  0.42744783 1.439639   0.42907533 1.4416267  0.42681348\n",
            " 1.4389004  0.42781344]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.854592, dtype=float32), 'agent_0': Array(-9.854592, dtype=float32), 'agent_1': Array(-9.854592, dtype=float32), 'agent_2': Array(-9.854592, dtype=float32), 'agent_3': Array(-9.854592, dtype=float32)}\n",
            "step: 260\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.61389023,  0.8444229 ,  0.06517513, -0.02557166,  0.53108233,\n",
            "        0.5286118 ,  1.2089143 ,  0.5809944 ,  0.5677369 ,  0.533154  ,\n",
            "       -0.3091812 ,  1.0625839 , -0.41798353,  1.0288678 , -1.1102276 ,\n",
            "       -0.68471056,  2.0259252 ,  8.384162  ], dtype=float32), 'agent_1': Array([ 0.61389023,  0.8444229 ,  0.06517513, -0.02557166,  0.53108233,\n",
            "        0.5286118 ,  0.5809944 , -0.71445704,  0.5677369 ,  0.533154  ,\n",
            "       -0.3091812 ,  1.0625839 , -0.41798353,  1.0288678 , -1.1102276 ,\n",
            "       -0.68471056, -0.47826585,  6.8778067 ], dtype=float32), 'agent_2': Array([ 0.61389023,  0.8444229 ,  0.06517513, -0.02557166,  0.53108233,\n",
            "        0.5286118 ,  0.5809944 ,  0.5677369 , -0.75039035,  0.533154  ,\n",
            "       -0.3091812 ,  1.0625839 , -0.41798353,  1.0288678 , -1.1102276 ,\n",
            "       -0.68471056,  0.23209691,  6.5428104 ], dtype=float32), 'agent_3': Array([ 0.61389023,  0.8444229 ,  0.06517513, -0.02557166,  0.53108233,\n",
            "        0.5286118 ,  0.5809944 ,  0.5677369 ,  0.533154  ,  1.1998326 ,\n",
            "       -0.3091812 ,  1.0625839 , -0.41798353,  1.0288678 , -1.1102276 ,\n",
            "       -0.68471056,  0.6309749 ,  8.407511  ], dtype=float32)}\n",
            "ctrl action chosen: [2.084232   0.02986417 2.0838954  0.03025028 2.0845172  0.02628526\n",
            " 2.0833526  0.0284902 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.0014915, dtype=float32), 'agent_0': Array(-4.0014915, dtype=float32), 'agent_1': Array(-4.0014915, dtype=float32), 'agent_2': Array(-4.0014915, dtype=float32), 'agent_3': Array(-4.0014915, dtype=float32)}\n",
            "step: 261\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58516616,  0.8486488 ,  0.07104313, -0.02066308,  0.52375674,\n",
            "        0.56798935,  1.255853  ,  0.52014184,  0.55057615,  0.55801445,\n",
            "       -0.19388199,  0.64964294, -0.7630348 , -0.20891581,  0.664245  ,\n",
            "       -0.15487142, -0.12931046, -0.7630577 ], dtype=float32), 'agent_1': Array([ 0.58516616,  0.8486488 ,  0.07104313, -0.02066308,  0.52375674,\n",
            "        0.56798935,  0.52014184, -0.4909157 ,  0.55057615,  0.55801445,\n",
            "       -0.19388199,  0.64964294, -0.7630348 , -0.20891581,  0.664245  ,\n",
            "       -0.15487142, -1.4040444 ,  0.33189422], dtype=float32), 'agent_2': Array([ 0.58516616,  0.8486488 ,  0.07104313, -0.02066308,  0.52375674,\n",
            "        0.56798935,  0.52014184,  0.55057615, -0.508211  ,  0.55801445,\n",
            "       -0.19388199,  0.64964294, -0.7630348 , -0.20891581,  0.664245  ,\n",
            "       -0.15487142, -0.96899444,  2.4491851 ], dtype=float32), 'agent_3': Array([ 0.58516616,  0.8486488 ,  0.07104313, -0.02066308,  0.52375674,\n",
            "        0.56798935,  0.52014184,  0.55057615,  0.55801445,  1.2556905 ,\n",
            "       -0.19388199,  0.64964294, -0.7630348 , -0.20891581,  0.664245  ,\n",
            "       -0.15487142,  0.2321797 , -0.6144239 ], dtype=float32)}\n",
            "ctrl action chosen: [0.4110797  1.3429924  0.41006407 1.3463296  0.41095698 1.3435719\n",
            " 0.41136295 1.3421639 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.905181, dtype=float32), 'agent_0': Array(-7.905181, dtype=float32), 'agent_1': Array(-7.905181, dtype=float32), 'agent_2': Array(-7.905181, dtype=float32), 'agent_3': Array(-7.905181, dtype=float32)}\n",
            "step: 262\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54405224,  0.850019  ,  0.06153278, -0.01308005,  0.52298236,\n",
            "        0.5335388 ,  1.2405326 ,  0.4936707 ,  0.52697   ,  0.54713345,\n",
            "       -0.82740784,  0.35390854, -0.51169395, -0.4328699 ,  0.8389732 ,\n",
            "       -0.8600617 , -0.16684747, -1.0479032 ], dtype=float32), 'agent_1': Array([ 0.54405224,  0.850019  ,  0.06153278, -0.01308005,  0.52298236,\n",
            "        0.5335388 ,  0.4936707 , -0.47061735,  0.52697   ,  0.54713345,\n",
            "       -0.82740784,  0.35390854, -0.51169395, -0.4328699 ,  0.8389732 ,\n",
            "       -0.8600617 ,  1.282365  , -0.7144666 ], dtype=float32), 'agent_2': Array([ 0.54405224,  0.850019  ,  0.06153278, -0.01308005,  0.52298236,\n",
            "        0.5335388 ,  0.4936707 ,  0.52697   , -0.46934345,  0.54713345,\n",
            "       -0.82740784,  0.35390854, -0.51169395, -0.4328699 ,  0.8389732 ,\n",
            "       -0.8600617 ,  0.5955988 , -0.33686244], dtype=float32), 'agent_3': Array([ 0.54405224,  0.850019  ,  0.06153278, -0.01308005,  0.52298236,\n",
            "        0.5335388 ,  0.4936707 ,  0.52697   ,  0.54713345,  1.2433082 ,\n",
            "       -0.82740784,  0.35390854, -0.51169395, -0.4328699 ,  0.8389732 ,\n",
            "       -0.8600617 ,  0.26504585, -1.0514731 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.3556747  -0.23271777 -1.3529826  -0.23380205 -1.3520489  -0.23518789\n",
            " -1.3554245  -0.23380601]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.47332, dtype=float32), 'agent_0': Array(-3.47332, dtype=float32), 'agent_1': Array(-3.47332, dtype=float32), 'agent_2': Array(-3.47332, dtype=float32), 'agent_3': Array(-3.47332, dtype=float32)}\n",
            "step: 263\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4516757e-01,  7.1679533e-01,  2.7785454e-02, -2.4496578e-03,\n",
            "        6.9672555e-01, -5.9398174e-02,  1.0544201e+00, -4.2465862e-02,\n",
            "       -1.8695097e-02, -1.3849142e-02, -1.1423588e+00, -3.5934448e-01,\n",
            "        2.6295185e-01, -4.1100189e-01,  1.2915671e+00,  1.1735738e+01,\n",
            "       -1.5804172e+01, -3.6124685e+00], dtype=float32), 'agent_1': Array([ 5.4516757e-01,  7.1679533e-01,  2.7785454e-02, -2.4496578e-03,\n",
            "        6.9672555e-01, -5.9398174e-02, -4.2465862e-02, -6.4385277e-01,\n",
            "       -1.8695097e-02, -1.3849142e-02, -1.1423588e+00, -3.5934448e-01,\n",
            "        2.6295185e-01, -4.1100189e-01,  1.2915671e+00,  1.1735738e+01,\n",
            "       -1.4695976e+01, -4.1627555e+00], dtype=float32), 'agent_2': Array([ 5.4516757e-01,  7.1679533e-01,  2.7785454e-02, -2.4496578e-03,\n",
            "        6.9672555e-01, -5.9398174e-02, -4.2465862e-02, -1.8695097e-02,\n",
            "       -6.1672342e-01, -1.3849142e-02, -1.1423588e+00, -3.5934448e-01,\n",
            "        2.6295185e-01, -4.1100189e-01,  1.2915671e+00,  1.1735738e+01,\n",
            "       -1.4690830e+01, -3.8081088e+00], dtype=float32), 'agent_3': Array([ 5.4516757e-01,  7.1679533e-01,  2.7785454e-02, -2.4496578e-03,\n",
            "        6.9672555e-01, -5.9398174e-02, -4.2465862e-02, -1.8695097e-02,\n",
            "       -1.3849142e-02,  1.0745807e+00, -1.1423588e+00, -3.5934448e-01,\n",
            "        2.6295185e-01, -4.1100189e-01,  1.2915671e+00,  1.1735738e+01,\n",
            "       -1.5494214e+01, -2.7277656e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.50732887  1.2688018  -0.5089932   1.2683873  -0.5089033   1.2673424\n",
            " -0.5080844   1.268097  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.829914, dtype=float32), 'agent_0': Array(-3.829914, dtype=float32), 'agent_1': Array(-3.829914, dtype=float32), 'agent_2': Array(-3.829914, dtype=float32), 'agent_3': Array(-3.829914, dtype=float32)}\n",
            "step: 264\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.549543  ,  0.57337487,  0.02394648, -0.0428185 ,  0.81782293,\n",
            "       -0.5840744 ,  1.2522452 , -0.5410182 , -0.5292561 , -0.5625969 ,\n",
            "       -0.68421364, -0.0462532 , -0.20321608, -1.7658274 , -1.3148562 ,\n",
            "        0.52371025, -0.51545686,  5.1425323 ], dtype=float32), 'agent_1': Array([ 0.549543  ,  0.57337487,  0.02394648, -0.0428185 ,  0.81782293,\n",
            "       -0.5840744 , -0.5410182 , -0.48657945, -0.5292561 , -0.5625969 ,\n",
            "       -0.68421364, -0.0462532 , -0.20321608, -1.7658274 , -1.3148562 ,\n",
            "        0.52371025, -1.4438599 ,  4.696325  ], dtype=float32), 'agent_2': Array([ 0.549543  ,  0.57337487,  0.02394648, -0.0428185 ,  0.81782293,\n",
            "       -0.5840744 , -0.5410182 , -0.5292561 , -0.4847601 , -0.5625969 ,\n",
            "       -0.68421364, -0.0462532 , -0.20321608, -1.7658274 , -1.3148562 ,\n",
            "        0.52371025, -2.4758422 ,  3.3896077 ], dtype=float32), 'agent_3': Array([ 0.549543  ,  0.57337487,  0.02394648, -0.0428185 ,  0.81782293,\n",
            "       -0.5840744 , -0.5410182 , -0.5292561 , -0.5625969 ,  1.2478727 ,\n",
            "       -0.68421364, -0.0462532 , -0.20321608, -1.7658274 , -1.3148562 ,\n",
            "        0.52371025, -2.0083265 ,  3.7595751 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.08257835 -0.47420144 -0.08424268 -0.47439262 -0.08559487 -0.47462544\n",
            " -0.08232502 -0.47447383]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6844015, dtype=float32), 'agent_0': Array(-3.6844015, dtype=float32), 'agent_1': Array(-3.6844015, dtype=float32), 'agent_2': Array(-3.6844015, dtype=float32), 'agent_3': Array(-3.6844015, dtype=float32)}\n",
            "step: 265\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.55960876,  0.6000022 ,  0.0029159 , -0.03063927,  0.7994062 ,\n",
            "       -0.50376356,  1.1458044 , -0.5226688 , -0.52999127, -0.531609  ,\n",
            "       -0.8893013 , -1.2979507 ,  0.91530085, -0.11912206,  0.46758088,\n",
            "       -0.98226863,  1.7635174 , -1.7045884 ], dtype=float32), 'agent_1': Array([ 0.55960876,  0.6000022 ,  0.0029159 , -0.03063927,  0.7994062 ,\n",
            "       -0.50376356, -0.5226688 , -0.59856397, -0.52999127, -0.531609  ,\n",
            "       -0.8893013 , -1.2979507 ,  0.91530085, -0.11912206,  0.46758088,\n",
            "       -0.98226863,  0.02154915, -2.8164763 ], dtype=float32), 'agent_2': Array([ 0.55960876,  0.6000022 ,  0.0029159 , -0.03063927,  0.7994062 ,\n",
            "       -0.50376356, -0.5226688 , -0.52999127, -0.6196612 , -0.531609  ,\n",
            "       -0.8893013 , -1.2979507 ,  0.91530085, -0.11912206,  0.46758088,\n",
            "       -0.98226863,  0.02288943, -2.7771773 ], dtype=float32), 'agent_3': Array([ 0.55960876,  0.6000022 ,  0.0029159 , -0.03063927,  0.7994062 ,\n",
            "       -0.50376356, -0.5226688 , -0.52999127, -0.531609  ,  1.1388829 ,\n",
            "       -0.8893013 , -1.2979507 ,  0.91530085, -0.11912206,  0.46758088,\n",
            "       -0.98226863,  1.1010144 , -2.2325354 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7144307   0.64730126 -0.71813214  0.6467596  -0.7180623   0.6463804\n",
            " -0.71709794  0.64892584]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.29306534, dtype=float32), 'agent_0': Array(-0.29306534, dtype=float32), 'agent_1': Array(-0.29306534, dtype=float32), 'agent_2': Array(-0.29306534, dtype=float32), 'agent_3': Array(-0.29306534, dtype=float32)}\n",
            "step: 266\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5965484 ,  0.60348177,  0.01155058, -0.07118058,  0.7941094 ,\n",
            "       -0.5368978 ,  1.2583913 , -0.55488807, -0.5522257 , -0.52733004,\n",
            "       -0.78954697, -1.0026932 ,  0.4018426 , -0.8686955 , -0.71361905,\n",
            "       -0.54736406, -0.85359377, -0.25483516], dtype=float32), 'agent_1': Array([ 0.5965484 ,  0.60348177,  0.01155058, -0.07118058,  0.7941094 ,\n",
            "       -0.5368978 , -0.55488807, -0.4923068 , -0.5522257 , -0.52733004,\n",
            "       -0.78954697, -1.0026932 ,  0.4018426 , -0.8686955 , -0.71361905,\n",
            "       -0.54736406,  0.1254707 ,  1.2206868 ], dtype=float32), 'agent_2': Array([ 0.5965484 ,  0.60348177,  0.01155058, -0.07118058,  0.7941094 ,\n",
            "       -0.5368978 , -0.55488807, -0.5522257 , -0.48682052, -0.52733004,\n",
            "       -0.78954697, -1.0026932 ,  0.4018426 , -0.8686955 , -0.71361905,\n",
            "       -0.54736406, -0.08140704,  0.8587734 ], dtype=float32), 'agent_3': Array([ 0.5965484 ,  0.60348177,  0.01155058, -0.07118058,  0.7941094 ,\n",
            "       -0.5368978 , -0.55488807, -0.5522257 , -0.52733004,  1.2624054 ,\n",
            "       -0.78954697, -1.0026932 ,  0.4018426 , -0.8686955 , -0.71361905,\n",
            "       -0.54736406, -0.12009353,  0.38893223], dtype=float32)}\n",
            "ctrl action chosen: [0.20987852 1.2927779  0.20819257 1.2934767  0.20729706 1.2929591\n",
            " 0.20969371 1.294038  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.5984247, dtype=float32), 'agent_0': Array(-1.5984247, dtype=float32), 'agent_1': Array(-1.5984247, dtype=float32), 'agent_2': Array(-1.5984247, dtype=float32), 'agent_3': Array(-1.5984247, dtype=float32)}\n",
            "step: 267\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6014046 ,  0.65514255,  0.01354956, -0.08357335,  0.7507465 ,\n",
            "       -0.44960576,  1.2652684 , -0.40398616, -0.41228846, -0.40120912,\n",
            "       -0.8814812 , -1.1099815 , -0.08326769, -0.5716767 , -0.36528954,\n",
            "       -3.5921607 ,  2.8601606 ,  0.02824801], dtype=float32), 'agent_1': Array([ 0.6014046 ,  0.65514255,  0.01354956, -0.08357335,  0.7507465 ,\n",
            "       -0.44960576, -0.40398616, -0.4806709 , -0.41228846, -0.40120912,\n",
            "       -0.8814812 , -1.1099815 , -0.08326769, -0.5716767 , -0.36528954,\n",
            "       -3.5921607 ,  4.2117567 ,  0.16953994], dtype=float32), 'agent_2': Array([ 0.6014046 ,  0.65514255,  0.01354956, -0.08357335,  0.7507465 ,\n",
            "       -0.44960576, -0.40398616, -0.41228846, -0.4800998 , -0.40120912,\n",
            "       -0.8814812 , -1.1099815 , -0.08326769, -0.5716767 , -0.36528954,\n",
            "       -3.5921607 ,  4.0672383 ,  0.28666452], dtype=float32), 'agent_3': Array([ 0.6014046 ,  0.65514255,  0.01354956, -0.08357335,  0.7507465 ,\n",
            "       -0.44960576, -0.40398616, -0.41228846, -0.40120912,  1.2611898 ,\n",
            "       -0.8814812 , -1.1099815 , -0.08326769, -0.5716767 , -0.36528954,\n",
            "       -3.5921607 ,  3.404467  , -0.20877028], dtype=float32)}\n",
            "ctrl action chosen: [-0.05641062 -0.23025855 -0.0598203  -0.23068449 -0.05971891 -0.23068681\n",
            " -0.05940412 -0.23041075]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.30237, dtype=float32), 'agent_0': Array(-3.30237, dtype=float32), 'agent_1': Array(-3.30237, dtype=float32), 'agent_2': Array(-3.30237, dtype=float32), 'agent_3': Array(-3.30237, dtype=float32)}\n",
            "step: 268\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58759815,  0.68213964,  0.00554847, -0.08120943,  0.72667724,\n",
            "       -0.43710914,  1.1452913 , -0.33786494, -0.34730154, -0.35436615,\n",
            "       -0.86011887, -1.1590004 , -0.484097  , -0.3303741 ,  0.1353107 ,\n",
            "       -0.5157094 , -0.8366464 , -2.4570098 ], dtype=float32), 'agent_1': Array([ 0.58759815,  0.68213964,  0.00554847, -0.08120943,  0.72667724,\n",
            "       -0.43710914, -0.33786494, -0.5814263 , -0.34730154, -0.35436615,\n",
            "       -0.86011887, -1.1590004 , -0.484097  , -0.3303741 ,  0.1353107 ,\n",
            "       -0.5157094 ,  0.12108593, -1.8237139 ], dtype=float32), 'agent_2': Array([ 0.58759815,  0.68213964,  0.00554847, -0.08120943,  0.72667724,\n",
            "       -0.43710914, -0.33786494, -0.34730154, -0.58072644, -0.35436615,\n",
            "       -0.86011887, -1.1590004 , -0.484097  , -0.3303741 ,  0.1353107 ,\n",
            "       -0.5157094 ,  0.16768919, -1.847745  ], dtype=float32), 'agent_3': Array([ 0.58759815,  0.68213964,  0.00554847, -0.08120943,  0.72667724,\n",
            "       -0.43710914, -0.33786494, -0.34730154, -0.35436615,  1.1394589 ,\n",
            "       -0.86011887, -1.1590004 , -0.484097  , -0.3303741 ,  0.1353107 ,\n",
            "       -0.5157094 , -0.06236471, -2.271643  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0716057  -0.1522482  -1.0717098  -0.1528089  -1.0714812  -0.15398246\n",
            " -1.0714498  -0.15214527]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.00517317, dtype=float32), 'agent_0': Array(0.00517317, dtype=float32), 'agent_1': Array(0.00517317, dtype=float32), 'agent_2': Array(0.00517317, dtype=float32), 'agent_3': Array(0.00517317, dtype=float32)}\n",
            "step: 269\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5558629 ,  0.63827145, -0.00855434, -0.07893395,  0.7657062 ,\n",
            "       -0.5715335 ,  1.0066787 , -0.5538675 , -0.5479506 , -0.5555905 ,\n",
            "       -0.84557533, -1.0602951 , -0.46862364,  0.30762297,  0.7125566 ,\n",
            "       -0.87103486,  1.2213992 , -3.2863321 ], dtype=float32), 'agent_1': Array([ 0.5558629 ,  0.63827145, -0.00855434, -0.07893395,  0.7657062 ,\n",
            "       -0.5715335 , -0.5538675 , -0.65480256, -0.5479506 , -0.5555905 ,\n",
            "       -0.84557533, -1.0602951 , -0.46862364,  0.30762297,  0.7125566 ,\n",
            "       -0.87103486, -1.1703826 , -1.236179  ], dtype=float32), 'agent_2': Array([ 0.5558629 ,  0.63827145, -0.00855434, -0.07893395,  0.7657062 ,\n",
            "       -0.5715335 , -0.5538675 , -0.5479506 , -0.6930698 , -0.5555905 ,\n",
            "       -0.84557533, -1.0602951 , -0.46862364,  0.30762297,  0.7125566 ,\n",
            "       -0.87103486, -0.6195569 , -2.910407  ], dtype=float32), 'agent_3': Array([ 0.5558629 ,  0.63827145, -0.00855434, -0.07893395,  0.7657062 ,\n",
            "       -0.5715335 , -0.5538675 , -0.5479506 , -0.5555905 ,  1.0144248 ,\n",
            "       -0.84557533, -1.0602951 , -0.46862364,  0.30762297,  0.7125566 ,\n",
            "       -0.87103486, -0.45441616, -3.2824259 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5465296  -0.60437053  0.5413257  -0.60155135  0.54407585 -0.6040724\n",
            "  0.54467696 -0.6030095 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.131242, dtype=float32), 'agent_0': Array(-2.131242, dtype=float32), 'agent_1': Array(-2.131242, dtype=float32), 'agent_2': Array(-2.131242, dtype=float32), 'agent_3': Array(-2.131242, dtype=float32)}\n",
            "step: 270\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3756899e-01,  7.3704326e-01, -1.6360348e-02, -3.3442445e-02,\n",
            "        6.7481947e-01, -1.9377333e-01,  7.0892322e-01, -2.9620802e-01,\n",
            "       -2.9365519e-01, -2.8892970e-01,  8.7261200e-03, -1.2828827e+00,\n",
            "       -1.5941858e-01,  9.7476226e-01,  2.3756709e+00, -7.5086699e+00,\n",
            "        1.0686296e+01, -6.8531585e+00], dtype=float32), 'agent_1': Array([ 0.537569  ,  0.73704326, -0.01636035, -0.03344245,  0.67481947,\n",
            "       -0.19377333, -0.29620802, -0.87247384, -0.2936552 , -0.2889297 ,\n",
            "        0.00872612, -1.2828827 , -0.15941858,  0.97476226,  2.375671  ,\n",
            "       -7.50867   ,  8.618813  , -5.6148367 ], dtype=float32), 'agent_2': Array([ 0.537569  ,  0.73704326, -0.01636035, -0.03344245,  0.67481947,\n",
            "       -0.19377333, -0.29620802, -0.2936552 , -1.009725  , -0.2889297 ,\n",
            "        0.00872612, -1.2828827 , -0.15941858,  0.97476226,  2.375671  ,\n",
            "       -7.50867   ,  7.8157063 , -7.275227  ], dtype=float32), 'agent_3': Array([ 0.537569  ,  0.73704326, -0.01636035, -0.03344245,  0.67481947,\n",
            "       -0.19377333, -0.29620802, -0.2936552 , -0.2889297 ,  0.68354297,\n",
            "        0.00872612, -1.2828827 , -0.15941858,  0.97476226,  2.375671  ,\n",
            "       -7.50867   ,  8.462085  , -7.873227  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.03314598 -0.7019477  -0.03394346 -0.7021369  -0.03459841 -0.7035529\n",
            " -0.03598675 -0.70386785]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.7511537, dtype=float32), 'agent_0': Array(-0.7511537, dtype=float32), 'agent_1': Array(-0.7511537, dtype=float32), 'agent_2': Array(-0.7511537, dtype=float32), 'agent_3': Array(-0.7511537, dtype=float32)}\n",
            "step: 271\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54872864,  0.7880347 , -0.04319378,  0.02054443,  0.6137701 ,\n",
            "        0.05849176,  0.45258388, -0.14964654, -0.13749668, -0.14253527,\n",
            "        0.09260178, -0.87337494,  0.3610611 ,  0.8734271 ,  0.915628  ,\n",
            "       -1.5885382 ,  3.2190175 ,  0.56279474], dtype=float32), 'agent_1': Array([ 0.54872864,  0.7880347 , -0.04319378,  0.02054443,  0.6137701 ,\n",
            "        0.05849176, -0.14964654, -1.1654531 , -0.13749668, -0.14253527,\n",
            "        0.09260178, -0.87337494,  0.3610611 ,  0.8734271 ,  0.915628  ,\n",
            "       -1.5885382 ,  0.56248593, -5.2389455 ], dtype=float32), 'agent_2': Array([ 0.54872864,  0.7880347 , -0.04319378,  0.02054443,  0.6137701 ,\n",
            "        0.05849176, -0.14964654, -0.13749668, -1.2840266 , -0.14253527,\n",
            "        0.09260178, -0.87337494,  0.3610611 ,  0.8734271 ,  0.915628  ,\n",
            "       -1.5885382 ,  1.8375136 ,  0.3631027 ], dtype=float32), 'agent_3': Array([ 0.54872864,  0.7880347 , -0.04319378,  0.02054443,  0.6137701 ,\n",
            "        0.05849176, -0.14964654, -0.13749668, -0.14253527,  0.45766076,\n",
            "        0.09260178, -0.87337494,  0.3610611 ,  0.8734271 ,  0.915628  ,\n",
            "       -1.5885382 ,  0.8161897 ,  0.8906785 ], dtype=float32)}\n",
            "ctrl action chosen: [-2.202944  -1.135654  -2.209495  -1.1394773 -2.2036583 -1.1382518\n",
            " -2.2072654 -1.1342527]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.21670443, dtype=float32), 'agent_0': Array(0.21670443, dtype=float32), 'agent_1': Array(0.21670443, dtype=float32), 'agent_2': Array(0.21670443, dtype=float32), 'agent_3': Array(0.21670443, dtype=float32)}\n",
            "step: 272\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5849764 ,  0.675794  , -0.02995094,  0.06144062,  0.73391455,\n",
            "       -0.3236546 ,  0.47534025, -0.60085285, -0.55387306, -0.59462535,\n",
            "       -0.08120537, -0.7771492 ,  0.6485343 ,  0.8539018 ,  0.7848526 ,\n",
            "        1.5501388 , -3.9232724 ,  0.52392226], dtype=float32), 'agent_1': Array([ 0.5849764 ,  0.675794  , -0.02995094,  0.06144062,  0.73391455,\n",
            "       -0.3236546 , -0.60085285, -1.2817278 , -0.55387306, -0.59462535,\n",
            "       -0.08120537, -0.7771492 ,  0.6485343 ,  0.8539018 ,  0.7848526 ,\n",
            "        1.5501388 , -1.2641041 , -0.18634135], dtype=float32), 'agent_2': Array([ 0.5849764 ,  0.675794  , -0.02995094,  0.06144062,  0.73391455,\n",
            "       -0.3236546 , -0.60085285, -0.55387306, -1.2688004 , -0.59462535,\n",
            "       -0.08120537, -0.7771492 ,  0.6485343 ,  0.8539018 ,  0.7848526 ,\n",
            "        1.5501388 , -2.5663743 ,  0.10937898], dtype=float32), 'agent_3': Array([ 0.5849764 ,  0.675794  , -0.02995094,  0.06144062,  0.73391455,\n",
            "       -0.3236546 , -0.60085285, -0.55387306, -0.59462535,  0.47200403,\n",
            "       -0.08120537, -0.7771492 ,  0.6485343 ,  0.8539018 ,  0.7848526 ,\n",
            "        1.5501388 , -1.7080871 ,  1.470782  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5680522   2.0752182  -0.56578946  2.072181   -0.56626964  2.071596\n",
            " -0.56588626  2.074417  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-11.378112, dtype=float32), 'agent_0': Array(-11.378112, dtype=float32), 'agent_1': Array(-11.378112, dtype=float32), 'agent_2': Array(-11.378112, dtype=float32), 'agent_3': Array(-11.378112, dtype=float32)}\n",
            "step: 273\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5988828 ,  0.6872525 , -0.01063974,  0.04261371,  0.7250896 ,\n",
            "       -0.4234858 ,  0.85876024, -0.5325808 , -0.55203354, -0.54333186,\n",
            "       -0.05869865, -0.5876541 , -0.07870197, -0.31690943, -1.8100404 ,\n",
            "       -0.3214305 , -2.7114506 , 10.508618  ], dtype=float32), 'agent_1': Array([ 0.5988828 ,  0.6872525 , -0.01063974,  0.04261371,  0.7250896 ,\n",
            "       -0.4234858 , -0.5325808 , -1.0604339 , -0.55203354, -0.54333186,\n",
            "       -0.05869865, -0.5876541 , -0.07870197, -0.31690943, -1.8100404 ,\n",
            "       -0.3214305 ,  1.7717521 ,  6.9572654 ], dtype=float32), 'agent_2': Array([ 0.5988828 ,  0.6872525 , -0.01063974,  0.04261371,  0.7250896 ,\n",
            "       -0.4234858 , -0.5325808 , -0.55203354, -0.93346196, -0.54333186,\n",
            "       -0.05869865, -0.5876541 , -0.07870197, -0.31690943, -1.8100404 ,\n",
            "       -0.3214305 ,  0.53364635,  9.614352  ], dtype=float32), 'agent_3': Array([ 5.98882794e-01,  6.87252522e-01, -1.06397411e-02,  4.26137149e-02,\n",
            "        7.25089610e-01, -4.23485786e-01, -5.32580793e-01, -5.52033544e-01,\n",
            "       -5.43331861e-01,  9.13721442e-01, -5.86986542e-02, -5.87654114e-01,\n",
            "       -7.87019730e-02, -3.16909432e-01, -1.81004035e+00, -3.21430504e-01,\n",
            "        1.39060128e+00,  1.19477825e+01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9557373  -0.5547559   0.95773476 -0.55358887  0.9559106  -0.5547435\n",
            "  0.95524037 -0.5545292 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.291596, dtype=float32), 'agent_0': Array(-8.291596, dtype=float32), 'agent_1': Array(-8.291596, dtype=float32), 'agent_2': Array(-8.291596, dtype=float32), 'agent_3': Array(-8.291596, dtype=float32)}\n",
            "step: 274\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.61103547,   0.85361826,  -0.01675529,   0.04058414,\n",
            "         0.5190453 ,   0.07513875,   1.0094931 ,   0.16599935,\n",
            "         0.08529177,   0.12475936,  -0.12669563,  -0.65050125,\n",
            "         0.8666754 ,   0.02197356,   0.23316114, -12.545144  ,\n",
            "        12.856611  ,   0.22665161], dtype=float32), 'agent_1': Array([  0.61103547,   0.85361826,  -0.01675529,   0.04058414,\n",
            "         0.5190453 ,   0.07513875,   0.16599935,  -0.95070183,\n",
            "         0.08529177,   0.12475936,  -0.12669563,  -0.65050125,\n",
            "         0.8666754 ,   0.02197356,   0.23316114, -12.545144  ,\n",
            "        16.269182  ,   0.96734744], dtype=float32), 'agent_2': Array([  0.61103547,   0.85361826,  -0.01675529,   0.04058414,\n",
            "         0.5190453 ,   0.07513875,   0.16599935,   0.08529177,\n",
            "        -0.78549737,   0.12475936,  -0.12669563,  -0.65050125,\n",
            "         0.8666754 ,   0.02197356,   0.23316114, -12.545144  ,\n",
            "        15.587763  ,   0.6702244 ], dtype=float32), 'agent_3': Array([  0.61103547,   0.85361826,  -0.01675529,   0.04058414,\n",
            "         0.5190453 ,   0.07513875,   0.16599935,   0.08529177,\n",
            "         0.12475936,   1.0412697 ,  -0.12669563,  -0.65050125,\n",
            "         0.8666754 ,   0.02197356,   0.23316114, -12.545144  ,\n",
            "        16.305525  ,  -1.3845534 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.12600298 -0.93750787  0.12546857 -0.9374035   0.12497453 -0.9378384\n",
            "  0.12259779 -0.9384324 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4344628, dtype=float32), 'agent_0': Array(-1.4344628, dtype=float32), 'agent_1': Array(-1.4344628, dtype=float32), 'agent_2': Array(-1.4344628, dtype=float32), 'agent_3': Array(-1.4344628, dtype=float32)}\n",
            "step: 275\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6444062 ,  0.91525805, -0.04428462,  0.07150356,  0.39399084,\n",
            "        0.32680795,  0.78540397,  0.5572008 ,  0.45365685,  0.5522039 ,\n",
            "       -0.32138824, -0.929451  ,  0.3875494 , -0.90395457,  2.8163548 ,\n",
            "       -2.802114  ,  1.7477518 , -8.083114  ], dtype=float32), 'agent_1': Array([ 0.6444062 ,  0.91525805, -0.04428462,  0.07150356,  0.39399084,\n",
            "        0.32680795,  0.5572008 , -1.1653436 ,  0.45365685,  0.5522039 ,\n",
            "       -0.32138824, -0.929451  ,  0.3875494 , -0.90395457,  2.8163548 ,\n",
            "       -2.802114  ,  3.2575855 , -8.503808  ], dtype=float32), 'agent_2': Array([ 0.6444062 ,  0.91525805, -0.04428462,  0.07150356,  0.39399084,\n",
            "        0.32680795,  0.5572008 ,  0.45365685, -0.97899234,  0.5522039 ,\n",
            "       -0.32138824, -0.929451  ,  0.3875494 , -0.90395457,  2.8163548 ,\n",
            "       -2.802114  ,  3.9903805 , -7.270845  ], dtype=float32), 'agent_3': Array([  0.6444062 ,   0.91525805,  -0.04428462,   0.07150356,\n",
            "         0.39399084,   0.32680795,   0.5572008 ,   0.45365685,\n",
            "         0.5522039 ,   0.6971179 ,  -0.32138824,  -0.929451  ,\n",
            "         0.3875494 ,  -0.90395457,   2.8163548 ,  -2.802114  ,\n",
            "         4.0415673 , -10.225963  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.2743313  -1.0963856  -0.27552924 -1.0940735  -0.27356157 -1.0973766\n",
            " -0.2742191  -1.0963472 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1162071, dtype=float32), 'agent_0': Array(-1.1162071, dtype=float32), 'agent_1': Array(-1.1162071, dtype=float32), 'agent_2': Array(-1.1162071, dtype=float32), 'agent_3': Array(-1.1162071, dtype=float32)}\n",
            "step: 276\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.64404666,  0.8854515 , -0.08510333,  0.10100652,  0.44556782,\n",
            "        0.13876045,  0.42019558,  0.4078215 ,  0.36726943,  0.41612303,\n",
            "       -0.09431839, -0.43058395, -0.2675414 ,  0.16475886, -0.9279876 ,\n",
            "        3.6328888 , -4.867386  ,  1.2427349 ], dtype=float32), 'agent_1': Array([ 0.64404666,  0.8854515 , -0.08510333,  0.10100652,  0.44556782,\n",
            "        0.13876045,  0.4078215 , -1.293906  ,  0.36726943,  0.41612303,\n",
            "       -0.09431839, -0.43058395, -0.2675414 ,  0.16475886, -0.9279876 ,\n",
            "        3.6328888 , -4.7481856 ,  1.3358042 ], dtype=float32), 'agent_2': Array([ 0.64404666,  0.8854515 , -0.08510333,  0.10100652,  0.44556782,\n",
            "        0.13876045,  0.4078215 ,  0.36726943, -1.3240405 ,  0.41612303,\n",
            "       -0.09431839, -0.43058395, -0.2675414 ,  0.16475886, -0.9279876 ,\n",
            "        3.6328888 , -3.2435362 ,  0.5997581 ], dtype=float32), 'agent_3': Array([ 0.64404666,  0.8854515 , -0.08510333,  0.10100652,  0.44556782,\n",
            "        0.13876045,  0.4078215 ,  0.36726943,  0.41612303,  0.44879806,\n",
            "       -0.09431839, -0.43058395, -0.2675414 ,  0.16475886, -0.9279876 ,\n",
            "        3.6328888 , -4.618578  ,  1.8354498 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.37588271  1.5727661  -0.37466416  1.5749445  -0.3705779   1.5691608\n",
            " -0.37525514  1.5734081 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.745089, dtype=float32), 'agent_0': Array(-1.745089, dtype=float32), 'agent_1': Array(-1.745089, dtype=float32), 'agent_2': Array(-1.745089, dtype=float32), 'agent_3': Array(-1.745089, dtype=float32)}\n",
            "step: 277\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.3049096e-01,  8.2754314e-01, -3.2458782e-02,  6.8492934e-02,\n",
            "        5.5626202e-01, -2.0232069e-01,  7.6662093e-01,  1.0220067e-01,\n",
            "        7.3997587e-02,  9.4511747e-02, -7.6055527e-02, -1.7757416e-01,\n",
            "       -4.5223236e-01, -3.8940406e-03, -2.4069076e+00,  5.4927592e+00,\n",
            "       -7.0717292e+00,  8.6515188e+00], dtype=float32), 'agent_1': Array([ 6.3049096e-01,  8.2754314e-01, -3.2458782e-02,  6.8492934e-02,\n",
            "        5.5626202e-01, -2.0232069e-01,  1.0220067e-01, -9.2422181e-01,\n",
            "        7.3997587e-02,  9.4511747e-02, -7.6055527e-02, -1.7757416e-01,\n",
            "       -4.5223236e-01, -3.8940406e-03, -2.4069076e+00,  5.4927592e+00,\n",
            "       -6.2926126e+00,  1.0227274e+01], dtype=float32), 'agent_2': Array([ 6.3049096e-01,  8.2754314e-01, -3.2458782e-02,  6.8492934e-02,\n",
            "        5.5626202e-01, -2.0232069e-01,  1.0220067e-01,  7.3997587e-02,\n",
            "       -1.0201066e+00,  9.4511747e-02, -7.6055527e-02, -1.7757416e-01,\n",
            "       -4.5223236e-01, -3.8940406e-03, -2.4069076e+00,  5.4927592e+00,\n",
            "       -6.5507832e+00,  7.7971783e+00], dtype=float32), 'agent_3': Array([ 6.3049096e-01,  8.2754314e-01, -3.2458782e-02,  6.8492934e-02,\n",
            "        5.5626202e-01, -2.0232069e-01,  1.0220067e-01,  7.3997587e-02,\n",
            "        9.4511747e-02,  7.3640782e-01, -7.6055527e-02, -1.7757416e-01,\n",
            "       -4.5223236e-01, -3.8940406e-03, -2.4069076e+00,  5.4927592e+00,\n",
            "       -7.1747909e+00,  7.9186249e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.6315778  -0.7541134  -0.6309434  -0.7524302  -0.63050073 -0.75507504\n",
            " -0.63229746 -0.75489193]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.330601, dtype=float32), 'agent_0': Array(-4.330601, dtype=float32), 'agent_1': Array(-4.330601, dtype=float32), 'agent_2': Array(-4.330601, dtype=float32), 'agent_3': Array(-4.330601, dtype=float32)}\n",
            "step: 278\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5970003 ,  0.71454865, -0.01848361,  0.06459184,  0.6963524 ,\n",
            "       -0.61338997,  0.80192727, -0.36630607, -0.35085744, -0.40692538,\n",
            "        0.22573471, -0.63352585, -0.0772953 , -0.36839363, -0.01931494,\n",
            "        4.6328287 , -2.8575277 , -2.848324  ], dtype=float32), 'agent_1': Array([ 0.5970003 ,  0.71454865, -0.01848361,  0.06459184,  0.6963524 ,\n",
            "       -0.61338997, -0.36630607, -0.7939035 , -0.35085744, -0.40692538,\n",
            "        0.22573471, -0.63352585, -0.0772953 , -0.36839363, -0.01931494,\n",
            "        4.6328287 , -7.418371  ,  0.6151544 ], dtype=float32), 'agent_2': Array([ 0.5970003 ,  0.71454865, -0.01848361,  0.06459184,  0.6963524 ,\n",
            "       -0.61338997, -0.36630607, -0.35085744, -0.9720213 , -0.40692538,\n",
            "        0.22573471, -0.63352585, -0.0772953 , -0.36839363, -0.01931494,\n",
            "        4.6328287 , -6.0993867 , -1.0935674 ], dtype=float32), 'agent_3': Array([ 0.5970003 ,  0.71454865, -0.01848361,  0.06459184,  0.6963524 ,\n",
            "       -0.61338997, -0.36630607, -0.35085744, -0.40692538,  0.7659837 ,\n",
            "        0.22573471, -0.63352585, -0.0772953 , -0.36839363, -0.01931494,\n",
            "        4.6328287 , -7.996464  , -2.156973  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.04129448  0.27557063 -0.04233624  0.28023425 -0.04152419  0.27775356\n",
            " -0.04113979  0.27826542]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.99768424, dtype=float32), 'agent_0': Array(-0.99768424, dtype=float32), 'agent_1': Array(-0.99768424, dtype=float32), 'agent_2': Array(-0.99768424, dtype=float32), 'agent_3': Array(-0.99768424, dtype=float32)}\n",
            "step: 279\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5718953 ,  0.7070656 , -0.00902405,  0.0200236 ,  0.7068069 ,\n",
            "       -0.5088515 ,  0.89553595, -0.49000713, -0.40411216, -0.53878105,\n",
            "        0.45833588, -0.22764206, -0.7204652 , -0.75782496, -1.4013962 ,\n",
            "       -0.01373057,  3.0546205 ,  2.042592  ], dtype=float32), 'agent_1': Array([ 0.5718953 ,  0.7070656 , -0.00902405,  0.0200236 ,  0.7068069 ,\n",
            "       -0.5088515 , -0.49000713, -0.56656826, -0.40411216, -0.53878105,\n",
            "        0.45833588, -0.22764206, -0.7204652 , -0.75782496, -1.4013962 ,\n",
            "       -0.01373057, -1.3681953 ,  3.9177358 ], dtype=float32), 'agent_2': Array([ 0.5718953 ,  0.7070656 , -0.00902405,  0.0200236 ,  0.7068069 ,\n",
            "       -0.5088515 , -0.49000713, -0.40411216, -0.823803  , -0.53878105,\n",
            "        0.45833588, -0.22764206, -0.7204652 , -0.75782496, -1.4013962 ,\n",
            "       -0.01373057, -0.66929984,  2.9614165 ], dtype=float32), 'agent_3': Array([ 0.5718953 ,  0.7070656 , -0.00902405,  0.0200236 ,  0.7068069 ,\n",
            "       -0.5088515 , -0.49000713, -0.40411216, -0.53878105,  0.8521159 ,\n",
            "        0.45833588, -0.22764206, -0.7204652 , -0.75782496, -1.4013962 ,\n",
            "       -0.01373057, -1.1691915 ,  1.6746862 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1435674 -1.9756216 -1.1526002 -1.9727355 -1.1501154 -1.974754\n",
            " -1.1487266 -1.9750614]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2790681, dtype=float32), 'agent_0': Array(1.2790681, dtype=float32), 'agent_1': Array(1.2790681, dtype=float32), 'agent_2': Array(1.2790681, dtype=float32), 'agent_3': Array(1.2790681, dtype=float32)}\n",
            "step: 280\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.52291566,   0.6917071 ,  -0.01785997,   0.05605422,\n",
            "         0.719778  ,  -0.4962811 ,   0.55098945,  -0.57656187,\n",
            "        -0.5591491 ,  -0.57215047,   0.04820824,  -0.9334564 ,\n",
            "        -1.2478352 ,   1.1843914 ,   2.2976387 ,  -0.13884024,\n",
            "        -0.8684919 , -10.211945  ], dtype=float32), 'agent_1': Array([ 0.52291566,  0.6917071 , -0.01785997,  0.05605422,  0.719778  ,\n",
            "       -0.4962811 , -0.57656187, -0.8459462 , -0.5591491 , -0.57215047,\n",
            "        0.04820824, -0.9334564 , -1.2478352 ,  1.1843914 ,  2.2976387 ,\n",
            "       -0.13884024, -0.02618486, -9.23023   ], dtype=float32), 'agent_2': Array([ 0.52291566,  0.6917071 , -0.01785997,  0.05605422,  0.719778  ,\n",
            "       -0.4962811 , -0.57656187, -0.5591491 , -1.1061178 , -0.57215047,\n",
            "        0.04820824, -0.9334564 , -1.2478352 ,  1.1843914 ,  2.2976387 ,\n",
            "       -0.13884024, -1.6203676 , -9.21208   ], dtype=float32), 'agent_3': Array([ 0.52291566,  0.6917071 , -0.01785997,  0.05605422,  0.719778  ,\n",
            "       -0.4962811 , -0.57656187, -0.5591491 , -0.57215047,  0.50060517,\n",
            "        0.04820824, -0.9334564 , -1.2478352 ,  1.1843914 ,  2.2976387 ,\n",
            "       -0.13884024,  1.0391744 , -9.183124  ], dtype=float32)}\n",
            "ctrl action chosen: [0.09704113 0.22259927 0.09585439 0.22338033 0.09655712 0.22221005\n",
            " 0.09581757 0.22288935]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.1742115, dtype=float32), 'agent_0': Array(-9.1742115, dtype=float32), 'agent_1': Array(-9.1742115, dtype=float32), 'agent_2': Array(-9.1742115, dtype=float32), 'agent_3': Array(-9.1742115, dtype=float32)}\n",
            "step: 281\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.47899187,  0.7268056 , -0.03211082,  0.04776228,  0.68442774,\n",
            "       -0.4108516 ,  0.5151634 , -0.45127624, -0.50819415, -0.38179508,\n",
            "        0.74563026, -0.15583038, -0.10007024, -0.8664597 , -0.10327635,\n",
            "       -1.885643  ,  1.2646008 ,  0.10781964], dtype=float32), 'agent_1': Array([ 0.47899187,  0.7268056 , -0.03211082,  0.04776228,  0.68442774,\n",
            "       -0.4108516 , -0.45127624, -0.9731425 , -0.50819415, -0.38179508,\n",
            "        0.74563026, -0.15583038, -0.10007024, -0.8664597 , -0.10327635,\n",
            "       -1.885643  ,  2.8046649 ,  1.2062879 ], dtype=float32), 'agent_2': Array([ 0.47899187,  0.7268056 , -0.03211082,  0.04776228,  0.68442774,\n",
            "       -0.4108516 , -0.45127624, -0.50819415, -1.2134855 , -0.38179508,\n",
            "        0.74563026, -0.15583038, -0.10007024, -0.8664597 , -0.10327635,\n",
            "       -1.885643  ,  1.665893  ,  0.75673604], dtype=float32), 'agent_3': Array([ 0.47899187,  0.7268056 , -0.03211082,  0.04776228,  0.68442774,\n",
            "       -0.4108516 , -0.45127624, -0.50819415, -0.38179508,  0.5256841 ,\n",
            "        0.74563026, -0.15583038, -0.10007024, -0.8664597 , -0.10327635,\n",
            "       -1.885643  ,  4.017871  ,  0.6907665 ], dtype=float32)}\n",
            "ctrl action chosen: [1.5466425  0.5290407  1.545822   0.5296939  1.5463262  0.52751976\n",
            " 1.5438924  0.52923495]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2787634, dtype=float32), 'agent_0': Array(1.2787634, dtype=float32), 'agent_1': Array(1.2787634, dtype=float32), 'agent_2': Array(1.2787634, dtype=float32), 'agent_3': Array(1.2787634, dtype=float32)}\n",
            "step: 282\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5155079 ,   0.88012546,  -0.05547352,   0.0161011 ,\n",
            "         0.4712141 ,   0.20054987,   0.6319004 ,   0.20177211,\n",
            "         0.11302571,   0.31441227,   0.6179333 ,   0.7040024 ,\n",
            "         0.35562515,  -0.7264572 ,  -1.2423178 , -13.045202  ,\n",
            "        15.669207  ,   4.3305664 ], dtype=float32), 'agent_1': Array([ 5.1550788e-01,  8.8012546e-01, -5.5473518e-02,  1.6101101e-02,\n",
            "        4.7121409e-01,  2.0054987e-01,  2.0177211e-01, -8.1580877e-01,\n",
            "        1.1302571e-01,  3.1441227e-01,  6.1793327e-01,  7.0400238e-01,\n",
            "        3.5562515e-01, -7.2645718e-01, -1.2423178e+00, -1.3045202e+01,\n",
            "        1.6345385e+01,  4.1633978e+00], dtype=float32), 'agent_2': Array([  0.5155079 ,   0.88012546,  -0.05547352,   0.0161011 ,\n",
            "         0.4712141 ,   0.20054987,   0.20177211,   0.11302571,\n",
            "        -1.0880706 ,   0.31441227,   0.6179333 ,   0.7040024 ,\n",
            "         0.35562515,  -0.7264572 ,  -1.2423178 , -13.045202  ,\n",
            "        15.4820175 ,   3.7138433 ], dtype=float32), 'agent_3': Array([ 5.1550788e-01,  8.8012546e-01, -5.5473518e-02,  1.6101101e-02,\n",
            "        4.7121409e-01,  2.0054987e-01,  2.0177211e-01,  1.1302571e-01,\n",
            "        3.1441227e-01,  7.4664730e-01,  6.1793327e-01,  7.0400238e-01,\n",
            "        3.5562515e-01, -7.2645718e-01, -1.2423178e+00, -1.3045202e+01,\n",
            "        1.6892998e+01,  6.5099368e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.5642148  0.8407804 -1.5642924  0.8398415 -1.5637206  0.8401882\n",
            " -1.5646138  0.8390209]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.7711344, dtype=float32), 'agent_0': Array(-3.7711344, dtype=float32), 'agent_1': Array(-3.7711344, dtype=float32), 'agent_2': Array(-3.7711344, dtype=float32), 'agent_3': Array(-3.7711344, dtype=float32)}\n",
            "step: 283\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5458357 ,   0.82050914,  -0.02151141,  -0.03483765,\n",
            "         0.5701652 ,  -0.03631468,   0.97113746,  -0.04787919,\n",
            "        -0.17100367,   0.0893483 ,   0.18320084,   0.94480515,\n",
            "         0.64275265,   0.38119105,  -3.1630006 ,   9.910182  ,\n",
            "       -11.173253  ,   7.5530367 ], dtype=float32), 'agent_1': Array([  0.5458357 ,   0.82050914,  -0.02151141,  -0.03483765,\n",
            "         0.5701652 ,  -0.03631468,  -0.04787919,  -0.45220202,\n",
            "        -0.17100367,   0.0893483 ,   0.18320084,   0.94480515,\n",
            "         0.64275265,   0.38119105,  -3.1630006 ,   9.910182  ,\n",
            "       -12.287346  ,   4.0868187 ], dtype=float32), 'agent_2': Array([  0.5458357 ,   0.82050914,  -0.02151141,  -0.03483765,\n",
            "         0.5701652 ,  -0.03631468,  -0.04787919,  -0.17100367,\n",
            "        -0.67631334,   0.0893483 ,   0.18320084,   0.94480515,\n",
            "         0.64275265,   0.38119105,  -3.1630006 ,   9.910182  ,\n",
            "       -12.578468  ,  11.166642  ], dtype=float32), 'agent_3': Array([  0.5458357 ,   0.82050914,  -0.02151141,  -0.03483765,\n",
            "         0.5701652 ,  -0.03631468,  -0.04787919,  -0.17100367,\n",
            "         0.0893483 ,   1.2153748 ,   0.18320084,   0.94480515,\n",
            "         0.64275265,   0.38119105,  -3.1630006 ,   9.910182  ,\n",
            "       -11.680841  ,  10.617991  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.2658592  -0.13067654 -0.271434   -0.13245478 -0.26482958 -0.13040479\n",
            " -0.26515734 -0.13041256]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.992711, dtype=float32), 'agent_0': Array(-4.992711, dtype=float32), 'agent_1': Array(-4.992711, dtype=float32), 'agent_2': Array(-4.992711, dtype=float32), 'agent_3': Array(-4.992711, dtype=float32)}\n",
            "step: 284\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57736546,  0.7114817 , -0.00678477, -0.03439602,  0.7018296 ,\n",
            "       -0.41850752,  1.0965443 , -0.47895932, -0.5777855 , -0.33110642,\n",
            "       -0.01378059,  0.51898956,  0.6492734 , -0.14267546,  0.08332699,\n",
            "        4.4352813 , -5.154673  ,  0.76829123], dtype=float32), 'agent_1': Array([ 0.57736546,  0.7114817 , -0.00678477, -0.03439602,  0.7018296 ,\n",
            "       -0.41850752, -0.47895932, -0.52018476, -0.5777855 , -0.33110642,\n",
            "       -0.01378059,  0.51898956,  0.6492734 , -0.14267546,  0.08332699,\n",
            "        4.4352813 , -5.6358395 , -0.28621876], dtype=float32), 'agent_2': Array([ 0.57736546,  0.7114817 , -0.00678477, -0.03439602,  0.7018296 ,\n",
            "       -0.41850752, -0.47895932, -0.5777855 , -0.4995055 , -0.33110642,\n",
            "       -0.01378059,  0.51898956,  0.6492734 , -0.14267546,  0.08332699,\n",
            "        4.4352813 , -3.303017  , -1.2275385 ], dtype=float32), 'agent_3': Array([ 0.57736546,  0.7114817 , -0.00678477, -0.03439602,  0.7018296 ,\n",
            "       -0.41850752, -0.47895932, -0.5777855 , -0.33110642,  1.233028  ,\n",
            "       -0.01378059,  0.51898956,  0.6492734 , -0.14267546,  0.08332699,\n",
            "        4.4352813 , -5.7003884 , -0.19692095], dtype=float32)}\n",
            "ctrl action chosen: [-1.3350607   0.95150256 -1.3390957   0.9517938  -1.3382595   0.948647\n",
            " -1.338995    0.9508832 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.8402202, dtype=float32), 'agent_0': Array(0.8402202, dtype=float32), 'agent_1': Array(0.8402202, dtype=float32), 'agent_2': Array(0.8402202, dtype=float32), 'agent_3': Array(0.8402202, dtype=float32)}\n",
            "step: 285\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6005936 ,  0.6792251 ,  0.00497624, -0.05789797,  0.73162585,\n",
            "       -0.56070143,  1.2889032 , -0.5637102 , -0.53740865, -0.5527015 ,\n",
            "       -0.35305023,  0.7698059 ,  0.3591299 ,  0.22490586, -0.08739115,\n",
            "       -0.1102117 , -0.5902753 , -0.36384833], dtype=float32), 'agent_1': Array([ 0.6005936 ,  0.6792251 ,  0.00497624, -0.05789797,  0.73162585,\n",
            "       -0.56070143, -0.5637102 , -0.49544865, -0.53740865, -0.5527015 ,\n",
            "       -0.35305023,  0.7698059 ,  0.3591299 ,  0.22490586, -0.08739115,\n",
            "       -0.1102117 ,  0.6120193 , -0.64497393], dtype=float32), 'agent_2': Array([ 0.6005936 ,  0.6792251 ,  0.00497624, -0.05789797,  0.73162585,\n",
            "       -0.56070143, -0.5637102 , -0.53740865, -0.47434705, -0.5527015 ,\n",
            "       -0.35305023,  0.7698059 ,  0.3591299 ,  0.22490586, -0.08739115,\n",
            "       -0.1102117 ,  2.2155404 , -0.9674714 ], dtype=float32), 'agent_3': Array([ 0.6005936 ,  0.6792251 ,  0.00497624, -0.05789797,  0.73162585,\n",
            "       -0.56070143, -0.5637102 , -0.53740865, -0.5527015 ,  1.2561772 ,\n",
            "       -0.35305023,  0.7698059 ,  0.3591299 ,  0.22490586, -0.08739115,\n",
            "       -0.1102117 , -2.0722802 , -1.0231051 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.68692654 -1.2460907  -0.68817234 -1.249921   -0.68680286 -1.2496735\n",
            " -0.6923376  -1.2476318 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.6432176, dtype=float32), 'agent_0': Array(-4.6432176, dtype=float32), 'agent_1': Array(-4.6432176, dtype=float32), 'agent_2': Array(-4.6432176, dtype=float32), 'agent_3': Array(-4.6432176, dtype=float32)}\n",
            "step: 286\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.0371798e-01,  6.8620080e-01, -7.5748865e-03, -5.4764375e-03,\n",
            "        7.2735214e-01, -5.4703605e-01,  9.8957354e-01, -5.2048087e-01,\n",
            "       -4.4465661e-01, -5.7596761e-01, -1.8329620e-01,  2.0942688e-01,\n",
            "       -2.9021502e-01,  1.4104409e+00,  2.2849758e+00,  6.6485880e-03,\n",
            "        2.4007127e-01, -8.0876884e+00], dtype=float32), 'agent_1': Array([ 6.0371798e-01,  6.8620080e-01, -7.5748865e-03, -5.4764375e-03,\n",
            "        7.2735214e-01, -5.4703605e-01, -5.2048087e-01, -8.8815355e-01,\n",
            "       -4.4465661e-01, -5.7596761e-01, -1.8329620e-01,  2.0942688e-01,\n",
            "       -2.9021502e-01,  1.4104409e+00,  2.2849758e+00,  6.6485880e-03,\n",
            "       -3.1940304e-03, -1.0220068e+01], dtype=float32), 'agent_2': Array([ 6.0371798e-01,  6.8620080e-01, -7.5748865e-03, -5.4764375e-03,\n",
            "        7.2735214e-01, -5.4703605e-01, -5.2048087e-01, -4.4465661e-01,\n",
            "       -8.9669943e-01, -5.7596761e-01, -1.8329620e-01,  2.0942688e-01,\n",
            "       -2.9021502e-01,  1.4104409e+00,  2.2849758e+00,  6.6485880e-03,\n",
            "        3.0329844e-01, -1.1445890e+01], dtype=float32), 'agent_3': Array([ 6.03717983e-01,  6.86200798e-01, -7.57488655e-03, -5.47643751e-03,\n",
            "        7.27352142e-01, -5.47036052e-01, -5.20480871e-01, -4.44656610e-01,\n",
            "       -5.75967610e-01,  8.53559971e-01, -1.83296204e-01,  2.09426880e-01,\n",
            "       -2.90215015e-01,  1.41044092e+00,  2.28497577e+00,  6.64858799e-03,\n",
            "        5.31804502e-01, -1.08822155e+01], dtype=float32)}\n",
            "ctrl action chosen: [-0.49307632  0.43390226 -0.4948322   0.433918   -0.4944375   0.43307775\n",
            " -0.4941333   0.4337375 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.3573642, dtype=float32), 'agent_0': Array(-3.3573642, dtype=float32), 'agent_1': Array(-3.3573642, dtype=float32), 'agent_2': Array(-3.3573642, dtype=float32), 'agent_3': Array(-3.3573642, dtype=float32)}\n",
            "step: 287\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5732608 ,  0.68077135, -0.01485133,  0.00564661,  0.7323237 ,\n",
            "       -0.53647715,  0.8506205 , -0.5523889 , -0.4998723 , -0.53806317,\n",
            "        0.3019333 ,  0.5774498 , -0.76363087, -0.25878516, -0.13429321,\n",
            "        0.68360335, -0.00628096, -1.2456758 ], dtype=float32), 'agent_1': Array([ 0.5732608 ,  0.68077135, -0.01485133,  0.00564661,  0.7323237 ,\n",
            "       -0.53647715, -0.5523889 , -1.0215663 , -0.4998723 , -0.53806317,\n",
            "        0.3019333 ,  0.5774498 , -0.76363087, -0.25878516, -0.13429321,\n",
            "        0.68360335, -0.6526913 ,  0.1939302 ], dtype=float32), 'agent_2': Array([ 0.5732608 ,  0.68077135, -0.01485133,  0.00564661,  0.7323237 ,\n",
            "       -0.53647715, -0.5523889 , -0.4998723 , -1.1200732 , -0.53806317,\n",
            "        0.3019333 ,  0.5774498 , -0.76363087, -0.25878516, -0.13429321,\n",
            "        0.68360335, -2.4060457 , -1.463864  ], dtype=float32), 'agent_3': Array([ 0.5732608 ,  0.68077135, -0.01485133,  0.00564661,  0.7323237 ,\n",
            "       -0.53647715, -0.5523889 , -0.4998723 , -0.53806317,  0.6797257 ,\n",
            "        0.3019333 ,  0.5774498 , -0.76363087, -0.25878516, -0.13429321,\n",
            "        0.68360335,  0.493709  , -0.7159316 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.7023576 -1.2196676  1.7002412 -1.2160432  1.6963199 -1.2206293\n",
            "  1.7024343 -1.218165 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.2784114, dtype=float32), 'agent_0': Array(0.2784114, dtype=float32), 'agent_1': Array(0.2784114, dtype=float32), 'agent_2': Array(0.2784114, dtype=float32), 'agent_3': Array(0.2784114, dtype=float32)}\n",
            "step: 288\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6972206e-01,  8.2651520e-01, -5.0938699e-02,  4.8835669e-02,\n",
            "        5.5847377e-01,  5.9753146e-02,  4.5973617e-01,  8.2636549e-04,\n",
            "        3.0683128e-03,  7.8019083e-02,  2.2134781e-01,  1.5106201e-01,\n",
            "       -3.3614635e-01, -4.0994465e-01,  1.2713374e+00, -1.2210236e+01,\n",
            "        1.5776504e+01, -4.7891979e+00], dtype=float32), 'agent_1': Array([ 5.6972206e-01,  8.2651520e-01, -5.0938699e-02,  4.8835669e-02,\n",
            "        5.5847377e-01,  5.9753146e-02,  8.2636549e-04, -1.2878100e+00,\n",
            "        3.0683128e-03,  7.8019083e-02,  2.2134781e-01,  1.5106201e-01,\n",
            "       -3.3614635e-01, -4.0994465e-01,  1.2713374e+00, -1.2210236e+01,\n",
            "        1.5361902e+01, -2.0922296e+00], dtype=float32), 'agent_2': Array([ 5.6972206e-01,  8.2651520e-01, -5.0938699e-02,  4.8835669e-02,\n",
            "        5.5847377e-01,  5.9753146e-02,  8.2636549e-04,  3.0683128e-03,\n",
            "       -1.2846212e+00,  7.8019083e-02,  2.2134781e-01,  1.5106201e-01,\n",
            "       -3.3614635e-01, -4.0994465e-01,  1.2713374e+00, -1.2210236e+01,\n",
            "        1.4027275e+01,  1.0824271e+00], dtype=float32), 'agent_3': Array([ 5.6972206e-01,  8.2651520e-01, -5.0938699e-02,  4.8835669e-02,\n",
            "        5.5847377e-01,  5.9753146e-02,  8.2636549e-04,  3.0683128e-03,\n",
            "        7.8019083e-02,  4.3778166e-01,  2.2134781e-01,  1.5106201e-01,\n",
            "       -3.3614635e-01, -4.0994465e-01,  1.2713374e+00, -1.2210236e+01,\n",
            "        1.6548094e+01,  2.5666213e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.33533028  1.9853905  -0.33480597  1.9887142  -0.33186215  1.9873724\n",
            " -0.33480552  1.9877725 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.572771, dtype=float32), 'agent_0': Array(-7.572771, dtype=float32), 'agent_1': Array(-7.572771, dtype=float32), 'agent_2': Array(-7.572771, dtype=float32), 'agent_3': Array(-7.572771, dtype=float32)}\n",
            "step: 289\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5311298e-01,  8.5314494e-01, -2.1971034e-02,  2.6084778e-03,\n",
            "        5.2120459e-01,  2.1469992e-01,  7.3862636e-01,  1.4764303e-01,\n",
            "        8.0403052e-02,  2.6517254e-01,  4.1408539e-01,  7.7753067e-01,\n",
            "       -1.6658306e-01,  5.7455516e-01, -2.1861479e+00,  1.1817232e+00,\n",
            "       -1.1074879e+00,  6.9122710e+00], dtype=float32), 'agent_1': Array([ 5.5311298e-01,  8.5314494e-01, -2.1971034e-02,  2.6084778e-03,\n",
            "        5.2120459e-01,  2.1469992e-01,  1.4764303e-01, -9.4284278e-01,\n",
            "        8.0403052e-02,  2.6517254e-01,  4.1408539e-01,  7.7753067e-01,\n",
            "       -1.6658306e-01,  5.7455516e-01, -2.1861479e+00,  1.1817232e+00,\n",
            "       -7.7575451e-01,  8.3270702e+00], dtype=float32), 'agent_2': Array([ 5.5311298e-01,  8.5314494e-01, -2.1971034e-02,  2.6084778e-03,\n",
            "        5.2120459e-01,  2.1469992e-01,  1.4764303e-01,  8.0403052e-02,\n",
            "       -8.9581907e-01,  2.6517254e-01,  4.1408539e-01,  7.7753067e-01,\n",
            "       -1.6658306e-01,  5.7455516e-01, -2.1861479e+00,  1.1817232e+00,\n",
            "       -2.6753118e+00,  1.1061459e+01], dtype=float32), 'agent_3': Array([ 5.5311298e-01,  8.5314494e-01, -2.1971034e-02,  2.6084778e-03,\n",
            "        5.2120459e-01,  2.1469992e-01,  1.4764303e-01,  8.0403052e-02,\n",
            "        2.6517254e-01,  7.8955716e-01,  4.1408539e-01,  7.7753067e-01,\n",
            "       -1.6658306e-01,  5.7455516e-01, -2.1861479e+00,  1.1817232e+00,\n",
            "       -5.3016090e-01,  9.6317339e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1406752  -0.60847324  1.1389028  -0.6077845   1.139301   -0.6101015\n",
            "  1.1386429  -0.60895455]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.757533, dtype=float32), 'agent_0': Array(-6.757533, dtype=float32), 'agent_1': Array(-6.757533, dtype=float32), 'agent_2': Array(-6.757533, dtype=float32), 'agent_3': Array(-6.757533, dtype=float32)}\n",
            "step: 290\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52931446,  0.91766244, -0.02605946,  0.00415368,  0.39648372,\n",
            "        0.579931  ,  0.72721374,  0.5391926 ,  0.4161552 ,  0.6012296 ,\n",
            "        0.29387474,  0.58078766, -0.4508257 , -0.41017964,  0.8056575 ,\n",
            "       -0.9882194 ,  0.9107586 , -2.7455435 ], dtype=float32), 'agent_1': Array([ 0.52931446,  0.91766244, -0.02605946,  0.00415368,  0.39648372,\n",
            "        0.579931  ,  0.5391926 , -0.9196116 ,  0.4161552 ,  0.6012296 ,\n",
            "        0.29387474,  0.58078766, -0.4508257 , -0.41017964,  0.8056575 ,\n",
            "       -0.9882194 ,  3.1907773 , -1.520774  ], dtype=float32), 'agent_2': Array([ 0.52931446,  0.91766244, -0.02605946,  0.00415368,  0.39648372,\n",
            "        0.579931  ,  0.5391926 ,  0.4161552 , -0.75070596,  0.6012296 ,\n",
            "        0.29387474,  0.58078766, -0.4508257 , -0.41017964,  0.8056575 ,\n",
            "       -0.9882194 ,  3.7385807 , -0.29448262], dtype=float32), 'agent_3': Array([ 0.52931446,  0.91766244, -0.02605946,  0.00415368,  0.39648372,\n",
            "        0.579931  ,  0.5391926 ,  0.4161552 ,  0.6012296 ,  0.88337296,\n",
            "        0.29387474,  0.58078766, -0.4508257 , -0.41017964,  0.8056575 ,\n",
            "       -0.9882194 , -0.17831132, -1.9790547 ], dtype=float32)}\n",
            "ctrl action chosen: [ 2.0684235  -0.55996895  2.0731254  -0.55646074  2.0747     -0.55927974\n",
            "  2.0682302  -0.55815005]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.925554, dtype=float32), 'agent_0': Array(-1.925554, dtype=float32), 'agent_1': Array(-1.925554, dtype=float32), 'agent_2': Array(-1.925554, dtype=float32), 'agent_3': Array(-1.925554, dtype=float32)}\n",
            "step: 291\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.516625  ,  0.91433835, -0.03735003,  0.01512355,  0.40294135,\n",
            "        0.5369129 ,  0.5545798 ,  0.56311667,  0.56575036,  0.5308983 ,\n",
            "       -0.21386147,  0.42581558, -0.41458607, -0.44870117,  1.169297  ,\n",
            "        0.8876973 , -1.5937632 , -4.6329837 ], dtype=float32), 'agent_1': Array([ 0.516625  ,  0.91433835, -0.03735003,  0.01512355,  0.40294135,\n",
            "        0.5369129 ,  0.56311667, -1.0464532 ,  0.56575036,  0.5308983 ,\n",
            "       -0.21386147,  0.42581558, -0.41458607, -0.44870117,  1.169297  ,\n",
            "        0.8876973 , -0.8175958 , -3.5174024 ], dtype=float32), 'agent_2': Array([ 0.516625  ,  0.91433835, -0.03735003,  0.01512355,  0.40294135,\n",
            "        0.5369129 ,  0.56311667,  0.56575036, -0.82756495,  0.5308983 ,\n",
            "       -0.21386147,  0.42581558, -0.41458607, -0.44870117,  1.169297  ,\n",
            "        0.8876973 ,  1.7624788 , -3.2193751 ], dtype=float32), 'agent_3': Array([ 0.516625  ,  0.91433835, -0.03735003,  0.01512355,  0.40294135,\n",
            "        0.5369129 ,  0.56311667,  0.56575036,  0.5308983 ,  0.7034319 ,\n",
            "       -0.21386147,  0.42581558, -0.41458607, -0.44870117,  1.169297  ,\n",
            "        0.8876973 , -2.2237315 , -5.5815887 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8727074   0.5626791  -0.87191147  0.5669732  -0.86632335  0.56149304\n",
            " -0.87256396  0.5616665 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.355858, dtype=float32), 'agent_0': Array(-8.355858, dtype=float32), 'agent_1': Array(-8.355858, dtype=float32), 'agent_2': Array(-8.355858, dtype=float32), 'agent_3': Array(-8.355858, dtype=float32)}\n",
            "step: 292\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.51344746,   0.79107624,  -0.02167257,   0.03732083,\n",
            "         0.6101934 ,  -0.07709758,   0.55510426,  -0.04294043,\n",
            "         0.15140386,  -0.14208122,  -0.04558563,   1.1264801 ,\n",
            "        -0.10070801,   0.7702966 ,  -0.21336989,  11.698646  ,\n",
            "       -14.63391   ,   1.706     ], dtype=float32), 'agent_1': Array([  0.51344746,   0.79107624,  -0.02167257,   0.03732083,\n",
            "         0.6101934 ,  -0.07709758,  -0.04294043,  -1.0104827 ,\n",
            "         0.15140386,  -0.14208122,  -0.04558563,   1.1264801 ,\n",
            "        -0.10070801,   0.7702966 ,  -0.21336989,  11.698646  ,\n",
            "       -15.003913  ,   2.2574813 ], dtype=float32), 'agent_2': Array([  0.51344746,   0.79107624,  -0.02167257,   0.03732083,\n",
            "         0.6101934 ,  -0.07709758,  -0.04294043,   0.15140386,\n",
            "        -0.77952045,  -0.14208122,  -0.04558563,   1.1264801 ,\n",
            "        -0.10070801,   0.7702966 ,  -0.21336989,  11.698646  ,\n",
            "       -11.660571  ,   2.0764954 ], dtype=float32), 'agent_3': Array([  0.51344746,   0.79107624,  -0.02167257,   0.03732083,\n",
            "         0.6101934 ,  -0.07709758,  -0.04294043,   0.15140386,\n",
            "        -0.14208122,   0.65235156,  -0.04558563,   1.1264801 ,\n",
            "        -0.10070801,   0.7702966 ,  -0.21336989,  11.698646  ,\n",
            "       -15.907474  ,   0.3573928 ], dtype=float32)}\n",
            "ctrl action chosen: [0.11516114 1.199057   0.11457139 1.2007385  0.11586455 1.1992671\n",
            " 0.11408349 1.198031  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.375165, dtype=float32), 'agent_0': Array(-1.375165, dtype=float32), 'agent_1': Array(-1.375165, dtype=float32), 'agent_2': Array(-1.375165, dtype=float32), 'agent_3': Array(-1.375165, dtype=float32)}\n",
            "step: 293\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4979898 ,  0.73173064,  0.01193286,  0.01350248,  0.6813558 ,\n",
            "       -0.32334924,  0.8669841 , -0.29218408,  0.02378979, -0.45046064,\n",
            "        0.3993988 ,  1.1761665 , -0.13230443, -0.49881226, -2.6077452 ,\n",
            "        1.4121157 , -1.6866671 ,  9.28534   ], dtype=float32), 'agent_1': Array([ 0.4979898 ,  0.73173064,  0.01193286,  0.01350248,  0.6813558 ,\n",
            "       -0.32334924, -0.29218408, -0.65163034,  0.02378979, -0.45046064,\n",
            "        0.3993988 ,  1.1761665 , -0.13230443, -0.49881226, -2.6077452 ,\n",
            "        1.4121157 , -1.817424  , 10.123591  ], dtype=float32), 'agent_2': Array([ 0.4979898 ,  0.73173064,  0.01193286,  0.01350248,  0.6813558 ,\n",
            "       -0.32334924, -0.29218408,  0.02378979, -0.4785734 , -0.45046064,\n",
            "        0.3993988 ,  1.1761665 , -0.13230443, -0.49881226, -2.6077452 ,\n",
            "        1.4121157 ,  0.45063135,  6.5167427 ], dtype=float32), 'agent_3': Array([ 0.4979898 ,  0.73173064,  0.01193286,  0.01350248,  0.6813558 ,\n",
            "       -0.32334924, -0.29218408,  0.02378979, -0.45046064,  0.8746318 ,\n",
            "        0.3993988 ,  1.1761665 , -0.13230443, -0.49881226, -2.6077452 ,\n",
            "        1.4121157 , -3.2948413 ,  5.555412  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.89118695 -0.14850137  0.8891288  -0.14830674  0.89186424 -0.1498703\n",
            "  0.8917416  -0.14857394]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7978966, dtype=float32), 'agent_0': Array(-1.7978966, dtype=float32), 'agent_1': Array(-1.7978966, dtype=float32), 'agent_2': Array(-1.7978966, dtype=float32), 'agent_3': Array(-1.7978966, dtype=float32)}\n",
            "step: 294\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52421105,  0.8552434 ,  0.02125293, -0.01280034,  0.51763237,\n",
            "        0.20692277,  1.0311356 ,  0.18325484,  0.6099384 , -0.05931754,\n",
            "       -0.03838539,  0.6300926 ,  1.1090755 ,  0.59293234, -0.594225  ,\n",
            "       -8.464043  , 12.0904665 ,  1.1700314 ], dtype=float32), 'agent_1': Array([ 0.52421105,  0.8552434 ,  0.02125293, -0.01280034,  0.51763237,\n",
            "        0.20692277,  0.18325484, -0.48267186,  0.6099384 , -0.05931754,\n",
            "       -0.03838539,  0.6300926 ,  1.1090755 ,  0.59293234, -0.594225  ,\n",
            "       -8.464043  , 10.4585285 , -1.1887442 ], dtype=float32), 'agent_2': Array([ 0.52421105,  0.8552434 ,  0.02125293, -0.01280034,  0.51763237,\n",
            "        0.20692277,  0.18325484,  0.6099384 , -0.5039769 , -0.05931754,\n",
            "       -0.03838539,  0.6300926 ,  1.1090755 ,  0.59293234, -0.594225  ,\n",
            "       -8.464043  , 10.0136175 , -0.02010401], dtype=float32), 'agent_3': Array([ 0.52421105,  0.8552434 ,  0.02125293, -0.01280034,  0.51763237,\n",
            "        0.20692277,  0.18325484,  0.6099384 , -0.05931754,  0.94338304,\n",
            "       -0.03838539,  0.6300926 ,  1.1090755 ,  0.59293234, -0.594225  ,\n",
            "       -8.464043  ,  9.064599  ,  0.13510656], dtype=float32)}\n",
            "ctrl action chosen: [-2.5553558   0.49028388 -2.5573454   0.4906418  -2.5552979   0.49006492\n",
            " -2.554479    0.48969796]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.25703943, dtype=float32), 'agent_0': Array(-0.25703943, dtype=float32), 'agent_1': Array(-0.25703943, dtype=float32), 'agent_2': Array(-0.25703943, dtype=float32), 'agent_3': Array(-0.25703943, dtype=float32)}\n",
            "step: 295\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5744176 ,   0.75328076,   0.04610485,  -0.03923592,\n",
            "         0.654907  ,  -0.11829332,   1.2488091 ,  -0.22429486,\n",
            "         0.21099566,  -0.5199044 ,   0.22478104,   0.9407997 ,\n",
            "         0.8293152 ,  -0.02935789,  -1.3054484 ,  10.531409  ,\n",
            "       -11.594535  ,   3.391761  ], dtype=float32), 'agent_1': Array([  0.5744176 ,   0.75328076,   0.04610485,  -0.03923592,\n",
            "         0.654907  ,  -0.11829332,  -0.22429486,  -0.5076301 ,\n",
            "         0.21099566,  -0.5199044 ,   0.22478104,   0.9407997 ,\n",
            "         0.8293152 ,  -0.02935789,  -1.3054484 ,  10.531409  ,\n",
            "       -13.148002  ,  -0.86575   ], dtype=float32), 'agent_2': Array([  0.5744176 ,   0.75328076,   0.04610485,  -0.03923592,\n",
            "         0.654907  ,  -0.11829332,  -0.22429486,   0.21099566,\n",
            "        -0.51350856,  -0.5199044 ,   0.22478104,   0.9407997 ,\n",
            "         0.8293152 ,  -0.02935789,  -1.3054484 ,  10.531409  ,\n",
            "       -13.722563  ,  -0.63518226], dtype=float32), 'agent_3': Array([  0.5744176 ,   0.75328076,   0.04610485,  -0.03923592,\n",
            "         0.654907  ,  -0.11829332,  -0.22429486,   0.21099566,\n",
            "        -0.5199044 ,   1.0713888 ,   0.22478104,   0.9407997 ,\n",
            "         0.8293152 ,  -0.02935789,  -1.3054484 ,  10.531409  ,\n",
            "       -14.007794  ,   3.5184953 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.46864343  0.51006204 -0.47518867  0.5098495  -0.47496197  0.50869215\n",
            " -0.47041902  0.5085922 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.408596, dtype=float32), 'agent_0': Array(-12.408596, dtype=float32), 'agent_1': Array(-12.408596, dtype=float32), 'agent_2': Array(-12.408596, dtype=float32), 'agent_3': Array(-12.408596, dtype=float32)}\n",
            "step: 296\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5930881 ,  0.6808644 ,  0.04648034, -0.06812619,  0.7277514 ,\n",
            "       -0.38411352,  1.2533311 , -0.54275185, -0.1471794 , -0.6067208 ,\n",
            "        0.31814575,  0.25072098, -0.07477999, -0.25367492, -0.8435168 ,\n",
            "        1.8405759 , -3.2622392 , -0.09610394], dtype=float32), 'agent_1': Array([ 0.5930881 ,  0.6808644 ,  0.04648034, -0.06812619,  0.7277514 ,\n",
            "       -0.38411352, -0.54275185, -0.51724416, -0.1471794 , -0.6067208 ,\n",
            "        0.31814575,  0.25072098, -0.07477999, -0.25367492, -0.8435168 ,\n",
            "        1.8405759 , -3.2534988 ,  0.08196561], dtype=float32), 'agent_2': Array([ 0.5930881 ,  0.6808644 ,  0.04648034, -0.06812619,  0.7277514 ,\n",
            "       -0.38411352, -0.54275185, -0.1471794 , -0.5212481 , -0.6067208 ,\n",
            "        0.31814575,  0.25072098, -0.07477999, -0.25367492, -0.8435168 ,\n",
            "        1.8405759 , -4.2890463 ,  0.28103778], dtype=float32), 'agent_3': Array([ 0.5930881 ,  0.6808644 ,  0.04648034, -0.06812619,  0.7277514 ,\n",
            "       -0.38411352, -0.54275185, -0.1471794 , -0.6067208 ,  1.2749097 ,\n",
            "        0.31814575,  0.25072098, -0.07477999, -0.25367492, -0.8435168 ,\n",
            "        1.8405759 ,  3.101845  ,  0.91023093], dtype=float32)}\n",
            "ctrl action chosen: [1.128373   0.7232844  1.1248187  0.7225128  1.1236355  0.72285706\n",
            " 1.133507   0.71982574]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3689574, dtype=float32), 'agent_0': Array(0.3689574, dtype=float32), 'agent_1': Array(0.3689574, dtype=float32), 'agent_2': Array(0.3689574, dtype=float32), 'agent_3': Array(0.3689574, dtype=float32)}\n",
            "step: 297\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5665213 ,   0.8301275 ,   0.07939515,  -0.06333671,\n",
            "         0.5482457 ,   0.14389215,   1.2516801 ,  -0.04068905,\n",
            "         0.33291674,   0.23686856,   0.30593872,   0.3993988 ,\n",
            "        -0.8335352 ,   0.30856436,  -0.5931205 , -13.016046  ,\n",
            "        14.893563  ,  -0.29047334], dtype=float32), 'agent_1': Array([  0.5665213 ,   0.8301275 ,   0.07939515,  -0.06333671,\n",
            "         0.5482457 ,   0.14389215,  -0.04068905,  -0.49728155,\n",
            "         0.33291674,   0.23686856,   0.30593872,   0.3993988 ,\n",
            "        -0.8335352 ,   0.30856436,  -0.5931205 , -13.016046  ,\n",
            "        14.53872   ,   0.60032153], dtype=float32), 'agent_2': Array([  0.5665213 ,   0.8301275 ,   0.07939515,  -0.06333671,\n",
            "         0.5482457 ,   0.14389215,  -0.04068905,   0.33291674,\n",
            "        -0.47708488,   0.23686856,   0.30593872,   0.3993988 ,\n",
            "        -0.8335352 ,   0.30856436,  -0.5931205 , -13.016046  ,\n",
            "        13.977948  ,   0.37256318], dtype=float32), 'agent_3': Array([  0.5665213 ,   0.8301275 ,   0.07939515,  -0.06333671,\n",
            "         0.5482457 ,   0.14389215,  -0.04068905,   0.33291674,\n",
            "         0.23686856,   1.2653866 ,   0.30593872,   0.3993988 ,\n",
            "        -0.8335352 ,   0.30856436,  -0.5931205 , -13.016046  ,\n",
            "        21.79965   ,  -0.7197421 ], dtype=float32)}\n",
            "ctrl action chosen: [1.7347623  0.512279   1.7346402  0.5122957  1.7349627  0.51179284\n",
            " 1.731782   0.5104336 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3114412, dtype=float32), 'agent_0': Array(-2.3114412, dtype=float32), 'agent_1': Array(-2.3114412, dtype=float32), 'agent_2': Array(-2.3114412, dtype=float32), 'agent_3': Array(-2.3114412, dtype=float32)}\n",
            "step: 298\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52250046,  0.89540964,  0.10269657, -0.05773295,  0.429374  ,\n",
            "        0.5464592 ,  1.2348366 ,  0.37145814,  0.5598217 ,  0.65961707,\n",
            "        0.13465881,  1.1778831 , -0.84171295,  0.48517358, -0.6292299 ,\n",
            "        0.00978579,  1.9190995 ,  0.28062105], dtype=float32), 'agent_1': Array([ 0.52250046,  0.89540964,  0.10269657, -0.05773295,  0.429374  ,\n",
            "        0.5464592 ,  0.37145814, -0.49070233,  0.5598217 ,  0.65961707,\n",
            "        0.13465881,  1.1778831 , -0.84171295,  0.48517358, -0.6292299 ,\n",
            "        0.00978579,  3.3772948 , -0.15072572], dtype=float32), 'agent_2': Array([ 0.52250046,  0.89540964,  0.10269657, -0.05773295,  0.429374  ,\n",
            "        0.5464592 ,  0.37145814,  0.5598217 , -0.49434206,  0.65961707,\n",
            "        0.13465881,  1.1778831 , -0.84171295,  0.48517358, -0.6292299 ,\n",
            "        0.00978579, -1.6773565 ,  0.7160866 ], dtype=float32), 'agent_3': Array([ 0.52250046,  0.89540964,  0.10269657, -0.05773295,  0.429374  ,\n",
            "        0.5464592 ,  0.37145814,  0.5598217 ,  0.65961707,  1.2329755 ,\n",
            "        0.13465881,  1.1778831 , -0.84171295,  0.48517358, -0.6292299 ,\n",
            "        0.00978579, -1.3300424 ,  0.16619907], dtype=float32)}\n",
            "ctrl action chosen: [-0.31971323  0.44487673 -0.3192399   0.44213784 -0.32505023  0.4453532\n",
            " -0.32606736  0.4473571 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.2816334, dtype=float32), 'agent_0': Array(-5.2816334, dtype=float32), 'agent_1': Array(-5.2816334, dtype=float32), 'agent_2': Array(-5.2816334, dtype=float32), 'agent_3': Array(-5.2816334, dtype=float32)}\n",
            "step: 299\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50838304,  0.8407056 ,  0.08966423, -0.07878993,  0.5281729 ,\n",
            "        0.38425833,  1.2345376 ,  0.22958456,  0.19435911,  0.26076868,\n",
            "        0.02264977,  1.0709763 , -0.13849735, -0.6943249 , -0.01290153,\n",
            "        6.2911053 , -5.09603   , -0.01436509], dtype=float32), 'agent_1': Array([ 0.50838304,  0.8407056 ,  0.08966423, -0.07878993,  0.5281729 ,\n",
            "        0.38425833,  0.22958456, -0.5087792 ,  0.19435911,  0.26076868,\n",
            "        0.02264977,  1.0709763 , -0.13849735, -0.6943249 , -0.01290153,\n",
            "        6.2911053 , -4.140861  ,  0.2999806 ], dtype=float32), 'agent_2': Array([ 0.50838304,  0.8407056 ,  0.08966423, -0.07878993,  0.5281729 ,\n",
            "        0.38425833,  0.22958456,  0.19435911, -0.49520725,  0.26076868,\n",
            "        0.02264977,  1.0709763 , -0.13849735, -0.6943249 , -0.01290153,\n",
            "        6.2911053 , -9.463881  ,  0.16597632], dtype=float32), 'agent_3': Array([  0.50838304,   0.8407056 ,   0.08966423,  -0.07878993,\n",
            "         0.5281729 ,   0.38425833,   0.22958456,   0.19435911,\n",
            "         0.26076868,   1.2398605 ,   0.02264977,   1.0709763 ,\n",
            "        -0.13849735,  -0.6943249 ,  -0.01290153,   6.2911053 ,\n",
            "       -11.2138605 ,   0.37420756], dtype=float32)}\n",
            "ctrl action chosen: [1.314954   0.6870523  1.31444    0.68701816 1.3137395  0.6874392\n",
            " 1.3142171  0.6873181 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.58475786, dtype=float32), 'agent_0': Array(0.58475786, dtype=float32), 'agent_1': Array(0.58475786, dtype=float32), 'agent_2': Array(0.58475786, dtype=float32), 'agent_3': Array(0.58475786, dtype=float32)}\n",
            "step: 300\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5053653 ,  0.8895475 ,  0.08571082, -0.07322576,  0.44271553,\n",
            "        0.63225085,  1.2512219 ,  0.5791651 ,  0.39954516,  0.39653012,\n",
            "       -0.5034447 ,  0.8339882 , -0.33682585, -0.670474  ,  0.26182508,\n",
            "       -1.7705443 , -0.35573834,  0.09636448], dtype=float32), 'agent_1': Array([ 0.5053653 ,  0.8895475 ,  0.08571082, -0.07322576,  0.44271553,\n",
            "        0.63225085,  0.5791651 , -0.49415928,  0.39954516,  0.39653012,\n",
            "       -0.5034447 ,  0.8339882 , -0.33682585, -0.670474  ,  0.26182508,\n",
            "       -1.7705443 ,  3.290357  ,  0.2769418 ], dtype=float32), 'agent_2': Array([ 0.5053653 ,  0.8895475 ,  0.08571082, -0.07322576,  0.44271553,\n",
            "        0.63225085,  0.5791651 ,  0.39954516, -0.4827873 ,  0.39653012,\n",
            "       -0.5034447 ,  0.8339882 , -0.33682585, -0.670474  ,  0.26182508,\n",
            "       -1.7705443 ,  3.7196703 , -0.4319771 ], dtype=float32), 'agent_3': Array([ 0.5053653 ,  0.8895475 ,  0.08571082, -0.07322576,  0.44271553,\n",
            "        0.63225085,  0.5791651 ,  0.39954516,  0.39653012,  1.2502117 ,\n",
            "       -0.5034447 ,  0.8339882 , -0.33682585, -0.670474  ,  0.26182508,\n",
            "       -1.7705443 ,  2.5075274 , -0.35057473], dtype=float32)}\n",
            "ctrl action chosen: [ 1.4603366 -1.2937278  1.4623184 -1.2982308  1.4634068 -1.3007678\n",
            "  1.4614921 -1.2979053]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6992664, dtype=float32), 'agent_0': Array(-3.6992664, dtype=float32), 'agent_1': Array(-3.6992664, dtype=float32), 'agent_2': Array(-3.6992664, dtype=float32), 'agent_3': Array(-3.6992664, dtype=float32)}\n",
            "step: 301\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50082725,  0.9023389 ,  0.02276723, -0.04237601,  0.42833465,\n",
            "        0.5056065 ,  0.93512744,  0.5757634 ,  0.5654441 ,  0.5490849 ,\n",
            "       -0.4005432 , -0.6257057 ,  0.1055479 , -2.3031535 ,  3.2366939 ,\n",
            "        0.438663  , -3.6845162 , -9.226581  ], dtype=float32), 'agent_1': Array([ 0.50082725,  0.9023389 ,  0.02276723, -0.04237601,  0.42833465,\n",
            "        0.5056065 ,  0.5757634 , -0.74401563,  0.5654441 ,  0.5490849 ,\n",
            "       -0.4005432 , -0.6257057 ,  0.1055479 , -2.3031535 ,  3.2366939 ,\n",
            "        0.438663  , -2.2358294 , -6.5783453 ], dtype=float32), 'agent_2': Array([ 0.50082725,  0.9023389 ,  0.02276723, -0.04237601,  0.42833465,\n",
            "        0.5056065 ,  0.5757634 ,  0.5654441 , -0.7879253 ,  0.5490849 ,\n",
            "       -0.4005432 , -0.6257057 ,  0.1055479 , -2.3031535 ,  3.2366939 ,\n",
            "        0.438663  ,  1.4584148 , -8.577078  ], dtype=float32), 'agent_3': Array([ 0.50082725,  0.9023389 ,  0.02276723, -0.04237601,  0.42833465,\n",
            "        0.5056065 ,  0.5757634 ,  0.5654441 ,  0.5490849 ,  0.90593946,\n",
            "       -0.4005432 , -0.6257057 ,  0.1055479 , -2.3031535 ,  3.2366939 ,\n",
            "        0.438663  ,  2.0354729 , -9.989404  ], dtype=float32)}\n",
            "ctrl action chosen: [0.3291742  1.5329921  0.3272682  1.5373248  0.3311996  1.5330309\n",
            " 0.33078575 1.5342567 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.149509, dtype=float32), 'agent_0': Array(-7.149509, dtype=float32), 'agent_1': Array(-7.149509, dtype=float32), 'agent_2': Array(-7.149509, dtype=float32), 'agent_3': Array(-7.149509, dtype=float32)}\n",
            "step: 302\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.0574201e-01,  8.8229316e-01,  2.7532599e-04, -3.9607458e-02,\n",
            "        4.6903086e-01,  2.7656403e-01,  9.5411217e-01,  4.1536698e-01,\n",
            "        5.4824311e-01,  5.4772240e-01,  3.7240982e-02,  3.1452179e-01,\n",
            "       -8.0609322e-02, -2.6529652e-01, -7.7561057e-01,  9.9481881e-01,\n",
            "       -2.4358821e+00,  4.0572834e+00], dtype=float32), 'agent_1': Array([ 5.0574201e-01,  8.8229316e-01,  2.7532599e-04, -3.9607458e-02,\n",
            "        4.6903086e-01,  2.7656403e-01,  4.1536698e-01, -5.6804681e-01,\n",
            "        5.4824311e-01,  5.4772240e-01,  3.7240982e-02,  3.1452179e-01,\n",
            "       -8.0609322e-02, -2.6529652e-01, -7.7561057e-01,  9.9481881e-01,\n",
            "       -1.8261896e+00,  7.0244808e+00], dtype=float32), 'agent_2': Array([ 5.0574201e-01,  8.8229316e-01,  2.7532599e-04, -3.9607458e-02,\n",
            "        4.6903086e-01,  2.7656403e-01,  4.1536698e-01,  5.4824311e-01,\n",
            "       -7.3449528e-01,  5.4772240e-01,  3.7240982e-02,  3.1452179e-01,\n",
            "       -8.0609322e-02, -2.6529652e-01, -7.7561057e-01,  9.9481881e-01,\n",
            "       -5.7259119e-01,  4.5049176e+00], dtype=float32), 'agent_3': Array([ 5.0574201e-01,  8.8229316e-01,  2.7532599e-04, -3.9607458e-02,\n",
            "        4.6903086e-01,  2.7656403e-01,  4.1536698e-01,  5.4824311e-01,\n",
            "        5.4772240e-01,  9.1241974e-01,  3.7240982e-02,  3.1452179e-01,\n",
            "       -8.0609322e-02, -2.6529652e-01, -7.7561057e-01,  9.9481881e-01,\n",
            "        2.4251953e-01,  4.1972394e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.2480243 -0.7768197 -1.2477992 -0.7769876 -1.245196  -0.7802493\n",
            " -1.246626  -0.7781809]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.0261874, dtype=float32), 'agent_0': Array(-4.0261874, dtype=float32), 'agent_1': Array(-4.0261874, dtype=float32), 'agent_2': Array(-4.0261874, dtype=float32), 'agent_3': Array(-4.0261874, dtype=float32)}\n",
            "step: 303\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.0587893e-01,  7.3912394e-01, -4.8344269e-02,  5.8668042e-03,\n",
            "        6.7180681e-01, -3.7390521e-01,  7.2707975e-01, -2.1767704e-01,\n",
            "       -3.7446517e-02, -8.4850835e-03, -1.0390282e-01, -7.7066422e-01,\n",
            "        4.6136379e-01,  5.6251121e-01,  2.9825892e+00,  1.3329397e+01,\n",
            "       -1.7004976e+01, -7.7085466e+00], dtype=float32), 'agent_1': Array([ 5.0587893e-01,  7.3912394e-01, -4.8344269e-02,  5.8668042e-03,\n",
            "        6.7180681e-01, -3.7390521e-01, -2.1767704e-01, -6.7824811e-01,\n",
            "       -3.7446517e-02, -8.4850835e-03, -1.0390282e-01, -7.7066422e-01,\n",
            "        4.6136379e-01,  5.6251121e-01,  2.9825892e+00,  1.3329397e+01,\n",
            "       -1.6493654e+01, -4.9674740e+00], dtype=float32), 'agent_2': Array([ 5.0587893e-01,  7.3912394e-01, -4.8344269e-02,  5.8668042e-03,\n",
            "        6.7180681e-01, -3.7390521e-01, -2.1767704e-01, -3.7446517e-02,\n",
            "       -9.1318810e-01, -8.4850835e-03, -1.0390282e-01, -7.7066422e-01,\n",
            "        4.6136379e-01,  5.6251121e-01,  2.9825892e+00,  1.3329397e+01,\n",
            "       -1.6159771e+01, -5.4975209e+00], dtype=float32), 'agent_3': Array([ 5.0587893e-01,  7.3912394e-01, -4.8344269e-02,  5.8668042e-03,\n",
            "        6.7180681e-01, -3.7390521e-01, -2.1767704e-01, -3.7446517e-02,\n",
            "       -8.4850835e-03,  7.0337164e-01, -1.0390282e-01, -7.7066422e-01,\n",
            "        4.6136379e-01,  5.6251121e-01,  2.9825892e+00,  1.3329397e+01,\n",
            "       -1.5161369e+01, -6.8004227e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.10880961 -0.6057417   0.10997538 -0.6058317   0.11005575 -0.6064234\n",
            "  0.10782874 -0.60609984]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.456925, dtype=float32), 'agent_0': Array(-3.456925, dtype=float32), 'agent_1': Array(-3.456925, dtype=float32), 'agent_2': Array(-3.456925, dtype=float32), 'agent_3': Array(-3.456925, dtype=float32)}\n",
            "step: 304\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52495664,  0.68997616, -0.07068308,  0.0574096 ,  0.71808153,\n",
            "       -0.56194174,  0.4593171 , -0.44289276, -0.22176865, -0.13393053,\n",
            "        0.5077839 , -0.60682297,  0.06843805,  0.5639901 ,  1.0902317 ,\n",
            "       -0.972321  ,  2.1314237 ,  0.26898456], dtype=float32), 'agent_1': Array([ 0.52495664,  0.68997616, -0.07068308,  0.0574096 ,  0.71808153,\n",
            "       -0.56194174, -0.44289276, -0.9264636 , -0.22176865, -0.13393053,\n",
            "        0.5077839 , -0.60682297,  0.06843805,  0.5639901 ,  1.0902317 ,\n",
            "       -0.972321  , -0.13795033, -5.902267  ], dtype=float32), 'agent_2': Array([ 0.52495664,  0.68997616, -0.07068308,  0.0574096 ,  0.71808153,\n",
            "       -0.56194174, -0.44289276, -0.22176865, -1.1755614 , -0.13393053,\n",
            "        0.5077839 , -0.60682297,  0.06843805,  0.5639901 ,  1.0902317 ,\n",
            "       -0.972321  ,  1.0237871 , -6.2048407 ], dtype=float32), 'agent_3': Array([ 0.52495664,  0.68997616, -0.07068308,  0.0574096 ,  0.71808153,\n",
            "       -0.56194174, -0.44289276, -0.22176865, -0.13393053,  0.47673908,\n",
            "        0.5077839 , -0.60682297,  0.06843805,  0.5639901 ,  1.0902317 ,\n",
            "       -0.972321  ,  1.9136124 , -0.17206502], dtype=float32)}\n",
            "ctrl action chosen: [ 0.43204388 -0.23720585  0.42449206 -0.24290752  0.42546454 -0.24528453\n",
            "  0.42833892 -0.23838887]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5210115, dtype=float32), 'agent_0': Array(0.5210115, dtype=float32), 'agent_1': Array(0.5210115, dtype=float32), 'agent_2': Array(0.5210115, dtype=float32), 'agent_3': Array(0.5210115, dtype=float32)}\n",
            "step: 305\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5352647 ,  0.7742847 , -0.07675252,  0.06863611,  0.6244049 ,\n",
            "       -0.1998704 ,  0.50952446, -0.20331818,  0.08537869,  0.19872822,\n",
            "        0.39229393, -0.49362183,  0.13263226,  0.70506334,  0.8300275 ,\n",
            "       -6.552053  ,  9.478514  ,  0.63690686], dtype=float32), 'agent_1': Array([ 0.5352647 ,  0.7742847 , -0.07675252,  0.06863611,  0.6244049 ,\n",
            "       -0.1998704 , -0.20331818, -1.1768523 ,  0.08537869,  0.19872822,\n",
            "        0.39229393, -0.49362183,  0.13263226,  0.70506334,  0.8300275 ,\n",
            "       -6.552053  ,  6.52086   , -5.688146  ], dtype=float32), 'agent_2': Array([ 0.5352647 ,  0.7742847 , -0.07675252,  0.06863611,  0.6244049 ,\n",
            "       -0.1998704 , -0.20331818,  0.08537869, -1.2572412 ,  0.19872822,\n",
            "        0.39229393, -0.49362183,  0.13263226,  0.70506334,  0.8300275 ,\n",
            "       -6.552053  ,  7.77386   , -0.261904  ], dtype=float32), 'agent_3': Array([ 0.5352647 ,  0.7742847 , -0.07675252,  0.06863611,  0.6244049 ,\n",
            "       -0.1998704 , -0.20331818,  0.08537869,  0.19872822,  0.49613994,\n",
            "        0.39229393, -0.49362183,  0.13263226,  0.70506334,  0.8300275 ,\n",
            "       -6.552053  ,  8.051533  ,  0.21673733], dtype=float32)}\n",
            "ctrl action chosen: [-1.4277928  1.5219209 -1.436241   1.5194755 -1.4282998  1.5215969\n",
            " -1.4290397  1.5218073]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9859415, dtype=float32), 'agent_0': Array(0.9859415, dtype=float32), 'agent_1': Array(0.9859415, dtype=float32), 'agent_2': Array(0.9859415, dtype=float32), 'agent_3': Array(0.9859415, dtype=float32)}\n",
            "step: 306\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5519212 ,  0.6675983 , -0.03335246,  0.05793876,  0.7415141 ,\n",
            "       -0.53502375,  0.7866332 , -0.6063202 , -0.3286584 , -0.20000729,\n",
            "        0.6237507 ,  0.5947113 ,  0.7836938 , -0.45560157, -3.2410307 ,\n",
            "        6.6329412 , -7.6153874 ,  7.3625565 ], dtype=float32), 'agent_1': Array([ 0.5519212 ,  0.6675983 , -0.03335246,  0.05793876,  0.7415141 ,\n",
            "       -0.53502375, -0.6063202 , -1.1160651 , -0.3286584 , -0.20000729,\n",
            "        0.6237507 ,  0.5947113 ,  0.7836938 , -0.45560157, -3.2410307 ,\n",
            "        6.6329412 , -6.2937274 ,  4.988604  ], dtype=float32), 'agent_2': Array([ 0.5519212 ,  0.6675983 , -0.03335246,  0.05793876,  0.7415141 ,\n",
            "       -0.53502375, -0.6063202 , -0.3286584 , -1.023688  , -0.20000729,\n",
            "        0.6237507 ,  0.5947113 ,  0.7836938 , -0.45560157, -3.2410307 ,\n",
            "        6.6329412 , -9.860274  ,  8.9529705 ], dtype=float32), 'agent_3': Array([  0.5519212 ,   0.6675983 ,  -0.03335246,   0.05793876,\n",
            "         0.7415141 ,  -0.53502375,  -0.6063202 ,  -0.3286584 ,\n",
            "        -0.20000729,   0.76893896,   0.6237507 ,   0.5947113 ,\n",
            "         0.7836938 ,  -0.45560157,  -3.2410307 ,   6.6329412 ,\n",
            "       -10.215277  ,   7.3933997 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5063391   0.55235326 -0.5074913   0.5523516  -0.50801176  0.550186\n",
            " -0.50972027  0.549541  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.3453436, dtype=float32), 'agent_0': Array(-7.3453436, dtype=float32), 'agent_1': Array(-7.3453436, dtype=float32), 'agent_2': Array(-7.3453436, dtype=float32), 'agent_3': Array(-7.3453436, dtype=float32)}\n",
            "step: 307\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5767848 ,  0.6427971 ,  0.00929877, -0.01432572,  0.7658461 ,\n",
            "       -0.5477782 ,  1.1578938 , -0.55738   , -0.5422667 , -0.49127176,\n",
            "        1.0208607 ,  1.1157036 ,  0.46367645, -1.5439155 , -3.3506138 ,\n",
            "        0.5766417 ,  1.5477991 ,  8.384894  ], dtype=float32), 'agent_1': Array([ 0.5767848 ,  0.6427971 ,  0.00929877, -0.01432572,  0.7658461 ,\n",
            "       -0.5477782 , -0.55738   , -0.784969  , -0.5422667 , -0.49127176,\n",
            "        1.0208607 ,  1.1157036 ,  0.46367645, -1.5439155 , -3.3506138 ,\n",
            "        0.5766417 ,  2.8291118 ,  8.771541  ], dtype=float32), 'agent_2': Array([ 5.7678479e-01,  6.4279711e-01,  9.2987744e-03, -1.4325718e-02,\n",
            "        7.6584607e-01, -5.4777819e-01, -5.5738002e-01, -5.4226673e-01,\n",
            "       -5.1714289e-01, -4.9127176e-01,  1.0208607e+00,  1.1157036e+00,\n",
            "        4.6367645e-01, -1.5439155e+00, -3.3506138e+00,  5.7664168e-01,\n",
            "       -2.1103232e+00,  1.0206976e+01], dtype=float32), 'agent_3': Array([ 0.5767848 ,  0.6427971 ,  0.00929877, -0.01432572,  0.7658461 ,\n",
            "       -0.5477782 , -0.55738   , -0.5422667 , -0.49127176,  1.1252388 ,\n",
            "        1.0208607 ,  1.1157036 ,  0.46367645, -1.5439155 , -3.3506138 ,\n",
            "        0.5766417 , -5.39027   ,  7.48538   ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.64116514 -1.0737447   0.64008695 -1.0752945   0.6382099  -1.072658\n",
            "  0.6396052  -1.0727544 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7954085, dtype=float32), 'agent_0': Array(0.7954085, dtype=float32), 'agent_1': Array(0.7954085, dtype=float32), 'agent_2': Array(0.7954085, dtype=float32), 'agent_3': Array(0.7954085, dtype=float32)}\n",
            "step: 308\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.9564734e-01,  7.6392490e-01,  2.1428093e-02, -2.6549354e-02,\n",
            "        6.4440262e-01, -3.5900030e-02,  1.1359001e+00,  1.0540512e-02,\n",
            "       -2.1761787e-01, -2.9798639e-01,  6.2870979e-01,  5.0659180e-01,\n",
            "        3.4930706e-01,  1.8007725e-01,  4.4853061e-01, -8.8356533e+00,\n",
            "        1.2431589e+01, -4.4427304e+00], dtype=float32), 'agent_1': Array([ 5.9564734e-01,  7.6392490e-01,  2.1428093e-02, -2.6549354e-02,\n",
            "        6.4440262e-01, -3.5900030e-02,  1.0540512e-02, -7.8675753e-01,\n",
            "       -2.1761787e-01, -2.9798639e-01,  6.2870979e-01,  5.0659180e-01,\n",
            "        3.4930706e-01,  1.8007725e-01,  4.4853061e-01, -8.8356533e+00,\n",
            "        1.3688972e+01, -4.4805980e+00], dtype=float32), 'agent_2': Array([ 0.59564734,  0.7639249 ,  0.02142809, -0.02654935,  0.6444026 ,\n",
            "       -0.03590003,  0.01054051, -0.21761787, -0.5999083 , -0.2979864 ,\n",
            "        0.6287098 ,  0.5065918 ,  0.34930706,  0.18007725,  0.4485306 ,\n",
            "       -8.835653  ,  8.9066925 , -4.35101   ], dtype=float32), 'agent_3': Array([ 0.59564734,  0.7639249 ,  0.02142809, -0.02654935,  0.6444026 ,\n",
            "       -0.03590003,  0.01054051, -0.21761787, -0.2979864 ,  1.0840298 ,\n",
            "        0.6287098 ,  0.5065918 ,  0.34930706,  0.18007725,  0.4485306 ,\n",
            "       -8.835653  ,  6.793325  , -4.1864357 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.1910828  -0.07550844  0.18984959 -0.07556967  0.18773116 -0.07551023\n",
            "  0.18598038 -0.07713021]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3465142, dtype=float32), 'agent_0': Array(-1.3465142, dtype=float32), 'agent_1': Array(-1.3465142, dtype=float32), 'agent_2': Array(-1.3465142, dtype=float32), 'agent_3': Array(-1.3465142, dtype=float32)}\n",
            "step: 309\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5918995 ,  0.84279567,  0.034929  , -0.03080579,  0.5362148 ,\n",
            "        0.36158815,  1.0371943 ,  0.45926914,  0.05248472, -0.12880275,\n",
            "        0.72197914,  0.5423546 , -0.3861189 ,  0.08893612, -0.32332852,\n",
            "       -4.7108216 ,  6.79151   , -2.5682855 ], dtype=float32), 'agent_1': Array([ 0.5918995 ,  0.84279567,  0.034929  , -0.03080579,  0.5362148 ,\n",
            "        0.36158815,  0.45926914, -0.88858116,  0.05248472, -0.12880275,\n",
            "        0.72197914,  0.5423546 , -0.3861189 ,  0.08893612, -0.32332852,\n",
            "       -4.7108216 ,  7.6669602 , -1.9370812 ], dtype=float32), 'agent_2': Array([ 0.5918995 ,  0.84279567,  0.034929  , -0.03080579,  0.5362148 ,\n",
            "        0.36158815,  0.45926914,  0.05248472, -0.7297315 , -0.12880275,\n",
            "        0.72197914,  0.5423546 , -0.3861189 ,  0.08893612, -0.32332852,\n",
            "       -4.7108216 ,  4.4794993 , -3.3405287 ], dtype=float32), 'agent_3': Array([ 0.5918995 ,  0.84279567,  0.034929  , -0.03080579,  0.5362148 ,\n",
            "        0.36158815,  0.45926914,  0.05248472, -0.12880275,  0.9661243 ,\n",
            "        0.72197914,  0.5423546 , -0.3861189 ,  0.08893612, -0.32332852,\n",
            "       -4.7108216 ,  2.7444794 , -3.2817352 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.14802052 -0.02785646  0.14806704 -0.02699753  0.14719528 -0.02984765\n",
            "  0.14448196 -0.0310438 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.5926527, dtype=float32), 'agent_0': Array(1.5926527, dtype=float32), 'agent_1': Array(1.5926527, dtype=float32), 'agent_2': Array(1.5926527, dtype=float32), 'agent_3': Array(1.5926527, dtype=float32)}\n",
            "step: 310\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5855397 ,  0.86307937,  0.03080168, -0.02243377,  0.5036289 ,\n",
            "        0.5242393 ,  0.8633473 ,  0.56185377,  0.11198159, -0.15090549,\n",
            "        0.7212162 , -0.05292892, -0.20987988, -0.0861503 ,  0.5534354 ,\n",
            "        0.01840695,  1.4297249 , -3.460059  ], dtype=float32), 'agent_1': Array([ 0.5855397 ,  0.86307937,  0.03080168, -0.02243377,  0.5036289 ,\n",
            "        0.5242393 ,  0.56185377, -0.94475865,  0.11198159, -0.15090549,\n",
            "        0.7212162 , -0.05292892, -0.20987988, -0.0861503 ,  0.5534354 ,\n",
            "        0.01840695, -0.8352677 , -1.0171335 ], dtype=float32), 'agent_2': Array([ 0.5855397 ,  0.86307937,  0.03080168, -0.02243377,  0.5036289 ,\n",
            "        0.5242393 ,  0.56185377,  0.11198159, -0.8873023 , -0.15090549,\n",
            "        0.7212162 , -0.05292892, -0.20987988, -0.0861503 ,  0.5534354 ,\n",
            "        0.01840695, -0.35146266, -2.8493779 ], dtype=float32), 'agent_3': Array([ 0.5855397 ,  0.86307937,  0.03080168, -0.02243377,  0.5036289 ,\n",
            "        0.5242393 ,  0.56185377,  0.11198159, -0.15090549,  0.78179854,\n",
            "        0.7212162 , -0.05292892, -0.20987988, -0.0861503 ,  0.5534354 ,\n",
            "        0.01840695, -1.7256666 , -3.5269113 ], dtype=float32)}\n",
            "ctrl action chosen: [-2.0862246  1.3296261 -2.0860124  1.337453  -2.0843537  1.3284624\n",
            " -2.0874488  1.3295089]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.6237537, dtype=float32), 'agent_0': Array(1.6237537, dtype=float32), 'agent_1': Array(1.6237537, dtype=float32), 'agent_2': Array(1.6237537, dtype=float32), 'agent_3': Array(1.6237537, dtype=float32)}\n",
            "step: 311\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.567435  ,  0.74595237,  0.05205933, -0.06447671,  0.66082346,\n",
            "        0.08354305,  1.072978  ,  0.01159539, -0.41367096, -0.6563598 ,\n",
            "        1.0002613 ,  0.05903244, -0.52553415, -0.30223894, -2.9036784 ,\n",
            "        6.2519417 , -8.233401  ,  7.6618915 ], dtype=float32), 'agent_1': Array([  0.567435  ,   0.74595237,   0.05205933,  -0.06447671,\n",
            "         0.66082346,   0.08354305,   0.01159539,  -0.6290078 ,\n",
            "        -0.41367096,  -0.6563598 ,   1.0002613 ,   0.05903244,\n",
            "        -0.52553415,  -0.30223894,  -2.9036784 ,   6.2519417 ,\n",
            "       -10.954231  ,   9.726846  ], dtype=float32), 'agent_2': Array([ 0.567435  ,  0.74595237,  0.05205933, -0.06447671,  0.66082346,\n",
            "        0.08354305,  0.01159539, -0.41367096, -0.63143593, -0.6563598 ,\n",
            "        1.0002613 ,  0.05903244, -0.52553415, -0.30223894, -2.9036784 ,\n",
            "        6.2519417 , -9.752382  ,  9.316861  ], dtype=float32), 'agent_3': Array([ 0.567435  ,  0.74595237,  0.05205933, -0.06447671,  0.66082346,\n",
            "        0.08354305,  0.01159539, -0.41367096, -0.6563598 ,  0.95786774,\n",
            "        1.0002613 ,  0.05903244, -0.52553415, -0.30223894, -2.9036784 ,\n",
            "        6.2519417 , -4.3185935 ,  6.260888  ], dtype=float32)}\n",
            "ctrl action chosen: [0.45520192 0.42362082 0.45372534 0.42274037 0.45467663 0.42319196\n",
            " 0.4587016  0.42468637]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-10.355255, dtype=float32), 'agent_0': Array(-10.355255, dtype=float32), 'agent_1': Array(-10.355255, dtype=float32), 'agent_2': Array(-10.355255, dtype=float32), 'agent_3': Array(-10.355255, dtype=float32)}\n",
            "step: 312\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5219465 ,  0.78679115,  0.07062488, -0.08965626,  0.6065753 ,\n",
            "        0.23424143,  1.2672586 ,  0.05225961, -0.32220238, -0.39167976,\n",
            "        0.7428646 , -0.44679642, -1.0159612 , -0.60139006,  0.21026823,\n",
            "       -4.840094  ,  5.827901  , -0.42103615], dtype=float32), 'agent_1': Array([ 0.5219465 ,  0.78679115,  0.07062488, -0.08965626,  0.6065753 ,\n",
            "        0.23424143,  0.05225961, -0.47564414, -0.32220238, -0.39167976,\n",
            "        0.7428646 , -0.44679642, -1.0159612 , -0.60139006,  0.21026823,\n",
            "       -4.840094  ,  4.0010386 , -0.7895024 ], dtype=float32), 'agent_2': Array([ 0.5219465 ,  0.78679115,  0.07062488, -0.08965626,  0.6065753 ,\n",
            "        0.23424143,  0.05225961, -0.32220238, -0.48661956, -0.39167976,\n",
            "        0.7428646 , -0.44679642, -1.0159612 , -0.60139006,  0.21026823,\n",
            "       -4.840094  ,  4.9353456 , -1.0604011 ], dtype=float32), 'agent_3': Array([ 0.5219465 ,  0.78679115,  0.07062488, -0.08965626,  0.6065753 ,\n",
            "        0.23424143,  0.05225961, -0.32220238, -0.39167976,  1.2600344 ,\n",
            "        0.7428646 , -0.44679642, -1.0159612 , -0.60139006,  0.21026823,\n",
            "       -4.840094  ,  8.790838  ,  4.843802  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.9761503   0.7879039  -1.9771923   0.78775555 -1.9771725   0.7874593\n",
            " -1.9786896   0.78776634]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0400473, dtype=float32), 'agent_0': Array(1.0400473, dtype=float32), 'agent_1': Array(1.0400473, dtype=float32), 'agent_2': Array(1.0400473, dtype=float32), 'agent_3': Array(1.0400473, dtype=float32)}\n",
            "step: 313\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5149399 ,  0.7083283 ,  0.06513013, -0.11110479,  0.6940351 ,\n",
            "       -0.09464853,  1.2673618 , -0.37146476, -0.61958015, -0.558121  ,\n",
            "        0.57878494, -0.76236725, -0.03938675, -0.42646775, -0.33031547,\n",
            "        3.5120687 , -6.705839  , -0.66013885], dtype=float32), 'agent_1': Array([ 0.5149399 ,  0.7083283 ,  0.06513013, -0.11110479,  0.6940351 ,\n",
            "       -0.09464853, -0.37146476, -0.4873731 , -0.61958015, -0.558121  ,\n",
            "        0.57878494, -0.76236725, -0.03938675, -0.42646775, -0.33031547,\n",
            "        3.5120687 , -8.498682  , -0.373324  ], dtype=float32), 'agent_2': Array([ 0.5149399 ,  0.7083283 ,  0.06513013, -0.11110479,  0.6940351 ,\n",
            "       -0.09464853, -0.37146476, -0.61958015, -0.4678675 , -0.558121  ,\n",
            "        0.57878494, -0.76236725, -0.03938675, -0.42646775, -0.33031547,\n",
            "        3.5120687 , -2.1753974 , -0.15918195], dtype=float32), 'agent_3': Array([ 0.5149399 ,  0.7083283 ,  0.06513013, -0.11110479,  0.6940351 ,\n",
            "       -0.09464853, -0.37146476, -0.61958015, -0.558121  ,  1.2719076 ,\n",
            "        0.57878494, -0.76236725, -0.03938675, -0.42646775, -0.33031547,\n",
            "        3.5120687 , -2.1321805 , -0.5597847 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.00536539  1.2125988  -0.00739187  1.2124046  -0.00536971  1.2104385\n",
            " -0.00466305  1.2104812 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.2725153, dtype=float32), 'agent_0': Array(-7.2725153, dtype=float32), 'agent_1': Array(-7.2725153, dtype=float32), 'agent_2': Array(-7.2725153, dtype=float32), 'agent_3': Array(-7.2725153, dtype=float32)}\n",
            "step: 314\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52005184,  0.7135884 ,  0.05925879, -0.10997193,  0.6893375 ,\n",
            "       -0.20297061,  1.244638  , -0.5399869 , -0.51352316, -0.48196632,\n",
            "       -0.27151108, -0.75502396,  0.15810728, -0.03445476,  0.27431875,\n",
            "       -1.0491756 , -1.2747419 ,  0.08526792], dtype=float32), 'agent_1': Array([ 0.52005184,  0.7135884 ,  0.05925879, -0.10997193,  0.6893375 ,\n",
            "       -0.20297061, -0.5399869 , -0.49437416, -0.51352316, -0.48196632,\n",
            "       -0.27151108, -0.75502396,  0.15810728, -0.03445476,  0.27431875,\n",
            "       -1.0491756 , -1.5509009 ,  0.14179946], dtype=float32), 'agent_2': Array([ 0.52005184,  0.7135884 ,  0.05925879, -0.10997193,  0.6893375 ,\n",
            "       -0.20297061, -0.5399869 , -0.51352316, -0.48252505, -0.48196632,\n",
            "       -0.27151108, -0.75502396,  0.15810728, -0.03445476,  0.27431875,\n",
            "       -1.0491756 ,  3.3903542 , -0.2721032 ], dtype=float32), 'agent_3': Array([ 0.52005184,  0.7135884 ,  0.05925879, -0.10997193,  0.6893375 ,\n",
            "       -0.20297061, -0.5399869 , -0.51352316, -0.48196632,  1.2455859 ,\n",
            "       -0.27151108, -0.75502396,  0.15810728, -0.03445476,  0.27431875,\n",
            "       -1.0491756 ,  2.391835  , -0.4485912 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.56227374 -0.06874803 -0.5676289  -0.0707958  -0.5575115  -0.07153826\n",
            " -0.5574279  -0.06884368]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.9280782, dtype=float32), 'agent_0': Array(-1.9280782, dtype=float32), 'agent_1': Array(-1.9280782, dtype=float32), 'agent_2': Array(-1.9280782, dtype=float32), 'agent_3': Array(-1.9280782, dtype=float32)}\n",
            "step: 315\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2761078e-01,  7.1114308e-01,  4.4628061e-02, -9.1952637e-02,\n",
            "        6.9557786e-01, -3.8743412e-01,  1.1658694e+00, -5.9305251e-01,\n",
            "       -4.8878777e-01, -5.2113092e-01, -4.4727325e-01, -3.3540726e-01,\n",
            "       -5.2452087e-04,  3.7537083e-02,  7.7566302e-01,  8.2829034e-01,\n",
            "       -4.8605666e+00, -1.0856805e+00], dtype=float32), 'agent_1': Array([ 5.2761078e-01,  7.1114308e-01,  4.4628061e-02, -9.1952637e-02,\n",
            "        6.9557786e-01, -3.8743412e-01, -5.9305251e-01, -5.6636125e-01,\n",
            "       -4.8878777e-01, -5.2113092e-01, -4.4727325e-01, -3.3540726e-01,\n",
            "       -5.2452087e-04,  3.7537083e-02,  7.7566302e-01,  8.2829034e-01,\n",
            "       -5.3176865e-02, -1.0511571e+00], dtype=float32), 'agent_2': Array([ 5.2761078e-01,  7.1114308e-01,  4.4628061e-02, -9.1952637e-02,\n",
            "        6.9557786e-01, -3.8743412e-01, -5.9305251e-01, -4.8878777e-01,\n",
            "       -5.6337637e-01, -5.2113092e-01, -4.4727325e-01, -3.3540726e-01,\n",
            "       -5.2452087e-04,  3.7537083e-02,  7.7566302e-01,  8.2829034e-01,\n",
            "       -1.2117622e+00, -1.2848259e+00], dtype=float32), 'agent_3': Array([ 5.2761078e-01,  7.1114308e-01,  4.4628061e-02, -9.1952637e-02,\n",
            "        6.9557786e-01, -3.8743412e-01, -5.9305251e-01, -4.8878777e-01,\n",
            "       -5.2113092e-01,  1.1295238e+00, -4.4727325e-01, -3.3540726e-01,\n",
            "       -5.2452087e-04,  3.7537083e-02,  7.7566302e-01,  8.2829034e-01,\n",
            "       -2.2281866e+00, -1.9093999e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.27640584  0.8588277  -0.2776991   0.85423005 -0.27859572  0.8546975\n",
            " -0.2781053   0.85430574]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.05403304, dtype=float32), 'agent_0': Array(-0.05403304, dtype=float32), 'agent_1': Array(-0.05403304, dtype=float32), 'agent_2': Array(-0.05403304, dtype=float32), 'agent_3': Array(-0.05403304, dtype=float32)}\n",
            "step: 316\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.51057196,  0.7160174 ,  0.03938797, -0.10776775,  0.68858826,\n",
            "       -0.5599352 ,  1.269272  , -0.48790708, -0.5154579 , -0.5423709 ,\n",
            "       -0.23527145, -0.16555786, -0.5289793 , -0.2372053 ,  0.4943933 ,\n",
            "       -1.3000922 , -1.2005482 , -0.4077386 ], dtype=float32), 'agent_1': Array([ 0.51057196,  0.7160174 ,  0.03938797, -0.10776775,  0.68858826,\n",
            "       -0.5599352 , -0.48790708, -0.47442096, -0.5154579 , -0.5423709 ,\n",
            "       -0.23527145, -0.16555786, -0.5289793 , -0.2372053 ,  0.4943933 ,\n",
            "       -1.3000922 ,  3.1863487 , -0.11508684], dtype=float32), 'agent_2': Array([ 0.51057196,  0.7160174 ,  0.03938797, -0.10776775,  0.68858826,\n",
            "       -0.5599352 , -0.48790708, -0.5154579 , -0.48143622, -0.5423709 ,\n",
            "       -0.23527145, -0.16555786, -0.5289793 , -0.2372053 ,  0.4943933 ,\n",
            "       -1.3000922 , -0.12888661, -0.23992735], dtype=float32), 'agent_3': Array([ 0.51057196,  0.7160174 ,  0.03938797, -0.10776775,  0.68858826,\n",
            "       -0.5599352 , -0.48790708, -0.5154579 , -0.5423709 ,  1.271811  ,\n",
            "       -0.23527145, -0.16555786, -0.5289793 , -0.2372053 ,  0.4943933 ,\n",
            "       -1.3000922 ,  0.9621386 ,  0.60100096], dtype=float32)}\n",
            "ctrl action chosen: [0.7689734 1.0573384 0.7727281 1.0553666 0.767308  1.055626  0.7715697\n",
            " 1.0595695]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9241872, dtype=float32), 'agent_0': Array(-0.9241872, dtype=float32), 'agent_1': Array(-0.9241872, dtype=float32), 'agent_2': Array(-0.9241872, dtype=float32), 'agent_3': Array(-0.9241872, dtype=float32)}\n",
            "step: 317\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.49488378,   0.84467226,   0.05346092,  -0.08851022,\n",
            "         0.5252016 ,  -0.19930372,   1.2666837 ,   0.10050923,\n",
            "        -0.0791375 ,  -0.05887682,  -0.6723404 ,  -0.02260208,\n",
            "         0.10963082,   0.07987867,  -0.07099114, -10.1465225 ,\n",
            "        10.24919   ,   0.10317301], dtype=float32), 'agent_1': Array([  0.49488378,   0.84467226,   0.05346092,  -0.08851022,\n",
            "         0.5252016 ,  -0.19930372,   0.10050923,  -0.48215073,\n",
            "        -0.0791375 ,  -0.05887682,  -0.6723404 ,  -0.02260208,\n",
            "         0.10963082,   0.07987867,  -0.07099114, -10.1465225 ,\n",
            "        13.635298  ,  -0.13873063], dtype=float32), 'agent_2': Array([  0.49488378,   0.84467226,   0.05346092,  -0.08851022,\n",
            "         0.5252016 ,  -0.19930372,   0.10050923,  -0.0791375 ,\n",
            "        -0.47780648,  -0.05887682,  -0.6723404 ,  -0.02260208,\n",
            "         0.10963082,   0.07987867,  -0.07099114, -10.1465225 ,\n",
            "        11.221253  ,   0.19055007], dtype=float32), 'agent_3': Array([ 4.94883776e-01,  8.44672263e-01,  5.34609221e-02, -8.85102153e-02,\n",
            "        5.25201619e-01, -1.99303716e-01,  1.00509226e-01, -7.91375041e-02,\n",
            "       -5.88768236e-02,  1.26935899e+00, -6.72340393e-01, -2.26020813e-02,\n",
            "        1.09630823e-01,  7.98786730e-02, -7.09911436e-02, -1.01465225e+01,\n",
            "        1.26427031e+01,  4.09791945e-03], dtype=float32)}\n",
            "ctrl action chosen: [1.235756   0.49436536 1.232151   0.49465814 1.2340685  0.49473563\n",
            " 1.2332007  0.4941639 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.8325167, dtype=float32), 'agent_0': Array(-2.8325167, dtype=float32), 'agent_1': Array(-2.8325167, dtype=float32), 'agent_2': Array(-2.8325167, dtype=float32), 'agent_3': Array(-2.8325167, dtype=float32)}\n",
            "step: 318\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49728653,  0.94677144,  0.07269467, -0.06730885,  0.3062824 ,\n",
            "        0.35357404,  1.2354687 ,  0.6638294 ,  0.5196445 ,  0.5855807 ,\n",
            "       -0.4482746 , -0.18415451, -0.02959967,  0.1127993 , -0.1473624 ,\n",
            "       -1.934521  ,  4.0594144 , -0.02829891], dtype=float32), 'agent_1': Array([ 0.49728653,  0.94677144,  0.07269467, -0.06730885,  0.3062824 ,\n",
            "        0.35357404,  0.6638294 , -0.5076711 ,  0.5196445 ,  0.5855807 ,\n",
            "       -0.4482746 , -0.18415451, -0.02959967,  0.1127993 , -0.1473624 ,\n",
            "       -1.934521  , -1.8081002 ,  0.01705253], dtype=float32), 'agent_2': Array([ 0.49728653,  0.94677144,  0.07269467, -0.06730885,  0.3062824 ,\n",
            "        0.35357404,  0.6638294 ,  0.5196445 , -0.4998334 ,  0.5855807 ,\n",
            "       -0.4482746 , -0.18415451, -0.02959967,  0.1127993 , -0.1473624 ,\n",
            "       -1.934521  ,  4.3558874 ,  0.02383087], dtype=float32), 'agent_3': Array([ 0.49728653,  0.94677144,  0.07269467, -0.06730885,  0.3062824 ,\n",
            "        0.35357404,  0.6638294 ,  0.5196445 ,  0.5855807 ,  1.2235502 ,\n",
            "       -0.4482746 , -0.18415451, -0.02959967,  0.1127993 , -0.1473624 ,\n",
            "       -1.934521  ,  3.0828404 , -0.31707007], dtype=float32)}\n",
            "ctrl action chosen: [0.8548462  0.66479456 0.8492642  0.67168087 0.85665643 0.66426307\n",
            " 0.85342896 0.6665911 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.1812046, dtype=float32), 'agent_0': Array(-3.1812046, dtype=float32), 'agent_1': Array(-3.1812046, dtype=float32), 'agent_2': Array(-3.1812046, dtype=float32), 'agent_3': Array(-3.1812046, dtype=float32)}\n",
            "step: 319\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4992792 ,  0.94685155,  0.07272698, -0.07562944,  0.3040774 ,\n",
            "        0.51776147,  1.2470782 ,  0.49655345,  0.56816614,  0.57152647,\n",
            "       -0.2418518 , -0.02889633,  0.09899735, -0.3633019 , -0.17273127,\n",
            "       -0.3332068 ,  4.6734543 , -0.02861998], dtype=float32), 'agent_1': Array([ 0.4992792 ,  0.94685155,  0.07272698, -0.07562944,  0.3040774 ,\n",
            "        0.51776147,  0.49655345, -0.49675632,  0.56816614,  0.57152647,\n",
            "       -0.2418518 , -0.02889633,  0.09899735, -0.3633019 , -0.17273127,\n",
            "       -0.3332068 , -3.1836176 , -0.06289614], dtype=float32), 'agent_2': Array([ 0.4992792 ,  0.94685155,  0.07272698, -0.07562944,  0.3040774 ,\n",
            "        0.51776147,  0.49655345,  0.56816614, -0.49612644,  0.57152647,\n",
            "       -0.2418518 , -0.02889633,  0.09899735, -0.3633019 , -0.17273127,\n",
            "       -0.3332068 ,  0.3562444 , -0.15384606], dtype=float32), 'agent_3': Array([ 0.4992792 ,  0.94685155,  0.07272698, -0.07562944,  0.3040774 ,\n",
            "        0.51776147,  0.49655345,  0.56816614,  0.57152647,  1.2431246 ,\n",
            "       -0.2418518 , -0.02889633,  0.09899735, -0.3633019 , -0.17273127,\n",
            "       -0.3332068 , -1.286373  ,  0.27802134], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9934229  -0.6357377   0.98165095 -0.6264783   0.9917964  -0.63311017\n",
            "  0.98481447 -0.62738234]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.563277, dtype=float32), 'agent_0': Array(-1.563277, dtype=float32), 'agent_1': Array(-1.563277, dtype=float32), 'agent_2': Array(-1.563277, dtype=float32), 'agent_3': Array(-1.563277, dtype=float32)}\n",
            "step: 320\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5032114 ,  0.94912326,  0.04441749, -0.06169783,  0.30559027,\n",
            "        0.6154386 ,  1.0414653 ,  0.4265297 ,  0.5553144 ,  0.52522016,\n",
            "       -0.7089138 , -0.02336502,  0.09260178, -0.9172392 ,  1.1976589 ,\n",
            "       -0.3806459 ,  0.24661824, -5.298464  ], dtype=float32), 'agent_1': Array([ 0.5032114 ,  0.94912326,  0.04441749, -0.06169783,  0.30559027,\n",
            "        0.6154386 ,  0.4265297 , -0.6951703 ,  0.5553144 ,  0.52522016,\n",
            "       -0.7089138 , -0.02336502,  0.09260178, -0.9172392 ,  1.1976589 ,\n",
            "       -0.3806459 ,  1.1192836 , -4.368535  ], dtype=float32), 'agent_2': Array([ 0.5032114 ,  0.94912326,  0.04441749, -0.06169783,  0.30559027,\n",
            "        0.6154386 ,  0.4265297 ,  0.5553144 , -0.68541425,  0.52522016,\n",
            "       -0.7089138 , -0.02336502,  0.09260178, -0.9172392 ,  1.1976589 ,\n",
            "       -0.3806459 , -0.11154249, -4.5528703 ], dtype=float32), 'agent_3': Array([ 0.5032114 ,  0.94912326,  0.04441749, -0.06169783,  0.30559027,\n",
            "        0.6154386 ,  0.4265297 ,  0.5553144 ,  0.52522016,  1.0605608 ,\n",
            "       -0.7089138 , -0.02336502,  0.09260178, -0.9172392 ,  1.1976589 ,\n",
            "       -0.3806459 ,  0.30282968, -4.9001355 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.96900356 -0.53489035 -0.9702337  -0.5325859  -0.96718377 -0.5369695\n",
            " -0.96976054 -0.53457433]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.280398, dtype=float32), 'agent_0': Array(-2.280398, dtype=float32), 'agent_1': Array(-2.280398, dtype=float32), 'agent_2': Array(-2.280398, dtype=float32), 'agent_3': Array(-2.280398, dtype=float32)}\n",
            "step: 321\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.30538201e-01,  8.58039677e-01,  1.40802958e-03, -2.88916174e-02,\n",
            "        5.12768209e-01,  4.32160832e-02,  7.43906021e-01, -1.73995629e-01,\n",
            "       -1.09359797e-03, -4.75165136e-02, -7.08103180e-01,  3.33499908e-01,\n",
            "        9.02056694e-01,  6.98767155e-02,  2.47687149e+00,  1.18951645e+01,\n",
            "       -1.57484407e+01, -7.05658197e+00], dtype=float32), 'agent_1': Array([ 5.30538201e-01,  8.58039677e-01,  1.40802958e-03, -2.88916174e-02,\n",
            "        5.12768209e-01,  4.32160832e-02, -1.73995629e-01, -8.78076077e-01,\n",
            "       -1.09359797e-03, -4.75165136e-02, -7.08103180e-01,  3.33499908e-01,\n",
            "        9.02056694e-01,  6.98767155e-02,  2.47687149e+00,  1.18951645e+01,\n",
            "       -1.64602032e+01, -3.45529795e+00], dtype=float32), 'agent_2': Array([ 5.30538201e-01,  8.58039677e-01,  1.40802958e-03, -2.88916174e-02,\n",
            "        5.12768209e-01,  4.32160832e-02, -1.73995629e-01, -1.09359797e-03,\n",
            "       -9.07601357e-01, -4.75165136e-02, -7.08103180e-01,  3.33499908e-01,\n",
            "        9.02056694e-01,  6.98767155e-02,  2.47687149e+00,  1.18951645e+01,\n",
            "       -1.43785543e+01, -4.73231077e+00], dtype=float32), 'agent_3': Array([ 5.30538201e-01,  8.58039677e-01,  1.40802958e-03, -2.88916174e-02,\n",
            "        5.12768209e-01,  4.32160832e-02, -1.73995629e-01, -1.09359797e-03,\n",
            "       -4.75165136e-02,  7.56423652e-01, -7.08103180e-01,  3.33499908e-01,\n",
            "        9.02056694e-01,  6.98767155e-02,  2.47687149e+00,  1.18951645e+01,\n",
            "       -1.50626631e+01, -7.44013834e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.2079785 -1.2388896  1.2106373 -1.2379434  1.2091588 -1.2401218\n",
            "  1.2062951 -1.2392344]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2160943, dtype=float32), 'agent_0': Array(-2.2160943, dtype=float32), 'agent_1': Array(-2.2160943, dtype=float32), 'agent_2': Array(-2.2160943, dtype=float32), 'agent_3': Array(-2.2160943, dtype=float32)}\n",
            "step: 322\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6185502e-01,  9.1326910e-01, -2.7184708e-02,  4.1042000e-02,\n",
            "        4.0437120e-01,  3.1797189e-01,  4.3532425e-01,  6.1026961e-04,\n",
            "        3.0856010e-01,  2.0619133e-01, -7.3871613e-01,  4.7492981e-01,\n",
            "        4.0977001e-01,  5.1797801e-01,  1.7995088e+00, -1.0075658e+01,\n",
            "        1.2805514e+01,  7.4661022e-01], dtype=float32), 'agent_1': Array([ 5.6185502e-01,  9.1326910e-01, -2.7184708e-02,  4.1042000e-02,\n",
            "        4.0437120e-01,  3.1797189e-01,  6.1026961e-04, -1.2440941e+00,\n",
            "        3.0856010e-01,  2.0619133e-01, -7.3871613e-01,  4.7492981e-01,\n",
            "        4.0977001e-01,  5.1797801e-01,  1.7995088e+00, -1.0075658e+01,\n",
            "        1.0095001e+01, -8.4330578e+00], dtype=float32), 'agent_2': Array([ 5.6185502e-01,  9.1326910e-01, -2.7184708e-02,  4.1042000e-02,\n",
            "        4.0437120e-01,  3.1797189e-01,  6.1026961e-04,  3.0856010e-01,\n",
            "       -1.2826828e+00,  2.0619133e-01, -7.3871613e-01,  4.7492981e-01,\n",
            "        4.0977001e-01,  5.1797801e-01,  1.7995088e+00, -1.0075658e+01,\n",
            "        1.3113571e+01, -4.7454519e+00], dtype=float32), 'agent_3': Array([ 5.6185502e-01,  9.1326910e-01, -2.7184708e-02,  4.1042000e-02,\n",
            "        4.0437120e-01,  3.1797189e-01,  6.1026961e-04,  3.0856010e-01,\n",
            "        2.0619133e-01,  4.1957849e-01, -7.3871613e-01,  4.7492981e-01,\n",
            "        4.0977001e-01,  5.1797801e-01,  1.7995088e+00, -1.0075658e+01,\n",
            "        1.1882477e+01,  5.6019241e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8291995  -0.41437864  0.81855005 -0.41886783  0.8249372  -0.41692147\n",
            "  0.82857484 -0.41444513]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.803851, dtype=float32), 'agent_0': Array(-5.803851, dtype=float32), 'agent_1': Array(-5.803851, dtype=float32), 'agent_2': Array(-5.803851, dtype=float32), 'agent_3': Array(-5.803851, dtype=float32)}\n",
            "step: 323\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60707957,  0.9589183 , -0.0291253 ,  0.05013271,  0.27769458,\n",
            "        0.5887169 ,  0.50059414,  0.3274817 ,  0.59412575,  0.5575185 ,\n",
            "       -0.6661415 ,  0.689888  ,  0.8065343 , -0.24674079,  0.94955975,\n",
            "       -0.4083784 , -1.3171706 ,  0.8283399 ], dtype=float32), 'agent_1': Array([ 0.60707957,  0.9589183 , -0.0291253 ,  0.05013271,  0.27769458,\n",
            "        0.5887169 ,  0.3274817 , -1.2645594 ,  0.59412575,  0.5575185 ,\n",
            "       -0.6661415 ,  0.689888  ,  0.8065343 , -0.24674079,  0.94955975,\n",
            "       -0.4083784 ,  2.5052953 , -0.3961029 ], dtype=float32), 'agent_2': Array([ 0.60707957,  0.9589183 , -0.0291253 ,  0.05013271,  0.27769458,\n",
            "        0.5887169 ,  0.3274817 ,  0.59412575, -1.2649521 ,  0.5575185 ,\n",
            "       -0.6661415 ,  0.689888  ,  0.8065343 , -0.24674079,  0.94955975,\n",
            "       -0.4083784 , -1.3848433 , -0.70234376], dtype=float32), 'agent_3': Array([ 0.60707957,  0.9589183 , -0.0291253 ,  0.05013271,  0.27769458,\n",
            "        0.5887169 ,  0.3274817 ,  0.59412575,  0.5575185 ,  0.5109542 ,\n",
            "       -0.6661415 ,  0.689888  ,  0.8065343 , -0.24674079,  0.94955975,\n",
            "       -0.4083784 ,  0.6542336 ,  1.6206955 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.2781602  -0.60336655  0.28544563 -0.60906965  0.28161514 -0.61392796\n",
            "  0.28268558 -0.6049095 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3106507, dtype=float32), 'agent_0': Array(-1.3106507, dtype=float32), 'agent_1': Array(-1.3106507, dtype=float32), 'agent_2': Array(-1.3106507, dtype=float32), 'agent_3': Array(-1.3106507, dtype=float32)}\n",
            "step: 324\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.61073303,  0.9568338 , -0.03188698,  0.07594392,  0.27872014,\n",
            "        0.4720395 ,  0.5191582 ,  0.43517056,  0.4687724 ,  0.54102176,\n",
            "       -0.71349144,  0.885582  , -0.46862364,  0.29637828,  0.9178581 ,\n",
            "       -0.18626416, -2.1714184 , -0.07276465], dtype=float32), 'agent_1': Array([ 0.61073303,  0.9568338 , -0.03188698,  0.07594392,  0.27872014,\n",
            "        0.4720395 ,  0.43517056, -1.2477796 ,  0.4687724 ,  0.54102176,\n",
            "       -0.71349144,  0.885582  , -0.46862364,  0.29637828,  0.9178581 ,\n",
            "       -0.18626416,  3.1509452 ,  0.9531019 ], dtype=float32), 'agent_2': Array([ 0.61073303,  0.9568338 , -0.03188698,  0.07594392,  0.27872014,\n",
            "        0.4720395 ,  0.43517056,  0.4687724 , -1.2378789 ,  0.54102176,\n",
            "       -0.71349144,  0.885582  , -0.46862364,  0.29637828,  0.9178581 ,\n",
            "       -0.18626416, -2.3859055 ,  0.99033594], dtype=float32), 'agent_3': Array([ 0.61073303,  0.9568338 , -0.03188698,  0.07594392,  0.27872014,\n",
            "        0.4720395 ,  0.43517056,  0.4687724 ,  0.54102176,  0.5253929 ,\n",
            "       -0.71349144,  0.885582  , -0.46862364,  0.29637828,  0.9178581 ,\n",
            "       -0.18626416, -0.25192693, -0.5703284 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2274457   0.8184128  -1.219204    0.8166828  -1.2253293   0.81557745\n",
            " -1.2257218   0.8165002 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.641292, dtype=float32), 'agent_0': Array(-0.641292, dtype=float32), 'agent_1': Array(-0.641292, dtype=float32), 'agent_2': Array(-0.641292, dtype=float32), 'agent_3': Array(-0.641292, dtype=float32)}\n",
            "step: 325\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7725918e-01,  8.7236392e-01,  1.3811333e-02,  5.6323666e-02,\n",
            "        4.8540512e-01, -1.8844561e-01,  8.2279956e-01, -8.3771385e-03,\n",
            "       -1.9324841e-01, -3.4741558e-02, -4.5943260e-01,  1.2668610e+00,\n",
            "       -7.3556900e-01,  4.7264233e-01, -2.3767939e+00,  1.1377801e+01,\n",
            "       -1.6354008e+01,  8.1979914e+00], dtype=float32), 'agent_1': Array([ 5.7725918e-01,  8.7236392e-01,  1.3811333e-02,  5.6323666e-02,\n",
            "        4.8540512e-01, -1.8844561e-01, -8.3771385e-03, -8.7429452e-01,\n",
            "       -1.9324841e-01, -3.4741558e-02, -4.5943260e-01,  1.2668610e+00,\n",
            "       -7.3556900e-01,  4.7264233e-01, -2.3767939e+00,  1.1377801e+01,\n",
            "       -1.2281636e+01,  1.0554444e+01], dtype=float32), 'agent_2': Array([ 5.7725918e-01,  8.7236392e-01,  1.3811333e-02,  5.6323666e-02,\n",
            "        4.8540512e-01, -1.8844561e-01, -8.3771385e-03, -1.9324841e-01,\n",
            "       -8.6143041e-01, -3.4741558e-02, -4.5943260e-01,  1.2668610e+00,\n",
            "       -7.3556900e-01,  4.7264233e-01, -2.3767939e+00,  1.1377801e+01,\n",
            "       -1.6249479e+01,  1.0542873e+01], dtype=float32), 'agent_3': Array([ 5.7725918e-01,  8.7236392e-01,  1.3811333e-02,  5.6323666e-02,\n",
            "        4.8540512e-01, -1.8844561e-01, -8.3771385e-03, -1.9324841e-01,\n",
            "       -3.4741558e-02,  8.0172259e-01, -4.5943260e-01,  1.2668610e+00,\n",
            "       -7.3556900e-01,  4.7264233e-01, -2.3767939e+00,  1.1377801e+01,\n",
            "       -1.4976150e+01,  6.9535546e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.756487    0.97115946 -0.751802    0.9737787  -0.75612944  0.9721328\n",
            " -0.75746113  0.9707208 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.9029126, dtype=float32), 'agent_0': Array(-3.9029126, dtype=float32), 'agent_1': Array(-3.9029126, dtype=float32), 'agent_2': Array(-3.9029126, dtype=float32), 'agent_3': Array(-3.9029126, dtype=float32)}\n",
            "step: 326\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5449052 ,  0.7941227 ,  0.03611314, -0.0123876 ,  0.6065571 ,\n",
            "       -0.5950007 ,  1.2936208 , -0.37256867, -0.6006745 , -0.5370791 ,\n",
            "        0.06113052,  0.63705444, -0.5657315 , -1.3862005 , -0.7936476 ,\n",
            "       -1.1834575 ,  2.1337667 ,  5.003003  ], dtype=float32), 'agent_1': Array([ 0.5449052 ,  0.7941227 ,  0.03611314, -0.0123876 ,  0.6065571 ,\n",
            "       -0.5950007 , -0.37256867, -0.40891367, -0.6006745 , -0.5370791 ,\n",
            "        0.06113052,  0.63705444, -0.5657315 , -1.3862005 , -0.7936476 ,\n",
            "       -1.1834575 , -0.92762005,  0.7948257 ], dtype=float32), 'agent_2': Array([ 0.5449052 ,  0.7941227 ,  0.03611314, -0.0123876 ,  0.6065571 ,\n",
            "       -0.5950007 , -0.37256867, -0.6006745 , -0.42443448, -0.5370791 ,\n",
            "        0.06113052,  0.63705444, -0.5657315 , -1.3862005 , -0.7936476 ,\n",
            "       -1.1834575 ,  2.115116  , -0.07469998], dtype=float32), 'agent_3': Array([ 0.5449052 ,  0.7941227 ,  0.03611314, -0.0123876 ,  0.6065571 ,\n",
            "       -0.5950007 , -0.37256867, -0.6006745 , -0.5370791 ,  1.1493016 ,\n",
            "        0.06113052,  0.63705444, -0.5657315 , -1.3862005 , -0.7936476 ,\n",
            "       -1.1834575 , -3.066431  ,  6.786884  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.06756883 -1.7078468  -0.06786171 -1.7117891  -0.06318828 -1.7143476\n",
            " -0.07093225 -1.7070775 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.181175, dtype=float32), 'agent_0': Array(-2.181175, dtype=float32), 'agent_1': Array(-2.181175, dtype=float32), 'agent_2': Array(-2.181175, dtype=float32), 'agent_3': Array(-2.181175, dtype=float32)}\n",
            "step: 327\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6087017 ,  0.82528704,  0.01778322,  0.02185085,  0.56401026,\n",
            "       -0.4305304 ,  1.043788  , -0.32811442, -0.4511995 , -0.53959095,\n",
            "       -0.6453037 ,  0.21390915,  1.858139  ,  0.3737586 ,  0.73141396,\n",
            "       -1.6565865 ,  3.334217  , -5.1988697 ], dtype=float32), 'agent_1': Array([ 0.6087017 ,  0.82528704,  0.01778322,  0.02185085,  0.56401026,\n",
            "       -0.4305304 , -0.32811442, -0.6590567 , -0.4511995 , -0.53959095,\n",
            "       -0.6453037 ,  0.21390915,  1.858139  ,  0.3737586 ,  0.73141396,\n",
            "       -1.6565865 , -0.31760246, -6.9381027 ], dtype=float32), 'agent_2': Array([ 0.6087017 ,  0.82528704,  0.01778322,  0.02185085,  0.56401026,\n",
            "       -0.4305304 , -0.32811442, -0.4511995 , -0.73133653, -0.53959095,\n",
            "       -0.6453037 ,  0.21390915,  1.858139  ,  0.3737586 ,  0.73141396,\n",
            "       -1.6565865 ,  3.2205613 , -7.0415087 ], dtype=float32), 'agent_3': Array([ 0.6087017 ,  0.82528704,  0.01778322,  0.02185085,  0.56401026,\n",
            "       -0.4305304 , -0.32811442, -0.4511995 , -0.53959095,  0.90423197,\n",
            "       -0.6453037 ,  0.21390915,  1.858139  ,  0.3737586 ,  0.73141396,\n",
            "       -1.6565865 ,  0.9069453 , -7.6107187 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.2171432   0.5068759  -0.21729088  0.5062366  -0.21783665  0.5076812\n",
            " -0.21646483  0.5073015 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.218803, dtype=float32), 'agent_0': Array(-5.218803, dtype=float32), 'agent_1': Array(-5.218803, dtype=float32), 'agent_2': Array(-5.218803, dtype=float32), 'agent_3': Array(-5.218803, dtype=float32)}\n",
            "step: 328\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.5299666e-01,  8.2848161e-01,  1.9162010e-02, -2.1261070e-04,\n",
            "        5.5968839e-01, -4.0373346e-01,  1.0969611e+00, -4.5284587e-01,\n",
            "       -4.0957254e-01, -5.4657131e-01, -4.0550232e-01,  3.8814545e-01,\n",
            "        4.8979521e-01, -4.8812750e-01, -9.2941511e-01,  4.9095365e-01,\n",
            "       -7.7960950e-01,  1.4846718e+00], dtype=float32), 'agent_1': Array([ 6.5299666e-01,  8.2848161e-01,  1.9162010e-02, -2.1261070e-04,\n",
            "        5.5968839e-01, -4.0373346e-01, -4.5284587e-01, -7.8994828e-01,\n",
            "       -4.0957254e-01, -5.4657131e-01, -4.0550232e-01,  3.8814545e-01,\n",
            "        4.8979521e-01, -4.8812750e-01, -9.2941511e-01,  4.9095365e-01,\n",
            "       -3.1631916e+00, -9.9067163e-01], dtype=float32), 'agent_2': Array([ 6.5299666e-01,  8.2848161e-01,  1.9162010e-02, -2.1261070e-04,\n",
            "        5.5968839e-01, -4.0373346e-01, -4.5284587e-01, -4.0957254e-01,\n",
            "       -7.9351026e-01, -5.4657131e-01, -4.0550232e-01,  3.8814545e-01,\n",
            "        4.8979521e-01, -4.8812750e-01, -9.2941511e-01,  4.9095365e-01,\n",
            "       -5.9595174e-01, -6.7206763e-02], dtype=float32), 'agent_3': Array([ 6.5299666e-01,  8.2848161e-01,  1.9162010e-02, -2.1261070e-04,\n",
            "        5.5968839e-01, -4.0373346e-01, -4.5284587e-01, -4.0957254e-01,\n",
            "       -5.4657131e-01,  9.4736814e-01, -4.0550232e-01,  3.8814545e-01,\n",
            "        4.8979521e-01, -4.8812750e-01, -9.2941511e-01,  4.9095365e-01,\n",
            "       -2.2855908e-01,  2.1546996e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.3619132  0.4157807  0.35370958 0.41267398 0.36006564 0.40952492\n",
            " 0.36133036 0.41558978]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.055372, dtype=float32), 'agent_0': Array(-0.055372, dtype=float32), 'agent_1': Array(-0.055372, dtype=float32), 'agent_2': Array(-0.055372, dtype=float32), 'agent_3': Array(-0.055372, dtype=float32)}\n",
            "step: 329\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6701465 ,  0.8737846 ,  0.01835315, -0.02112814,  0.48550737,\n",
            "       -0.19264814,  1.1567513 , -0.35039964, -0.20445712, -0.3365581 ,\n",
            "       -0.5101681 ,  0.31700134,  0.13383627, -0.6665919 , -1.0191442 ,\n",
            "       -4.8712482 ,  5.920702  ,  2.368625  ], dtype=float32), 'agent_1': Array([ 0.6701465 ,  0.8737846 ,  0.01835315, -0.02112814,  0.48550737,\n",
            "       -0.19264814, -0.35039964, -0.7760196 , -0.20445712, -0.3365581 ,\n",
            "       -0.5101681 ,  0.31700134,  0.13383627, -0.6665919 , -1.0191442 ,\n",
            "       -4.8712482 ,  3.9245305 ,  1.6376632 ], dtype=float32), 'agent_2': Array([ 0.6701465 ,  0.8737846 ,  0.01835315, -0.02112814,  0.48550737,\n",
            "       -0.19264814, -0.35039964, -0.20445712, -0.7746794 , -0.3365581 ,\n",
            "       -0.5101681 ,  0.31700134,  0.13383627, -0.6665919 , -1.0191442 ,\n",
            "       -4.8712482 ,  5.6868095 ,  1.5084258 ], dtype=float32), 'agent_3': Array([ 0.6701465 ,  0.8737846 ,  0.01835315, -0.02112814,  0.48550737,\n",
            "       -0.19264814, -0.35039964, -0.20445712, -0.3365581 ,  1.0261385 ,\n",
            "       -0.5101681 ,  0.31700134,  0.13383627, -0.6665919 , -1.0191442 ,\n",
            "       -4.8712482 ,  5.9327    ,  2.6572182 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2013451   0.44604084 -1.2026703   0.44529405 -1.2028812   0.44435483\n",
            " -1.203269    0.44497913]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.0922783, dtype=float32), 'agent_0': Array(-0.0922783, dtype=float32), 'agent_1': Array(-0.0922783, dtype=float32), 'agent_2': Array(-0.0922783, dtype=float32), 'agent_3': Array(-0.0922783, dtype=float32)}\n",
            "step: 330\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6574243 ,  0.82128245,  0.01098195, -0.07136024,  0.5659349 ,\n",
            "       -0.46594346,  1.2696288 , -0.6174739 , -0.48518145, -0.57878006,\n",
            "       -0.21777153,  0.54483414, -0.52024126, -1.6881303 , -1.4899358 ,\n",
            "        1.4553845 , -4.3310094 , -0.05352512], dtype=float32), 'agent_1': Array([ 0.6574243 ,  0.82128245,  0.01098195, -0.07136024,  0.5659349 ,\n",
            "       -0.46594346, -0.6174739 , -0.5542013 , -0.48518145, -0.57878006,\n",
            "       -0.21777153,  0.54483414, -0.52024126, -1.6881303 , -1.4899358 ,\n",
            "        1.4553845 , -0.5816702 ,  6.5226207 ], dtype=float32), 'agent_2': Array([ 0.6574243 ,  0.82128245,  0.01098195, -0.07136024,  0.5659349 ,\n",
            "       -0.46594346, -0.6174739 , -0.48518145, -0.5555364 , -0.57878006,\n",
            "       -0.21777153,  0.54483414, -0.52024126, -1.6881303 , -1.4899358 ,\n",
            "        1.4553845 , -4.4803004 ,  6.4100585 ], dtype=float32), 'agent_3': Array([ 0.6574243 ,  0.82128245,  0.01098195, -0.07136024,  0.5659349 ,\n",
            "       -0.46594346, -0.6174739 , -0.48518145, -0.57878006,  1.2631301 ,\n",
            "       -0.21777153,  0.54483414, -0.52024126, -1.6881303 , -1.4899358 ,\n",
            "        1.4553845 , -1.4185725 ,  3.8203285 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.9262596 -1.4101003 -1.9265869 -1.4087777 -1.9269537 -1.4073858\n",
            " -1.92372   -1.4082804]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.655702, dtype=float32), 'agent_0': Array(-2.655702, dtype=float32), 'agent_1': Array(-2.655702, dtype=float32), 'agent_2': Array(-2.655702, dtype=float32), 'agent_3': Array(-2.655702, dtype=float32)}\n",
            "step: 331\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1695778e-01,  8.2715350e-01,  3.8695948e-03, -6.2890463e-02,\n",
            "        5.5843258e-01, -5.8240330e-01,  1.0268070e+00, -5.1824093e-01,\n",
            "       -5.7006001e-01, -5.2971590e-01, -6.9060326e-01,  4.5747757e-01,\n",
            "       -9.8342896e-01,  4.4616494e-01,  1.4236865e+00, -9.2668217e-01,\n",
            "       -9.7001851e-01, -8.2694244e+00], dtype=float32), 'agent_1': Array([ 6.1695778e-01,  8.2715350e-01,  3.8695948e-03, -6.2890463e-02,\n",
            "        5.5843258e-01, -5.8240330e-01, -5.1824093e-01, -6.6229522e-01,\n",
            "       -5.7006001e-01, -5.2971590e-01, -6.9060326e-01,  4.5747757e-01,\n",
            "       -9.8342896e-01,  4.4616494e-01,  1.4236865e+00, -9.2668217e-01,\n",
            "        2.6275039e+00, -6.2086782e+00], dtype=float32), 'agent_2': Array([ 6.1695778e-01,  8.2715350e-01,  3.8695948e-03, -6.2890463e-02,\n",
            "        5.5843258e-01, -5.8240330e-01, -5.1824093e-01, -5.7006001e-01,\n",
            "       -6.7026973e-01, -5.2971590e-01, -6.9060326e-01,  4.5747757e-01,\n",
            "       -9.8342896e-01,  4.4616494e-01,  1.4236865e+00, -9.2668217e-01,\n",
            "       -5.2102017e-01, -5.9962587e+00], dtype=float32), 'agent_3': Array([ 6.1695778e-01,  8.2715350e-01,  3.8695948e-03, -6.2890463e-02,\n",
            "        5.5843258e-01, -5.8240330e-01, -5.1824093e-01, -5.7006001e-01,\n",
            "       -5.2971590e-01,  1.0872765e+00, -6.9060326e-01,  4.5747757e-01,\n",
            "       -9.8342896e-01,  4.4616494e-01,  1.4236865e+00, -9.2668217e-01,\n",
            "        1.5612987e+00, -6.1631484e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.238852    0.21946146 -0.23993266  0.22044268 -0.23984505  0.21979877\n",
            " -0.2385203   0.2208547 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-10.920597, dtype=float32), 'agent_0': Array(-10.920597, dtype=float32), 'agent_1': Array(-10.920597, dtype=float32), 'agent_2': Array(-10.920597, dtype=float32), 'agent_3': Array(-10.920597, dtype=float32)}\n",
            "step: 332\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5800843e-01,  8.5464448e-01, -9.4038603e-04, -6.0050115e-02,\n",
            "        5.1572853e-01, -5.3338176e-01,  7.9247409e-01, -3.4675923e-01,\n",
            "       -5.2939939e-01, -4.2090753e-01, -4.3158531e-01,  5.6438446e-01,\n",
            "       -1.3563156e+00, -1.8363112e-01, -1.0003390e-01, -6.0942239e-01,\n",
            "        2.5371879e-01, -3.4129851e+00], dtype=float32), 'agent_1': Array([ 5.5800843e-01,  8.5464448e-01, -9.4038603e-04, -6.0050115e-02,\n",
            "        5.1572853e-01, -5.3338176e-01, -3.4675923e-01, -7.4087095e-01,\n",
            "       -5.2939939e-01, -4.2090753e-01, -4.3158531e-01,  5.6438446e-01,\n",
            "       -1.3563156e+00, -1.8363112e-01, -1.0003390e-01, -6.0942239e-01,\n",
            "        1.0821782e+00,  4.4510591e-01], dtype=float32), 'agent_2': Array([ 5.5800843e-01,  8.5464448e-01, -9.4038603e-04, -6.0050115e-02,\n",
            "        5.1572853e-01, -5.3338176e-01, -3.4675923e-01, -5.2939939e-01,\n",
            "       -7.4320495e-01, -4.2090753e-01, -4.3158531e-01,  5.6438446e-01,\n",
            "       -1.3563156e+00, -1.8363112e-01, -1.0003390e-01, -6.0942239e-01,\n",
            "       -4.2481479e-01, -6.6722220e-01], dtype=float32), 'agent_3': Array([ 5.5800843e-01,  8.5464448e-01, -9.4038603e-04, -6.0050115e-02,\n",
            "        5.1572853e-01, -5.3338176e-01, -3.4675923e-01, -5.2939939e-01,\n",
            "       -4.2090753e-01,  9.3134779e-01, -4.3158531e-01,  5.6438446e-01,\n",
            "       -1.3563156e+00, -1.8363112e-01, -1.0003390e-01, -6.0942239e-01,\n",
            "       -1.2318808e-01, -2.5075696e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.3117237  -0.7976204  -0.30750096 -0.79117507 -0.31065023 -0.793908\n",
            " -0.31181887 -0.7945631 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.26649377, dtype=float32), 'agent_0': Array(0.26649377, dtype=float32), 'agent_1': Array(0.26649377, dtype=float32), 'agent_2': Array(0.26649377, dtype=float32), 'agent_3': Array(0.26649377, dtype=float32)}\n",
            "step: 333\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2969456e-01,  8.5309553e-01, -7.6942989e-03,  4.8950049e-03,\n",
            "        5.2167505e-01, -5.4303956e-01,  4.3988392e-01, -3.6784521e-01,\n",
            "       -5.5081397e-01, -5.1341897e-01, -6.8721771e-01,  4.3201447e-02,\n",
            "       -7.4118376e-01,  1.5466764e+00,  2.4874816e+00,  2.1817528e-01,\n",
            "        1.1161044e-03, -2.0125854e+00], dtype=float32), 'agent_1': Array([ 5.2969456e-01,  8.5309553e-01, -7.6942989e-03,  4.8950049e-03,\n",
            "        5.2167505e-01, -5.4303956e-01, -3.6784521e-01, -9.6916211e-01,\n",
            "       -5.5081397e-01, -5.1341897e-01, -6.8721771e-01,  4.3201447e-02,\n",
            "       -7.4118376e-01,  1.5466764e+00,  2.4874816e+00,  2.1817528e-01,\n",
            "       -5.7848227e-01, -6.1080446e+00], dtype=float32), 'agent_2': Array([ 5.2969456e-01,  8.5309553e-01, -7.6942989e-03,  4.8950049e-03,\n",
            "        5.2167505e-01, -5.4303956e-01, -3.6784521e-01, -5.5081397e-01,\n",
            "       -1.0307132e+00, -5.1341897e-01, -6.8721771e-01,  4.3201447e-02,\n",
            "       -7.4118376e-01,  1.5466764e+00,  2.4874816e+00,  2.1817528e-01,\n",
            "        1.2249131e-01, -7.6559048e+00], dtype=float32), 'agent_3': Array([ 5.2969456e-01,  8.5309553e-01, -7.6942989e-03,  4.8950049e-03,\n",
            "        5.2167505e-01, -5.4303956e-01, -3.6784521e-01, -5.5081397e-01,\n",
            "       -5.1341897e-01,  5.2156043e-01, -6.8721771e-01,  4.3201447e-02,\n",
            "       -7.4118376e-01,  1.5466764e+00,  2.4874816e+00,  2.1817528e-01,\n",
            "       -1.9122506e+00, -9.7598200e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.62669903 -0.57610095  0.62702507 -0.5769723   0.62707746 -0.57795906\n",
            "  0.6266592  -0.57834363]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0661588, dtype=float32), 'agent_0': Array(-1.0661588, dtype=float32), 'agent_1': Array(-1.0661588, dtype=float32), 'agent_2': Array(-1.0661588, dtype=float32), 'agent_3': Array(-1.0661588, dtype=float32)}\n",
            "step: 334\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5274674 ,  0.92216545, -0.01748984,  0.03587935,  0.3847306 ,\n",
            "       -0.16247495,  0.486314  , -0.01387228, -0.14560021, -0.21038753,\n",
            "       -0.4749298 , -0.46310425,  0.9554863 , -0.27580786,  1.832169  ,\n",
            "       -7.920237  , 10.155594  ,  0.11894211], dtype=float32), 'agent_1': Array([ 0.5274674 ,  0.92216545, -0.01748984,  0.03587935,  0.3847306 ,\n",
            "       -0.16247495, -0.01387228, -1.1760782 , -0.14560021, -0.21038753,\n",
            "       -0.4749298 , -0.46310425,  0.9554863 , -0.27580786,  1.832169  ,\n",
            "       -7.920237  ,  9.2529125 , -2.757409  ], dtype=float32), 'agent_2': Array([ 0.5274674 ,  0.92216545, -0.01748984,  0.03587935,  0.3847306 ,\n",
            "       -0.16247495, -0.01387228, -0.14560021, -1.2316339 , -0.21038753,\n",
            "       -0.4749298 , -0.46310425,  0.9554863 , -0.27580786,  1.832169  ,\n",
            "       -7.920237  , 11.3130245 , -2.171644  ], dtype=float32), 'agent_3': Array([ 0.5274674 ,  0.92216545, -0.01748984,  0.03587935,  0.3847306 ,\n",
            "       -0.16247495, -0.01387228, -0.14560021, -0.21038753,  0.48123878,\n",
            "       -0.4749298 , -0.46310425,  0.9554863 , -0.27580786,  1.832169  ,\n",
            "       -7.920237  ,  8.423735  ,  0.2199362 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.1122955  -0.12820384  0.10831615 -0.12878895  0.10982141 -0.1304727\n",
            "  0.11264017 -0.1272787 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9858922, dtype=float32), 'agent_0': Array(-0.9858922, dtype=float32), 'agent_1': Array(-0.9858922, dtype=float32), 'agent_2': Array(-0.9858922, dtype=float32), 'agent_3': Array(-0.9858922, dtype=float32)}\n",
            "step: 335\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57174903,  0.95371586, -0.04575421,  0.0642826 ,  0.2901731 ,\n",
            "        0.11203352,  0.55401784,  0.22548676,  0.1967961 , -0.00695873,\n",
            "       -0.32663345, -0.38957596,  0.40352345, -0.57530606,  1.3405269 ,\n",
            "       -3.2987206 ,  4.313319  ,  1.6469215 ], dtype=float32), 'agent_1': Array([ 0.57174903,  0.95371586, -0.04575421,  0.0642826 ,  0.2901731 ,\n",
            "        0.11203352,  0.22548676, -1.2448785 ,  0.1967961 , -0.00695873,\n",
            "       -0.32663345, -0.38957596,  0.40352345, -0.57530606,  1.3405269 ,\n",
            "       -3.2987206 ,  3.8104224 , -0.35673425], dtype=float32), 'agent_2': Array([ 0.57174903,  0.95371586, -0.04575421,  0.0642826 ,  0.2901731 ,\n",
            "        0.11203352,  0.22548676,  0.1967961 , -1.2441255 , -0.00695873,\n",
            "       -0.32663345, -0.38957596,  0.40352345, -0.57530606,  1.3405269 ,\n",
            "       -3.2987206 ,  5.6425576 , -0.08558732], dtype=float32), 'agent_3': Array([ 0.57174903,  0.95371586, -0.04575421,  0.0642826 ,  0.2901731 ,\n",
            "        0.11203352,  0.22548676,  0.1967961 , -0.00695873,  0.53897595,\n",
            "       -0.32663345, -0.38957596,  0.40352345, -0.57530606,  1.3405269 ,\n",
            "       -3.2987206 ,  3.082291  ,  1.1305575 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1295174   0.81362873 -1.1297977   0.8142146  -1.1292816   0.81001174\n",
            " -1.130645    0.814398  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.60401076, dtype=float32), 'agent_0': Array(0.60401076, dtype=float32), 'agent_1': Array(0.60401076, dtype=float32), 'agent_2': Array(0.60401076, dtype=float32), 'agent_3': Array(0.60401076, dtype=float32)}\n",
            "step: 336\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.57901037,   0.8730097 ,  -0.03829359,   0.06666539,\n",
            "         0.48160508,  -0.3793665 ,   0.8497379 ,  -0.28552285,\n",
            "        -0.24773686,  -0.55066985,   0.15106201,   0.17595291,\n",
            "         0.3050685 ,  -0.23463593,  -0.9910512 ,  11.152478  ,\n",
            "       -13.714851  ,   5.4923844 ], dtype=float32), 'agent_1': Array([  0.57901037,   0.8730097 ,  -0.03829359,   0.06666539,\n",
            "         0.48160508,  -0.3793665 ,  -0.28552285,  -1.062364  ,\n",
            "        -0.24773686,  -0.55066985,   0.15106201,   0.17595291,\n",
            "         0.3050685 ,  -0.23463593,  -0.9910512 ,  11.152478  ,\n",
            "       -13.910761  ,   6.3792815 ], dtype=float32), 'agent_2': Array([  0.57901037,   0.8730097 ,  -0.03829359,   0.06666539,\n",
            "         0.48160508,  -0.3793665 ,  -0.28552285,  -0.24773686,\n",
            "        -1.0209378 ,  -0.55066985,   0.15106201,   0.17595291,\n",
            "         0.3050685 ,  -0.23463593,  -0.9910512 ,  11.152478  ,\n",
            "       -13.127252  ,   7.7930627 ], dtype=float32), 'agent_3': Array([  0.57901037,   0.8730097 ,  -0.03829359,   0.06666539,\n",
            "         0.48160508,  -0.3793665 ,  -0.28552285,  -0.24773686,\n",
            "        -0.55066985,   0.87009794,   0.15106201,   0.17595291,\n",
            "         0.3050685 ,  -0.23463593,  -0.9910512 ,  11.152478  ,\n",
            "       -13.847603  ,   8.001131  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.8574968  -0.3301379   0.855784   -0.3286927   0.8590075  -0.32852986\n",
            "  0.85834587 -0.33014005]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.9786916, dtype=float32), 'agent_0': Array(-2.9786916, dtype=float32), 'agent_1': Array(-2.9786916, dtype=float32), 'agent_2': Array(-2.9786916, dtype=float32), 'agent_3': Array(-2.9786916, dtype=float32)}\n",
            "step: 337\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60550535,  0.9188685 , -0.04647548,  0.06840063,  0.38580066,\n",
            "       -0.14437713,  0.7806683 , -0.04858955,  0.0285464 , -0.31300536,\n",
            "       -0.13098717, -0.04825592,  0.94724894, -0.06640477,  0.43685564,\n",
            "       -7.9805713 , 10.087079  , -3.254721  ], dtype=float32), 'agent_1': Array([ 0.60550535,  0.9188685 , -0.04647548,  0.06840063,  0.38580066,\n",
            "       -0.14437713, -0.04858955, -0.9597105 ,  0.0285464 , -0.31300536,\n",
            "       -0.13098717, -0.04825592,  0.94724894, -0.06640477,  0.43685564,\n",
            "       -7.9805713 ,  9.835373  ,  0.57934064], dtype=float32), 'agent_2': Array([ 0.60550535,  0.9188685 , -0.04647548,  0.06840063,  0.38580066,\n",
            "       -0.14437713, -0.04858955,  0.0285464 , -0.83954215, -0.31300536,\n",
            "       -0.13098717, -0.04825592,  0.94724894, -0.06640477,  0.43685564,\n",
            "       -7.9805713 , 10.807469  ,  1.9933902 ], dtype=float32), 'agent_3': Array([ 0.60550535,  0.9188685 , -0.04647548,  0.06840063,  0.38580066,\n",
            "       -0.14437713, -0.04858955,  0.0285464 , -0.31300536,  1.0052657 ,\n",
            "       -0.13098717, -0.04825592,  0.94724894, -0.06640477,  0.43685564,\n",
            "       -7.9805713 ,  9.8729515 ,  1.3487631 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.4305079  -0.19494888 -1.4275372  -0.1921672  -1.4277298  -0.19437112\n",
            " -1.4268858  -0.19287358]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6919795, dtype=float32), 'agent_0': Array(-0.6919795, dtype=float32), 'agent_1': Array(-0.6919795, dtype=float32), 'agent_2': Array(-0.6919795, dtype=float32), 'agent_3': Array(-0.6919795, dtype=float32)}\n",
            "step: 338\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6400706 ,  0.85916036, -0.03737572,  0.08144831,  0.5037985 ,\n",
            "       -0.44930503,  0.6671886 , -0.38301498, -0.25404143, -0.5948151 ,\n",
            "       -0.16264915,  0.02212524,  0.46129227,  0.40387148,  0.4841776 ,\n",
            "        7.0970383 , -9.434901  , -2.2727494 ], dtype=float32), 'agent_1': Array([ 0.6400706 ,  0.85916036, -0.03737572,  0.08144831,  0.5037985 ,\n",
            "       -0.44930503, -0.38301498, -0.94576126, -0.25404143, -0.5948151 ,\n",
            "       -0.16264915,  0.02212524,  0.46129227,  0.40387148,  0.4841776 ,\n",
            "        7.0970383 , -9.912951  , -0.54773253], dtype=float32), 'agent_2': Array([ 0.6400706 ,  0.85916036, -0.03737572,  0.08144831,  0.5037985 ,\n",
            "       -0.44930503, -0.38301498, -0.25404143, -0.7935063 , -0.5948151 ,\n",
            "       -0.16264915,  0.02212524,  0.46129227,  0.40387148,  0.4841776 ,\n",
            "        7.0970383 , -9.063519  , -0.06745622], dtype=float32), 'agent_3': Array([ 0.6400706 ,  0.85916036, -0.03737572,  0.08144831,  0.5037985 ,\n",
            "       -0.44930503, -0.38301498, -0.25404143, -0.5948151 ,  1.0156122 ,\n",
            "       -0.16264915,  0.02212524,  0.46129227,  0.40387148,  0.4841776 ,\n",
            "        7.0970383 , -6.4007406 , -1.713043  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.55253744  0.00545681 -0.55334854  0.00674373 -0.55319494  0.00532048\n",
            " -0.5544057   0.00312818]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.3100696, dtype=float32), 'agent_0': Array(-3.3100696, dtype=float32), 'agent_1': Array(-3.3100696, dtype=float32), 'agent_2': Array(-3.3100696, dtype=float32), 'agent_3': Array(-3.3100696, dtype=float32)}\n",
            "step: 339\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6518982 ,  0.83356607, -0.0289024 ,  0.09716503,  0.54303885,\n",
            "       -0.56411946,  0.57297444, -0.5718646 , -0.46185195, -0.5336842 ,\n",
            "        0.02374649, -0.2591133 ,  0.04475117,  0.35933504,  0.45552126,\n",
            "        0.2138002 ,  0.6546373 , -1.912406  ], dtype=float32), 'agent_1': Array([ 0.6518982 ,  0.83356607, -0.0289024 ,  0.09716503,  0.54303885,\n",
            "       -0.56411946, -0.5718646 , -0.9829299 , -0.46185195, -0.5336842 ,\n",
            "        0.02374649, -0.2591133 ,  0.04475117,  0.35933504,  0.45552126,\n",
            "        0.2138002 , -0.49680495, -1.204734  ], dtype=float32), 'agent_2': Array([ 0.6518982 ,  0.83356607, -0.0289024 ,  0.09716503,  0.54303885,\n",
            "       -0.56411946, -0.5718646 , -0.46185195, -0.7841453 , -0.5336842 ,\n",
            "        0.02374649, -0.2591133 ,  0.04475117,  0.35933504,  0.45552126,\n",
            "        0.2138002 , -2.7013018 , -0.2774731 ], dtype=float32), 'agent_3': Array([ 0.6518982 ,  0.83356607, -0.0289024 ,  0.09716503,  0.54303885,\n",
            "       -0.56411946, -0.5718646 , -0.46185195, -0.5336842 ,  0.9689197 ,\n",
            "        0.02374649, -0.2591133 ,  0.04475117,  0.35933504,  0.45552126,\n",
            "        0.2138002 ,  3.2004774 , -0.5858386 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.22261399 -0.79372996  0.22003925 -0.79147106  0.21551904 -0.78953457\n",
            "  0.22467396 -0.7905035 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.2528718, dtype=float32), 'agent_0': Array(0.2528718, dtype=float32), 'agent_1': Array(0.2528718, dtype=float32), 'agent_2': Array(0.2528718, dtype=float32), 'agent_3': Array(0.2528718, dtype=float32)}\n",
            "step: 340\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6487465 ,  0.875469  , -0.03661451,  0.1393785 ,  0.46128836,\n",
            "       -0.31850222,  0.47344762, -0.39308745, -0.3727309 , -0.13000669,\n",
            "       -0.44527054, -0.381279  ,  0.0117898 ,  1.189123  ,  1.5582975 ,\n",
            "       -4.376811  ,  5.907046  ,  0.56657284], dtype=float32), 'agent_1': Array([ 0.6487465 ,  0.875469  , -0.03661451,  0.1393785 ,  0.46128836,\n",
            "       -0.31850222, -0.39308745, -1.2582185 , -0.3727309 , -0.13000669,\n",
            "       -0.44527054, -0.381279  ,  0.0117898 ,  1.189123  ,  1.5582975 ,\n",
            "       -4.376811  ,  4.7921605 , -4.9312387 ], dtype=float32), 'agent_2': Array([ 0.6487465 ,  0.875469  , -0.03661451,  0.1393785 ,  0.46128836,\n",
            "       -0.31850222, -0.39308745, -0.3727309 , -1.0581524 , -0.13000669,\n",
            "       -0.44527054, -0.381279  ,  0.0117898 ,  1.189123  ,  1.5582975 ,\n",
            "       -4.376811  ,  2.466659  , -6.996281  ], dtype=float32), 'agent_3': Array([ 0.6487465 ,  0.875469  , -0.03661451,  0.1393785 ,  0.46128836,\n",
            "       -0.31850222, -0.39308745, -0.3727309 , -0.13000669,  0.6917286 ,\n",
            "       -0.44527054, -0.381279  ,  0.0117898 ,  1.189123  ,  1.5582975 ,\n",
            "       -4.376811  ,  8.088321  , -7.54577   ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.52351624 -0.5696142   0.5174131  -0.57329935  0.5167544  -0.57653517\n",
            "  0.5170454  -0.5715133 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.549211, dtype=float32), 'agent_0': Array(-0.549211, dtype=float32), 'agent_1': Array(-0.549211, dtype=float32), 'agent_2': Array(-0.549211, dtype=float32), 'agent_3': Array(-0.549211, dtype=float32)}\n",
            "step: 341\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6391681 ,  0.9350693 , -0.06772799,  0.15328743,  0.31234822,\n",
            "        0.10294552,  0.5015121 , -0.02110104, -0.07557252,  0.38193205,\n",
            "       -0.09698868, -0.29010773, -0.54945946, -0.05859079, -0.10332818,\n",
            "       -7.2435827 ,  9.443061  ,  0.7014708 ], dtype=float32), 'agent_1': Array([ 0.6391681 ,  0.9350693 , -0.06772799,  0.15328743,  0.31234822,\n",
            "        0.10294552, -0.02110104, -1.2665863 , -0.07557252,  0.38193205,\n",
            "       -0.09698868, -0.29010773, -0.54945946, -0.05859079, -0.10332818,\n",
            "       -7.2435827 ,  8.443041  ,  0.31088072], dtype=float32), 'agent_2': Array([ 0.6391681 ,  0.9350693 , -0.06772799,  0.15328743,  0.31234822,\n",
            "        0.10294552, -0.02110104, -0.07557252, -1.2851048 ,  0.38193205,\n",
            "       -0.09698868, -0.29010773, -0.54945946, -0.05859079, -0.10332818,\n",
            "       -7.2435827 ,  7.17747   , -0.15910351], dtype=float32), 'agent_3': Array([ 0.6391681 ,  0.9350693 , -0.06772799,  0.15328743,  0.31234822,\n",
            "        0.10294552, -0.02110104, -0.07557252,  0.38193205,  0.47008345,\n",
            "       -0.09698868, -0.29010773, -0.54945946, -0.05859079, -0.10332818,\n",
            "       -7.2435827 , 11.0173025 ,  0.5714729 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.79198736 -0.25897682 -0.7905352  -0.25833267 -0.78930694 -0.25998774\n",
            " -0.7946894  -0.25912428]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.4388342, dtype=float32), 'agent_0': Array(-0.4388342, dtype=float32), 'agent_1': Array(-0.4388342, dtype=float32), 'agent_2': Array(-0.4388342, dtype=float32), 'agent_3': Array(-0.4388342, dtype=float32)}\n",
            "step: 342\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5992697 ,  0.89570504, -0.04501398,  0.15523002,  0.41423407,\n",
            "       -0.13921066,  0.55261993, -0.30535257, -0.43289024,  0.20152323,\n",
            "       -0.4474163 , -0.166893  , -0.8322954 ,  0.45334688, -0.03954358,\n",
            "        8.220201  , -9.8078985 ,  0.25864753], dtype=float32), 'agent_1': Array([  0.5992697 ,   0.89570504,  -0.04501398,   0.15523002,\n",
            "         0.41423407,  -0.13921066,  -0.30535257,  -1.2146807 ,\n",
            "        -0.43289024,   0.20152323,  -0.4474163 ,  -0.166893  ,\n",
            "        -0.8322954 ,   0.45334688,  -0.03954358,   8.220201  ,\n",
            "       -10.4159975 ,   0.35651758], dtype=float32), 'agent_2': Array([  0.5992697 ,   0.89570504,  -0.04501398,   0.15523002,\n",
            "         0.41423407,  -0.13921066,  -0.30535257,  -0.43289024,\n",
            "        -1.2411789 ,   0.20152323,  -0.4474163 ,  -0.166893  ,\n",
            "        -0.8322954 ,   0.45334688,  -0.03954358,   8.220201  ,\n",
            "       -11.792055  ,   0.8776153 ], dtype=float32), 'agent_3': Array([ 0.5992697 ,  0.89570504, -0.04501398,  0.15523002,  0.41423407,\n",
            "       -0.13921066, -0.30535257, -0.43289024,  0.20152323,  0.50155574,\n",
            "       -0.4474163 , -0.166893  , -0.8322954 ,  0.45334688, -0.03954358,\n",
            "        8.220201  , -8.769764  ,  0.233736  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9915393  -0.73638505 -0.9922727  -0.7347075  -0.9905991  -0.73589694\n",
            " -0.9939909  -0.7355831 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.63940036, dtype=float32), 'agent_0': Array(-0.63940036, dtype=float32), 'agent_1': Array(-0.63940036, dtype=float32), 'agent_2': Array(-0.63940036, dtype=float32), 'agent_3': Array(-0.63940036, dtype=float32)}\n",
            "step: 343\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5806381 ,  0.84311444, -0.03381265,  0.15054742,  0.5151216 ,\n",
            "       -0.5246817 ,  0.4810446 , -0.5988153 , -0.6141548 , -0.21621992,\n",
            "       -0.773716  ,  0.14362335, -0.18655062, -1.1209731 , -0.7572708 ,\n",
            "        0.87300825, -4.358427  ,  0.26710466], dtype=float32), 'agent_1': Array([ 0.5806381 ,  0.84311444, -0.03381265,  0.15054742,  0.5151216 ,\n",
            "       -0.5246817 , -0.5988153 , -1.2397392 , -0.6141548 , -0.21621992,\n",
            "       -0.773716  ,  0.14362335, -0.18655062, -1.1209731 , -0.7572708 ,\n",
            "        0.87300825, -0.17875794, -0.1958315 ], dtype=float32), 'agent_2': Array([ 0.5806381 ,  0.84311444, -0.03381265,  0.15054742,  0.5151216 ,\n",
            "       -0.5246817 , -0.5988153 , -0.6141548 , -1.2360865 , -0.21621992,\n",
            "       -0.773716  ,  0.14362335, -0.18655062, -1.1209731 , -0.7572708 ,\n",
            "        0.87300825,  2.3989081 , -0.02732038], dtype=float32), 'agent_3': Array([ 0.5806381 ,  0.84311444, -0.03381265,  0.15054742,  0.5151216 ,\n",
            "       -0.5246817 , -0.5988153 , -0.6141548 , -0.21621992,  0.4813395 ,\n",
            "       -0.773716  ,  0.14362335, -0.18655062, -1.1209731 , -0.7572708 ,\n",
            "        0.87300825, -5.9476085 ,  0.6605085 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.1895658   0.11194602 -0.18521991  0.10903497 -0.1816098   0.10596962\n",
            " -0.19377416  0.11184169]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.724605, dtype=float32), 'agent_0': Array(-2.724605, dtype=float32), 'agent_1': Array(-2.724605, dtype=float32), 'agent_2': Array(-2.724605, dtype=float32), 'agent_3': Array(-2.724605, dtype=float32)}\n",
            "step: 344\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5663136 ,  0.86259073, -0.04311374,  0.11219814,  0.49141642,\n",
            "       -0.55273074,  0.5573201 , -0.4684298 , -0.3447464 , -0.3473637 ,\n",
            "       -0.5435467 ,  0.06685257, -0.5341053 , -0.6879437 , -0.9265607 ,\n",
            "       -2.033437  ,  0.6541923 ,  0.9975074 ], dtype=float32), 'agent_1': Array([ 0.5663136 ,  0.86259073, -0.04311374,  0.11219814,  0.49141642,\n",
            "       -0.55273074, -0.4684298 , -1.2131419 , -0.3447464 , -0.3473637 ,\n",
            "       -0.5435467 ,  0.06685257, -0.5341053 , -0.6879437 , -0.9265607 ,\n",
            "       -2.033437  ,  3.5353281 , -0.32921696], dtype=float32), 'agent_2': Array([ 0.5663136 ,  0.86259073, -0.04311374,  0.11219814,  0.49141642,\n",
            "       -0.55273074, -0.4684298 , -0.3447464 , -1.1569483 , -0.3473637 ,\n",
            "       -0.5435467 ,  0.06685257, -0.5341053 , -0.6879437 , -0.9265607 ,\n",
            "       -2.033437  ,  6.2127557 ,  0.9497205 ], dtype=float32), 'agent_3': Array([ 0.5663136 ,  0.86259073, -0.04311374,  0.11219814,  0.49141642,\n",
            "       -0.55273074, -0.4684298 , -0.3447464 , -0.3473637 ,  0.56428355,\n",
            "       -0.5435467 ,  0.06685257, -0.5341053 , -0.6879437 , -0.9265607 ,\n",
            "       -2.033437  , -2.4637702 ,  1.7260369 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5576841   2.173909   -0.5578575   2.1713917  -0.56044024  2.1692116\n",
            " -0.5679643   2.1749709 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3131121, dtype=float32), 'agent_0': Array(0.3131121, dtype=float32), 'agent_1': Array(0.3131121, dtype=float32), 'agent_2': Array(0.3131121, dtype=float32), 'agent_3': Array(0.3131121, dtype=float32)}\n",
            "step: 345\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54260576,  0.8595117 , -0.03703288,  0.03480398,  0.50858325,\n",
            "       -0.55021864,  0.8206034 , -0.49237934, -0.29089183, -0.5926836 ,\n",
            "        0.25873184,  0.18262863, -0.4586935 , -1.7478174 , -3.6870475 ,\n",
            "       -0.2765945 ,  1.722483  ,  6.2289376 ], dtype=float32), 'agent_1': Array([ 0.54260576,  0.8595117 , -0.03703288,  0.03480398,  0.50858325,\n",
            "       -0.55021864, -0.49237934, -0.92913306, -0.29089183, -0.5926836 ,\n",
            "        0.25873184,  0.18262863, -0.4586935 , -1.7478174 , -3.6870475 ,\n",
            "       -0.2765945 , -0.82843304,  8.8874035 ], dtype=float32), 'agent_2': Array([ 0.54260576,  0.8595117 , -0.03703288,  0.03480398,  0.50858325,\n",
            "       -0.55021864, -0.49237934, -0.29089183, -0.84349525, -0.5926836 ,\n",
            "        0.25873184,  0.18262863, -0.4586935 , -1.7478174 , -3.6870475 ,\n",
            "       -0.2765945 ,  0.46641308,  9.081773  ], dtype=float32), 'agent_3': Array([ 0.54260576,  0.8595117 , -0.03703288,  0.03480398,  0.50858325,\n",
            "       -0.55021864, -0.49237934, -0.29089183, -0.5926836 ,  0.9392415 ,\n",
            "        0.25873184,  0.18262863, -0.4586935 , -1.7478174 , -3.6870475 ,\n",
            "       -0.2765945 , -1.9216797 ,  9.595492  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.91162646 -0.6701493  -0.9160881  -0.67097926 -0.9149026  -0.67213535\n",
            " -0.91565955 -0.6720643 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.213062, dtype=float32), 'agent_0': Array(-9.213062, dtype=float32), 'agent_1': Array(-9.213062, dtype=float32), 'agent_2': Array(-9.213062, dtype=float32), 'agent_3': Array(-9.213062, dtype=float32)}\n",
            "step: 346\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.2522737e-01,  8.5969114e-01, -3.4022175e-02, -4.3355497e-03,\n",
            "        5.0966156e-01, -5.1430011e-01,  6.9788569e-01, -5.6976104e-01,\n",
            "       -3.6495429e-01, -5.9723562e-01, -2.8181076e-01, -6.4878464e-01,\n",
            "       -8.4233284e-02, -6.0085911e-01, -6.6084659e-01, -1.6028434e-04,\n",
            "       -2.1646540e-01, -4.8098159e+00], dtype=float32), 'agent_1': Array([ 5.2522737e-01,  8.5969114e-01, -3.4022175e-02, -4.3355497e-03,\n",
            "        5.0966156e-01, -5.1430011e-01, -5.6976104e-01, -8.5861528e-01,\n",
            "       -3.6495429e-01, -5.9723562e-01, -2.8181076e-01, -6.4878464e-01,\n",
            "       -8.4233284e-02, -6.0085911e-01, -6.6084659e-01, -1.6028434e-04,\n",
            "       -1.0854675e+00, -8.4037352e-01], dtype=float32), 'agent_2': Array([ 5.2522737e-01,  8.5969114e-01, -3.4022175e-02, -4.3355497e-03,\n",
            "        5.0966156e-01, -5.1430011e-01, -5.6976104e-01, -3.6495429e-01,\n",
            "       -7.7852356e-01, -5.9723562e-01, -2.8181076e-01, -6.4878464e-01,\n",
            "       -8.4233284e-02, -6.0085911e-01, -6.6084659e-01, -1.6028434e-04,\n",
            "       -2.7335973e+00, -1.1806582e+00], dtype=float32), 'agent_3': Array([ 5.2522737e-01,  8.5969114e-01, -3.4022175e-02, -4.3355497e-03,\n",
            "        5.0966156e-01, -5.1430011e-01, -5.6976104e-01, -3.6495429e-01,\n",
            "       -5.9723562e-01,  1.0152684e+00, -2.8181076e-01, -6.4878464e-01,\n",
            "       -8.4233284e-02, -6.0085911e-01, -6.6084659e-01, -1.6028434e-04,\n",
            "        1.7800479e+00, -1.1010288e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5131998  -0.24714501  0.51219827 -0.24185503  0.5098346  -0.24256289\n",
            "  0.51901746 -0.24181223]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6306837, dtype=float32), 'agent_0': Array(-1.6306837, dtype=float32), 'agent_1': Array(-1.6306837, dtype=float32), 'agent_2': Array(-1.6306837, dtype=float32), 'agent_3': Array(-1.6306837, dtype=float32)}\n",
            "step: 347\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52391475,  0.92445266, -0.02762271, -0.03846953,  0.37834433,\n",
            "       -0.17228948,  0.560852  , -0.29040182, -0.12203357, -0.149141  ,\n",
            "       -0.10309219, -0.6126404 ,  0.3089428 ,  0.44155508, -0.6977752 ,\n",
            "       -7.348894  ,  8.334426  , -2.8458753 ], dtype=float32), 'agent_1': Array([ 0.52391475,  0.92445266, -0.02762271, -0.03846953,  0.37834433,\n",
            "       -0.17228948, -0.29040182, -0.8232564 , -0.12203357, -0.149141  ,\n",
            "       -0.10309219, -0.6126404 ,  0.3089428 ,  0.44155508, -0.6977752 ,\n",
            "       -7.348894  ,  7.8736577 ,  0.3231321 ], dtype=float32), 'agent_2': Array([ 0.52391475,  0.92445266, -0.02762271, -0.03846953,  0.37834433,\n",
            "       -0.17228948, -0.29040182, -0.12203357, -0.8140873 , -0.149141  ,\n",
            "       -0.10309219, -0.6126404 ,  0.3089428 ,  0.44155508, -0.6977752 ,\n",
            "       -7.348894  ,  6.4454794 , -1.7647538 ], dtype=float32), 'agent_3': Array([ 0.52391475,  0.92445266, -0.02762271, -0.03846953,  0.37834433,\n",
            "       -0.17228948, -0.29040182, -0.12203357, -0.149141  ,  0.9723916 ,\n",
            "       -0.10309219, -0.6126404 ,  0.3089428 ,  0.44155508, -0.6977752 ,\n",
            "       -7.348894  , 11.3606825 , -2.486703  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9495312  -0.72852546 -0.9477783  -0.7267182  -0.9491186  -0.7283675\n",
            " -0.95050234 -0.7286701 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.06393909, dtype=float32), 'agent_0': Array(0.06393909, dtype=float32), 'agent_1': Array(0.06393909, dtype=float32), 'agent_2': Array(0.06393909, dtype=float32), 'agent_3': Array(0.06393909, dtype=float32)}\n",
            "step: 348\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.6250155e-01,  8.6987299e-01, -6.0163341e-03, -7.8249862e-03,\n",
            "        4.9317703e-01, -5.0830764e-01,  4.6173882e-01, -6.0562927e-01,\n",
            "       -5.4137313e-01, -3.8075081e-01, -3.0627251e-01, -6.6242218e-01,\n",
            "        8.9069605e-01,  1.9694492e+00,  5.9804296e-01,  5.0173230e+00,\n",
            "       -7.8062835e+00,  1.5992408e-01], dtype=float32), 'agent_1': Array([ 0.56250155,  0.869873  , -0.00601633, -0.00782499,  0.49317703,\n",
            "       -0.50830764, -0.60562927, -0.9739573 , -0.54137313, -0.3807508 ,\n",
            "       -0.3062725 , -0.6624222 ,  0.89069605,  1.9694492 ,  0.59804296,\n",
            "        5.017323  , -4.426676  , -4.194298  ], dtype=float32), 'agent_2': Array([ 5.6250155e-01,  8.6987299e-01, -6.0163341e-03, -7.8249862e-03,\n",
            "        4.9317703e-01, -5.0830764e-01, -6.0562927e-01, -5.4137313e-01,\n",
            "       -1.0922585e+00, -3.8075081e-01, -3.0627251e-01, -6.6242218e-01,\n",
            "        8.9069605e-01,  1.9694492e+00,  5.9804296e-01,  5.0173230e+00,\n",
            "       -8.3268967e+00, -7.0804462e+00], dtype=float32), 'agent_3': Array([ 5.6250155e-01,  8.6987299e-01, -6.0163341e-03, -7.8249862e-03,\n",
            "        4.9317703e-01, -5.0830764e-01, -6.0562927e-01, -5.4137313e-01,\n",
            "       -3.8075081e-01,  5.9990603e-01, -3.0627251e-01, -6.6242218e-01,\n",
            "        8.9069605e-01,  1.9694492e+00,  5.9804296e-01,  5.0173230e+00,\n",
            "       -6.3259211e+00, -9.7112312e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.1268252 2.0366907 1.127316  2.0304806 1.1269504 2.028164  1.1269239\n",
            " 2.0233407]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.025411, dtype=float32), 'agent_0': Array(-2.025411, dtype=float32), 'agent_1': Array(-2.025411, dtype=float32), 'agent_2': Array(-2.025411, dtype=float32), 'agent_3': Array(-2.025411, dtype=float32)}\n",
            "step: 349\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6179189 ,   0.9424802 ,   0.0294152 ,  -0.03872946,\n",
            "         0.33070487,  -0.14379483,   0.76984906,  -0.13534643,\n",
            "        -0.20119075,   0.06949767,   0.5485058 ,  -0.45900345,\n",
            "         1.2680292 ,   0.3098548 ,  -2.667822  , -10.725346  ,\n",
            "        12.085399  ,   9.823583  ], dtype=float32), 'agent_1': Array([  0.6179189 ,   0.9424802 ,   0.0294152 ,  -0.03872946,\n",
            "         0.33070487,  -0.14379483,  -0.13534643,  -0.786837  ,\n",
            "        -0.20119075,   0.06949767,   0.5485058 ,  -0.45900345,\n",
            "         1.2680292 ,   0.3098548 ,  -2.667822  , -10.725346  ,\n",
            "        15.067407  ,   6.4293103 ], dtype=float32), 'agent_2': Array([  0.6179189 ,   0.9424802 ,   0.0294152 ,  -0.03872946,\n",
            "         0.33070487,  -0.14379483,  -0.13534643,  -0.20119075,\n",
            "        -0.96298   ,   0.06949767,   0.5485058 ,  -0.45900345,\n",
            "         1.2680292 ,   0.3098548 ,  -2.667822  , -10.725346  ,\n",
            "        11.901474  ,   5.6271133 ], dtype=float32), 'agent_3': Array([  0.6179189 ,   0.9424802 ,   0.0294152 ,  -0.03872946,\n",
            "         0.33070487,  -0.14379483,  -0.13534643,  -0.20119075,\n",
            "         0.06949767,   0.6391306 ,   0.5485058 ,  -0.45900345,\n",
            "         1.2680292 ,   0.3098548 ,  -2.667822  , -10.725346  ,\n",
            "        13.87938   ,   5.5853457 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.8947295   0.7776185  -0.89607775  0.7756176  -0.89494973  0.77583677\n",
            " -0.89663017  0.7761835 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.654722, dtype=float32), 'agent_0': Array(-9.654722, dtype=float32), 'agent_1': Array(-9.654722, dtype=float32), 'agent_2': Array(-9.654722, dtype=float32), 'agent_3': Array(-9.654722, dtype=float32)}\n",
            "step: 350\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6578965 ,  0.9066652 ,  0.0604727 , -0.11056788,  0.40258676,\n",
            "       -0.38275585,  1.3126904 , -0.27175602, -0.443483  , -0.1278646 ,\n",
            "        0.54364204, -0.09536743,  0.4156947 ,  0.29914817, -3.3158782 ,\n",
            "        7.748692  , -9.981279  ,  6.372279  ], dtype=float32), 'agent_1': Array([ 0.6578965 ,  0.9066652 ,  0.0604727 , -0.11056788,  0.40258676,\n",
            "       -0.38275585, -0.27175602, -0.4466192 , -0.443483  , -0.1278646 ,\n",
            "        0.54364204, -0.09536743,  0.4156947 ,  0.29914817, -3.3158782 ,\n",
            "        7.748692  , -9.592495  ,  3.1353397 ], dtype=float32), 'agent_2': Array([  0.6578965 ,   0.9066652 ,   0.0604727 ,  -0.11056788,\n",
            "         0.40258676,  -0.38275585,  -0.27175602,  -0.443483  ,\n",
            "        -0.58689475,  -0.1278646 ,   0.54364204,  -0.09536743,\n",
            "         0.4156947 ,   0.29914817,  -3.3158782 ,   7.748692  ,\n",
            "       -10.55201   ,  10.38498   ], dtype=float32), 'agent_3': Array([  0.6578965 ,   0.9066652 ,   0.0604727 ,  -0.11056788,\n",
            "         0.40258676,  -0.38275585,  -0.27175602,  -0.443483  ,\n",
            "        -0.1278646 ,   1.010089  ,   0.54364204,  -0.09536743,\n",
            "         0.4156947 ,   0.29914817,  -3.3158782 ,   7.748692  ,\n",
            "       -10.272821  ,   8.914783  ], dtype=float32)}\n",
            "ctrl action chosen: [0.41570085 0.02801577 0.41121635 0.02659986 0.41700384 0.02872522\n",
            " 0.41631013 0.02813908]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.2635574, dtype=float32), 'agent_0': Array(-1.2635574, dtype=float32), 'agent_1': Array(-1.2635574, dtype=float32), 'agent_2': Array(-1.2635574, dtype=float32), 'agent_3': Array(-1.2635574, dtype=float32)}\n",
            "step: 351\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.673087  ,  0.9060712 ,  0.06846313, -0.11777373,  0.40059608,\n",
            "       -0.4009648 ,  1.238658  , -0.27165118, -0.4716655 , -0.15823194,\n",
            "        0.35476685, -0.5961418 ,  0.2515316 ,  0.07563984, -0.26190197,\n",
            "       -2.5670233 ,  2.5301633 , -1.480132  ], dtype=float32), 'agent_1': Array([ 0.673087  ,  0.9060712 ,  0.06846313, -0.11777373,  0.40059608,\n",
            "       -0.4009648 , -0.27165118, -0.5000479 , -0.4716655 , -0.15823194,\n",
            "        0.35476685, -0.5961418 ,  0.2515316 ,  0.07563984, -0.26190197,\n",
            "       -2.5670233 ,  3.3466325 , -0.72577435], dtype=float32), 'agent_2': Array([ 0.673087  ,  0.9060712 ,  0.06846313, -0.11777373,  0.40059608,\n",
            "       -0.4009648 , -0.27165118, -0.4716655 , -0.51437575, -0.15823194,\n",
            "        0.35476685, -0.5961418 ,  0.2515316 ,  0.07563984, -0.26190197,\n",
            "       -2.5670233 ,  2.9322348 , -0.7121914 ], dtype=float32), 'agent_3': Array([ 0.673087  ,  0.9060712 ,  0.06846313, -0.11777373,  0.40059608,\n",
            "       -0.4009648 , -0.27165118, -0.4716655 , -0.15823194,  1.2462953 ,\n",
            "        0.35476685, -0.5961418 ,  0.2515316 ,  0.07563984, -0.26190197,\n",
            "       -2.5670233 ,  2.7814426 ,  2.690893  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.35859108 -1.5677649  -0.35964423 -1.5657191  -0.3594966  -1.5659378\n",
            " -0.3598303  -1.5625021 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9981941, dtype=float32), 'agent_0': Array(0.9981941, dtype=float32), 'agent_1': Array(0.9981941, dtype=float32), 'agent_2': Array(0.9981941, dtype=float32), 'agent_3': Array(0.9981941, dtype=float32)}\n",
            "step: 352\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6721261 ,   0.8963596 ,   0.07315614,  -0.07216041,\n",
            "         0.43125466,  -0.5061096 ,   0.79990387,  -0.34990177,\n",
            "        -0.5468198 ,  -0.23895395,  -0.14810562,  -0.69589615,\n",
            "        -0.44745207,   1.5271924 ,   3.0273695 ,   1.565207  ,\n",
            "        -2.692853  , -12.959306  ], dtype=float32), 'agent_1': Array([  0.6721261 ,   0.8963596 ,   0.07315614,  -0.07216041,\n",
            "         0.43125466,  -0.5061096 ,  -0.34990177,  -0.902084  ,\n",
            "        -0.5468198 ,  -0.23895395,  -0.14810562,  -0.69589615,\n",
            "        -0.44745207,   1.5271924 ,   3.0273695 ,   1.565207  ,\n",
            "        -2.9944487 , -12.554761  ], dtype=float32), 'agent_2': Array([ 0.6721261 ,  0.8963596 ,  0.07315614, -0.07216041,  0.43125466,\n",
            "       -0.5061096 , -0.34990177, -0.5468198 , -0.8042433 , -0.23895395,\n",
            "       -0.14810562, -0.69589615, -0.44745207,  1.5271924 ,  3.0273695 ,\n",
            "        1.565207  , -1.3610144 , -9.525574  ], dtype=float32), 'agent_3': Array([ 0.6721261 ,  0.8963596 ,  0.07315614, -0.07216041,  0.43125466,\n",
            "       -0.5061096 , -0.34990177, -0.5468198 , -0.23895395,  1.0862701 ,\n",
            "       -0.14810562, -0.69589615, -0.44745207,  1.5271924 ,  3.0273695 ,\n",
            "        1.565207  , -2.6296988 , -6.553708  ], dtype=float32)}\n",
            "ctrl action chosen: [0.53769207 0.39258686 0.53644055 0.39264587 0.5362535  0.3937123\n",
            " 0.53621006 0.3942734 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.075382, dtype=float32), 'agent_0': Array(-4.075382, dtype=float32), 'agent_1': Array(-4.075382, dtype=float32), 'agent_2': Array(-4.075382, dtype=float32), 'agent_3': Array(-4.075382, dtype=float32)}\n",
            "step: 353\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.65628576,  0.9354159 ,  0.07950629, -0.02506598,  0.3435806 ,\n",
            "       -0.25700617,  0.49288574, -0.15935846, -0.27029347, -0.0295482 ,\n",
            "        0.48093796, -0.56915283, -0.1464963 ,  0.37535977,  0.8612326 ,\n",
            "       -5.804114  ,  7.7103343 , -1.748014  ], dtype=float32), 'agent_1': Array([ 0.65628576,  0.9354159 ,  0.07950629, -0.02506598,  0.3435806 ,\n",
            "       -0.25700617, -0.15935846, -1.2137444 , -0.27029347, -0.0295482 ,\n",
            "        0.48093796, -0.56915283, -0.1464963 ,  0.37535977,  0.8612326 ,\n",
            "       -5.804114  ,  6.3184457 , -3.6464188 ], dtype=float32), 'agent_2': Array([ 0.65628576,  0.9354159 ,  0.07950629, -0.02506598,  0.3435806 ,\n",
            "       -0.25700617, -0.15935846, -0.27029347, -0.95467436, -0.0295482 ,\n",
            "        0.48093796, -0.56915283, -0.1464963 ,  0.37535977,  0.8612326 ,\n",
            "       -5.804114  ,  8.357938  , -0.8462321 ], dtype=float32), 'agent_3': Array([ 0.65628576,  0.9354159 ,  0.07950629, -0.02506598,  0.3435806 ,\n",
            "       -0.25700617, -0.15935846, -0.27029347, -0.0295482 ,  0.96809095,\n",
            "        0.48093796, -0.56915283, -0.1464963 ,  0.37535977,  0.8612326 ,\n",
            "       -5.804114  ,  6.5791645 , -0.9760255 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.08925751  0.34983578 -0.09296099  0.34921274 -0.08913478  0.34972435\n",
            " -0.08995415  0.35045317]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.21534002, dtype=float32), 'agent_0': Array(0.21534002, dtype=float32), 'agent_1': Array(0.21534002, dtype=float32), 'agent_2': Array(0.21534002, dtype=float32), 'agent_3': Array(0.21534002, dtype=float32)}\n",
            "step: 354\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.66009045,  0.9497631 ,  0.08208974, -0.01958633,  0.30137628,\n",
            "       -0.12322874,  0.54833466, -0.06825487, -0.11259453,  0.04736603,\n",
            "        0.7250309 , -0.13513565, -0.02422333, -0.04267501, -0.4341977 ,\n",
            "       -0.7176925 ,  1.0928805 ,  2.120042  ], dtype=float32), 'agent_1': Array([ 0.66009045,  0.9497631 ,  0.08208974, -0.01958633,  0.30137628,\n",
            "       -0.12322874, -0.06825487, -1.1994812 , -0.11259453,  0.04736603,\n",
            "        0.7250309 , -0.13513565, -0.02422333, -0.04267501, -0.4341977 ,\n",
            "       -0.7176925 ,  0.52293855,  1.9659476 ], dtype=float32), 'agent_2': Array([ 0.66009045,  0.9497631 ,  0.08208974, -0.01958633,  0.30137628,\n",
            "       -0.12322874, -0.06825487, -0.11259453, -0.8921855 ,  0.04736603,\n",
            "        0.7250309 , -0.13513565, -0.02422333, -0.04267501, -0.4341977 ,\n",
            "       -0.7176925 ,  1.2769918 ,  2.9918349 ], dtype=float32), 'agent_3': Array([ 0.66009045,  0.9497631 ,  0.08208974, -0.01958633,  0.30137628,\n",
            "       -0.12322874, -0.06825487, -0.11259453,  0.04736603,  1.04015   ,\n",
            "        0.7250309 , -0.13513565, -0.02422333, -0.04267501, -0.4341977 ,\n",
            "       -0.7176925 , -0.01744368,  3.7228749 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.12024722 -0.832584    0.12017204 -0.8314068   0.12031358 -0.8348307\n",
            "  0.11576038 -0.83008343]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.4129475, dtype=float32), 'agent_0': Array(1.4129475, dtype=float32), 'agent_1': Array(1.4129475, dtype=float32), 'agent_2': Array(1.4129475, dtype=float32), 'agent_3': Array(1.4129475, dtype=float32)}\n",
            "step: 355\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6431606 ,  0.95874417,  0.07361339,  0.01071839,  0.27436468,\n",
            "       -0.04292938,  0.49305883, -0.01224125, -0.02431967,  0.09100266,\n",
            "        0.4210472 , -0.20332336, -0.52502155, -0.07228739,  1.3186857 ,\n",
            "       -1.4574329 ,  1.7932137 , -0.14681973], dtype=float32), 'agent_1': Array([ 0.6431606 ,  0.95874417,  0.07361339,  0.01071839,  0.27436468,\n",
            "       -0.04292938, -0.01224125, -1.2543005 , -0.02431967,  0.09100266,\n",
            "        0.4210472 , -0.20332336, -0.52502155, -0.07228739,  1.3186857 ,\n",
            "       -1.4574329 ,  1.3584383 ,  0.03945963], dtype=float32), 'agent_2': Array([ 0.6431606 ,  0.95874417,  0.07361339,  0.01071839,  0.27436468,\n",
            "       -0.04292938, -0.01224125, -0.02431967, -1.0487735 ,  0.09100266,\n",
            "        0.4210472 , -0.20332336, -0.52502155, -0.07228739,  1.3186857 ,\n",
            "       -1.4574329 ,  1.9528043 , -5.244341  ], dtype=float32), 'agent_3': Array([ 0.6431606 ,  0.95874417,  0.07361339,  0.01071839,  0.27436468,\n",
            "       -0.04292938, -0.01224125, -0.02431967,  0.09100266,  0.9098094 ,\n",
            "        0.4210472 , -0.20332336, -0.52502155, -0.07228739,  1.3186857 ,\n",
            "       -1.4574329 ,  1.474244  , -5.2862277 ], dtype=float32)}\n",
            "ctrl action chosen: [0.99973625 1.0511373  1.0010331  1.0531081  0.99734086 1.0441158\n",
            " 0.9957619  1.0458665 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.0688684, dtype=float32), 'agent_0': Array(0.0688684, dtype=float32), 'agent_1': Array(0.0688684, dtype=float32), 'agent_2': Array(0.0688684, dtype=float32), 'agent_3': Array(0.0688684, dtype=float32)}\n",
            "step: 356\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1931801e-01,  9.9528503e-01,  8.4435955e-02, -3.1576140e-04,\n",
            "        4.7730274e-02,  5.2381295e-01,  8.0092484e-01,  5.3755522e-01,\n",
            "        5.5443960e-01,  6.0902947e-01,  1.3689995e+00,  4.1389465e-01,\n",
            "       -2.3210049e-01,  4.8873121e-01, -1.7033515e+00, -4.9811177e+00,\n",
            "        7.2512331e+00,  8.1934566e+00], dtype=float32), 'agent_1': Array([ 6.1931801e-01,  9.9528503e-01,  8.4435955e-02, -3.1576140e-04,\n",
            "        4.7730274e-02,  5.2381295e-01,  5.3755522e-01, -9.3980050e-01,\n",
            "        5.5443960e-01,  6.0902947e-01,  1.3689995e+00,  4.1389465e-01,\n",
            "       -2.3210049e-01,  4.8873121e-01, -1.7033515e+00, -4.9811177e+00,\n",
            "        7.1534648e+00,  9.2868757e+00], dtype=float32), 'agent_2': Array([ 6.1931801e-01,  9.9528503e-01,  8.4435955e-02, -3.1576140e-04,\n",
            "        4.7730274e-02,  5.2381295e-01,  5.3755522e-01,  5.5443960e-01,\n",
            "       -8.1909072e-01,  6.0902947e-01,  1.3689995e+00,  4.1389465e-01,\n",
            "       -2.3210049e-01,  4.8873121e-01, -1.7033515e+00, -4.9811177e+00,\n",
            "        6.9785867e+00,  7.2323503e+00], dtype=float32), 'agent_3': Array([ 6.1931801e-01,  9.9528503e-01,  8.4435955e-02, -3.1576140e-04,\n",
            "        4.7730274e-02,  5.2381295e-01,  5.3755522e-01,  5.5443960e-01,\n",
            "        6.0902947e-01,  1.1053984e+00,  1.3689995e+00,  4.1389465e-01,\n",
            "       -2.3210049e-01,  4.8873121e-01, -1.7033515e+00, -4.9811177e+00,\n",
            "        3.5763159e+00,  6.4291110e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.11834771 0.9985492  0.11740955 0.999309   0.12070049 0.9941285\n",
            " 0.11730514 0.9990063 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2623076, dtype=float32), 'agent_0': Array(-2.2623076, dtype=float32), 'agent_1': Array(-2.2623076, dtype=float32), 'agent_2': Array(-2.2623076, dtype=float32), 'agent_3': Array(-2.2623076, dtype=float32)}\n",
            "step: 357\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60095465,  0.99173963,  0.10428192, -0.03865567,  0.06390216,\n",
            "        0.5429944 ,  1.2944199 ,  0.5294203 ,  0.52998567,  0.4805861 ,\n",
            "        1.0903835 ,  0.44460297, -0.50724745,  0.8154097 , -0.82780015,\n",
            "        1.1282064 , -0.2773676 ,  7.9913135 ], dtype=float32), 'agent_1': Array([ 0.60095465,  0.99173963,  0.10428192, -0.03865567,  0.06390216,\n",
            "        0.5429944 ,  0.5294203 , -0.44356433,  0.52998567,  0.4805861 ,\n",
            "        1.0903835 ,  0.44460297, -0.50724745,  0.8154097 , -0.82780015,\n",
            "        1.1282064 , -1.6381079 ,  5.112579  ], dtype=float32), 'agent_2': Array([ 0.60095465,  0.99173963,  0.10428192, -0.03865567,  0.06390216,\n",
            "        0.5429944 ,  0.5294203 ,  0.52998567, -0.44117507,  0.4805861 ,\n",
            "        1.0903835 ,  0.44460297, -0.50724745,  0.8154097 , -0.82780015,\n",
            "        1.1282064 , -1.406825  ,  3.8152952 ], dtype=float32), 'agent_3': Array([ 0.60095465,  0.99173963,  0.10428192, -0.03865567,  0.06390216,\n",
            "        0.5429944 ,  0.5294203 ,  0.52998567,  0.4805861 ,  1.2940832 ,\n",
            "        1.0903835 ,  0.44460297, -0.50724745,  0.8154097 , -0.82780015,\n",
            "        1.1282064 , -3.5527644 , -0.20606592], dtype=float32)}\n",
            "ctrl action chosen: [0.5077285  0.21915348 0.5067176  0.22116739 0.5080822  0.21820667\n",
            " 0.5059664  0.2166266 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.2463057, dtype=float32), 'agent_0': Array(0.2463057, dtype=float32), 'agent_1': Array(0.2463057, dtype=float32), 'agent_2': Array(0.2463057, dtype=float32), 'agent_3': Array(0.2463057, dtype=float32)}\n",
            "step: 358\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6060253 ,  0.99547195,  0.06758536, -0.02685974,  0.06120725,\n",
            "        0.54869527,  1.2524468 ,  0.5365341 ,  0.5503642 ,  0.42713568,\n",
            "       -0.01273155, -0.17089844,  0.45844316, -0.8622654 , -0.05470993,\n",
            "       -0.68379736, -0.26409698, -0.17606343], dtype=float32), 'agent_1': Array([ 0.6060253 ,  0.99547195,  0.06758536, -0.02685974,  0.06120725,\n",
            "        0.54869527,  0.5365341 , -0.47528782,  0.5503642 ,  0.42713568,\n",
            "       -0.01273155, -0.17089844,  0.45844316, -0.8622654 , -0.05470993,\n",
            "       -0.68379736,  0.59813094, -0.01325136], dtype=float32), 'agent_2': Array([ 0.6060253 ,  0.99547195,  0.06758536, -0.02685974,  0.06120725,\n",
            "        0.54869527,  0.5365341 ,  0.5503642 , -0.50954854,  0.42713568,\n",
            "       -0.01273155, -0.17089844,  0.45844316, -0.8622654 , -0.05470993,\n",
            "       -0.68379736,  0.94414604, -0.34718478], dtype=float32), 'agent_3': Array([ 0.6060253 ,  0.99547195,  0.06758536, -0.02685974,  0.06120725,\n",
            "        0.54869527,  0.5365341 ,  0.5503642 ,  0.42713568,  1.2353318 ,\n",
            "       -0.01273155, -0.17089844,  0.45844316, -0.8622654 , -0.05470993,\n",
            "       -0.68379736,  0.9534064 , -0.7216707 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.08360784 -0.5888215   0.0854525  -0.58820117  0.088671   -0.59313345\n",
            "  0.08570543 -0.59146386]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.6809402, dtype=float32), 'agent_0': Array(0.6809402, dtype=float32), 'agent_1': Array(0.6809402, dtype=float32), 'agent_2': Array(0.6809402, dtype=float32), 'agent_3': Array(0.6809402, dtype=float32)}\n",
            "step: 359\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1706269e-01,  9.9748009e-01,  2.9732749e-02, -8.9825998e-04,\n",
            "        6.4410016e-02,  4.9808696e-01,  1.0674663e+00,  5.2080125e-01,\n",
            "        5.2960950e-01,  4.4655839e-01, -8.1777573e-02, -3.3884048e-01,\n",
            "       -6.8283081e-02, -2.0588338e+00,  1.9696028e+00, -3.5096046e-02,\n",
            "       -6.3109493e-01, -6.7452135e+00], dtype=float32), 'agent_1': Array([ 6.1706269e-01,  9.9748009e-01,  2.9732749e-02, -8.9825998e-04,\n",
            "        6.4410016e-02,  4.9808696e-01,  5.2080125e-01, -7.0540488e-01,\n",
            "        5.2960950e-01,  4.4655839e-01, -8.1777573e-02, -3.3884048e-01,\n",
            "       -6.8283081e-02, -2.0588338e+00,  1.9696028e+00, -3.5096046e-02,\n",
            "       -4.7189561e-01, -7.7850165e+00], dtype=float32), 'agent_2': Array([ 6.1706269e-01,  9.9748009e-01,  2.9732749e-02, -8.9825998e-04,\n",
            "        6.4410016e-02,  4.9808696e-01,  5.2080125e-01,  5.2960950e-01,\n",
            "       -7.2742844e-01,  4.4655839e-01, -8.1777573e-02, -3.3884048e-01,\n",
            "       -6.8283081e-02, -2.0588338e+00,  1.9696028e+00, -3.5096046e-02,\n",
            "       -4.9140567e-01, -6.6921430e+00], dtype=float32), 'agent_3': Array([ 6.1706269e-01,  9.9748009e-01,  2.9732749e-02, -8.9825998e-04,\n",
            "        6.4410016e-02,  4.9808696e-01,  5.2080125e-01,  5.2960950e-01,\n",
            "        4.4655839e-01,  9.8924279e-01, -8.1777573e-02, -3.3884048e-01,\n",
            "       -6.8283081e-02, -2.0588338e+00,  1.9696028e+00, -3.5096046e-02,\n",
            "        5.5822462e-01, -6.7749791e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.7336515  -0.20302057 -0.7333979  -0.20079589 -0.7317215  -0.20421797\n",
            " -0.7335949  -0.20239668]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.26902175, dtype=float32), 'agent_0': Array(0.26902175, dtype=float32), 'agent_1': Array(0.26902175, dtype=float32), 'agent_2': Array(0.26902175, dtype=float32), 'agent_3': Array(0.26902175, dtype=float32)}\n",
            "step: 360\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5938066 ,   0.9692269 ,  -0.01318798,   0.04738446,\n",
            "         0.24120525,   0.05611099,   0.71237904,   0.04753269,\n",
            "         0.07931715,   0.012985  ,  -0.15444756,  -0.32930374,\n",
            "        -0.73406696,  -1.1451205 ,   2.4535758 ,   9.052106  ,\n",
            "       -11.229735  ,  -7.1251636 ], dtype=float32), 'agent_1': Array([  0.5938066 ,   0.9692269 ,  -0.01318798,   0.04738446,\n",
            "         0.24120525,   0.05611099,   0.04753269,  -1.095799  ,\n",
            "         0.07931715,   0.012985  ,  -0.15444756,  -0.32930374,\n",
            "        -0.73406696,  -1.1451205 ,   2.4535758 ,   9.052106  ,\n",
            "       -11.94094   ,  -7.3924747 ], dtype=float32), 'agent_2': Array([  0.5938066 ,   0.9692269 ,  -0.01318798,   0.04738446,\n",
            "         0.24120525,   0.05611099,   0.04753269,   0.07931715,\n",
            "        -1.0419861 ,   0.012985  ,  -0.15444756,  -0.32930374,\n",
            "        -0.73406696,  -1.1451205 ,   2.4535758 ,   9.052106  ,\n",
            "       -11.494581  ,  -6.423012  ], dtype=float32), 'agent_3': Array([  0.5938066 ,   0.9692269 ,  -0.01318798,   0.04738446,\n",
            "         0.24120525,   0.05611099,   0.04753269,   0.07931715,\n",
            "         0.012985  ,   0.7031254 ,  -0.15444756,  -0.32930374,\n",
            "        -0.73406696,  -1.1451205 ,   2.4535758 ,   9.052106  ,\n",
            "       -11.50479   ,  -5.834083  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.29475364 -0.7479825  -0.29508084 -0.7472073  -0.29385218 -0.7490019\n",
            " -0.2951801  -0.74784577]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.2814858, dtype=float32), 'agent_0': Array(-0.2814858, dtype=float32), 'agent_1': Array(-0.2814858, dtype=float32), 'agent_2': Array(-0.2814858, dtype=float32), 'agent_3': Array(-0.2814858, dtype=float32)}\n",
            "step: 361\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5409198 ,  0.9147683 , -0.03524101,  0.0964698 ,  0.3907054 ,\n",
            "       -0.34988314,  0.46161738, -0.3903302 , -0.33246127, -0.4048671 ,\n",
            "        0.20356178, -0.0831604 , -1.2717247 , -1.0307965 , -0.2331506 ,\n",
            "        5.646761  , -7.078939  ,  1.5730159 ], dtype=float32), 'agent_1': Array([ 0.5409198 ,  0.9147683 , -0.03524101,  0.0964698 ,  0.3907054 ,\n",
            "       -0.34988314, -0.3903302 , -1.2797192 , -0.33246127, -0.4048671 ,\n",
            "        0.20356178, -0.0831604 , -1.2717247 , -1.0307965 , -0.2331506 ,\n",
            "        5.646761  , -7.928357  ,  1.3491026 ], dtype=float32), 'agent_2': Array([ 0.5409198 ,  0.9147683 , -0.03524101,  0.0964698 ,  0.3907054 ,\n",
            "       -0.34988314, -0.3903302 , -0.33246127, -1.2827893 , -0.4048671 ,\n",
            "        0.20356178, -0.0831604 , -1.2717247 , -1.0307965 , -0.2331506 ,\n",
            "        5.646761  , -7.373368  ,  1.3527073 ], dtype=float32), 'agent_3': Array([ 0.5409198 ,  0.9147683 , -0.03524101,  0.0964698 ,  0.3907054 ,\n",
            "       -0.34988314, -0.3903302 , -0.33246127, -0.4048671 ,  0.45930845,\n",
            "        0.20356178, -0.0831604 , -1.2717247 , -1.0307965 , -0.2331506 ,\n",
            "        5.646761  , -7.3722167 ,  1.3841496 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2640444  -0.6227586  -1.2666651  -0.6216118  -1.2646006  -0.62284803\n",
            " -1.2655491  -0.62332606]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.40887272, dtype=float32), 'agent_0': Array(-0.40887272, dtype=float32), 'agent_1': Array(-0.40887272, dtype=float32), 'agent_2': Array(-0.40887272, dtype=float32), 'agent_3': Array(-0.40887272, dtype=float32)}\n",
            "step: 362\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49830586,  0.8862103 , -0.04249258,  0.10568089,  0.44906273,\n",
            "       -0.5471461 ,  0.47917178, -0.5677805 , -0.55714387, -0.56204116,\n",
            "        0.31023026,  0.35266876, -0.08941293,  0.3810357 ,  0.91670793,\n",
            "       -0.73705626, -0.11318164, -0.36152965], dtype=float32), 'agent_1': Array([ 0.49830586,  0.8862103 , -0.04249258,  0.10568089,  0.44906273,\n",
            "       -0.5471461 , -0.5677805 , -1.2419723 , -0.55714387, -0.56204116,\n",
            "        0.31023026,  0.35266876, -0.08941293,  0.3810357 ,  0.91670793,\n",
            "       -0.73705626,  0.31525853, -0.13956474], dtype=float32), 'agent_2': Array([ 0.49830586,  0.8862103 , -0.04249258,  0.10568089,  0.44906273,\n",
            "       -0.5471461 , -0.5677805 , -0.55714387, -1.2502898 , -0.56204116,\n",
            "        0.31023026,  0.35266876, -0.08941293,  0.3810357 ,  0.91670793,\n",
            "       -0.73705626, -0.6883433 , -0.00216537], dtype=float32), 'agent_3': Array([ 0.49830586,  0.8862103 , -0.04249258,  0.10568089,  0.44906273,\n",
            "       -0.5471461 , -0.5677805 , -0.55714387, -0.56204116,  0.48950452,\n",
            "        0.31023026,  0.35266876, -0.08941293,  0.3810357 ,  0.91670793,\n",
            "       -0.73705626,  0.4363248 ,  0.10778944], dtype=float32)}\n",
            "ctrl action chosen: [ 0.3732366  -0.38983554  0.37332612 -0.38902843  0.37068018 -0.39205107\n",
            "  0.37285766 -0.38884217]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.7147977, dtype=float32), 'agent_0': Array(-2.7147977, dtype=float32), 'agent_1': Array(-2.7147977, dtype=float32), 'agent_2': Array(-2.7147977, dtype=float32), 'agent_3': Array(-2.7147977, dtype=float32)}\n",
            "step: 363\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5164149 ,  0.9213646 , -0.04656406,  0.10799365,  0.3704814 ,\n",
            "       -0.28724042,  0.49947697, -0.34060648, -0.40133956, -0.31690803,\n",
            "       -0.2272129 , -0.3674507 ,  0.5707741 ,  0.5252069 ,  0.20978585,\n",
            "       -4.804153  ,  7.5902414 , -0.07719415], dtype=float32), 'agent_1': Array([ 0.5164149 ,  0.9213646 , -0.04656406,  0.10799365,  0.3704814 ,\n",
            "       -0.28724042, -0.34060648, -1.2316244 , -0.40133956, -0.31690803,\n",
            "       -0.2272129 , -0.3674507 ,  0.5707741 ,  0.5252069 ,  0.20978585,\n",
            "       -4.804153  ,  6.441822  , -0.43863112], dtype=float32), 'agent_2': Array([ 0.5164149 ,  0.9213646 , -0.04656406,  0.10799365,  0.3704814 ,\n",
            "       -0.28724042, -0.34060648, -0.40133956, -1.2262442 , -0.31690803,\n",
            "       -0.2272129 , -0.3674507 ,  0.5707741 ,  0.5252069 ,  0.20978585,\n",
            "       -4.804153  ,  5.157332  , -0.05341507], dtype=float32), 'agent_3': Array([ 0.5164149 ,  0.9213646 , -0.04656406,  0.10799365,  0.3704814 ,\n",
            "       -0.28724042, -0.34060648, -0.40133956, -0.31690803,  0.5203806 ,\n",
            "       -0.2272129 , -0.3674507 ,  0.5707741 ,  0.5252069 ,  0.20978585,\n",
            "       -4.804153  ,  6.978504  ,  0.13815513], dtype=float32)}\n",
            "ctrl action chosen: [ 1.4805803 -1.0988905  1.4802119 -1.0975546  1.4811242 -1.0990607\n",
            "  1.4798017 -1.0981846]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3889612, dtype=float32), 'agent_0': Array(0.3889612, dtype=float32), 'agent_1': Array(0.3889612, dtype=float32), 'agent_2': Array(0.3889612, dtype=float32), 'agent_3': Array(0.3889612, dtype=float32)}\n",
            "step: 364\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5368269 ,   0.98807377,  -0.06509376,   0.10627326,\n",
            "         0.09043815,   0.47219577,   0.48116395,   0.38267052,\n",
            "         0.27402413,   0.43815875,  -0.06504059,  -0.5832672 ,\n",
            "         0.2135396 ,   0.63237476,   0.07993936, -13.297808  ,\n",
            "        17.244474  ,   0.3786337 ], dtype=float32), 'agent_1': Array([  0.5368269 ,   0.98807377,  -0.06509376,   0.10627326,\n",
            "         0.09043815,   0.47219577,   0.38267052,  -1.2723097 ,\n",
            "         0.27402413,   0.43815875,  -0.06504059,  -0.5832672 ,\n",
            "         0.2135396 ,   0.63237476,   0.07993936, -13.297808  ,\n",
            "        16.810493  ,   0.3633168 ], dtype=float32), 'agent_2': Array([ 5.3682691e-01,  9.8807377e-01, -6.5093763e-02,  1.0627326e-01,\n",
            "        9.0438150e-02,  4.7219577e-01,  3.8267052e-01,  2.7402413e-01,\n",
            "       -1.2608389e+00,  4.3815875e-01, -6.5040588e-02, -5.8326721e-01,\n",
            "        2.1353960e-01,  6.3237476e-01,  7.9939358e-02, -1.3297808e+01,\n",
            "        1.5966035e+01, -2.0664078e-03], dtype=float32), 'agent_3': Array([  0.5368269 ,   0.98807377,  -0.06509376,   0.10627326,\n",
            "         0.09043815,   0.47219577,   0.38267052,   0.27402413,\n",
            "         0.43815875,   0.4828934 ,  -0.06504059,  -0.5832672 ,\n",
            "         0.2135396 ,   0.63237476,   0.07993936, -13.297808  ,\n",
            "        17.523256  ,  -0.18042879], dtype=float32)}\n",
            "ctrl action chosen: [0.8232596  1.4047364  0.82408357 1.4052709  0.824692   1.4041755\n",
            " 0.82253385 1.4048126 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.97907, dtype=float32), 'agent_0': Array(-5.97907, dtype=float32), 'agent_1': Array(-5.97907, dtype=float32), 'agent_2': Array(-5.97907, dtype=float32), 'agent_3': Array(-5.97907, dtype=float32)}\n",
            "step: 365\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5395731 ,  0.9967917 , -0.02695903,  0.06739138,  0.0337352 ,\n",
            "        0.5659084 ,  0.81268895,  0.5698918 ,  0.5268207 ,  0.5696648 ,\n",
            "       -0.31137466,  0.11730194,  0.03763437,  2.3302524 , -1.9112846 ,\n",
            "        0.8405874 , -2.084186  ,  8.571001  ], dtype=float32), 'agent_1': Array([ 0.5395731 ,  0.9967917 , -0.02695903,  0.06739138,  0.0337352 ,\n",
            "        0.5659084 ,  0.5698918 , -0.9302864 ,  0.5268207 ,  0.5696648 ,\n",
            "       -0.31137466,  0.11730194,  0.03763437,  2.3302524 , -1.9112846 ,\n",
            "        0.8405874 , -0.5802732 ,  9.199178  ], dtype=float32), 'agent_2': Array([ 0.5395731 ,  0.9967917 , -0.02695903,  0.06739138,  0.0337352 ,\n",
            "        0.5659084 ,  0.5698918 ,  0.5268207 , -0.9510759 ,  0.5696648 ,\n",
            "       -0.31137466,  0.11730194,  0.03763437,  2.3302524 , -1.9112846 ,\n",
            "        0.8405874 ,  1.6178495 ,  8.363285  ], dtype=float32), 'agent_3': Array([ 0.5395731 ,  0.9967917 , -0.02695903,  0.06739138,  0.0337352 ,\n",
            "        0.5659084 ,  0.5698918 ,  0.5268207 ,  0.5696648 ,  0.78964156,\n",
            "       -0.31137466,  0.11730194,  0.03763437,  2.3302524 , -1.9112846 ,\n",
            "        0.8405874 , -1.8064555 ,  7.9184175 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.7346556  -0.45482278 -1.7345297  -0.45321333 -1.732424   -0.4557608\n",
            " -1.7346374  -0.45454255]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.457608, dtype=float32), 'agent_0': Array(-4.457608, dtype=float32), 'agent_1': Array(-4.457608, dtype=float32), 'agent_2': Array(-4.457608, dtype=float32), 'agent_3': Array(-4.457608, dtype=float32)}\n",
            "step: 366\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7332665e-01,  9.5283002e-01,  1.7097006e-02,  5.4929633e-02,\n",
            "        2.9800254e-01, -1.3721330e-01,  8.8991535e-01, -7.8200705e-02,\n",
            "        2.3338132e-02, -1.9227366e-01, -1.0511398e+00, -6.0853958e-01,\n",
            "        1.0091066e+00,  4.1055211e-01, -4.4470283e-01,  1.3743622e+01,\n",
            "       -1.7655699e+01, -9.6783394e-01], dtype=float32), 'agent_1': Array([ 5.7332665e-01,  9.5283002e-01,  1.7097006e-02,  5.4929633e-02,\n",
            "        2.9800254e-01, -1.3721330e-01, -7.8200705e-02, -8.0551916e-01,\n",
            "        2.3338132e-02, -1.9227366e-01, -1.0511398e+00, -6.0853958e-01,\n",
            "        1.0091066e+00,  4.1055211e-01, -4.4470283e-01,  1.3743622e+01,\n",
            "       -1.7158131e+01,  8.5327560e-01], dtype=float32), 'agent_2': Array([  0.57332665,   0.95283   ,   0.01709701,   0.05492963,\n",
            "         0.29800254,  -0.1372133 ,  -0.07820071,   0.02333813,\n",
            "        -0.8425156 ,  -0.19227366,  -1.0511398 ,  -0.6085396 ,\n",
            "         1.0091066 ,   0.4105521 ,  -0.44470283,  13.743622  ,\n",
            "       -13.343669  ,   0.08715388], dtype=float32), 'agent_3': Array([ 5.7332665e-01,  9.5283002e-01,  1.7097006e-02,  5.4929633e-02,\n",
            "        2.9800254e-01, -1.3721330e-01, -7.8200705e-02,  2.3338132e-02,\n",
            "       -1.9227366e-01,  7.8568023e-01, -1.0511398e+00, -6.0853958e-01,\n",
            "        1.0091066e+00,  4.1055211e-01, -4.4470283e-01,  1.3743622e+01,\n",
            "       -1.9794127e+01, -2.2371304e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.0978729  -0.2770158  -1.097773   -0.2761039  -1.0986704  -0.2781311\n",
            " -1.0977616  -0.27708676]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.087438, dtype=float32), 'agent_0': Array(-6.087438, dtype=float32), 'agent_1': Array(-6.087438, dtype=float32), 'agent_2': Array(-6.087438, dtype=float32), 'agent_3': Array(-6.087438, dtype=float32)}\n",
            "step: 367\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60778815,  0.89006686,  0.03043417,  0.03628353,  0.45336342,\n",
            "       -0.58988065,  0.8218105 , -0.56683266, -0.35336742, -0.62522495,\n",
            "       -0.73928833, -1.0804176 ,  0.43234825,  0.11478729, -0.45656967,\n",
            "       -0.42389882,  0.38746217, -1.8182629 ], dtype=float32), 'agent_1': Array([ 0.60778815,  0.89006686,  0.03043417,  0.03628353,  0.45336342,\n",
            "       -0.58988065, -0.56683266, -0.7493033 , -0.35336742, -0.62522495,\n",
            "       -0.73928833, -1.0804176 ,  0.43234825,  0.11478729, -0.45656967,\n",
            "       -0.42389882, -0.98988724, -0.11309481], dtype=float32), 'agent_2': Array([ 0.60778815,  0.89006686,  0.03043417,  0.03628353,  0.45336342,\n",
            "       -0.58988065, -0.56683266, -0.35336742, -0.8694693 , -0.62522495,\n",
            "       -0.73928833, -1.0804176 ,  0.43234825,  0.11478729, -0.45656967,\n",
            "       -0.42389882, -1.2427546 , -1.5995836 ], dtype=float32), 'agent_3': Array([ 0.60778815,  0.89006686,  0.03043417,  0.03628353,  0.45336342,\n",
            "       -0.58988065, -0.56683266, -0.35336742, -0.62522495,  0.67411965,\n",
            "       -0.73928833, -1.0804176 ,  0.43234825,  0.11478729, -0.45656967,\n",
            "       -0.42389882,  1.90631   , -2.4016566 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.3069315   0.7638584  -1.3125168   0.7672957  -1.3104503   0.763303\n",
            " -1.3067734   0.76429504]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.447944, dtype=float32), 'agent_0': Array(-2.447944, dtype=float32), 'agent_1': Array(-2.447944, dtype=float32), 'agent_2': Array(-2.447944, dtype=float32), 'agent_3': Array(-2.447944, dtype=float32)}\n",
            "step: 368\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6181088 ,  0.89084125,  0.03485512, -0.01166122,  0.4528255 ,\n",
            "       -0.5461673 ,  0.987022  , -0.5721548 , -0.52215296, -0.5076193 ,\n",
            "       -0.1522541 , -0.9451866 , -0.02416372, -1.0346103 , -2.3239858 ,\n",
            "        0.587594  ,  0.7147693 ,  4.9698005 ], dtype=float32), 'agent_1': Array([ 0.6181088 ,  0.89084125,  0.03485512, -0.01166122,  0.4528255 ,\n",
            "       -0.5461673 , -0.5721548 , -0.54882765, -0.52215296, -0.5076193 ,\n",
            "       -0.1522541 , -0.9451866 , -0.02416372, -1.0346103 , -2.3239858 ,\n",
            "        0.587594  ,  0.32022154,  5.5681024 ], dtype=float32), 'agent_2': Array([ 0.6181088 ,  0.89084125,  0.03485512, -0.01166122,  0.4528255 ,\n",
            "       -0.5461673 , -0.5721548 , -0.52215296, -0.69504964, -0.5076193 ,\n",
            "       -0.1522541 , -0.9451866 , -0.02416372, -1.0346103 , -2.3239858 ,\n",
            "        0.587594  , -5.649958  ,  5.4235144 ], dtype=float32), 'agent_3': Array([ 0.6181088 ,  0.89084125,  0.03485512, -0.01166122,  0.4528255 ,\n",
            "       -0.5461673 , -0.5721548 , -0.52215296, -0.5076193 ,  0.8321177 ,\n",
            "       -0.1522541 , -0.9451866 , -0.02416372, -1.0346103 , -2.3239858 ,\n",
            "        0.587594  ,  1.3533336 ,  5.14685   ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1004879e+00 -5.3333491e-04  1.0986452e+00 -1.4266707e-03\n",
            "  1.0941319e+00 -4.4992436e-03  1.0997163e+00 -1.7058821e-03]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.9848652, dtype=float32), 'agent_0': Array(-3.9848652, dtype=float32), 'agent_1': Array(-3.9848652, dtype=float32), 'agent_2': Array(-3.9848652, dtype=float32), 'agent_3': Array(-3.9848652, dtype=float32)}\n",
            "step: 369\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6027295 ,   0.97294307,   0.05401422,  -0.03168087,\n",
            "         0.22239755,   0.12357876,   1.1109998 ,   0.05055886,\n",
            "        -0.14904286,   0.18443953,  -0.34418106,  -0.8626938 ,\n",
            "        -0.44935942,   0.55502504,  -1.1688751 , -12.065779  ,\n",
            "        16.63967   ,   2.7989526 ], dtype=float32), 'agent_1': Array([  0.6027295 ,   0.97294307,   0.05401422,  -0.03168087,\n",
            "         0.22239755,   0.12357876,   0.05055886,  -0.5091131 ,\n",
            "        -0.14904286,   0.18443953,  -0.34418106,  -0.8626938 ,\n",
            "        -0.44935942,   0.55502504,  -1.1688751 , -12.065779  ,\n",
            "        15.970189  ,   0.18768217], dtype=float32), 'agent_2': Array([  0.6027295 ,   0.97294307,   0.05401422,  -0.03168087,\n",
            "         0.22239755,   0.12357876,   0.05055886,  -0.14904286,\n",
            "        -0.56248564,   0.18443953,  -0.34418106,  -0.8626938 ,\n",
            "        -0.44935942,   0.55502504,  -1.1688751 , -12.065779  ,\n",
            "        11.077148  ,   2.567056  ], dtype=float32), 'agent_3': Array([  0.6027295 ,   0.97294307,   0.05401422,  -0.03168087,\n",
            "         0.22239755,   0.12357876,   0.05055886,  -0.14904286,\n",
            "         0.18443953,   0.9466793 ,  -0.34418106,  -0.8626938 ,\n",
            "        -0.44935942,   0.55502504,  -1.1688751 , -12.065779  ,\n",
            "        16.43325   ,   1.8345448 ], dtype=float32)}\n",
            "ctrl action chosen: [0.9476747  1.4533321  0.9454501  1.4543536  0.950434   1.4528458\n",
            " 0.94637036 1.4535656 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7345428, dtype=float32), 'agent_0': Array(-1.7345428, dtype=float32), 'agent_1': Array(-1.7345428, dtype=float32), 'agent_2': Array(-1.7345428, dtype=float32), 'agent_3': Array(-1.7345428, dtype=float32)}\n",
            "step: 370\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5697596 ,  0.99301016,  0.08864354, -0.06368838,  0.04491064,\n",
            "        0.600568  ,  1.2877113 ,  0.5643769 ,  0.23017351,  0.60707694,\n",
            "       -0.6749153 , -0.5460739 , -0.6117463 , -0.03347984, -0.8955691 ,\n",
            "        0.5285407 , -0.87339544, -1.0627562 ], dtype=float32), 'agent_1': Array([ 0.5697596 ,  0.99301016,  0.08864354, -0.06368838,  0.04491064,\n",
            "        0.600568  ,  0.5643769 , -0.46737364,  0.23017351,  0.60707694,\n",
            "       -0.6749153 , -0.5460739 , -0.6117463 , -0.03347984, -0.8955691 ,\n",
            "        0.5285407 ,  0.9783328 , -0.72396296], dtype=float32), 'agent_2': Array([ 0.5697596 ,  0.99301016,  0.08864354, -0.06368838,  0.04491064,\n",
            "        0.600568  ,  0.5643769 ,  0.23017351, -0.45380875,  0.60707694,\n",
            "       -0.6749153 , -0.5460739 , -0.6117463 , -0.03347984, -0.8955691 ,\n",
            "        0.5285407 ,  0.7291746 , -1.197941  ], dtype=float32), 'agent_3': Array([ 0.5697596 ,  0.99301016,  0.08864354, -0.06368838,  0.04491064,\n",
            "        0.600568  ,  0.5643769 ,  0.23017351,  0.60707694,  1.2939565 ,\n",
            "       -0.6749153 , -0.5460739 , -0.6117463 , -0.03347984, -0.8955691 ,\n",
            "        0.5285407 , -2.0641534 ,  3.443887  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.00754117  0.57123613 -0.00409533  0.56958413 -0.00332593  0.56652915\n",
            " -0.00803653  0.5758894 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.3476424, dtype=float32), 'agent_0': Array(-5.3476424, dtype=float32), 'agent_1': Array(-5.3476424, dtype=float32), 'agent_2': Array(-5.3476424, dtype=float32), 'agent_3': Array(-5.3476424, dtype=float32)}\n",
            "step: 371\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5595787 ,  0.9897877 ,  0.08714051, -0.07068016,  0.08792675,\n",
            "        0.45615873,  1.2412231 ,  0.5161578 ,  0.12750538,  0.4260977 ,\n",
            "       -1.2881279 ,  0.07820129,  0.1445055 , -0.06806941, -0.7184782 ,\n",
            "        2.078115  , -3.9857693 , -0.70080936], dtype=float32), 'agent_1': Array([ 0.5595787 ,  0.9897877 ,  0.08714051, -0.07068016,  0.08792675,\n",
            "        0.45615873,  0.5161578 , -0.52692693,  0.12750538,  0.4260977 ,\n",
            "       -1.2881279 ,  0.07820129,  0.1445055 , -0.06806941, -0.7184782 ,\n",
            "        2.078115  , -1.2062083 ,  0.08733033], dtype=float32), 'agent_2': Array([ 0.5595787 ,  0.9897877 ,  0.08714051, -0.07068016,  0.08792675,\n",
            "        0.45615873,  0.5161578 ,  0.12750538, -0.5106061 ,  0.4260977 ,\n",
            "       -1.2881279 ,  0.07820129,  0.1445055 , -0.06806941, -0.7184782 ,\n",
            "        2.078115  , -2.4533687 , -0.5837773 ], dtype=float32), 'agent_3': Array([ 0.5595787 ,  0.9897877 ,  0.08714051, -0.07068016,  0.08792675,\n",
            "        0.45615873,  0.5161578 ,  0.12750538,  0.4260977 ,  1.2660644 ,\n",
            "       -1.2881279 ,  0.07820129,  0.1445055 , -0.06806941, -0.7184782 ,\n",
            "        2.078115  , -4.446407  ,  0.2535132 ], dtype=float32)}\n",
            "ctrl action chosen: [0.95265573 0.4216927  0.9564926  0.42128426 0.9535823  0.41986015\n",
            " 0.95154595 0.42180917]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.68663424, dtype=float32), 'agent_0': Array(-0.68663424, dtype=float32), 'agent_1': Array(-0.68663424, dtype=float32), 'agent_2': Array(-0.68663424, dtype=float32), 'agent_3': Array(-0.68663424, dtype=float32)}\n",
            "step: 372\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56389886,  0.99221027,  0.09108486, -0.07899293,  0.03134686,\n",
            "        0.5587639 ,  1.2312341 ,  0.5987468 ,  0.37262538,  0.5488947 ,\n",
            "       -1.0593414 ,  0.4313469 ,  0.03421307, -0.15710025, -0.5462848 ,\n",
            "       -1.1014433 ,  0.77550143,  0.19903451], dtype=float32), 'agent_1': Array([ 0.56389886,  0.99221027,  0.09108486, -0.07899293,  0.03134686,\n",
            "        0.5587639 ,  0.5987468 , -0.5070051 ,  0.37262538,  0.5488947 ,\n",
            "       -1.0593414 ,  0.4313469 ,  0.03421307, -0.15710025, -0.5462848 ,\n",
            "       -1.1014433 , -0.7484141 ,  0.72592956], dtype=float32), 'agent_2': Array([ 0.56389886,  0.99221027,  0.09108486, -0.07899293,  0.03134686,\n",
            "        0.5587639 ,  0.5987468 ,  0.37262538, -0.4969638 ,  0.5488947 ,\n",
            "       -1.0593414 ,  0.4313469 ,  0.03421307, -0.15710025, -0.5462848 ,\n",
            "       -1.1014433 ,  5.2773957 ,  0.3470521 ], dtype=float32), 'agent_3': Array([ 0.56389886,  0.99221027,  0.09108486, -0.07899293,  0.03134686,\n",
            "        0.5587639 ,  0.5987468 ,  0.37262538,  0.5488947 ,  1.2234972 ,\n",
            "       -1.0593414 ,  0.4313469 ,  0.03421307, -0.15710025, -0.5462848 ,\n",
            "       -1.1014433 ,  1.3147038 , -0.25269884], dtype=float32)}\n",
            "ctrl action chosen: [ 0.6658676 -1.2804233  0.6637962 -1.2761521  0.6679853 -1.2871858\n",
            "  0.6658115 -1.2814854]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.218015, dtype=float32), 'agent_0': Array(-2.218015, dtype=float32), 'agent_1': Array(-2.218015, dtype=float32), 'agent_2': Array(-2.218015, dtype=float32), 'agent_3': Array(-2.218015, dtype=float32)}\n",
            "step: 373\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5745679 ,  0.9972488 ,  0.0557445 , -0.04358299,  0.02208849,\n",
            "        0.53127086,  0.89475614,  0.4921719 ,  0.56815445,  0.5518963 ,\n",
            "       -1.7161846 ,  0.28028488,  0.12845993, -1.800718  ,  2.1847262 ,\n",
            "        0.2606209 , -1.5033098 , -9.397609  ], dtype=float32), 'agent_1': Array([ 0.5745679 ,  0.9972488 ,  0.0557445 , -0.04358299,  0.02208849,\n",
            "        0.53127086,  0.4921719 , -0.7587953 ,  0.56815445,  0.5518963 ,\n",
            "       -1.7161846 ,  0.28028488,  0.12845993, -1.800718  ,  2.1847262 ,\n",
            "        0.2606209 , -2.252327  , -7.6598206 ], dtype=float32), 'agent_2': Array([ 0.5745679 ,  0.9972488 ,  0.0557445 , -0.04358299,  0.02208849,\n",
            "        0.53127086,  0.4921719 ,  0.56815445, -0.755979  ,  0.5518963 ,\n",
            "       -1.7161846 ,  0.28028488,  0.12845993, -1.800718  ,  2.1847262 ,\n",
            "        0.2606209 ,  1.9033698 , -7.914405  ], dtype=float32), 'agent_3': Array([ 0.5745679 ,  0.9972488 ,  0.0557445 , -0.04358299,  0.02208849,\n",
            "        0.53127086,  0.4921719 ,  0.56815445,  0.5518963 ,  0.8506929 ,\n",
            "       -1.7161846 ,  0.28028488,  0.12845993, -1.800718  ,  2.1847262 ,\n",
            "        0.2606209 , -0.9738142 , -9.997048  ], dtype=float32)}\n",
            "ctrl action chosen: [1.2774258  0.4486645  1.2750221  0.45060444 1.279256   0.44722024\n",
            " 1.2775009  0.44899198]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.733437, dtype=float32), 'agent_0': Array(-4.733437, dtype=float32), 'agent_1': Array(-4.733437, dtype=float32), 'agent_2': Array(-4.733437, dtype=float32), 'agent_3': Array(-4.733437, dtype=float32)}\n",
            "step: 374\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56903756,  0.99829596,  0.04140612, -0.03937119,  0.01185946,\n",
            "        0.54332   ,  0.79420274,  0.5073473 ,  0.6101675 ,  0.5360032 ,\n",
            "       -0.58231354,  0.59280396, -0.07475615, -0.53022164, -0.45961645,\n",
            "       -0.49456334,  0.78707343,  0.09134427], dtype=float32), 'agent_1': Array([ 0.56903756,  0.99829596,  0.04140612, -0.03937119,  0.01185946,\n",
            "        0.54332   ,  0.5073473 , -0.829432  ,  0.6101675 ,  0.5360032 ,\n",
            "       -0.58231354,  0.59280396, -0.07475615, -0.53022164, -0.45961645,\n",
            "       -0.49456334,  2.1460185 ,  0.47361702], dtype=float32), 'agent_2': Array([ 0.56903756,  0.99829596,  0.04140612, -0.03937119,  0.01185946,\n",
            "        0.54332   ,  0.5073473 ,  0.6101675 , -0.7984077 ,  0.5360032 ,\n",
            "       -0.58231354,  0.59280396, -0.07475615, -0.53022164, -0.45961645,\n",
            "       -0.49456334, -0.8739936 ,  2.0299141 ], dtype=float32), 'agent_3': Array([ 0.56903756,  0.99829596,  0.04140612, -0.03937119,  0.01185946,\n",
            "        0.54332   ,  0.5073473 ,  0.6101675 ,  0.5360032 ,  0.7158855 ,\n",
            "       -0.58231354,  0.59280396, -0.07475615, -0.53022164, -0.45961645,\n",
            "       -0.49456334, -0.15590584, -0.49596736], dtype=float32)}\n",
            "ctrl action chosen: [0.24276468 0.98432386 0.24467288 0.9843311  0.24190319 0.9862017\n",
            " 0.24072754 0.98381686]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.737975, dtype=float32), 'agent_0': Array(-3.737975, dtype=float32), 'agent_1': Array(-3.737975, dtype=float32), 'agent_2': Array(-3.737975, dtype=float32), 'agent_3': Array(-3.737975, dtype=float32)}\n",
            "step: 375\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5606037 ,  0.99564266,  0.04053089, -0.08026219,  0.02471791,\n",
            "        0.53243095,  1.0037402 ,  0.55506295,  0.47928372,  0.49518812,\n",
            "       -0.30565262,  0.59051514, -0.422585  ,  0.47289085, -2.484301  ,\n",
            "        0.73619807, -0.3830185 ,  7.130837  ], dtype=float32), 'agent_1': Array([ 0.5606037 ,  0.99564266,  0.04053089, -0.08026219,  0.02471791,\n",
            "        0.53243095,  0.55506295, -0.5720454 ,  0.47928372,  0.49518812,\n",
            "       -0.30565262,  0.59051514, -0.422585  ,  0.47289085, -2.484301  ,\n",
            "        0.73619807,  0.25799254,  8.098996  ], dtype=float32), 'agent_2': Array([ 0.5606037 ,  0.99564266,  0.04053089, -0.08026219,  0.02471791,\n",
            "        0.53243095,  0.55506295,  0.47928372, -0.48556122,  0.49518812,\n",
            "       -0.30565262,  0.59051514, -0.422585  ,  0.47289085, -2.484301  ,\n",
            "        0.73619807, -2.9017534 ,  7.176756  ], dtype=float32), 'agent_3': Array([ 0.5606037 ,  0.99564266,  0.04053089, -0.08026219,  0.02471791,\n",
            "        0.53243095,  0.55506295,  0.47928372,  0.49518812,  0.93787074,\n",
            "       -0.30565262,  0.59051514, -0.422585  ,  0.47289085, -2.484301  ,\n",
            "        0.73619807, -0.5144817 ,  7.7003036 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.6518797  -0.28854188  1.6510053  -0.2872348   1.6514868  -0.29003698\n",
            "  1.6509309  -0.2891525 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.3827395, dtype=float32), 'agent_0': Array(-1.3827395, dtype=float32), 'agent_1': Array(-1.3827395, dtype=float32), 'agent_2': Array(-1.3827395, dtype=float32), 'agent_3': Array(-1.3827395, dtype=float32)}\n",
            "step: 376\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5264151 ,  0.9951813 ,  0.01982049, -0.09545025,  0.01051714,\n",
            "        0.56146026,  1.1121235 ,  0.5616249 ,  0.52456015,  0.5591104 ,\n",
            "       -0.9549141 ,  0.32777786, -0.70859194, -0.6612763 , -0.20435667,\n",
            "        0.02040718, -0.40748614,  1.0254377 ], dtype=float32), 'agent_1': Array([ 0.5264151 ,  0.9951813 ,  0.01982049, -0.09545025,  0.01051714,\n",
            "        0.56146026,  0.5616249 , -0.5071394 ,  0.52456015,  0.5591104 ,\n",
            "       -0.9549141 ,  0.32777786, -0.70859194, -0.6612763 , -0.20435667,\n",
            "        0.02040718, -1.0640192 , -0.33932   ], dtype=float32), 'agent_2': Array([ 0.5264151 ,  0.9951813 ,  0.01982049, -0.09545025,  0.01051714,\n",
            "        0.56146026,  0.5616249 ,  0.52456015, -0.5137979 ,  0.5591104 ,\n",
            "       -0.9549141 ,  0.32777786, -0.70859194, -0.6612763 , -0.20435667,\n",
            "        0.02040718,  1.4447874 , -0.07565691], dtype=float32), 'agent_3': Array([ 0.5264151 ,  0.9951813 ,  0.01982049, -0.09545025,  0.01051714,\n",
            "        0.56146026,  0.5616249 ,  0.52456015,  0.5591104 ,  1.0759369 ,\n",
            "       -0.9549141 ,  0.32777786, -0.70859194, -0.6612763 , -0.20435667,\n",
            "        0.02040718,  0.65364856,  1.2478024 ], dtype=float32)}\n",
            "ctrl action chosen: [0.12202049 1.4192268  0.12080484 1.418673   0.1270996  1.4117914\n",
            " 0.12295689 1.4174454 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.334591, dtype=float32), 'agent_0': Array(-5.334591, dtype=float32), 'agent_1': Array(-5.334591, dtype=float32), 'agent_2': Array(-5.334591, dtype=float32), 'agent_3': Array(-5.334591, dtype=float32)}\n",
            "step: 377\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50231147,  0.99134654,  0.01548044, -0.1262213 ,  0.03256711,\n",
            "        0.48064375,  1.284689  ,  0.4540515 ,  0.5423157 ,  0.5235247 ,\n",
            "       -0.7384777 ,  0.27217865,  0.10429621, -0.68682814,  0.56829387,\n",
            "        0.82540894, -1.6271594 , -1.6054403 ], dtype=float32), 'agent_1': Array([ 0.50231147,  0.99134654,  0.01548044, -0.1262213 ,  0.03256711,\n",
            "        0.48064375,  0.4540515 , -0.45848185,  0.5423157 ,  0.5235247 ,\n",
            "       -0.7384777 ,  0.27217865,  0.10429621, -0.68682814,  0.56829387,\n",
            "        0.82540894, -1.7912247 , -0.52407795], dtype=float32), 'agent_2': Array([ 0.50231147,  0.99134654,  0.01548044, -0.1262213 ,  0.03256711,\n",
            "        0.48064375,  0.4540515 ,  0.5423157 , -0.48341596,  0.5235247 ,\n",
            "       -0.7384777 ,  0.27217865,  0.10429621, -0.68682814,  0.56829387,\n",
            "        0.82540894,  0.0390645 , -0.9348302 ], dtype=float32), 'agent_3': Array([ 0.50231147,  0.99134654,  0.01548044, -0.1262213 ,  0.03256711,\n",
            "        0.48064375,  0.4540515 ,  0.5423157 ,  0.5235247 ,  1.2924422 ,\n",
            "       -0.7384777 ,  0.27217865,  0.10429621, -0.68682814,  0.56829387,\n",
            "        0.82540894, -0.5911778 , -1.1741307 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.41960555 -0.41073197  0.419236   -0.40822873  0.4243582  -0.41435522\n",
            "  0.41992617 -0.41187093]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.7243667, dtype=float32), 'agent_0': Array(-3.7243667, dtype=float32), 'agent_1': Array(-3.7243667, dtype=float32), 'agent_2': Array(-3.7243667, dtype=float32), 'agent_3': Array(-3.7243667, dtype=float32)}\n",
            "step: 378\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.52254725,  0.99681187, -0.00428397, -0.07804246,  0.01603701,\n",
            "        0.5231142 ,  1.0907981 ,  0.5062962 ,  0.558989  ,  0.5488429 ,\n",
            "       -0.29497147, -0.15897751,  0.58972836, -0.6853893 ,  1.6487608 ,\n",
            "       -0.8063877 ,  1.4004326 , -4.0581303 ], dtype=float32), 'agent_1': Array([ 0.52254725,  0.99681187, -0.00428397, -0.07804246,  0.01603701,\n",
            "        0.5231142 ,  0.5062962 , -0.61425537,  0.558989  ,  0.5488429 ,\n",
            "       -0.29497147, -0.15897751,  0.58972836, -0.6853893 ,  1.6487608 ,\n",
            "       -0.8063877 ,  1.6820933 , -2.5440583 ], dtype=float32), 'agent_2': Array([ 5.2254725e-01,  9.9681187e-01, -4.2839730e-03, -7.8042455e-02,\n",
            "        1.6037006e-02,  5.2311420e-01,  5.0629622e-01,  5.5898899e-01,\n",
            "       -7.5091714e-01,  5.4884291e-01, -2.9497147e-01, -1.5897751e-01,\n",
            "        5.8972836e-01, -6.8538928e-01,  1.6487608e+00, -8.0638772e-01,\n",
            "       -3.5769793e-01, -6.5506902e+00], dtype=float32), 'agent_3': Array([ 5.2254725e-01,  9.9681187e-01, -4.2839730e-03, -7.8042455e-02,\n",
            "        1.6037006e-02,  5.2311420e-01,  5.0629622e-01,  5.5898899e-01,\n",
            "        5.4884291e-01,  1.0883778e+00, -2.9497147e-01, -1.5897751e-01,\n",
            "        5.8972836e-01, -6.8538928e-01,  1.6487608e+00, -8.0638772e-01,\n",
            "        3.6861134e-01, -4.4758115e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.3631333   0.55464965 -1.3632934   0.5583417  -1.3583038   0.552429\n",
            " -1.3633372   0.55477834]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.34191942, dtype=float32), 'agent_0': Array(-0.34191942, dtype=float32), 'agent_1': Array(-0.34191942, dtype=float32), 'agent_2': Array(-0.34191942, dtype=float32), 'agent_3': Array(-0.34191942, dtype=float32)}\n",
            "step: 379\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4218423e-01,  9.7014225e-01, -1.6216286e-02, -7.0279546e-02,\n",
            "        2.3156413e-01,  1.9904468e-03,  1.1310629e+00, -1.9775091e-02,\n",
            "       -3.6549300e-02, -9.8107802e-03, -3.8433075e-02, -2.5844574e-02,\n",
            "        1.4383793e-01,  4.5526999e-01, -4.8017150e-01,  1.2216122e+01,\n",
            "       -1.4751519e+01,  2.9561541e+00], dtype=float32), 'agent_1': Array([ 5.4218423e-01,  9.7014225e-01, -1.6216286e-02, -7.0279546e-02,\n",
            "        2.3156413e-01,  1.9904468e-03, -1.9775091e-02, -5.1012075e-01,\n",
            "       -3.6549300e-02, -9.8107802e-03, -3.8433075e-02, -2.5844574e-02,\n",
            "        1.4383793e-01,  4.5526999e-01, -4.8017150e-01,  1.2216122e+01,\n",
            "       -1.4661754e+01,  2.2172689e+00], dtype=float32), 'agent_2': Array([ 5.4218423e-01,  9.7014225e-01, -1.6216286e-02, -7.0279546e-02,\n",
            "        2.3156413e-01,  1.9904468e-03, -1.9775091e-02, -3.6549300e-02,\n",
            "       -7.5711781e-01, -9.8107802e-03, -3.8433075e-02, -2.5844574e-02,\n",
            "        1.4383793e-01,  4.5526999e-01, -4.8017150e-01,  1.2216122e+01,\n",
            "       -1.6740662e+01,  2.9161787e+00], dtype=float32), 'agent_3': Array([ 5.4218423e-01,  9.7014225e-01, -1.6216286e-02, -7.0279546e-02,\n",
            "        2.3156413e-01,  1.9904468e-03, -1.9775091e-02, -3.6549300e-02,\n",
            "       -9.8107802e-03,  1.1213670e+00, -3.8433075e-02, -2.5844574e-02,\n",
            "        1.4383793e-01,  4.5526999e-01, -4.8017150e-01,  1.2216122e+01,\n",
            "       -1.5804752e+01,  2.5939939e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.6127446   1.709463   -0.6149132   1.71015    -0.6133868   1.7099148\n",
            " -0.61372316  1.7087382 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.450532, dtype=float32), 'agent_0': Array(-3.450532, dtype=float32), 'agent_1': Array(-3.450532, dtype=float32), 'agent_2': Array(-3.450532, dtype=float32), 'agent_3': Array(-3.450532, dtype=float32)}\n",
            "step: 380\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54069686,  0.90011364, -0.00617757, -0.0833905 ,  0.42755497,\n",
            "       -0.53348696,  1.27502   , -0.53898245, -0.6003507 , -0.5666177 ,\n",
            "       -0.2196312 ,  0.06494522, -0.09937286,  0.82552963, -0.39892155,\n",
            "       -0.04828299, -1.5954328 , -0.6160639 ], dtype=float32), 'agent_1': Array([ 0.54069686,  0.90011364, -0.00617757, -0.0833905 ,  0.42755497,\n",
            "       -0.53348696, -0.53898245, -0.46995765, -0.6003507 , -0.5666177 ,\n",
            "       -0.2196312 ,  0.06494522, -0.09937286,  0.82552963, -0.39892155,\n",
            "       -0.04828299, -0.8203052 ,  0.3002489 ], dtype=float32), 'agent_2': Array([ 0.54069686,  0.90011364, -0.00617757, -0.0833905 ,  0.42755497,\n",
            "       -0.53348696, -0.53898245, -0.6003507 , -0.4560988 , -0.5666177 ,\n",
            "       -0.2196312 ,  0.06494522, -0.09937286,  0.82552963, -0.39892155,\n",
            "       -0.04828299,  1.0202756 ,  2.5102012 ], dtype=float32), 'agent_3': Array([ 0.54069686,  0.90011364, -0.00617757, -0.0833905 ,  0.42755497,\n",
            "       -0.53348696, -0.53898245, -0.6003507 , -0.5666177 ,  1.2715    ,\n",
            "       -0.2196312 ,  0.06494522, -0.09937286,  0.82552963, -0.39892155,\n",
            "       -0.04828299, -0.8256694 ,  0.16743562], dtype=float32)}\n",
            "ctrl action chosen: [0.5092324  0.38611907 0.50745326 0.38448098 0.51246125 0.3891644\n",
            " 0.5094571  0.38631365]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.6192684, dtype=float32), 'agent_0': Array(-5.6192684, dtype=float32), 'agent_1': Array(-5.6192684, dtype=float32), 'agent_2': Array(-5.6192684, dtype=float32), 'agent_3': Array(-5.6192684, dtype=float32)}\n",
            "step: 381\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.545767  ,  0.942799  ,  0.01731462, -0.07420178,  0.3245374 ,\n",
            "       -0.32407245,  1.2353501 , -0.29286698, -0.31078064, -0.33258113,\n",
            "       -0.39286613,  0.3214836 ,  0.31989813,  0.5006453 , -0.6404938 ,\n",
            "       -6.903185  ,  7.1446004 ,  0.04093579], dtype=float32), 'agent_1': Array([ 0.545767  ,  0.942799  ,  0.01731462, -0.07420178,  0.3245374 ,\n",
            "       -0.32407245, -0.29286698, -0.50761104, -0.31078064, -0.33258113,\n",
            "       -0.39286613,  0.3214836 ,  0.31989813,  0.5006453 , -0.6404938 ,\n",
            "       -6.903185  ,  7.8859606 ,  0.01257975], dtype=float32), 'agent_2': Array([ 0.545767  ,  0.942799  ,  0.01731462, -0.07420178,  0.3245374 ,\n",
            "       -0.32407245, -0.29286698, -0.31078064, -0.4838986 , -0.33258113,\n",
            "       -0.39286613,  0.3214836 ,  0.31989813,  0.5006453 , -0.6404938 ,\n",
            "       -6.903185  ,  9.548151  ,  0.49024427], dtype=float32), 'agent_3': Array([ 0.545767  ,  0.942799  ,  0.01731462, -0.07420178,  0.3245374 ,\n",
            "       -0.32407245, -0.29286698, -0.31078064, -0.33258113,  1.2598675 ,\n",
            "       -0.39286613,  0.3214836 ,  0.31989813,  0.5006453 , -0.6404938 ,\n",
            "       -6.903185  ,  8.232181  , -0.14250502], dtype=float32)}\n",
            "ctrl action chosen: [1.0332704  0.22332913 1.0298302  0.22393419 1.0288497  0.22320957\n",
            " 1.0303769  0.22344273]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.17726767, dtype=float32), 'agent_0': Array(-0.17726767, dtype=float32), 'agent_1': Array(-0.17726767, dtype=float32), 'agent_2': Array(-0.17726767, dtype=float32), 'agent_3': Array(-0.17726767, dtype=float32)}\n",
            "step: 382\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5457738 ,   0.99653316,   0.05559089,  -0.05861786,\n",
            "         0.01988185,   0.3875796 ,   1.225616  ,   0.4476392 ,\n",
            "         0.4936686 ,   0.42936197,  -0.4389763 ,   0.3487587 ,\n",
            "        -0.28036833,   0.619587  ,   0.12514386, -13.750144  ,\n",
            "        16.138924  ,  -0.14629641], dtype=float32), 'agent_1': Array([  0.5457738 ,   0.99653316,   0.05559089,  -0.05861786,\n",
            "         0.01988185,   0.3875796 ,   0.4476392 ,  -0.5269542 ,\n",
            "         0.4936686 ,   0.42936197,  -0.4389763 ,   0.3487587 ,\n",
            "        -0.28036833,   0.619587  ,   0.12514386, -13.750144  ,\n",
            "        16.662497  ,   0.12753469], dtype=float32), 'agent_2': Array([  0.5457738 ,   0.99653316,   0.05559089,  -0.05861786,\n",
            "         0.01988185,   0.3875796 ,   0.4476392 ,   0.4936686 ,\n",
            "        -0.5226454 ,   0.42936197,  -0.4389763 ,   0.3487587 ,\n",
            "        -0.28036833,   0.619587  ,   0.12514386, -13.750144  ,\n",
            "        17.651525  ,  -0.5168578 ], dtype=float32), 'agent_3': Array([  0.5457738 ,   0.99653316,   0.05559089,  -0.05861786,\n",
            "         0.01988185,   0.3875796 ,   0.4476392 ,   0.4936686 ,\n",
            "         0.42936197,   1.2043757 ,  -0.4389763 ,   0.3487587 ,\n",
            "        -0.28036833,   0.619587  ,   0.12514386, -13.750144  ,\n",
            "        16.88793   ,  -1.0960969 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.0348006   0.32190514 -1.0351967   0.32238984 -1.0348831   0.32148013\n",
            " -1.0358626   0.32125768]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6740661, dtype=float32), 'agent_0': Array(-1.6740661, dtype=float32), 'agent_1': Array(-1.6740661, dtype=float32), 'agent_2': Array(-1.6740661, dtype=float32), 'agent_3': Array(-1.6740661, dtype=float32)}\n",
            "step: 383\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5388573 ,   0.98893046,   0.0600778 ,  -0.06712059,\n",
            "         0.11790679,   0.12442835,   1.2331583 ,   0.20234723,\n",
            "         0.2811061 ,   0.20312637,  -0.15592575,   0.10557175,\n",
            "        -0.09020567,   0.07641338,  -0.32350004,   9.156594  ,\n",
            "       -11.889216  ,   0.13364995], dtype=float32), 'agent_1': Array([  0.5388573 ,   0.98893046,   0.0600778 ,  -0.06712059,\n",
            "         0.11790679,   0.12442835,   0.20234723,  -0.50572836,\n",
            "         0.2811061 ,   0.20312637,  -0.15592575,   0.10557175,\n",
            "        -0.09020567,   0.07641338,  -0.32350004,   9.156594  ,\n",
            "       -11.7998085 ,   0.26026538], dtype=float32), 'agent_2': Array([  0.5388573 ,   0.98893046,   0.0600778 ,  -0.06712059,\n",
            "         0.11790679,   0.12442835,   0.20234723,   0.2811061 ,\n",
            "        -0.5210813 ,   0.20312637,  -0.15592575,   0.10557175,\n",
            "        -0.09020567,   0.07641338,  -0.32350004,   9.156594  ,\n",
            "       -11.265652  ,   0.19914602], dtype=float32), 'agent_3': Array([  0.5388573 ,   0.98893046,   0.0600778 ,  -0.06712059,\n",
            "         0.11790679,   0.12442835,   0.20234723,   0.2811061 ,\n",
            "         0.20312637,   1.1798908 ,  -0.15592575,   0.10557175,\n",
            "        -0.09020567,   0.07641338,  -0.32350004,   9.156594  ,\n",
            "       -11.319115  ,   0.52809656], dtype=float32)}\n",
            "ctrl action chosen: [-0.31680635 -0.44646147 -0.31789112 -0.44598168 -0.3179732  -0.44763908\n",
            " -0.31770355 -0.44781515]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.597693, dtype=float32), 'agent_0': Array(-1.597693, dtype=float32), 'agent_1': Array(-1.597693, dtype=float32), 'agent_2': Array(-1.597693, dtype=float32), 'agent_3': Array(-1.597693, dtype=float32)}\n",
            "step: 384\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53605175,  0.9536363 ,  0.04365554, -0.06303924,  0.2910293 ,\n",
            "       -0.35163522,  1.1012956 , -0.26241317, -0.16842712, -0.25339395,\n",
            "       -0.50644875,  0.09889603, -0.15408993,  0.13811295,  0.7823221 ,\n",
            "        6.5009284 , -8.721767  , -3.8015003 ], dtype=float32), 'agent_1': Array([ 0.53605175,  0.9536363 ,  0.04365554, -0.06303924,  0.2910293 ,\n",
            "       -0.35163522, -0.26241317, -0.602906  , -0.16842712, -0.25339395,\n",
            "       -0.50644875,  0.09889603, -0.15408993,  0.13811295,  0.7823221 ,\n",
            "        6.5009284 , -8.341     , -2.9807143 ], dtype=float32), 'agent_2': Array([ 0.53605175,  0.9536363 ,  0.04365554, -0.06303924,  0.2910293 ,\n",
            "       -0.35163522, -0.26241317, -0.16842712, -0.6344727 , -0.25339395,\n",
            "       -0.50644875,  0.09889603, -0.15408993,  0.13811295,  0.7823221 ,\n",
            "        6.5009284 , -8.085557  , -2.5793803 ], dtype=float32), 'agent_3': Array([ 0.53605175,  0.9536363 ,  0.04365554, -0.06303924,  0.2910293 ,\n",
            "       -0.35163522, -0.26241317, -0.16842712, -0.25339395,  1.0465465 ,\n",
            "       -0.50644875,  0.09889603, -0.15408993,  0.13811295,  0.7823221 ,\n",
            "        6.5009284 , -8.24805   , -3.5588086 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.27600902 -0.02033222 -0.2778636  -0.02005813 -0.2776331  -0.02101339\n",
            " -0.277891   -0.02157283]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.01149362, dtype=float32), 'agent_0': Array(0.01149362, dtype=float32), 'agent_1': Array(0.01149362, dtype=float32), 'agent_2': Array(0.01149362, dtype=float32), 'agent_3': Array(0.01149362, dtype=float32)}\n",
            "step: 385\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5214491 ,  0.9223498 ,  0.03439081, -0.05831682,  0.38037786,\n",
            "       -0.5758605 ,  0.9856809 , -0.53482664, -0.41134477, -0.51155597,\n",
            "       -0.22358894, -0.18758774, -0.30950308, -0.04428726,  0.52048475,\n",
            "        1.1827428 ,  0.24498041, -2.2460313 ], dtype=float32), 'agent_1': Array([ 0.5214491 ,  0.9223498 ,  0.03439081, -0.05831682,  0.38037786,\n",
            "       -0.5758605 , -0.53482664, -0.70735466, -0.41134477, -0.51155597,\n",
            "       -0.22358894, -0.18758774, -0.30950308, -0.04428726,  0.52048475,\n",
            "        1.1827428 , -2.506606  , -2.1667566 ], dtype=float32), 'agent_2': Array([ 0.5214491 ,  0.9223498 ,  0.03439081, -0.05831682,  0.38037786,\n",
            "       -0.5758605 , -0.53482664, -0.41134477, -0.6282488 , -0.51155597,\n",
            "       -0.22358894, -0.18758774, -0.30950308, -0.04428726,  0.52048475,\n",
            "        1.1827428 , -2.0582328 ,  0.9481779 ], dtype=float32), 'agent_3': Array([ 0.5214491 ,  0.9223498 ,  0.03439081, -0.05831682,  0.38037786,\n",
            "       -0.5758605 , -0.53482664, -0.41134477, -0.51155597,  0.9506339 ,\n",
            "       -0.22358894, -0.18758774, -0.30950308, -0.04428726,  0.52048475,\n",
            "        1.1827428 , -2.5516186 , -1.7902818 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.6747098  -0.38337523  0.6716221  -0.38205558  0.67077106 -0.37731573\n",
            "  0.6722096  -0.38229635]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.47807047, dtype=float32), 'agent_0': Array(0.47807047, dtype=float32), 'agent_1': Array(0.47807047, dtype=float32), 'agent_2': Array(0.47807047, dtype=float32), 'agent_3': Array(0.47807047, dtype=float32)}\n",
            "step: 386\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.508402  ,  0.96726835,  0.02916072, -0.01967832,  0.25130567,\n",
            "       -0.17933582,  0.7602205 , -0.23415196, -0.06370881, -0.21109422,\n",
            "       -0.22463799, -0.13504028, -0.23348331, -0.16641487,  1.8074313 ,\n",
            "       -8.189508  , 11.775627  , -5.2492065 ], dtype=float32), 'agent_1': Array([ 0.508402  ,  0.96726835,  0.02916072, -0.01967832,  0.25130567,\n",
            "       -0.17933582, -0.23415196, -0.9126448 , -0.06370881, -0.21109422,\n",
            "       -0.22463799, -0.13504028, -0.23348331, -0.16641487,  1.8074313 ,\n",
            "       -8.189508  ,  9.606209  , -4.462637  ], dtype=float32), 'agent_2': Array([ 0.508402  ,  0.96726835,  0.02916072, -0.01967832,  0.25130567,\n",
            "       -0.17933582, -0.23415196, -0.06370881, -0.7060939 , -0.21109422,\n",
            "       -0.22463799, -0.13504028, -0.23348331, -0.16641487,  1.8074313 ,\n",
            "       -8.189508  , 10.49832   , -2.6947353 ], dtype=float32), 'agent_3': Array([ 0.508402  ,  0.96726835,  0.02916072, -0.01967832,  0.25130567,\n",
            "       -0.17933582, -0.23415196, -0.06370881, -0.21109422,  0.75358087,\n",
            "       -0.22463799, -0.13504028, -0.23348331, -0.16641487,  1.8074313 ,\n",
            "       -8.189508  ,  9.300735  , -4.7321177 ], dtype=float32)}\n",
            "ctrl action chosen: [0.6618397  0.79273    0.6588377  0.79347855 0.661987   0.7943275\n",
            " 0.6582467  0.7925407 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.40387797, dtype=float32), 'agent_0': Array(-0.40387797, dtype=float32), 'agent_1': Array(-0.40387797, dtype=float32), 'agent_2': Array(-0.40387797, dtype=float32), 'agent_3': Array(-0.40387797, dtype=float32)}\n",
            "step: 387\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.48875624,  0.9992538 ,  0.02529546, -0.0252781 ,  0.01459895,\n",
            "        0.47569892,  0.8437034 ,  0.35163945,  0.545126  ,  0.35109174,\n",
            "        0.30941963, -0.26426315, -0.43162704, -0.01888264, -1.1966937 ,\n",
            "       -9.305715  , 12.772789  ,  4.279895  ], dtype=float32), 'agent_1': Array([ 0.48875624,  0.9992538 ,  0.02529546, -0.0252781 ,  0.01459895,\n",
            "        0.47569892,  0.35163945, -0.7597739 ,  0.545126  ,  0.35109174,\n",
            "        0.30941963, -0.26426315, -0.43162704, -0.01888264, -1.1966937 ,\n",
            "       -9.305715  , 11.969756  ,  6.242972  ], dtype=float32), 'agent_2': Array([ 0.48875624,  0.9992538 ,  0.02529546, -0.0252781 ,  0.01459895,\n",
            "        0.47569892,  0.35163945,  0.545126  , -0.5272123 ,  0.35109174,\n",
            "        0.30941963, -0.26426315, -0.43162704, -0.01888264, -1.1966937 ,\n",
            "       -9.305715  , 11.133057  ,  5.8704615 ], dtype=float32), 'agent_3': Array([ 0.48875624,  0.9992538 ,  0.02529546, -0.0252781 ,  0.01459895,\n",
            "        0.47569892,  0.35163945,  0.545126  ,  0.35109174,  0.8613823 ,\n",
            "        0.30941963, -0.26426315, -0.43162704, -0.01888264, -1.1966937 ,\n",
            "       -9.305715  , 11.255149  ,  4.9685855 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.6222337  -0.0172328   0.6236479  -0.01791845  0.6243168  -0.01816788\n",
            "  0.6231491  -0.01723624]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0393558, dtype=float32), 'agent_0': Array(-1.0393558, dtype=float32), 'agent_1': Array(-1.0393558, dtype=float32), 'agent_2': Array(-1.0393558, dtype=float32), 'agent_3': Array(-1.0393558, dtype=float32)}\n",
            "step: 388\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.46808824,  0.99925846,  0.00564105, -0.02951127, -0.0240806 ,\n",
            "        0.5699697 ,  0.8931617 ,  0.5488901 ,  0.54144514,  0.5282093 ,\n",
            "        0.0893116 , -0.59814453,  0.1959145 , -0.75802755, -0.3883848 ,\n",
            "        0.67425305, -1.3394555 , -0.54813576], dtype=float32), 'agent_1': Array([ 0.46808824,  0.99925846,  0.00564105, -0.02951127, -0.0240806 ,\n",
            "        0.5699697 ,  0.5488901 , -0.6008233 ,  0.54144514,  0.5282093 ,\n",
            "        0.0893116 , -0.59814453,  0.1959145 , -0.75802755, -0.3883848 ,\n",
            "        0.67425305,  0.55911356,  2.515201  ], dtype=float32), 'agent_2': Array([ 0.46808824,  0.99925846,  0.00564105, -0.02951127, -0.0240806 ,\n",
            "        0.5699697 ,  0.5488901 ,  0.54144514, -0.516008  ,  0.5282093 ,\n",
            "        0.0893116 , -0.59814453,  0.1959145 , -0.75802755, -0.3883848 ,\n",
            "        0.67425305, -2.362605  ,  0.18522388], dtype=float32), 'agent_3': Array([ 0.46808824,  0.99925846,  0.00564105, -0.02951127, -0.0240806 ,\n",
            "        0.5699697 ,  0.5488901 ,  0.54144514,  0.5282093 ,  0.9270262 ,\n",
            "        0.0893116 , -0.59814453,  0.1959145 , -0.75802755, -0.3883848 ,\n",
            "        0.67425305,  0.89206964,  0.25170612], dtype=float32)}\n",
            "ctrl action chosen: [-0.22932851 -1.0401697  -0.22470991 -1.0352582  -0.22790325 -1.0405546\n",
            " -0.22424476 -1.0407073 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.50034606, dtype=float32), 'agent_0': Array(0.50034606, dtype=float32), 'agent_1': Array(0.50034606, dtype=float32), 'agent_2': Array(0.50034606, dtype=float32), 'agent_3': Array(0.50034606, dtype=float32)}\n",
            "step: 389\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.8192242e-01,  9.9782598e-01, -2.7482385e-02,  4.1973698e-03,\n",
            "        5.9753429e-02,  3.2536569e-01,  5.9429812e-01,  4.2889872e-01,\n",
            "        2.2888982e-01,  4.1102141e-01, -6.3543320e-01, -8.5754395e-01,\n",
            "       -5.8484077e-02, -1.5907288e+00,  2.7167337e+00,  4.2430539e+00,\n",
            "       -6.3142929e+00, -9.0507507e+00], dtype=float32), 'agent_1': Array([ 4.8192242e-01,  9.9782598e-01, -2.7482385e-02,  4.1973698e-03,\n",
            "        5.9753429e-02,  3.2536569e-01,  4.2889872e-01, -8.0360597e-01,\n",
            "        2.2888982e-01,  4.1102141e-01, -6.3543320e-01, -8.5754395e-01,\n",
            "       -5.8484077e-02, -1.5907288e+00,  2.7167337e+00,  4.2430539e+00,\n",
            "       -3.5930059e+00, -7.8711715e+00], dtype=float32), 'agent_2': Array([ 4.8192242e-01,  9.9782598e-01, -2.7482385e-02,  4.1973698e-03,\n",
            "        5.9753429e-02,  3.2536569e-01,  4.2889872e-01,  2.2888982e-01,\n",
            "       -7.8950971e-01,  4.1102141e-01, -6.3543320e-01, -8.5754395e-01,\n",
            "       -5.8484077e-02, -1.5907288e+00,  2.7167337e+00,  4.2430539e+00,\n",
            "       -6.9669333e+00, -9.0416632e+00], dtype=float32), 'agent_3': Array([ 4.8192242e-01,  9.9782598e-01, -2.7482385e-02,  4.1973698e-03,\n",
            "        5.9753429e-02,  3.2536569e-01,  4.2889872e-01,  2.2888982e-01,\n",
            "        4.1102141e-01,  6.3373882e-01, -6.3543320e-01, -8.5754395e-01,\n",
            "       -5.8484077e-02, -1.5907288e+00,  2.7167337e+00,  4.2430539e+00,\n",
            "       -3.0747313e+00, -9.0035391e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.2672925   0.24549378 -1.2662073   0.2458255  -1.266149    0.24415669\n",
            " -1.2653949   0.2441636 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.7620218, dtype=float32), 'agent_0': Array(-1.7620218, dtype=float32), 'agent_1': Array(-1.7620218, dtype=float32), 'agent_2': Array(-1.7620218, dtype=float32), 'agent_3': Array(-1.7620218, dtype=float32)}\n",
            "step: 390\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.48122206,   0.94322056,  -0.03576648,   0.03687813,\n",
            "         0.32817033,  -0.39065373,   0.5107205 ,  -0.21527115,\n",
            "        -0.51130843,  -0.19551353,  -0.24371147,  -0.3016472 ,\n",
            "         0.17938614,   0.04403969,   0.17067747,  12.859676  ,\n",
            "       -16.67765   ,   0.8096532 ], dtype=float32), 'agent_1': Array([  0.48122206,   0.94322056,  -0.03576648,   0.03687813,\n",
            "         0.32817033,  -0.39065373,  -0.21527115,  -0.8863125 ,\n",
            "        -0.51130843,  -0.19551353,  -0.24371147,  -0.3016472 ,\n",
            "         0.17938614,   0.04403969,   0.17067747,  12.859676  ,\n",
            "       -15.946459  ,   0.83931583], dtype=float32), 'agent_2': Array([  0.48122206,   0.94322056,  -0.03576648,   0.03687813,\n",
            "         0.32817033,  -0.39065373,  -0.21527115,  -0.51130843,\n",
            "        -0.9828003 ,  -0.19551353,  -0.24371147,  -0.3016472 ,\n",
            "         0.17938614,   0.04403969,   0.17067747,  12.859676  ,\n",
            "       -17.091883  ,  -1.3244666 ], dtype=float32), 'agent_3': Array([  0.48122206,   0.94322056,  -0.03576648,   0.03687813,\n",
            "         0.32817033,  -0.39065373,  -0.21527115,  -0.51130843,\n",
            "        -0.19551353,   0.50091755,  -0.24371147,  -0.3016472 ,\n",
            "         0.17938614,   0.04403969,   0.17067747,  12.859676  ,\n",
            "       -15.036102  ,   0.28719053], dtype=float32)}\n",
            "ctrl action chosen: [1.2745965  0.18771838 1.2736281  0.18841682 1.2728676  0.18745689\n",
            " 1.273026   0.18731998]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.743329, dtype=float32), 'agent_0': Array(-2.743329, dtype=float32), 'agent_1': Array(-2.743329, dtype=float32), 'agent_2': Array(-2.743329, dtype=float32), 'agent_3': Array(-2.743329, dtype=float32)}\n",
            "step: 391\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4906574 ,  0.9746878 , -0.04177358,  0.04031039,  0.21590225,\n",
            "       -0.14831263,  0.5648831 ,  0.04798773, -0.28101993,  0.10904235,\n",
            "       -0.17299652, -0.23183823, -0.01260042, -0.12869681,  0.10580626,\n",
            "       -9.6811905 , 11.615127  ,  1.6256248 ], dtype=float32), 'agent_1': Array([ 0.4906574 ,  0.9746878 , -0.04177358,  0.04031039,  0.21590225,\n",
            "       -0.14831263,  0.04798773, -0.80944896, -0.28101993,  0.10904235,\n",
            "       -0.17299652, -0.23183823, -0.01260042, -0.12869681,  0.10580626,\n",
            "       -9.6811905 , 12.005248  ,  1.7534935 ], dtype=float32), 'agent_2': Array([ 0.4906574 ,  0.9746878 , -0.04177358,  0.04031039,  0.21590225,\n",
            "       -0.14831263,  0.04798773, -0.28101993, -1.0344782 ,  0.10904235,\n",
            "       -0.17299652, -0.23183823, -0.01260042, -0.12869681,  0.10580626,\n",
            "       -9.6811905 , 11.12774   , -0.7294856 ], dtype=float32), 'agent_3': Array([ 4.9065739e-01,  9.7468781e-01, -4.1773580e-02,  4.0310387e-02,\n",
            "        2.1590225e-01, -1.4831263e-01,  4.7987733e-02, -2.8101993e-01,\n",
            "        1.0904235e-01,  5.3037238e-01, -1.7299652e-01, -2.3183823e-01,\n",
            "       -1.2600422e-02, -1.2869681e-01,  1.0580626e-01, -9.6811905e+00,\n",
            "        1.2796856e+01,  1.3184500e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.07446941 0.27403083 0.07460898 0.27371502 0.0737091  0.27376264\n",
            " 0.07285713 0.273969  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.5272286, dtype=float32), 'agent_0': Array(-2.5272286, dtype=float32), 'agent_1': Array(-2.5272286, dtype=float32), 'agent_2': Array(-2.5272286, dtype=float32), 'agent_3': Array(-2.5272286, dtype=float32)}\n",
            "step: 392\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4962802 ,  0.99513346, -0.02977494,  0.01719392,  0.09234282,\n",
            "        0.20638311,  0.6781568 ,  0.36131042,  0.01326337,  0.45639968,\n",
            "       -0.35510063,  0.09832382, -0.0410378 ,  0.9308994 , -1.2268027 ,\n",
            "       -3.5104797 ,  5.334348  ,  2.3061688 ], dtype=float32), 'agent_1': Array([ 0.4962802 ,  0.99513346, -0.02977494,  0.01719392,  0.09234282,\n",
            "        0.20638311,  0.36131042, -0.66142464,  0.01326337,  0.45639968,\n",
            "       -0.35510063,  0.09832382, -0.0410378 ,  0.9308994 , -1.2268027 ,\n",
            "       -3.5104797 ,  4.0400963 ,  3.8168232 ], dtype=float32), 'agent_2': Array([ 0.4962802 ,  0.99513346, -0.02977494,  0.01719392,  0.09234282,\n",
            "        0.20638311,  0.36131042,  0.01326337, -0.93849593,  0.45639968,\n",
            "       -0.35510063,  0.09832382, -0.0410378 ,  0.9308994 , -1.2268027 ,\n",
            "       -3.5104797 ,  4.0543656 ,  3.9952364 ], dtype=float32), 'agent_3': Array([ 0.4962802 ,  0.99513346, -0.02977494,  0.01719392,  0.09234282,\n",
            "        0.20638311,  0.36131042,  0.01326337,  0.45639968,  0.72095895,\n",
            "       -0.35510063,  0.09832382, -0.0410378 ,  0.9308994 , -1.2268027 ,\n",
            "       -3.5104797 ,  4.634721  ,  5.2232747 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5645802  -0.04828728  0.56561315 -0.04483501  0.56633294 -0.0461899\n",
            "  0.5637339  -0.04231071]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.399082, dtype=float32), 'agent_0': Array(0.399082, dtype=float32), 'agent_1': Array(0.399082, dtype=float32), 'agent_2': Array(0.399082, dtype=float32), 'agent_3': Array(0.399082, dtype=float32)}\n",
            "step: 393\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.8465285e-01,  9.9983448e-01, -1.1784399e-02,  1.2966603e-04,\n",
            "        1.3868520e-02,  4.7841537e-01,  7.1208775e-01,  5.5748844e-01,\n",
            "        2.3683548e-01,  5.7937974e-01, -2.9277802e-01,  3.7136078e-01,\n",
            "       -2.5740862e-01,  6.3755453e-01, -4.1487160e-01, -1.0845621e+00,\n",
            "        3.8251073e+00,  4.2797130e-01], dtype=float32), 'agent_1': Array([ 4.8465285e-01,  9.9983448e-01, -1.1784399e-02,  1.2966603e-04,\n",
            "        1.3868520e-02,  4.7841537e-01,  5.5748844e-01, -5.3831029e-01,\n",
            "        2.3683548e-01,  5.7937974e-01, -2.9277802e-01,  3.7136078e-01,\n",
            "       -2.5740862e-01,  6.3755453e-01, -4.1487160e-01, -1.0845621e+00,\n",
            "        1.0547079e+00,  1.8002583e+00], dtype=float32), 'agent_2': Array([ 4.8465285e-01,  9.9983448e-01, -1.1784399e-02,  1.2966603e-04,\n",
            "        1.3868520e-02,  4.7841537e-01,  5.5748844e-01,  2.3683548e-01,\n",
            "       -8.2139242e-01,  5.7937974e-01, -2.9277802e-01,  3.7136078e-01,\n",
            "       -2.5740862e-01,  6.3755453e-01, -4.1487160e-01, -1.0845621e+00,\n",
            "        2.9275947e+00,  1.1851625e+00], dtype=float32), 'agent_3': Array([ 4.8465285e-01,  9.9983448e-01, -1.1784399e-02,  1.2966603e-04,\n",
            "        1.3868520e-02,  4.7841537e-01,  5.5748844e-01,  2.3683548e-01,\n",
            "        5.7937974e-01,  8.6648983e-01, -2.9277802e-01,  3.7136078e-01,\n",
            "       -2.5740862e-01,  6.3755453e-01, -4.1487160e-01, -1.0845621e+00,\n",
            "       -7.9110759e-01,  8.5146964e-01], dtype=float32)}\n",
            "ctrl action chosen: [0.16835465 0.5368784  0.16834527 0.5450053  0.1708163  0.53756326\n",
            " 0.16390759 0.545671  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.01215655, dtype=float32), 'agent_0': Array(-0.01215655, dtype=float32), 'agent_1': Array(-0.01215655, dtype=float32), 'agent_2': Array(-0.01215655, dtype=float32), 'agent_3': Array(-0.01215655, dtype=float32)}\n",
            "step: 394\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.47579533,  0.9990211 ,  0.02328804, -0.02759418,  0.02555594,\n",
            "        0.54945624,  0.9226932 ,  0.5161499 ,  0.29069546,  0.46547928,\n",
            "       -0.06341934,  0.6656647 , -0.01815557,  1.7382518 , -1.2663443 ,\n",
            "        1.042337  ,  0.11873696,  5.6523013 ], dtype=float32), 'agent_1': Array([ 0.47579533,  0.9990211 ,  0.02328804, -0.02759418,  0.02555594,\n",
            "        0.54945624,  0.5161499 , -0.48982564,  0.29069546,  0.46547928,\n",
            "       -0.06341934,  0.6656647 , -0.01815557,  1.7382518 , -1.2663443 ,\n",
            "        1.042337  , -1.2951255 , -0.25778577], dtype=float32), 'agent_2': Array([ 0.47579533,  0.9990211 ,  0.02328804, -0.02759418,  0.02555594,\n",
            "        0.54945624,  0.5161499 ,  0.29069546, -0.5967864 ,  0.46547928,\n",
            "       -0.06341934,  0.6656647 , -0.01815557,  1.7382518 , -1.2663443 ,\n",
            "        1.042337  ,  0.7198862 ,  6.0508924 ], dtype=float32), 'agent_3': Array([ 0.47579533,  0.9990211 ,  0.02328804, -0.02759418,  0.02555594,\n",
            "        0.54945624,  0.5161499 ,  0.29069546,  0.46547928,  0.9651399 ,\n",
            "       -0.06341934,  0.6656647 , -0.01815557,  1.7382518 , -1.2663443 ,\n",
            "        1.042337  , -2.832161  ,  1.2118096 ], dtype=float32)}\n",
            "ctrl action chosen: [0.7913876  0.11424336 0.7888802  0.11114319 0.79201084 0.1129986\n",
            " 0.7862143  0.11304527]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.21154755, dtype=float32), 'agent_0': Array(0.21154755, dtype=float32), 'agent_1': Array(0.21154755, dtype=float32), 'agent_2': Array(0.21154755, dtype=float32), 'agent_3': Array(0.21154755, dtype=float32)}\n",
            "step: 395\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.47739613,  0.99755216,  0.04959223, -0.04920324, -0.00306891,\n",
            "        0.58077973,  1.1069245 ,  0.5562287 ,  0.5261474 ,  0.52402234,\n",
            "       -0.5186558 ,  0.1203537 , -0.03415942,  0.45237797, -0.96679145,\n",
            "       -0.5404087 , -1.418136  ,  2.870538  ], dtype=float32), 'agent_1': Array([ 0.47739613,  0.99755216,  0.04959223, -0.04920324, -0.00306891,\n",
            "        0.58077973,  0.5562287 , -0.5236969 ,  0.5261474 ,  0.52402234,\n",
            "       -0.5186558 ,  0.1203537 , -0.03415942,  0.45237797, -0.96679145,\n",
            "       -0.5404087 , -0.16902378, -0.31820685], dtype=float32), 'agent_2': Array([ 4.7739613e-01,  9.9755216e-01,  4.9592230e-02, -4.9203236e-02,\n",
            "       -3.0689130e-03,  5.8077973e-01,  5.5622870e-01,  5.2614743e-01,\n",
            "       -5.0177974e-01,  5.2402234e-01, -5.1865578e-01,  1.2035370e-01,\n",
            "       -3.4159422e-02,  4.5237797e-01, -9.6679145e-01, -5.4040867e-01,\n",
            "        4.6594963e+00, -6.6087234e-01], dtype=float32), 'agent_3': Array([ 0.47739613,  0.99755216,  0.04959223, -0.04920324, -0.00306891,\n",
            "        0.58077973,  0.5562287 ,  0.5261474 ,  0.52402234,  0.9110955 ,\n",
            "       -0.5186558 ,  0.1203537 , -0.03415942,  0.45237797, -0.96679145,\n",
            "       -0.5404087 ,  1.1857495 , -0.8758358 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.4247455   0.47331518 -0.42405757  0.4673375  -0.41738838  0.45990375\n",
            " -0.4222265   0.46382585]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.57618916, dtype=float32), 'agent_0': Array(-0.57618916, dtype=float32), 'agent_1': Array(-0.57618916, dtype=float32), 'agent_2': Array(-0.57618916, dtype=float32), 'agent_3': Array(-0.57618916, dtype=float32)}\n",
            "step: 396\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.7475135e-01,  9.8924065e-01,  5.5091068e-02, -9.4417036e-02,\n",
            "        9.7228773e-02,  2.3371513e-01,  1.2630517e+00,  2.7180198e-01,\n",
            "        4.4988599e-01,  3.0629212e-01, -6.2975883e-01,  2.5844574e-01,\n",
            "        1.8204451e-01, -4.7354189e-01, -1.3978603e+00,  5.7520857e+00,\n",
            "       -9.2114649e+00,  3.8778479e-03], dtype=float32), 'agent_1': Array([ 0.47475135,  0.98924065,  0.05509107, -0.09441704,  0.09722877,\n",
            "        0.23371513,  0.27180198, -0.5062923 ,  0.449886  ,  0.30629212,\n",
            "       -0.62975883,  0.25844574,  0.1820445 , -0.4735419 , -1.3978603 ,\n",
            "        5.7520857 , -7.936198  ,  0.2371361 ], dtype=float32), 'agent_2': Array([ 0.47475135,  0.98924065,  0.05509107, -0.09441704,  0.09722877,\n",
            "        0.23371513,  0.27180198,  0.449886  , -0.48692948,  0.30629212,\n",
            "       -0.62975883,  0.25844574,  0.1820445 , -0.4735419 , -1.3978603 ,\n",
            "        5.7520857 , -4.0139422 ,  0.02298891], dtype=float32), 'agent_3': Array([ 0.47475135,  0.98924065,  0.05509107, -0.09441704,  0.09722877,\n",
            "        0.23371513,  0.27180198,  0.449886  ,  0.30629212,  1.0451097 ,\n",
            "       -0.62975883,  0.25844574,  0.1820445 , -0.4735419 , -1.3978603 ,\n",
            "        5.7520857 , -6.254141  ,  4.1467357 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.07681181  0.8389201  -0.07831812  0.8392491  -0.07653427  0.8367048\n",
            " -0.07373357  0.8399356 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.25235403, dtype=float32), 'agent_0': Array(-0.25235403, dtype=float32), 'agent_1': Array(-0.25235403, dtype=float32), 'agent_2': Array(-0.25235403, dtype=float32), 'agent_3': Array(-0.25235403, dtype=float32)}\n",
            "step: 397\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4898552 ,  0.97793216,  0.02761484, -0.12639053,  0.16404721,\n",
            "       -0.03644922,  1.2596649 ,  0.05723827,  0.34869093,  0.14853087,\n",
            "       -0.6649971 ,  0.23651123,  0.36839843, -0.46078172, -0.37956184,\n",
            "        2.0322073 , -4.15646   , -0.19847062], dtype=float32), 'agent_1': Array([ 0.4898552 ,  0.97793216,  0.02761484, -0.12639053,  0.16404721,\n",
            "       -0.03644922,  0.05723827, -0.4761555 ,  0.34869093,  0.14853087,\n",
            "       -0.6649971 ,  0.23651123,  0.36839843, -0.46078172, -0.37956184,\n",
            "        2.0322073 , -2.9930007 ,  0.08751787], dtype=float32), 'agent_2': Array([ 0.4898552 ,  0.97793216,  0.02761484, -0.12639053,  0.16404721,\n",
            "       -0.03644922,  0.05723827,  0.34869093, -0.4862451 ,  0.14853087,\n",
            "       -0.6649971 ,  0.23651123,  0.36839843, -0.46078172, -0.37956184,\n",
            "        2.0322073 , -1.478794  , -0.01718068], dtype=float32), 'agent_3': Array([ 0.4898552 ,  0.97793216,  0.02761484, -0.12639053,  0.16404721,\n",
            "       -0.03644922,  0.05723827,  0.34869093,  0.14853087,  1.2855943 ,\n",
            "       -0.6649971 ,  0.23651123,  0.36839843, -0.46078172, -0.37956184,\n",
            "        2.0322073 , -2.1440494 ,  0.521626  ], dtype=float32)}\n",
            "ctrl action chosen: [0.36126012 2.2338986  0.35949755 2.2337027  0.3631428  2.2289014\n",
            " 0.3609915  2.231385  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1003444, dtype=float32), 'agent_0': Array(-1.1003444, dtype=float32), 'agent_1': Array(-1.1003444, dtype=float32), 'agent_2': Array(-1.1003444, dtype=float32), 'agent_3': Array(-1.1003444, dtype=float32)}\n",
            "step: 398\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5087952 ,  0.9863152 ,  0.03321262, -0.1258693 ,  0.10117382,\n",
            "        0.04880248,  1.2578987 ,  0.20306428,  0.55288476,  0.32955953,\n",
            "       -0.38437843, -0.0746727 ,  0.28055906, -0.11445907,  0.03758746,\n",
            "       -3.422069  ,  3.1492245 , -0.07358643], dtype=float32), 'agent_1': Array([ 0.5087952 ,  0.9863152 ,  0.03321262, -0.1258693 ,  0.10117382,\n",
            "        0.04880248,  0.20306428, -0.48003402,  0.55288476,  0.32955953,\n",
            "       -0.38437843, -0.0746727 ,  0.28055906, -0.11445907,  0.03758746,\n",
            "       -3.422069  ,  4.353779  , -0.08036891], dtype=float32), 'agent_2': Array([ 0.5087952 ,  0.9863152 ,  0.03321262, -0.1258693 ,  0.10117382,\n",
            "        0.04880248,  0.20306428,  0.55288476, -0.48556817,  0.32955953,\n",
            "       -0.38437843, -0.0746727 ,  0.28055906, -0.11445907,  0.03758746,\n",
            "       -3.422069  ,  4.4809833 , -0.29555526], dtype=float32), 'agent_3': Array([ 0.5087952 ,  0.9863152 ,  0.03321262, -0.1258693 ,  0.10117382,\n",
            "        0.04880248,  0.20306428,  0.55288476,  0.32955953,  1.2767749 ,\n",
            "       -0.38437843, -0.0746727 ,  0.28055906, -0.11445907,  0.03758746,\n",
            "       -3.422069  ,  4.843389  , -0.57135147], dtype=float32)}\n",
            "ctrl action chosen: [ 0.49549672 -1.5272057   0.4951908  -1.5266292   0.4960968  -1.5287911\n",
            "  0.49421817 -1.5278785 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.752027, dtype=float32), 'agent_0': Array(-9.752027, dtype=float32), 'agent_1': Array(-9.752027, dtype=float32), 'agent_2': Array(-9.752027, dtype=float32), 'agent_3': Array(-9.752027, dtype=float32)}\n",
            "step: 399\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5297976 ,   0.9966888 ,   0.01519929,  -0.06736165,\n",
            "         0.04293129,   0.19560489,   0.8973321 ,   0.4104699 ,\n",
            "         0.5814681 ,   0.5459074 ,  -0.4703045 ,  -0.29354095,\n",
            "         0.5167842 ,  -1.1477319 ,   3.3360407 ,  -1.2535737 ,\n",
            "         2.370221  , -10.08867   ], dtype=float32), 'agent_1': Array([ 0.5297976 ,  0.9966888 ,  0.01519929, -0.06736165,  0.04293129,\n",
            "        0.19560489,  0.4104699 , -0.7520418 ,  0.5814681 ,  0.5459074 ,\n",
            "       -0.4703045 , -0.29354095,  0.5167842 , -1.1477319 ,  3.3360407 ,\n",
            "       -1.2535737 ,  3.1737874 , -6.9479556 ], dtype=float32), 'agent_2': Array([ 0.5297976 ,  0.9966888 ,  0.01519929, -0.06736165,  0.04293129,\n",
            "        0.19560489,  0.4104699 ,  0.5814681 , -0.8207336 ,  0.5459074 ,\n",
            "       -0.4703045 , -0.29354095,  0.5167842 , -1.1477319 ,  3.3360407 ,\n",
            "       -1.2535737 , -1.7692152 , -8.474529  ], dtype=float32), 'agent_3': Array([  0.5297976 ,   0.9966888 ,   0.01519929,  -0.06736165,\n",
            "         0.04293129,   0.19560489,   0.4104699 ,   0.5814681 ,\n",
            "         0.5459074 ,   0.88826257,  -0.4703045 ,  -0.29354095,\n",
            "         0.5167842 ,  -1.1477319 ,   3.3360407 ,  -1.2535737 ,\n",
            "         2.667658  , -11.286967  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.31037036 -1.4438925   0.3069871  -1.441403    0.31217426 -1.4454494\n",
            "  0.31055284 -1.4437184 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.6267247, dtype=float32), 'agent_0': Array(-4.6267247, dtype=float32), 'agent_1': Array(-4.6267247, dtype=float32), 'agent_2': Array(-4.6267247, dtype=float32), 'agent_3': Array(-4.6267247, dtype=float32)}\n",
            "step: 400\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.56648535,  0.99871886, -0.02679969,  0.02713006,  0.03326336,\n",
            "        0.29693314,  0.4135615 ,  0.5003655 ,  0.50218153,  0.5528423 ,\n",
            "       -0.16703606, -0.10204315,  0.5280733 , -1.204114  ,  2.559971  ,\n",
            "       -0.53826845,  3.0489578 , -2.0870228 ], dtype=float32), 'agent_1': Array([  0.56648535,   0.99871886,  -0.02679969,   0.02713006,\n",
            "         0.03326336,   0.29693314,   0.5003655 ,  -1.1978496 ,\n",
            "         0.50218153,   0.5528423 ,  -0.16703606,  -0.10204315,\n",
            "         0.5280733 ,  -1.204114  ,   2.559971  ,  -0.53826845,\n",
            "         1.7717923 , -10.475961  ], dtype=float32), 'agent_2': Array([ 0.56648535,  0.99871886, -0.02679969,  0.02713006,  0.03326336,\n",
            "        0.29693314,  0.5003655 ,  0.50218153, -1.2959131 ,  0.5528423 ,\n",
            "       -0.16703606, -0.10204315,  0.5280733 , -1.204114  ,  2.559971  ,\n",
            "       -0.53826845, -0.41891485, -6.197998  ], dtype=float32), 'agent_3': Array([ 0.56648535,  0.99871886, -0.02679969,  0.02713006,  0.03326336,\n",
            "        0.29693314,  0.5003655 ,  0.50218153,  0.5528423 ,  0.40154654,\n",
            "       -0.16703606, -0.10204315,  0.5280733 , -1.204114  ,  2.559971  ,\n",
            "       -0.53826845, -0.7062406 , -0.10912067], dtype=float32)}\n",
            "ctrl action chosen: [-0.25043067  1.4093043  -0.24899045  1.408329   -0.24737674  1.402943\n",
            " -0.25573322  1.4163902 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6754184, dtype=float32), 'agent_0': Array(-3.6754184, dtype=float32), 'agent_1': Array(-3.6754184, dtype=float32), 'agent_2': Array(-3.6754184, dtype=float32), 'agent_3': Array(-3.6754184, dtype=float32)}\n",
            "step: 401\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1813861e-01,  9.9568069e-01, -3.7633905e-03,  1.1245051e-02,\n",
            "        9.2082925e-02,  2.5382251e-01,  6.9522232e-01,  4.1174319e-01,\n",
            "        2.9243284e-01,  3.5138118e-01,  1.0514259e-01,  2.7151108e-01,\n",
            "        1.0162711e+00,  4.7248396e-01, -6.8338281e-01,  2.9067018e+00,\n",
            "       -1.8983507e+00,  7.0919261e+00], dtype=float32), 'agent_1': Array([ 6.1813861e-01,  9.9568069e-01, -3.7633905e-03,  1.1245051e-02,\n",
            "        9.2082925e-02,  2.5382251e-01,  4.1174319e-01, -1.0872991e+00,\n",
            "        2.9243284e-01,  3.5138118e-01,  1.0514259e-01,  2.7151108e-01,\n",
            "        1.0162711e+00,  4.7248396e-01, -6.8338281e-01,  2.9067018e+00,\n",
            "       -1.9492382e+00,  4.5663242e+00], dtype=float32), 'agent_2': Array([ 6.1813861e-01,  9.9568069e-01, -3.7633905e-03,  1.1245051e-02,\n",
            "        9.2082925e-02,  2.5382251e-01,  4.1174319e-01,  2.9243284e-01,\n",
            "       -1.0595063e+00,  3.5138118e-01,  1.0514259e-01,  2.7151108e-01,\n",
            "        1.0162711e+00,  4.7248396e-01, -6.8338281e-01,  2.9067018e+00,\n",
            "       -5.1717863e+00,  5.6874294e+00], dtype=float32), 'agent_3': Array([ 6.1813861e-01,  9.9568069e-01, -3.7633905e-03,  1.1245051e-02,\n",
            "        9.2082925e-02,  2.5382251e-01,  4.1174319e-01,  2.9243284e-01,\n",
            "        3.5138118e-01,  6.7188692e-01,  1.0514259e-01,  2.7151108e-01,\n",
            "        1.0162711e+00,  4.7248396e-01, -6.8338281e-01,  2.9067018e+00,\n",
            "       -5.0822825e+00,  7.0125260e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.148517   0.02745064 1.1464405  0.02868439 1.1462715  0.02551998\n",
            " 1.145801   0.02732757]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.9569607, dtype=float32), 'agent_0': Array(-2.9569607, dtype=float32), 'agent_1': Array(-2.9569607, dtype=float32), 'agent_2': Array(-2.9569607, dtype=float32), 'agent_3': Array(-2.9569607, dtype=float32)}\n",
            "step: 402\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2977535e-01,  9.9988669e-01,  8.0096535e-04,  1.4965022e-02,\n",
            "        1.4415145e-03,  5.7751024e-01,  9.4003248e-01,  5.9575599e-01,\n",
            "        5.1195818e-01,  5.3255844e-01, -2.0484924e-01, -1.2187958e-01,\n",
            "       -2.0684004e-01,  5.7847631e-01, -6.2378265e-02, -2.3652607e-01,\n",
            "        1.8756326e+00,  4.9749055e+00], dtype=float32), 'agent_1': Array([ 6.2977535e-01,  9.9988669e-01,  8.0096535e-04,  1.4965022e-02,\n",
            "        1.4415145e-03,  5.7751024e-01,  5.9575599e-01, -1.0504308e+00,\n",
            "        5.1195818e-01,  5.3255844e-01, -2.0484924e-01, -1.2187958e-01,\n",
            "       -2.0684004e-01,  5.7847631e-01, -6.2378265e-02, -2.3652607e-01,\n",
            "       -1.6366107e+00,  1.8931029e+00], dtype=float32), 'agent_2': Array([ 6.2977535e-01,  9.9988669e-01,  8.0096535e-04,  1.4965022e-02,\n",
            "        1.4415145e-03,  5.7751024e-01,  5.9575599e-01,  5.1195818e-01,\n",
            "       -9.2322689e-01,  5.3255844e-01, -2.0484924e-01, -1.2187958e-01,\n",
            "       -2.0684004e-01,  5.7847631e-01, -6.2378265e-02, -2.3652607e-01,\n",
            "        2.5512037e+00,  3.9563324e+00], dtype=float32), 'agent_3': Array([ 6.2977535e-01,  9.9988669e-01,  8.0096535e-04,  1.4965022e-02,\n",
            "        1.4415145e-03,  5.7751024e-01,  5.9575599e-01,  5.1195818e-01,\n",
            "        5.3255844e-01,  9.6872318e-01, -2.0484924e-01, -1.2187958e-01,\n",
            "       -2.0684004e-01,  5.7847631e-01, -6.2378265e-02, -2.3652607e-01,\n",
            "        4.6595094e-01,  5.9992142e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.141234   0.9250811  0.13625485 0.9280386  0.14366287 0.9211543\n",
            " 0.13985549 0.9253904 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6938889, dtype=float32), 'agent_0': Array(-1.6938889, dtype=float32), 'agent_1': Array(-1.6938889, dtype=float32), 'agent_2': Array(-1.6938889, dtype=float32), 'agent_3': Array(-1.6938889, dtype=float32)}\n",
            "step: 403\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6166528 ,  0.99862397,  0.03521447, -0.02568663,  0.02916189,\n",
            "        0.53392226,  1.3236026 ,  0.4169624 ,  0.5367928 ,  0.5034585 ,\n",
            "       -0.08540154, -0.09403229, -0.38058758,  0.42886403, -0.88596463,\n",
            "        1.5836135 , -1.9745221 ,  0.5427485 ], dtype=float32), 'agent_1': Array([ 0.6166528 ,  0.99862397,  0.03521447, -0.02568663,  0.02916189,\n",
            "        0.53392226,  0.4169624 , -0.615788  ,  0.5367928 ,  0.5034585 ,\n",
            "       -0.08540154, -0.09403229, -0.38058758,  0.42886403, -0.88596463,\n",
            "        1.5836135 , -4.602453  , 10.512209  ], dtype=float32), 'agent_2': Array([ 0.6166528 ,  0.99862397,  0.03521447, -0.02568663,  0.02916189,\n",
            "        0.53392226,  0.4169624 ,  0.5367928 , -0.44352812,  0.5034585 ,\n",
            "       -0.08540154, -0.09403229, -0.38058758,  0.42886403, -0.88596463,\n",
            "        1.5836135 , -0.5213866 ,  5.9018908 ], dtype=float32), 'agent_3': Array([ 0.6166528 ,  0.99862397,  0.03521447, -0.02568663,  0.02916189,\n",
            "        0.53392226,  0.4169624 ,  0.5367928 ,  0.5034585 ,  1.313608  ,\n",
            "       -0.08540154, -0.09403229, -0.38058758,  0.42886403, -0.88596463,\n",
            "        1.5836135 , -0.73015016, -0.44426388], dtype=float32)}\n",
            "ctrl action chosen: [ 2.2646465 -2.0087771  2.264494  -2.0098011  2.26638   -2.0109015\n",
            "  2.2642393 -2.0117962]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.7625332, dtype=float32), 'agent_0': Array(-0.7625332, dtype=float32), 'agent_1': Array(-0.7625332, dtype=float32), 'agent_2': Array(-0.7625332, dtype=float32), 'agent_3': Array(-0.7625332, dtype=float32)}\n",
            "step: 404\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5875432 ,  0.99957913, -0.0104128 ,  0.02400319,  0.01252778,\n",
            "        0.54105157,  0.99309194,  0.46890688,  0.58063775,  0.58250946,\n",
            "       -0.7633686 , -0.12111664, -0.4638791 , -1.4853616 ,  2.4790084 ,\n",
            "       -0.72456247,  0.2328409 , -9.279507  ], dtype=float32), 'agent_1': Array([ 0.5875432 ,  0.99957913, -0.0104128 ,  0.02400319,  0.01252778,\n",
            "        0.54105157,  0.46890688, -0.6888824 ,  0.58063775,  0.58250946,\n",
            "       -0.7633686 , -0.12111664, -0.4638791 , -1.4853616 ,  2.4790084 ,\n",
            "       -0.72456247,  2.8406887 , -4.988507  ], dtype=float32), 'agent_2': Array([ 0.5875432 ,  0.99957913, -0.0104128 ,  0.02400319,  0.01252778,\n",
            "        0.54105157,  0.46890688,  0.58063775, -0.7555111 ,  0.58250946,\n",
            "       -0.7633686 , -0.12111664, -0.4638791 , -1.4853616 ,  2.4790084 ,\n",
            "       -0.72456247, -0.06877599, -7.8351054 ], dtype=float32), 'agent_3': Array([ 0.5875432 ,  0.99957913, -0.0104128 ,  0.02400319,  0.01252778,\n",
            "        0.54105157,  0.46890688,  0.58063775,  0.58250946,  1.0163039 ,\n",
            "       -0.7633686 , -0.12111664, -0.4638791 , -1.4853616 ,  2.4790084 ,\n",
            "       -0.72456247,  0.8361593 , -8.461402  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.27197906  0.89558464 -0.27522185  0.8980028  -0.2707739   0.8944385\n",
            " -0.27291977  0.895768  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-17.970203, dtype=float32), 'agent_0': Array(-17.970203, dtype=float32), 'agent_1': Array(-17.970203, dtype=float32), 'agent_2': Array(-17.970203, dtype=float32), 'agent_3': Array(-17.970203, dtype=float32)}\n",
            "step: 405\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5751077 ,  0.9961481 , -0.01213739,  0.01913949,  0.08470753,\n",
            "        0.340656  ,  0.96587193,  0.37131712,  0.35476306,  0.3952623 ,\n",
            "       -0.1932621 , -0.01688004, -0.56985617,  0.06553398, -1.0396314 ,\n",
            "        4.1869755 , -5.409348  ,  2.9336696 ], dtype=float32), 'agent_1': Array([ 0.5751077 ,  0.9961481 , -0.01213739,  0.01913949,  0.08470753,\n",
            "        0.340656  ,  0.37131712, -0.4802372 ,  0.35476306,  0.3952623 ,\n",
            "       -0.1932621 , -0.01688004, -0.56985617,  0.06553398, -1.0396314 ,\n",
            "        4.1869755 , -2.6696281 ,  3.579152  ], dtype=float32), 'agent_2': Array([ 0.5751077 ,  0.9961481 , -0.01213739,  0.01913949,  0.08470753,\n",
            "        0.340656  ,  0.37131712,  0.35476306, -0.68329644,  0.3952623 ,\n",
            "       -0.1932621 , -0.01688004, -0.56985617,  0.06553398, -1.0396314 ,\n",
            "        4.1869755 , -6.7518997 ,  4.137112  ], dtype=float32), 'agent_3': Array([ 0.5751077 ,  0.9961481 , -0.01213739,  0.01913949,  0.08470753,\n",
            "        0.340656  ,  0.37131712,  0.35476306,  0.3952623 ,  0.99287134,\n",
            "       -0.1932621 , -0.01688004, -0.56985617,  0.06553398, -1.0396314 ,\n",
            "        4.1869755 , -5.8049855 ,  3.1844728 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9201067  -0.41391385 -0.91641265 -0.41056222 -0.92028016 -0.4141655\n",
            " -0.9214371  -0.41413462]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1008683, dtype=float32), 'agent_0': Array(-1.1008683, dtype=float32), 'agent_1': Array(-1.1008683, dtype=float32), 'agent_2': Array(-1.1008683, dtype=float32), 'agent_3': Array(-1.1008683, dtype=float32)}\n",
            "step: 406\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.4785240e-01,  9.3753326e-01, -8.0138836e-03,  5.5633947e-02,\n",
            "        3.4332514e-01, -3.1505775e-01,  8.2455367e-01, -1.8841584e-01,\n",
            "       -3.5913709e-01, -2.9753938e-01, -5.9180260e-01, -6.1502457e-01,\n",
            "        2.8454065e-01,  3.3384165e-01,  1.2386572e+00,  1.2122403e+01,\n",
            "       -1.5513415e+01, -5.1228814e+00], dtype=float32), 'agent_1': Array([ 5.4785240e-01,  9.3753326e-01, -8.0138836e-03,  5.5633947e-02,\n",
            "        3.4332514e-01, -3.1505775e-01, -1.8841584e-01, -6.2240338e-01,\n",
            "       -3.5913709e-01, -2.9753938e-01, -5.9180260e-01, -6.1502457e-01,\n",
            "        2.8454065e-01,  3.3384165e-01,  1.2386572e+00,  1.2122403e+01,\n",
            "       -1.3533338e+01, -3.1836200e+00], dtype=float32), 'agent_2': Array([ 5.4785240e-01,  9.3753326e-01, -8.0138836e-03,  5.5633947e-02,\n",
            "        3.4332514e-01, -3.1505775e-01, -1.8841584e-01, -3.5913709e-01,\n",
            "       -7.8393221e-01, -2.9753938e-01, -5.9180260e-01, -6.1502457e-01,\n",
            "        2.8454065e-01,  3.3384165e-01,  1.2386572e+00,  1.2122403e+01,\n",
            "       -1.6158169e+01, -3.3928609e+00], dtype=float32), 'agent_3': Array([ 5.4785240e-01,  9.3753326e-01, -8.0138836e-03,  5.5633947e-02,\n",
            "        3.4332514e-01, -3.1505775e-01, -1.8841584e-01, -3.5913709e-01,\n",
            "       -2.9753938e-01,  8.4876966e-01, -5.9180260e-01, -6.1502457e-01,\n",
            "        2.8454065e-01,  3.3384165e-01,  1.2386572e+00,  1.2122403e+01,\n",
            "       -1.6078375e+01, -4.9806271e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.3919237   0.78367585 -0.39335212  0.7823549  -0.39198762  0.7831312\n",
            " -0.3929086   0.7840917 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.540313, dtype=float32), 'agent_0': Array(-1.540313, dtype=float32), 'agent_1': Array(-1.540313, dtype=float32), 'agent_2': Array(-1.540313, dtype=float32), 'agent_3': Array(-1.540313, dtype=float32)}\n",
            "step: 407\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5689868 ,  0.911042  , -0.01343182,  0.01161207,  0.41193113,\n",
            "       -0.558324  ,  0.9239316 , -0.39742848, -0.5601629 , -0.5599912 ,\n",
            "       -0.2893448 , -0.7194519 ,  0.12037754, -1.1522589 , -2.1347747 ,\n",
            "       -1.0550138 ,  0.44423535,  5.276858  ], dtype=float32), 'agent_1': Array([ 0.5689868 ,  0.911042  , -0.01343182,  0.01161207,  0.41193113,\n",
            "       -0.558324  , -0.39742848, -0.47075608, -0.5601629 , -0.5599912 ,\n",
            "       -0.2893448 , -0.7194519 ,  0.12037754, -1.1522589 , -2.1347747 ,\n",
            "       -1.0550138 , -0.03292338,  1.414097  ], dtype=float32), 'agent_2': Array([ 0.5689868 ,  0.911042  , -0.01343182,  0.01161207,  0.41193113,\n",
            "       -0.558324  , -0.39742848, -0.5601629 , -0.5532645 , -0.5599912 ,\n",
            "       -0.2893448 , -0.7194519 ,  0.12037754, -1.1522589 , -2.1347747 ,\n",
            "       -1.0550138 ,  1.0253198 ,  7.3412986 ], dtype=float32), 'agent_3': Array([ 0.5689868 ,  0.911042  , -0.01343182,  0.01161207,  0.41193113,\n",
            "       -0.558324  , -0.39742848, -0.5601629 , -0.5599912 ,  0.9742206 ,\n",
            "       -0.2893448 , -0.7194519 ,  0.12037754, -1.1522589 , -2.1347747 ,\n",
            "       -1.0550138 ,  0.38474047,  5.65456   ], dtype=float32)}\n",
            "ctrl action chosen: [1.7489817  0.43705153 1.7494557  0.4314831  1.747266   0.43666434\n",
            " 1.7478615  0.43664062]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.89459527, dtype=float32), 'agent_0': Array(-0.89459527, dtype=float32), 'agent_1': Array(-0.89459527, dtype=float32), 'agent_2': Array(-0.89459527, dtype=float32), 'agent_3': Array(-0.89459527, dtype=float32)}\n",
            "step: 408\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7379162e-01,  9.8706436e-01, -1.2800242e-02, -2.2079211e-02,\n",
            "        1.5828058e-01,  6.0748577e-02,  1.1538000e+00,  2.0892900e-01,\n",
            "        9.8345689e-02,  3.6283679e-02, -4.6248436e-01, -7.4872971e-01,\n",
            "        1.2843609e-01, -4.8923406e-01, -1.1799026e+00, -1.4404875e+01,\n",
            "        1.7320036e+01,  3.9996386e+00], dtype=float32), 'agent_1': Array([ 5.7379162e-01,  9.8706436e-01, -1.2800242e-02, -2.2079211e-02,\n",
            "        1.5828058e-01,  6.0748577e-02,  2.0892900e-01, -4.9992275e-01,\n",
            "        9.8345689e-02,  3.6283679e-02, -4.6248436e-01, -7.4872971e-01,\n",
            "        1.2843609e-01, -4.8923406e-01, -1.1799026e+00, -1.4404875e+01,\n",
            "        1.6214554e+01, -2.0575167e-01], dtype=float32), 'agent_2': Array([ 5.7379162e-01,  9.8706436e-01, -1.2800242e-02, -2.2079211e-02,\n",
            "        1.5828058e-01,  6.0748577e-02,  2.0892900e-01,  9.8345689e-02,\n",
            "       -4.9133486e-01,  3.6283679e-02, -4.6248436e-01, -7.4872971e-01,\n",
            "        1.2843609e-01, -4.8923406e-01, -1.1799026e+00, -1.4404875e+01,\n",
            "        1.8067451e+01, -9.6793048e-02], dtype=float32), 'agent_3': Array([ 5.7379162e-01,  9.8706436e-01, -1.2800242e-02, -2.2079211e-02,\n",
            "        1.5828058e-01,  6.0748577e-02,  2.0892900e-01,  9.8345689e-02,\n",
            "        3.6283679e-02,  1.1991951e+00, -4.6248436e-01, -7.4872971e-01,\n",
            "        1.2843609e-01, -4.8923406e-01, -1.1799026e+00, -1.4404875e+01,\n",
            "        1.6608557e+01,  4.9288063e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.08321175 -1.3903797  -0.08651358 -1.3896327  -0.08719582 -1.3897184\n",
            " -0.08295333 -1.391898  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.9132524, dtype=float32), 'agent_0': Array(-5.9132524, dtype=float32), 'agent_1': Array(-5.9132524, dtype=float32), 'agent_2': Array(-5.9132524, dtype=float32), 'agent_3': Array(-5.9132524, dtype=float32)}\n",
            "step: 409\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5926916 ,  0.9989169 , -0.01793216, -0.00896555,  0.04198826,\n",
            "        0.3513907 ,  0.9690544 ,  0.4551939 ,  0.4098523 ,  0.30331293,\n",
            "       -0.97498894, -0.7027626 ,  0.08398294, -0.5663682 ,  1.4289418 ,\n",
            "       -2.1453478 ,  2.343655  , -6.2897577 ], dtype=float32), 'agent_1': Array([ 5.9269160e-01,  9.9891692e-01, -1.7932156e-02, -8.9655546e-03,\n",
            "        4.1988265e-02,  3.5139069e-01,  4.5519391e-01, -8.6303401e-01,\n",
            "        4.0985230e-01,  3.0331293e-01, -9.7498894e-01, -7.0276260e-01,\n",
            "        8.3982944e-02, -5.6636822e-01,  1.4289418e+00, -2.1453478e+00,\n",
            "        1.7241331e+00, -1.0829260e+01], dtype=float32), 'agent_2': Array([ 0.5926916 ,  0.9989169 , -0.01793216, -0.00896555,  0.04198826,\n",
            "        0.3513907 ,  0.4551939 ,  0.4098523 , -0.7560289 ,  0.30331293,\n",
            "       -0.97498894, -0.7027626 ,  0.08398294, -0.5663682 ,  1.4289418 ,\n",
            "       -2.1453478 ,  2.7998953 , -8.393122  ], dtype=float32), 'agent_3': Array([ 0.5926916 ,  0.9989169 , -0.01793216, -0.00896555,  0.04198826,\n",
            "        0.3513907 ,  0.4551939 ,  0.4098523 ,  0.30331293,  1.0757266 ,\n",
            "       -0.97498894, -0.7027626 ,  0.08398294, -0.5663682 ,  1.4289418 ,\n",
            "       -2.1453478 ,  2.2999153 , -5.2040663 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5236568   0.8282479  -0.52245486  0.8295286  -0.5206166   0.8269019\n",
            " -0.5243839   0.82900035]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6926947, dtype=float32), 'agent_0': Array(-3.6926947, dtype=float32), 'agent_1': Array(-3.6926947, dtype=float32), 'agent_2': Array(-3.6926947, dtype=float32), 'agent_3': Array(-3.6926947, dtype=float32)}\n",
            "step: 410\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.58108157,  0.98881084, -0.01158332, -0.03851775,  0.14365003,\n",
            "        0.08762993,  1.0740964 ,  0.14854075,  0.17194426,  0.03053968,\n",
            "       -0.18577576, -0.2278328 ,  0.06188154,  0.4732021 , -1.8766669 ,\n",
            "        6.093658  , -7.8864765 ,  4.545664  ], dtype=float32), 'agent_1': Array([ 0.58108157,  0.98881084, -0.01158332, -0.03851775,  0.14365003,\n",
            "        0.08762993,  0.14854075, -0.92125654,  0.17194426,  0.03053968,\n",
            "       -0.18577576, -0.2278328 ,  0.06188154,  0.4732021 , -1.8766669 ,\n",
            "        6.093658  , -8.887737  ,  2.5990307 ], dtype=float32), 'agent_2': Array([ 0.58108157,  0.98881084, -0.01158332, -0.03851775,  0.14365003,\n",
            "        0.08762993,  0.14854075,  0.17194426, -0.7783084 ,  0.03053968,\n",
            "       -0.18577576, -0.2278328 ,  0.06188154,  0.4732021 , -1.8766669 ,\n",
            "        6.093658  , -7.569499  ,  2.4530666 ], dtype=float32), 'agent_3': Array([ 0.58108157,  0.98881084, -0.01158332, -0.03851775,  0.14365003,\n",
            "        0.08762993,  0.14854075,  0.17194426,  0.03053968,  1.2167288 ,\n",
            "       -0.18577576, -0.2278328 ,  0.06188154,  0.4732021 , -1.8766669 ,\n",
            "        6.093658  , -7.9040074 ,  4.3327465 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.11554318 -0.0430693  -0.11945114 -0.04320421 -0.11773507 -0.0454647\n",
            " -0.1169504  -0.044111  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4578172, dtype=float32), 'agent_0': Array(-1.4578172, dtype=float32), 'agent_1': Array(-1.4578172, dtype=float32), 'agent_2': Array(-1.4578172, dtype=float32), 'agent_3': Array(-1.4578172, dtype=float32)}\n",
            "step: 411\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.59487164,  0.97523814,  0.00398035, -0.04040885,  0.21739802,\n",
            "       -0.11136603,  1.1286329 , -0.12025669, -0.03915583, -0.20591578,\n",
            "        0.01213551, -0.6632805 ,  0.08177757,  0.60519606, -0.3063436 ,\n",
            "        2.7013285 , -3.4191337 ,  0.99966556], dtype=float32), 'agent_1': Array([ 5.9487164e-01,  9.7523814e-01,  3.9803465e-03, -4.0408853e-02,\n",
            "        2.1739802e-01, -1.1136603e-01, -1.2025669e-01, -9.5752716e-01,\n",
            "       -3.9155830e-02, -2.0591578e-01,  1.2135506e-02, -6.6328049e-01,\n",
            "        8.1777573e-02,  6.0519606e-01, -3.0634359e-01,  2.7013285e+00,\n",
            "       -4.5405917e+00, -3.6623517e-01], dtype=float32), 'agent_2': Array([ 0.59487164,  0.97523814,  0.00398035, -0.04040885,  0.21739802,\n",
            "       -0.11136603, -0.12025669, -0.03915583, -0.79485136, -0.20591578,\n",
            "        0.01213551, -0.6632805 ,  0.08177757,  0.60519606, -0.3063436 ,\n",
            "        2.7013285 , -3.742824  , -0.5455113 ], dtype=float32), 'agent_3': Array([ 5.9487164e-01,  9.7523814e-01,  3.9803465e-03, -4.0408853e-02,\n",
            "        2.1739802e-01, -1.1136603e-01, -1.2025669e-01, -3.9155830e-02,\n",
            "       -2.0591578e-01,  1.2017349e+00,  1.2135506e-02, -6.6328049e-01,\n",
            "        8.1777573e-02,  6.0519606e-01, -3.0634359e-01,  2.7013285e+00,\n",
            "       -4.1818042e+00,  2.1379395e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.9799692  -0.73941505  0.977668   -0.7397367   0.97924757 -0.74273473\n",
            "  0.9780332  -0.7413362 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.9529781, dtype=float32), 'agent_0': Array(0.9529781, dtype=float32), 'agent_1': Array(0.9529781, dtype=float32), 'agent_2': Array(0.9529781, dtype=float32), 'agent_3': Array(0.9529781, dtype=float32)}\n",
            "step: 412\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8610815e-01,  9.9945313e-01,  2.2843821e-02, -2.3330262e-02,\n",
            "        5.2193711e-03,  3.9172423e-01,  1.0028492e+00,  3.4834009e-01,\n",
            "        4.6817487e-01,  2.8921887e-01, -1.6150475e-01, -6.1597824e-01,\n",
            "       -3.9367676e-01,  4.3523610e-01,  1.0685033e+00, -1.2166951e+01,\n",
            "        1.4478262e+01, -4.3854194e+00], dtype=float32), 'agent_1': Array([ 5.8610815e-01,  9.9945313e-01,  2.2843821e-02, -2.3330262e-02,\n",
            "        5.2193711e-03,  3.9172423e-01,  3.4834009e-01, -1.1279256e+00,\n",
            "        4.6817487e-01,  2.8921887e-01, -1.6150475e-01, -6.1597824e-01,\n",
            "       -3.9367676e-01,  4.3523610e-01,  1.0685033e+00, -1.2166951e+01,\n",
            "        1.3954434e+01, -5.2298040e+00], dtype=float32), 'agent_2': Array([ 5.8610815e-01,  9.9945313e-01,  2.2843821e-02, -2.3330262e-02,\n",
            "        5.2193711e-03,  3.9172423e-01,  3.4834009e-01,  4.6817487e-01,\n",
            "       -9.7371441e-01,  2.8921887e-01, -1.6150475e-01, -6.1597824e-01,\n",
            "       -3.9367676e-01,  4.3523610e-01,  1.0685033e+00, -1.2166951e+01,\n",
            "        1.4833908e+01, -4.4658117e+00], dtype=float32), 'agent_3': Array([ 5.8610815e-01,  9.9945313e-01,  2.2843821e-02, -2.3330262e-02,\n",
            "        5.2193711e-03,  3.9172423e-01,  3.4834009e-01,  4.6817487e-01,\n",
            "        2.8921887e-01,  1.0500655e+00, -1.6150475e-01, -6.1597824e-01,\n",
            "       -3.9367676e-01,  4.3523610e-01,  1.0685033e+00, -1.2166951e+01,\n",
            "        1.4706592e+01, -4.9113803e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.15633167 1.1197504  0.1539044  1.120357   0.15748976 1.1199329\n",
            " 0.15580669 1.1193826 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.108009, dtype=float32), 'agent_0': Array(-2.108009, dtype=float32), 'agent_1': Array(-2.108009, dtype=float32), 'agent_2': Array(-2.108009, dtype=float32), 'agent_3': Array(-2.108009, dtype=float32)}\n",
            "step: 413\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5881912 ,  0.9957083 ,  0.05395521, -0.04632331, -0.05922947,\n",
            "        0.5442335 ,  1.1777024 ,  0.52704406,  0.5602475 ,  0.4948905 ,\n",
            "        0.9202957 , -0.56734085,  0.31229258,  1.2391298 , -1.6194435 ,\n",
            "        0.18446791, -0.7136257 ,  5.7105937 ], dtype=float32), 'agent_1': Array([ 0.5881912 ,  0.9957083 ,  0.05395521, -0.04632331, -0.05922947,\n",
            "        0.5442335 ,  0.52704406, -0.9466705 ,  0.5602475 ,  0.4948905 ,\n",
            "        0.9202957 , -0.56734085,  0.31229258,  1.2391298 , -1.6194435 ,\n",
            "        0.18446791,  0.5138094 ,  6.700167  ], dtype=float32), 'agent_2': Array([ 0.5881912 ,  0.9957083 ,  0.05395521, -0.04632331, -0.05922947,\n",
            "        0.5442335 ,  0.52704406,  0.5602475 , -0.72729695,  0.4948905 ,\n",
            "        0.9202957 , -0.56734085,  0.31229258,  1.2391298 , -1.6194435 ,\n",
            "        0.18446791, -1.9362403 ,  7.0444174 ], dtype=float32), 'agent_3': Array([ 0.5881912 ,  0.9957083 ,  0.05395521, -0.04632331, -0.05922947,\n",
            "        0.5442335 ,  0.52704406,  0.5602475 ,  0.4948905 ,  1.1987281 ,\n",
            "        0.9202957 , -0.56734085,  0.31229258,  1.2391298 , -1.6194435 ,\n",
            "        0.18446791,  1.0736336 ,  5.633173  ], dtype=float32)}\n",
            "ctrl action chosen: [0.12065629 1.6970204  0.12061511 1.6988511  0.11952736 1.6936496\n",
            " 0.12101854 1.697124  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.076052, dtype=float32), 'agent_0': Array(-1.076052, dtype=float32), 'agent_1': Array(-1.076052, dtype=float32), 'agent_2': Array(-1.076052, dtype=float32), 'agent_3': Array(-1.076052, dtype=float32)}\n",
            "step: 414\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5859141 ,  0.993116  ,  0.06842288, -0.07924029, -0.05253505,\n",
            "        0.51149577,  1.2876477 ,  0.5289448 ,  0.43572795,  0.52534646,\n",
            "        0.60129166, -0.76732635, -0.59012175, -0.31468084, -0.83328736,\n",
            "        0.21954855, -0.38527218,  0.06028516], dtype=float32), 'agent_1': Array([ 0.5859141 ,  0.993116  ,  0.06842288, -0.07924029, -0.05253505,\n",
            "        0.51149577,  0.5289448 , -0.5034828 ,  0.43572795,  0.52534646,\n",
            "        0.60129166, -0.76732635, -0.59012175, -0.31468084, -0.83328736,\n",
            "        0.21954855, -0.14350514,  9.46448   ], dtype=float32), 'agent_2': Array([ 0.5859141 ,  0.993116  ,  0.06842288, -0.07924029, -0.05253505,\n",
            "        0.51149577,  0.5289448 ,  0.43572795, -0.4451302 ,  0.52534646,\n",
            "        0.60129166, -0.76732635, -0.59012175, -0.31468084, -0.83328736,\n",
            "        0.21954855, -2.0260062 , -0.2985146 ], dtype=float32), 'agent_3': Array([ 0.5859141 ,  0.993116  ,  0.06842288, -0.07924029, -0.05253505,\n",
            "        0.51149577,  0.5289448 ,  0.43572795,  0.52534646,  1.2925231 ,\n",
            "        0.60129166, -0.76732635, -0.59012175, -0.31468084, -0.83328736,\n",
            "        0.21954855,  0.89184207,  0.16162476], dtype=float32)}\n",
            "ctrl action chosen: [-1.3582138  -0.08545037 -1.3605657  -0.08476191 -1.359388   -0.08841223\n",
            " -1.3569406  -0.0869537 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.0198655, dtype=float32), 'agent_0': Array(-4.0198655, dtype=float32), 'agent_1': Array(-4.0198655, dtype=float32), 'agent_2': Array(-4.0198655, dtype=float32), 'agent_3': Array(-4.0198655, dtype=float32)}\n",
            "step: 415\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5133635e-01,  9.7993314e-01,  4.5822974e-02, -7.7891856e-02,\n",
            "        1.7766336e-01, -7.6199174e-02,  1.1960585e+00, -4.3158751e-02,\n",
            "       -2.0692179e-01,  1.1577163e-02,  4.8146248e-01, -7.5864792e-01,\n",
            "       -5.3902864e-01,  1.3919301e-01,  9.6750194e-03,  1.2022718e+01,\n",
            "       -1.5436218e+01, -1.3841789e+00], dtype=float32), 'agent_1': Array([ 5.5133635e-01,  9.7993314e-01,  4.5822974e-02, -7.7891856e-02,\n",
            "        1.7766336e-01, -7.6199174e-02, -4.3158751e-02, -4.8878530e-01,\n",
            "       -2.0692179e-01,  1.1577163e-02,  4.8146248e-01, -7.5864792e-01,\n",
            "       -5.3902864e-01,  1.3919301e-01,  9.6750194e-03,  1.2022718e+01,\n",
            "       -1.5231400e+01,  2.6576003e-01], dtype=float32), 'agent_2': Array([ 5.5133635e-01,  9.7993314e-01,  4.5822974e-02, -7.7891856e-02,\n",
            "        1.7766336e-01, -7.6199174e-02, -4.3158751e-02, -2.0692179e-01,\n",
            "       -5.1107818e-01,  1.1577163e-02,  4.8146248e-01, -7.5864792e-01,\n",
            "       -5.3902864e-01,  1.3919301e-01,  9.6750194e-03,  1.2022718e+01,\n",
            "       -1.6259426e+01, -1.3655336e-01], dtype=float32), 'agent_3': Array([ 5.5133635e-01,  9.7993314e-01,  4.5822974e-02, -7.7891856e-02,\n",
            "        1.7766336e-01, -7.6199174e-02, -4.3158751e-02, -2.0692179e-01,\n",
            "        1.1577163e-02,  1.1909171e+00,  4.8146248e-01, -7.5864792e-01,\n",
            "       -5.3902864e-01,  1.3919301e-01,  9.6750194e-03,  1.2022718e+01,\n",
            "       -1.3776740e+01, -2.3942661e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.2230328  1.8994629 -1.2230407  1.8992045 -1.222927   1.8989514\n",
            " -1.225641   1.8991095]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3039145, dtype=float32), 'agent_0': Array(-2.3039145, dtype=float32), 'agent_1': Array(-2.3039145, dtype=float32), 'agent_2': Array(-2.3039145, dtype=float32), 'agent_3': Array(-2.3039145, dtype=float32)}\n",
            "step: 416\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5266516 ,  0.92875606,  0.02943679, -0.09144697,  0.35802665,\n",
            "       -0.5824288 ,  1.2521259 , -0.5620471 , -0.62303567, -0.5058459 ,\n",
            "        0.12145042, -0.5311966 , -0.36644936,  0.25962052,  0.8985107 ,\n",
            "       -0.47707248,  0.12132946, -0.40553   ], dtype=float32), 'agent_1': Array([ 0.5266516 ,  0.92875606,  0.02943679, -0.09144697,  0.35802665,\n",
            "       -0.5824288 , -0.5620471 , -0.48968768, -0.62303567, -0.5058459 ,\n",
            "        0.12145042, -0.5311966 , -0.36644936,  0.25962052,  0.8985107 ,\n",
            "       -0.47707248, -0.579555  , -1.4374696 ], dtype=float32), 'agent_2': Array([ 0.5266516 ,  0.92875606,  0.02943679, -0.09144697,  0.35802665,\n",
            "       -0.5824288 , -0.5620471 , -0.62303567, -0.48699558, -0.5058459 ,\n",
            "        0.12145042, -0.5311966 , -0.36644936,  0.25962052,  0.8985107 ,\n",
            "       -0.47707248,  2.8269827 , -1.1155565 ], dtype=float32), 'agent_3': Array([ 0.5266516 ,  0.92875606,  0.02943679, -0.09144697,  0.35802665,\n",
            "       -0.5824288 , -0.5620471 , -0.62303567, -0.5058459 ,  1.243905  ,\n",
            "        0.12145042, -0.5311966 , -0.36644936,  0.25962052,  0.8985107 ,\n",
            "       -0.47707248, -3.0512536 ,  0.15735693], dtype=float32)}\n",
            "ctrl action chosen: [1.5801336 2.0330756 1.5753046 2.030439  1.5802525 2.0309334 1.5707041\n",
            " 2.035126 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-8.760818, dtype=float32), 'agent_0': Array(-8.760818, dtype=float32), 'agent_1': Array(-8.760818, dtype=float32), 'agent_2': Array(-8.760818, dtype=float32), 'agent_3': Array(-8.760818, dtype=float32)}\n",
            "step: 417\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.51739067,   0.98704344,   0.04330905,  -0.07904273,\n",
            "         0.13274778,  -0.03488883,   1.2743547 ,  -0.03680114,\n",
            "         0.06859762,  -0.03885455,   0.1229763 ,   0.40712357,\n",
            "         0.3588438 ,  -0.3481338 ,  -0.66725314, -13.16764   ,\n",
            "        16.306126  ,   0.45725322], dtype=float32), 'agent_1': Array([  0.51739067,   0.98704344,   0.04330905,  -0.07904273,\n",
            "         0.13274778,  -0.03488883,  -0.03680114,  -0.5069376 ,\n",
            "         0.06859762,  -0.03885455,   0.1229763 ,   0.40712357,\n",
            "         0.3588438 ,  -0.3481338 ,  -0.66725314, -13.16764   ,\n",
            "        15.51564   ,   0.87652624], dtype=float32), 'agent_2': Array([  0.51739067,   0.98704344,   0.04330905,  -0.07904273,\n",
            "         0.13274778,  -0.03488883,  -0.03680114,   0.06859762,\n",
            "        -0.4813728 ,  -0.03885455,   0.1229763 ,   0.40712357,\n",
            "         0.3588438 ,  -0.3481338 ,  -0.66725314, -13.16764   ,\n",
            "        19.750072  ,   0.5071746 ], dtype=float32), 'agent_3': Array([  0.51739067,   0.98704344,   0.04330905,  -0.07904273,\n",
            "         0.13274778,  -0.03488883,  -0.03680114,   0.06859762,\n",
            "        -0.03885455,   1.2866408 ,   0.1229763 ,   0.40712357,\n",
            "         0.3588438 ,  -0.3481338 ,  -0.66725314, -13.16764   ,\n",
            "        14.599521  ,   1.0179343 ], dtype=float32)}\n",
            "ctrl action chosen: [0.83784795 0.34624287 0.8378254  0.34626395 0.8354385  0.344896\n",
            " 0.8391232  0.34550804]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.034734, dtype=float32), 'agent_0': Array(-12.034734, dtype=float32), 'agent_1': Array(-12.034734, dtype=float32), 'agent_2': Array(-12.034734, dtype=float32), 'agent_3': Array(-12.034734, dtype=float32)}\n",
            "step: 418\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.53701526,  0.9910123 ,  0.06500649, -0.08305699, -0.08228289,\n",
            "        0.5441667 ,  1.2426248 ,  0.52551746,  0.653375  ,  0.53743917,\n",
            "        0.3911972 ,  0.8459091 ,  0.43679476,  0.5511421 , -1.0752665 ,\n",
            "        0.03005143,  1.7546473 , -0.37909415], dtype=float32), 'agent_1': Array([ 0.53701526,  0.9910123 ,  0.06500649, -0.08305699, -0.08228289,\n",
            "        0.5441667 ,  0.52551746, -0.4942792 ,  0.653375  ,  0.53743917,\n",
            "        0.3911972 ,  0.8459091 ,  0.43679476,  0.5511421 , -1.0752665 ,\n",
            "        0.03005143,  2.1560524 ,  0.6215346 ], dtype=float32), 'agent_2': Array([ 0.53701526,  0.9910123 ,  0.06500649, -0.08305699, -0.08228289,\n",
            "        0.5441667 ,  0.52551746,  0.653375  , -0.50175214,  0.53743917,\n",
            "        0.3911972 ,  0.8459091 ,  0.43679476,  0.5511421 , -1.0752665 ,\n",
            "        0.03005143, -2.2537916 , -0.24425817], dtype=float32), 'agent_3': Array([ 0.53701526,  0.9910123 ,  0.06500649, -0.08305699, -0.08228289,\n",
            "        0.5441667 ,  0.52551746,  0.653375  ,  0.53743917,  1.228523  ,\n",
            "        0.3911972 ,  0.8459091 ,  0.43679476,  0.5511421 , -1.0752665 ,\n",
            "        0.03005143,  2.7764504 , -0.40322703], dtype=float32)}\n",
            "ctrl action chosen: [-1.0408027   0.6417462  -1.0411289   0.64360857 -1.047584    0.6417471\n",
            " -1.0404779   0.6409062 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6897048, dtype=float32), 'agent_0': Array(-0.6897048, dtype=float32), 'agent_1': Array(-0.6897048, dtype=float32), 'agent_2': Array(-0.6897048, dtype=float32), 'agent_3': Array(-0.6897048, dtype=float32)}\n",
            "step: 419\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5618721 ,   0.98076993,   0.0454493 ,  -0.12309618,\n",
            "         0.14447154,   0.06510789,   1.2392648 ,   0.03768426,\n",
            "         0.03535087,   0.08818747,   0.540781  ,   0.9495735 ,\n",
            "         0.82736015,  -0.40741825,  -0.49423462,  13.546459  ,\n",
            "       -14.997113  ,  -0.54788643], dtype=float32), 'agent_1': Array([  0.5618721 ,   0.98076993,   0.0454493 ,  -0.12309618,\n",
            "         0.14447154,   0.06510789,   0.03768426,  -0.49198666,\n",
            "         0.03535087,   0.08818747,   0.540781  ,   0.9495735 ,\n",
            "         0.82736015,  -0.40741825,  -0.49423462,  13.546459  ,\n",
            "       -14.923798  ,  -0.61352915], dtype=float32), 'agent_2': Array([  0.5618721 ,   0.98076993,   0.0454493 ,  -0.12309618,\n",
            "         0.14447154,   0.06510789,   0.03768426,   0.03535087,\n",
            "        -0.49629354,   0.08818747,   0.540781  ,   0.9495735 ,\n",
            "         0.82736015,  -0.40741825,  -0.49423462,  13.546459  ,\n",
            "       -19.289062  ,  -0.37744114], dtype=float32), 'agent_3': Array([  0.5618721 ,   0.98076993,   0.0454493 ,  -0.12309618,\n",
            "         0.14447154,   0.06510789,   0.03768426,   0.03535087,\n",
            "         0.08818747,   1.2430549 ,   0.540781  ,   0.9495735 ,\n",
            "         0.82736015,  -0.40741825,  -0.49423462,  13.546459  ,\n",
            "       -14.419421  ,   0.0607898 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.2724839   1.3615191  -0.27360782  1.3619115  -0.27173063  1.3617313\n",
            " -0.2734457   1.3605785 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4764464, dtype=float32), 'agent_0': Array(-1.4764464, dtype=float32), 'agent_1': Array(-1.4764464, dtype=float32), 'agent_2': Array(-1.4764464, dtype=float32), 'agent_3': Array(-1.4764464, dtype=float32)}\n",
            "step: 420\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5836061 ,  0.9281118 ,  0.00957234, -0.14967811,  0.34075415,\n",
            "       -0.38361204,  1.2575384 , -0.39799625, -0.567274  , -0.34607342,\n",
            "        0.4002571 ,  1.0679245 ,  0.10178089, -0.45297432, -0.65863085,\n",
            "        5.4380746 , -5.7531137 ,  0.5100859 ], dtype=float32), 'agent_1': Array([ 0.5836061 ,  0.9281118 ,  0.00957234, -0.14967811,  0.34075415,\n",
            "       -0.38361204, -0.39799625, -0.4934941 , -0.567274  , -0.34607342,\n",
            "        0.4002571 ,  1.0679245 ,  0.10178089, -0.45297432, -0.65863085,\n",
            "        5.4380746 , -5.5039907 , -0.13746715], dtype=float32), 'agent_2': Array([ 0.5836061 ,  0.9281118 ,  0.00957234, -0.14967811,  0.34075415,\n",
            "       -0.38361204, -0.39799625, -0.567274  , -0.4763148 , -0.34607342,\n",
            "        0.4002571 ,  1.0679245 ,  0.10178089, -0.45297432, -0.65863085,\n",
            "        5.4380746 , -7.064971  ,  0.30186516], dtype=float32), 'agent_3': Array([ 0.5836061 ,  0.9281118 ,  0.00957234, -0.14967811,  0.34075415,\n",
            "       -0.38361204, -0.39799625, -0.567274  , -0.34607342,  1.2664506 ,\n",
            "        0.4002571 ,  1.0679245 ,  0.10178089, -0.45297432, -0.65863085,\n",
            "        5.4380746 , -5.5781083 , -0.07966772], dtype=float32)}\n",
            "ctrl action chosen: [2.0433285  0.5616203  2.0392303  0.5615424  2.0389032  0.5632027\n",
            " 2.0395477  0.56084937]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.3685815, dtype=float32), 'agent_0': Array(-2.3685815, dtype=float32), 'agent_1': Array(-2.3685815, dtype=float32), 'agent_2': Array(-2.3685815, dtype=float32), 'agent_3': Array(-2.3685815, dtype=float32)}\n",
            "step: 421\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.57884824,   0.9716986 ,   0.03207891,  -0.1598014 ,\n",
            "         0.1709863 ,   0.10037731,   1.2547228 ,   0.09638463,\n",
            "        -0.15790114,   0.14525145,   0.4122734 ,   1.2500763 ,\n",
            "        -0.10164976,  -0.15042953,  -0.69330937, -11.114352  ,\n",
            "        14.785111  ,   0.03375354], dtype=float32), 'agent_1': Array([  0.57884824,   0.9716986 ,   0.03207891,  -0.1598014 ,\n",
            "         0.1709863 ,   0.10037731,   0.09638463,  -0.49910516,\n",
            "        -0.15790114,   0.14525145,   0.4122734 ,   1.2500763 ,\n",
            "        -0.10164976,  -0.15042953,  -0.69330937, -11.114352  ,\n",
            "        15.089953  ,   0.481606  ], dtype=float32), 'agent_2': Array([  0.57884824,   0.9716986 ,   0.03207891,  -0.1598014 ,\n",
            "         0.1709863 ,   0.10037731,   0.09638463,  -0.15790114,\n",
            "        -0.49817836,   0.14525145,   0.4122734 ,   1.2500763 ,\n",
            "        -0.10164976,  -0.15042953,  -0.69330937, -11.114352  ,\n",
            "        13.848971  ,   0.44120124], dtype=float32), 'agent_3': Array([  0.57884824,   0.9716986 ,   0.03207891,  -0.1598014 ,\n",
            "         0.1709863 ,   0.10037731,   0.09638463,  -0.15790114,\n",
            "         0.14525145,   1.2412952 ,   0.4122734 ,   1.2500763 ,\n",
            "        -0.10164976,  -0.15042953,  -0.69330937, -11.114352  ,\n",
            "        14.934185  ,  -0.05962643], dtype=float32)}\n",
            "ctrl action chosen: [-1.130962    0.98279303 -1.1321402   0.9831788  -1.1311834   0.9831903\n",
            " -1.1320019   0.98300815]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.634506, dtype=float32), 'agent_0': Array(-7.634506, dtype=float32), 'agent_1': Array(-7.634506, dtype=float32), 'agent_2': Array(-7.634506, dtype=float32), 'agent_3': Array(-7.634506, dtype=float32)}\n",
            "step: 422\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8747470e-01,  9.3600768e-01, -1.1775997e-03, -1.7258826e-01,\n",
            "        3.0675998e-01, -1.7481768e-01,  1.2546663e+00, -1.6527256e-01,\n",
            "       -4.2620456e-01, -1.2736210e-01,  5.8617592e-01,  8.4295273e-01,\n",
            "        1.5927553e-01, -4.3636876e-01,  2.5487852e-01,  1.0485305e+01,\n",
            "       -1.1710554e+01, -4.5760259e-01], dtype=float32), 'agent_1': Array([ 5.8747470e-01,  9.3600768e-01, -1.1775997e-03, -1.7258826e-01,\n",
            "        3.0675998e-01, -1.7481768e-01, -1.6527256e-01, -4.6470043e-01,\n",
            "       -4.2620456e-01, -1.2736210e-01,  5.8617592e-01,  8.4295273e-01,\n",
            "        1.5927553e-01, -4.3636876e-01,  2.5487852e-01,  1.0485305e+01,\n",
            "       -1.1800378e+01,  1.2786195e-01], dtype=float32), 'agent_2': Array([ 5.8747470e-01,  9.3600768e-01, -1.1775997e-03, -1.7258826e-01,\n",
            "        3.0675998e-01, -1.7481768e-01, -1.6527256e-01, -4.2620456e-01,\n",
            "       -4.7692510e-01, -1.2736210e-01,  5.8617592e-01,  8.4295273e-01,\n",
            "        1.5927553e-01, -4.3636876e-01,  2.5487852e-01,  1.0485305e+01,\n",
            "       -1.1786763e+01, -1.4091559e-01], dtype=float32), 'agent_3': Array([ 5.8747470e-01,  9.3600768e-01, -1.1775997e-03, -1.7258826e-01,\n",
            "        3.0675998e-01, -1.7481768e-01, -1.6527256e-01, -4.2620456e-01,\n",
            "       -1.2736210e-01,  1.2608811e+00,  5.8617592e-01,  8.4295273e-01,\n",
            "        1.5927553e-01, -4.3636876e-01,  2.5487852e-01,  1.0485305e+01,\n",
            "       -1.1600678e+01, -2.0118067e-02], dtype=float32)}\n",
            "ctrl action chosen: [-1.0828503  2.0045846 -1.0844554  2.004956  -1.0847089  2.0048232\n",
            " -1.0845762  2.0040832]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.7714477, dtype=float32), 'agent_0': Array(-2.7714477, dtype=float32), 'agent_1': Array(-2.7714477, dtype=float32), 'agent_2': Array(-2.7714477, dtype=float32), 'agent_3': Array(-2.7714477, dtype=float32)}\n",
            "step: 423\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5934978 ,  0.8783547 , -0.0320448 , -0.16632962,  0.4469906 ,\n",
            "       -0.56414276,  1.2589635 , -0.5737096 , -0.5881409 , -0.54428   ,\n",
            "        0.02179146,  1.4010429 ,  0.03225803,  0.09126841,  0.19862683,\n",
            "        0.08965615, -0.42935652,  0.4261752 ], dtype=float32), 'agent_1': Array([ 0.5934978 ,  0.8783547 , -0.0320448 , -0.16632962,  0.4469906 ,\n",
            "       -0.56414276, -0.5737096 , -0.47248906, -0.5881409 , -0.54428   ,\n",
            "        0.02179146,  1.4010429 ,  0.03225803,  0.09126841,  0.19862683,\n",
            "        0.08965615, -0.19746186, -0.28526628], dtype=float32), 'agent_2': Array([ 0.5934978 ,  0.8783547 , -0.0320448 , -0.16632962,  0.4469906 ,\n",
            "       -0.56414276, -0.5737096 , -0.5881409 , -0.488638  , -0.54428   ,\n",
            "        0.02179146,  1.4010429 ,  0.03225803,  0.09126841,  0.19862683,\n",
            "        0.08965615,  4.4191084 , -0.32015654], dtype=float32), 'agent_3': Array([ 0.5934978 ,  0.8783547 , -0.0320448 , -0.16632962,  0.4469906 ,\n",
            "       -0.56414276, -0.5737096 , -0.5881409 , -0.54428   ,  1.2579651 ,\n",
            "        0.02179146,  1.4010429 ,  0.03225803,  0.09126841,  0.19862683,\n",
            "        0.08965615, -1.7082609 ,  0.0518213 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5343727  -1.4038234  -0.537153   -1.4073737  -0.53510815 -1.4076712\n",
            " -0.5399313  -1.4038843 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.087154, dtype=float32), 'agent_0': Array(-9.087154, dtype=float32), 'agent_1': Array(-9.087154, dtype=float32), 'agent_2': Array(-9.087154, dtype=float32), 'agent_3': Array(-9.087154, dtype=float32)}\n",
            "step: 424\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6039522 ,  0.8912496 , -0.02123518, -0.09982172,  0.441881  ,\n",
            "       -0.53831697,  0.96372634, -0.5266161 , -0.3409204 , -0.550583  ,\n",
            "       -0.3432274 ,  0.81243515,  0.22245646,  1.8605332 ,  2.908985  ,\n",
            "       -0.03762716,  0.43963477, -8.22396   ], dtype=float32), 'agent_1': Array([ 0.6039522 ,  0.8912496 , -0.02123518, -0.09982172,  0.441881  ,\n",
            "       -0.53831697, -0.5266161 , -0.77729124, -0.3409204 , -0.550583  ,\n",
            "       -0.3432274 ,  0.81243515,  0.22245646,  1.8605332 ,  2.908985  ,\n",
            "       -0.03762716,  0.45513543, -7.8409815 ], dtype=float32), 'agent_2': Array([ 0.6039522 ,  0.8912496 , -0.02123518, -0.09982172,  0.441881  ,\n",
            "       -0.53831697, -0.5266161 , -0.3409204 , -0.8410472 , -0.550583  ,\n",
            "       -0.3432274 ,  0.81243515,  0.22245646,  1.8605332 ,  2.908985  ,\n",
            "       -0.03762716,  4.3038263 , -9.120475  ], dtype=float32), 'agent_3': Array([ 0.6039522 ,  0.8912496 , -0.02123518, -0.09982172,  0.441881  ,\n",
            "       -0.53831697, -0.5266161 , -0.3409204 , -0.550583  ,  0.91735834,\n",
            "       -0.3432274 ,  0.81243515,  0.22245646,  1.8605332 ,  2.908985  ,\n",
            "       -0.03762716,  0.227019  , -9.4244795 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.4592932   0.6609242  -1.46082     0.6614771  -1.4625785   0.66252685\n",
            " -1.4603732   0.66093445]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.7802014, dtype=float32), 'agent_0': Array(-3.7802014, dtype=float32), 'agent_1': Array(-3.7802014, dtype=float32), 'agent_2': Array(-3.7802014, dtype=float32), 'agent_3': Array(-3.7802014, dtype=float32)}\n",
            "step: 425\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.60646826,  0.87861323, -0.01763452, -0.07845584,  0.47071502,\n",
            "       -0.5578252 ,  0.9293748 , -0.5713715 , -0.34143358, -0.573412  ,\n",
            "        0.45528412,  1.040268  , -0.04947186,  0.36402455, -0.02727552,\n",
            "        1.3512133 , -0.09521993,  1.5100629 ], dtype=float32), 'agent_1': Array([ 0.60646826,  0.87861323, -0.01763452, -0.07845584,  0.47071502,\n",
            "       -0.5578252 , -0.5713715 , -0.7299731 , -0.34143358, -0.573412  ,\n",
            "        0.45528412,  1.040268  , -0.04947186,  0.36402455, -0.02727552,\n",
            "        1.3512133 , -0.42144665,  3.7672172 ], dtype=float32), 'agent_2': Array([ 0.60646826,  0.87861323, -0.01763452, -0.07845584,  0.47071502,\n",
            "       -0.5578252 , -0.5713715 , -0.34143358, -0.9033717 , -0.573412  ,\n",
            "        0.45528412,  1.040268  , -0.04947186,  0.36402455, -0.02727552,\n",
            "        1.3512133 , -1.9386348 ,  0.84892964], dtype=float32), 'agent_3': Array([ 0.60646826,  0.87861323, -0.01763452, -0.07845584,  0.47071502,\n",
            "       -0.5578252 , -0.5713715 , -0.34143358, -0.573412  ,  0.8552582 ,\n",
            "        0.45528412,  1.040268  , -0.04947186,  0.36402455, -0.02727552,\n",
            "        1.3512133 ,  0.12080575,  1.3811421 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.5569507   0.6940019  -1.5605379   0.6957805  -1.5608507   0.6916238\n",
            " -1.556672    0.69285816]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.9659657, dtype=float32), 'agent_0': Array(-3.9659657, dtype=float32), 'agent_1': Array(-3.9659657, dtype=float32), 'agent_2': Array(-3.9659657, dtype=float32), 'agent_3': Array(-3.9659657, dtype=float32)}\n",
            "step: 426\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5904077 ,  0.8606401 , -0.01038165, -0.08246231,  0.5023852 ,\n",
            "       -0.54511297,  1.1060643 , -0.55088574, -0.5499048 , -0.54588616,\n",
            "        0.70471764,  1.0688782 , -0.58385134, -0.05864427, -0.9360371 ,\n",
            "        0.8119013 ,  0.9816789 ,  5.8262744 ], dtype=float32), 'agent_1': Array([ 0.5904077 ,  0.8606401 , -0.01038165, -0.08246231,  0.5023852 ,\n",
            "       -0.54511297, -0.55088574, -0.4952855 , -0.5499048 , -0.54588616,\n",
            "        0.70471764,  1.0688782 , -0.58385134, -0.05864427, -0.9360371 ,\n",
            "        0.8119013 ,  1.3213755 ,  4.7197824 ], dtype=float32), 'agent_2': Array([ 0.5904077 ,  0.8606401 , -0.01038165, -0.08246231,  0.5023852 ,\n",
            "       -0.54511297, -0.55088574, -0.5499048 , -0.7496419 , -0.54588616,\n",
            "        0.70471764,  1.0688782 , -0.58385134, -0.05864427, -0.9360371 ,\n",
            "        0.8119013 , -3.9399323 ,  5.336145  ], dtype=float32), 'agent_3': Array([ 0.5904077 ,  0.8606401 , -0.01038165, -0.08246231,  0.5023852 ,\n",
            "       -0.54511297, -0.55088574, -0.5499048 , -0.54588616,  1.0197642 ,\n",
            "        0.70471764,  1.0688782 , -0.58385134, -0.05864427, -0.9360371 ,\n",
            "        0.8119013 ,  1.2073674 ,  5.28005   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.49182835 -0.09372778 -0.4918487  -0.09490693 -0.49573064 -0.09130146\n",
            " -0.49307236 -0.09371222]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.2354727, dtype=float32), 'agent_0': Array(-4.2354727, dtype=float32), 'agent_1': Array(-4.2354727, dtype=float32), 'agent_2': Array(-4.2354727, dtype=float32), 'agent_3': Array(-4.2354727, dtype=float32)}\n",
            "step: 427\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5505661 ,  0.85403156,  0.01123097, -0.07573545,  0.5145562 ,\n",
            "       -0.52072996,  1.2504704 , -0.50986177, -0.59162784, -0.5162581 ,\n",
            "        0.19259453,  1.152134  , -0.6409526 ,  0.9389816 , -0.11164558,\n",
            "        0.73838884, -0.43282145,  0.15063924], dtype=float32), 'agent_1': Array([ 0.5505661 ,  0.85403156,  0.01123097, -0.07573545,  0.5145562 ,\n",
            "       -0.52072996, -0.50986177, -0.50352263, -0.59162784, -0.5162581 ,\n",
            "        0.19259453,  1.152134  , -0.6409526 ,  0.9389816 , -0.11164558,\n",
            "        0.73838884, -0.01675151, -0.08178925], dtype=float32), 'agent_2': Array([ 0.5505661 ,  0.85403156,  0.01123097, -0.07573545,  0.5145562 ,\n",
            "       -0.52072996, -0.50986177, -0.59162784, -0.5773177 , -0.5162581 ,\n",
            "        0.19259453,  1.152134  , -0.6409526 ,  0.9389816 , -0.11164558,\n",
            "        0.73838884,  0.82659304,  3.4006774 ], dtype=float32), 'agent_3': Array([ 0.5505661 ,  0.85403156,  0.01123097, -0.07573545,  0.5145562 ,\n",
            "       -0.52072996, -0.50986177, -0.59162784, -0.5162581 ,  1.1539383 ,\n",
            "        0.19259453,  1.152134  , -0.6409526 ,  0.9389816 , -0.11164558,\n",
            "        0.73838884, -0.18903333,  2.1176364 ], dtype=float32)}\n",
            "ctrl action chosen: [0.19140428 0.5970301  0.18975443 0.5940347  0.18848212 0.6002377\n",
            " 0.18922168 0.6006638 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.8786333, dtype=float32), 'agent_0': Array(0.8786333, dtype=float32), 'agent_1': Array(0.8786333, dtype=float32), 'agent_2': Array(0.8786333, dtype=float32), 'agent_3': Array(0.8786333, dtype=float32)}\n",
            "step: 428\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.51845396,  0.8749389 ,  0.03055102, -0.07268275,  0.47777167,\n",
            "       -0.41652283,  1.248323  , -0.36909452, -0.38971788, -0.37682983,\n",
            "        0.26574135,  0.8831024 , -0.56449175,  0.81208646,  0.5871433 ,\n",
            "       -1.9919494 ,  2.2755582 , -1.3988358 ], dtype=float32), 'agent_1': Array([ 0.51845396,  0.8749389 ,  0.03055102, -0.07268275,  0.47777167,\n",
            "       -0.41652283, -0.36909452, -0.50733507, -0.38971788, -0.37682983,\n",
            "        0.26574135,  0.8831024 , -0.56449175,  0.81208646,  0.5871433 ,\n",
            "       -1.9919494 ,  2.8990793 , -0.8770365 ], dtype=float32), 'agent_2': Array([ 0.51845396,  0.8749389 ,  0.03055102, -0.07268275,  0.47777167,\n",
            "       -0.41652283, -0.36909452, -0.38971788, -0.48874173, -0.37682983,\n",
            "        0.26574135,  0.8831024 , -0.56449175,  0.81208646,  0.5871433 ,\n",
            "       -1.9919494 ,  4.9249425 , -1.1622499 ], dtype=float32), 'agent_3': Array([ 0.51845396,  0.8749389 ,  0.03055102, -0.07268275,  0.47777167,\n",
            "       -0.41652283, -0.36909452, -0.38971788, -0.37682983,  1.260627  ,\n",
            "        0.26574135,  0.8831024 , -0.56449175,  0.81208646,  0.5871433 ,\n",
            "       -1.9919494 ,  3.215788  , -0.871911  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.21136427  1.4723752  -0.21255048  1.472989   -0.21305872  1.473553\n",
            " -0.21239941  1.4753433 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5121794, dtype=float32), 'agent_0': Array(0.5121794, dtype=float32), 'agent_1': Array(0.5121794, dtype=float32), 'agent_2': Array(0.5121794, dtype=float32), 'agent_3': Array(0.5121794, dtype=float32)}\n",
            "step: 429\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.50595355,  0.8552582 ,  0.03662348, -0.07593326,  0.51129866,\n",
            "       -0.5088126 ,  1.2510424 , -0.4320592 , -0.3761766 , -0.42920053,\n",
            "       -0.16841888,  0.5373001 ,  0.00510216, -0.02865691, -0.30376273,\n",
            "        2.425781  , -2.9779084 ,  0.3399967 ], dtype=float32), 'agent_1': Array([ 0.50595355,  0.8552582 ,  0.03662348, -0.07593326,  0.51129866,\n",
            "       -0.5088126 , -0.4320592 , -0.48868856, -0.3761766 , -0.42920053,\n",
            "       -0.16841888,  0.5373001 ,  0.00510216, -0.02865691, -0.30376273,\n",
            "        2.425781  , -2.467914  ,  0.51325977], dtype=float32), 'agent_2': Array([ 0.50595355,  0.8552582 ,  0.03662348, -0.07593326,  0.51129866,\n",
            "       -0.5088126 , -0.4320592 , -0.3761766 , -0.48429585, -0.42920053,\n",
            "       -0.16841888,  0.5373001 ,  0.00510216, -0.02865691, -0.30376273,\n",
            "        2.425781  , -1.1929468 , -0.2815313 ], dtype=float32), 'agent_3': Array([ 0.50595355,  0.8552582 ,  0.03662348, -0.07593326,  0.51129866,\n",
            "       -0.5088126 , -0.4320592 , -0.3761766 , -0.42920053,  1.2533208 ,\n",
            "       -0.16841888,  0.5373001 ,  0.00510216, -0.02865691, -0.30376273,\n",
            "        2.425781  , -2.6080165 , -0.45504877], dtype=float32)}\n",
            "ctrl action chosen: [ 0.00607318 -0.29040298  0.00430639 -0.29094252  0.00555727 -0.29454395\n",
            "  0.0040395  -0.29339117]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.391724, dtype=float32), 'agent_0': Array(-3.391724, dtype=float32), 'agent_1': Array(-3.391724, dtype=float32), 'agent_2': Array(-3.391724, dtype=float32), 'agent_3': Array(-3.391724, dtype=float32)}\n",
            "step: 430\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.51646817,  0.84690994,  0.02904937, -0.06016375,  0.5275227 ,\n",
            "       -0.5339776 ,  1.1322354 , -0.46250522, -0.3447782 , -0.4853942 ,\n",
            "       -0.58813095,  0.09622574,  0.26923418, -0.13965666,  0.6227128 ,\n",
            "        0.23544432,  0.33670807, -2.449027  ], dtype=float32), 'agent_1': Array([ 0.51646817,  0.84690994,  0.02904937, -0.06016375,  0.5275227 ,\n",
            "       -0.5339776 , -0.46250522, -0.5761606 , -0.3447782 , -0.4853942 ,\n",
            "       -0.58813095,  0.09622574,  0.26923418, -0.13965666,  0.6227128 ,\n",
            "        0.23544432, -0.07355035, -1.5124195 ], dtype=float32), 'agent_2': Array([ 0.51646817,  0.84690994,  0.02904937, -0.06016375,  0.5275227 ,\n",
            "       -0.5339776 , -0.46250522, -0.3447782 , -0.6442904 , -0.4853942 ,\n",
            "       -0.58813095,  0.09622574,  0.26923418, -0.13965666,  0.6227128 ,\n",
            "        0.23544432,  1.0315725 , -3.520679  ], dtype=float32), 'agent_3': Array([ 0.51646817,  0.84690994,  0.02904937, -0.06016375,  0.5275227 ,\n",
            "       -0.5339776 , -0.46250522, -0.3447782 , -0.4853942 ,  1.0716246 ,\n",
            "       -0.58813095,  0.09622574,  0.26923418, -0.13965666,  0.6227128 ,\n",
            "        0.23544432, -0.6271574 , -3.7177062 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.733743   -0.20307973  0.7313273  -0.20207043  0.7321839  -0.20477074\n",
            "  0.7315159  -0.20310104]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.38480967, dtype=float32), 'agent_0': Array(0.38480967, dtype=float32), 'agent_1': Array(0.38480967, dtype=float32), 'agent_2': Array(0.38480967, dtype=float32), 'agent_3': Array(0.38480967, dtype=float32)}\n",
            "step: 431\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.1977193e-01,  9.2404109e-01,  2.4589138e-02, -4.5883846e-02,\n",
            "        3.7873241e-01, -9.4826132e-02,  1.0122410e+00, -4.4796523e-02,\n",
            "        1.3774833e-01, -8.1724755e-02, -3.8795471e-01, -6.4468384e-02,\n",
            "        8.7022781e-04, -4.7069919e-01,  7.1687996e-01, -8.7862501e+00,\n",
            "        1.1645494e+01, -2.9352446e+00], dtype=float32), 'agent_1': Array([ 5.1977193e-01,  9.2404109e-01,  2.4589138e-02, -4.5883846e-02,\n",
            "        3.7873241e-01, -9.4826132e-02, -4.4796523e-02, -6.7851150e-01,\n",
            "        1.3774833e-01, -8.1724755e-02, -3.8795471e-01, -6.4468384e-02,\n",
            "        8.7022781e-04, -4.7069919e-01,  7.1687996e-01, -8.7862501e+00,\n",
            "        1.1037248e+01, -2.7801588e+00], dtype=float32), 'agent_2': Array([ 5.1977193e-01,  9.2404109e-01,  2.4589138e-02, -4.5883846e-02,\n",
            "        3.7873241e-01, -9.4826132e-02, -4.4796523e-02,  1.3774833e-01,\n",
            "       -7.6227635e-01, -8.1724755e-02, -3.8795471e-01, -6.4468384e-02,\n",
            "        8.7022781e-04, -4.7069919e-01,  7.1687996e-01, -8.7862501e+00,\n",
            "        1.2677577e+01, -1.4539100e+00], dtype=float32), 'agent_3': Array([ 5.19771934e-01,  9.24041092e-01,  2.45891381e-02, -4.58838455e-02,\n",
            "        3.78732413e-01, -9.48261321e-02, -4.47965227e-02,  1.37748331e-01,\n",
            "       -8.17247555e-02,  9.26256359e-01, -3.87954712e-01, -6.44683838e-02,\n",
            "        8.70227814e-04, -4.70699191e-01,  7.16879964e-01, -8.78625011e+00,\n",
            "        1.09013405e+01, -2.93045139e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.21119472 0.1347807  0.20973124 0.13627002 0.21066344 0.13547717\n",
            " 0.21011654 0.13487844]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.6699872, dtype=float32), 'agent_0': Array(-0.6699872, dtype=float32), 'agent_1': Array(-0.6699872, dtype=float32), 'agent_2': Array(-0.6699872, dtype=float32), 'agent_3': Array(-0.6699872, dtype=float32)}\n",
            "step: 432\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.51560855,  0.96481544,  0.0123476 , -0.04334324,  0.25903702,\n",
            "        0.26487878,  0.9211521 ,  0.28976014,  0.55539566,  0.24153268,\n",
            "       -0.28734207, -0.09145737, -0.22022724, -0.66574746,  0.06595247,\n",
            "       -3.4512773 ,  5.262828  , -1.3010011 ], dtype=float32), 'agent_1': Array([ 0.51560855,  0.96481544,  0.0123476 , -0.04334324,  0.25903702,\n",
            "        0.26487878,  0.28976014, -0.7118304 ,  0.55539566,  0.24153268,\n",
            "       -0.28734207, -0.09145737, -0.22022724, -0.66574746,  0.06595247,\n",
            "       -3.4512773 ,  4.8321705 ,  0.5175894 ], dtype=float32), 'agent_2': Array([ 0.51560855,  0.96481544,  0.0123476 , -0.04334324,  0.25903702,\n",
            "        0.26487878,  0.28976014,  0.55539566, -0.7408327 ,  0.24153268,\n",
            "       -0.28734207, -0.09145737, -0.22022724, -0.66574746,  0.06595247,\n",
            "       -3.4512773 ,  5.4996753 ,  0.7597986 ], dtype=float32), 'agent_3': Array([ 0.51560855,  0.96481544,  0.0123476 , -0.04334324,  0.25903702,\n",
            "        0.26487878,  0.28976014,  0.55539566,  0.24153268,  0.85576665,\n",
            "       -0.28734207, -0.09145737, -0.22022724, -0.66574746,  0.06595247,\n",
            "       -3.4512773 ,  4.5257096 , -0.9087582 ], dtype=float32)}\n",
            "ctrl action chosen: [0.43098924 0.19967629 0.432258   0.20193382 0.43274966 0.19914357\n",
            " 0.43094334 0.19983467]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5981486, dtype=float32), 'agent_0': Array(0.5981486, dtype=float32), 'agent_1': Array(0.5981486, dtype=float32), 'agent_2': Array(0.5981486, dtype=float32), 'agent_3': Array(0.5981486, dtype=float32)}\n",
            "step: 433\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.9988642e-01,  9.7395259e-01,  2.4295100e-03, -5.1057786e-02,\n",
            "        2.2091565e-01,  4.5645180e-01,  9.3130261e-01,  4.5124990e-01,\n",
            "        5.7662046e-01,  3.9416152e-01,  2.9592514e-01,  1.7557144e-01,\n",
            "       -4.2511821e-01, -3.9080596e-01, -4.8374602e-01, -1.3062840e+00,\n",
            "        3.9987895e+00,  8.8113248e-01], dtype=float32), 'agent_1': Array([ 4.9988642e-01,  9.7395259e-01,  2.4295100e-03, -5.1057786e-02,\n",
            "        2.2091565e-01,  4.5645180e-01,  4.5124990e-01, -6.1828530e-01,\n",
            "        5.7662046e-01,  3.9416152e-01,  2.9592514e-01,  1.7557144e-01,\n",
            "       -4.2511821e-01, -3.9080596e-01, -4.8374602e-01, -1.3062840e+00,\n",
            "        3.1659865e+00,  2.7181022e+00], dtype=float32), 'agent_2': Array([ 0.49988642,  0.9739526 ,  0.00242951, -0.05105779,  0.22091565,\n",
            "        0.4564518 ,  0.4512499 ,  0.57662046, -0.6823336 ,  0.39416152,\n",
            "        0.29592514,  0.17557144, -0.4251182 , -0.39080596, -0.48374602,\n",
            "       -1.306284  , -1.1350546 ,  1.6756988 ], dtype=float32), 'agent_3': Array([ 4.9988642e-01,  9.7395259e-01,  2.4295100e-03, -5.1057786e-02,\n",
            "        2.2091565e-01,  4.5645180e-01,  4.5124990e-01,  5.7662046e-01,\n",
            "        3.9416152e-01,  8.6759382e-01,  2.9592514e-01,  1.7557144e-01,\n",
            "       -4.2511821e-01, -3.9080596e-01, -4.8374602e-01, -1.3062840e+00,\n",
            "        3.1214497e+00,  1.2577673e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.2444887  -0.70962447 -1.2445785  -0.7049249  -1.246639   -0.704412\n",
            " -1.2447613  -0.70809114]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.5891312, dtype=float32), 'agent_0': Array(0.5891312, dtype=float32), 'agent_1': Array(0.5891312, dtype=float32), 'agent_2': Array(0.5891312, dtype=float32), 'agent_3': Array(0.5891312, dtype=float32)}\n",
            "step: 434\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.9169901e-01,  8.9949906e-01, -2.8046153e-02, -2.9080182e-02,\n",
            "        4.3505105e-01, -1.7106231e-02,  7.3852372e-01, -5.6817457e-02,\n",
            "       -1.2610239e-01, -9.4505250e-02,  3.8790703e-01, -5.4359436e-02,\n",
            "       -3.7372112e-03, -7.8130685e-02,  1.7607058e+00,  1.2176968e+01,\n",
            "       -1.3930459e+01, -5.8397241e+00], dtype=float32), 'agent_1': Array([ 4.9169901e-01,  8.9949906e-01, -2.8046153e-02, -2.9080182e-02,\n",
            "        4.3505105e-01, -1.7106231e-02, -5.6817457e-02, -7.0805711e-01,\n",
            "       -1.2610239e-01, -9.4505250e-02,  3.8790703e-01, -5.4359436e-02,\n",
            "       -3.7372112e-03, -7.8130685e-02,  1.7607058e+00,  1.2176968e+01,\n",
            "       -1.4638119e+01, -3.4394305e+00], dtype=float32), 'agent_2': Array([ 4.9169901e-01,  8.9949906e-01, -2.8046153e-02, -2.9080182e-02,\n",
            "        4.3505105e-01, -1.7106231e-02, -5.6817457e-02, -1.2610239e-01,\n",
            "       -8.2936966e-01, -9.4505250e-02,  3.8790703e-01, -5.4359436e-02,\n",
            "       -3.7372112e-03, -7.8130685e-02,  1.7607058e+00,  1.2176968e+01,\n",
            "       -1.8367765e+01, -4.8561668e+00], dtype=float32), 'agent_3': Array([ 4.9169901e-01,  8.9949906e-01, -2.8046153e-02, -2.9080182e-02,\n",
            "        4.3505105e-01, -1.7106231e-02, -5.6817457e-02, -1.2610239e-01,\n",
            "       -9.4505250e-02,  7.0259911e-01,  3.8790703e-01, -5.4359436e-02,\n",
            "       -3.7372112e-03, -7.8130685e-02,  1.7607058e+00,  1.2176968e+01,\n",
            "       -1.3576633e+01, -5.1827703e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.2813552  0.08235654 0.28244165 0.0832218  0.28371632 0.08425349\n",
            " 0.2803904  0.08226506]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.7374706, dtype=float32), 'agent_0': Array(-2.7374706, dtype=float32), 'agent_1': Array(-2.7374706, dtype=float32), 'agent_2': Array(-2.7374706, dtype=float32), 'agent_3': Array(-2.7374706, dtype=float32)}\n",
            "step: 435\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4859991 ,  0.8747939 , -0.03375972, -0.01074778,  0.48319831,\n",
            "       -0.12055954,  0.59922683, -0.2168903 , -0.40062255, -0.1814802 ,\n",
            "        0.3569603 ,  0.2776146 , -0.15832782,  0.2968448 ,  0.5841772 ,\n",
            "       -0.68518   ,  1.9007523 , -2.0102239 ], dtype=float32), 'agent_1': Array([ 0.4859991 ,  0.8747939 , -0.03375972, -0.01074778,  0.48319831,\n",
            "       -0.12055954, -0.2168903 , -0.7009051 , -0.40062255, -0.1814802 ,\n",
            "        0.3569603 ,  0.2776146 , -0.15832782,  0.2968448 ,  0.5841772 ,\n",
            "       -0.68518   ,  0.54119855,  1.1704531 ], dtype=float32), 'agent_2': Array([ 0.4859991 ,  0.8747939 , -0.03375972, -0.01074778,  0.48319831,\n",
            "       -0.12055954, -0.2168903 , -0.40062255, -0.92124444, -0.1814802 ,\n",
            "        0.3569603 ,  0.2776146 , -0.15832782,  0.2968448 ,  0.5841772 ,\n",
            "       -0.68518   , -1.3129498 , -0.7221654 ], dtype=float32), 'agent_3': Array([ 0.4859991 ,  0.8747939 , -0.03375972, -0.01074778,  0.48319831,\n",
            "       -0.12055954, -0.2168903 , -0.40062255, -0.1814802 ,  0.5777628 ,\n",
            "        0.3569603 ,  0.2776146 , -0.15832782,  0.2968448 ,  0.5841772 ,\n",
            "       -0.68518   ,  1.910578  , -2.230683  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5110235   0.17235936 -0.51091987  0.17769295 -0.51444525  0.17312367\n",
            " -0.51327145  0.17356457]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.2463238, dtype=float32), 'agent_0': Array(1.2463238, dtype=float32), 'agent_1': Array(1.2463238, dtype=float32), 'agent_2': Array(1.2463238, dtype=float32), 'agent_3': Array(1.2463238, dtype=float32)}\n",
            "step: 436\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.48096842,  0.8389285 , -0.0383461 ,  0.00864158,  0.5428203 ,\n",
            "       -0.25817633,  0.5403199 , -0.40894395, -0.592508  , -0.33012316,\n",
            "        0.1991272 ,  0.19721985, -0.32080412,  0.07275271,  0.35163212,\n",
            "        1.8423674 , -2.6327283 , -0.49914125], dtype=float32), 'agent_1': Array([ 0.48096842,  0.8389285 , -0.0383461 ,  0.00864158,  0.5428203 ,\n",
            "       -0.25817633, -0.40894395, -0.63353527, -0.592508  , -0.33012316,\n",
            "        0.1991272 ,  0.19721985, -0.32080412,  0.07275271,  0.35163212,\n",
            "        1.8423674 , -3.5163507 ,  1.6286374 ], dtype=float32), 'agent_2': Array([ 0.48096842,  0.8389285 , -0.0383461 ,  0.00864158,  0.5428203 ,\n",
            "       -0.25817633, -0.40894395, -0.592508  , -0.91472894, -0.33012316,\n",
            "        0.1991272 ,  0.19721985, -0.32080412,  0.07275271,  0.35163212,\n",
            "        1.8423674 , -0.84668946,  0.9520376 ], dtype=float32), 'agent_3': Array([ 0.48096842,  0.8389285 , -0.0383461 ,  0.00864158,  0.5428203 ,\n",
            "       -0.25817633, -0.40894395, -0.592508  , -0.33012316,  0.5169118 ,\n",
            "        0.1991272 ,  0.19721985, -0.32080412,  0.07275271,  0.35163212,\n",
            "        1.8423674 , -2.808635  ,  0.4983548 ], dtype=float32)}\n",
            "ctrl action chosen: [1.0719311  0.24459477 1.0688229  0.24798004 1.0745245  0.24441431\n",
            " 1.0699089  0.24664043]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.7946742, dtype=float32), 'agent_0': Array(0.7946742, dtype=float32), 'agent_1': Array(0.7946742, dtype=float32), 'agent_2': Array(0.7946742, dtype=float32), 'agent_3': Array(0.7946742, dtype=float32)}\n",
            "step: 437\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.5682138e-01,  9.3268484e-01, -3.7310254e-02, -1.5509496e-03,\n",
            "        3.5875407e-01,  2.5522688e-01,  5.8911085e-01,  6.2635876e-02,\n",
            "       -4.6381418e-02,  1.7546022e-01,  2.0723343e-01,  3.0889511e-01,\n",
            "       -4.5815110e-01,  2.4808973e-01, -4.9391398e-01, -1.1933437e+01,\n",
            "        1.5129774e+01,  1.5090612e+00], dtype=float32), 'agent_1': Array([ 4.5682138e-01,  9.3268484e-01, -3.7310254e-02, -1.5509496e-03,\n",
            "        3.5875407e-01,  2.5522688e-01,  6.2635876e-02, -5.0500000e-01,\n",
            "       -4.6381418e-02,  1.7546022e-01,  2.0723343e-01,  3.0889511e-01,\n",
            "       -4.5815110e-01,  2.4808973e-01, -4.9391398e-01, -1.1933437e+01,\n",
            "        1.4141457e+01,  2.3691111e+00], dtype=float32), 'agent_2': Array([ 4.5682138e-01,  9.3268484e-01, -3.7310254e-02, -1.5509496e-03,\n",
            "        3.5875407e-01,  2.5522688e-01,  6.2635876e-02, -4.6381418e-02,\n",
            "       -8.0374944e-01,  1.7546022e-01,  2.0723343e-01,  3.0889511e-01,\n",
            "       -4.5815110e-01,  2.4808973e-01, -4.9391398e-01, -1.1933437e+01,\n",
            "        1.6440578e+01,  2.9942281e+00], dtype=float32), 'agent_3': Array([ 4.5682138e-01,  9.3268484e-01, -3.7310254e-02, -1.5509496e-03,\n",
            "        3.5875407e-01,  2.5522688e-01,  6.2635876e-02, -4.6381418e-02,\n",
            "        1.7546022e-01,  6.0706264e-01,  2.0723343e-01,  3.0889511e-01,\n",
            "       -4.5815110e-01,  2.4808973e-01, -4.9391398e-01, -1.1933437e+01,\n",
            "        1.4726003e+01,  2.8320279e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.30967546  0.4926385  -0.30836987  0.49217573 -0.3094946   0.49040937\n",
            " -0.30893564  0.49193347]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1705706, dtype=float32), 'agent_0': Array(-1.1705706, dtype=float32), 'agent_1': Array(-1.1705706, dtype=float32), 'agent_2': Array(-1.1705706, dtype=float32), 'agent_3': Array(-1.1705706, dtype=float32)}\n",
            "step: 438\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.43514296,  0.94965816, -0.00455227, -0.00997105,  0.31309643,\n",
            "        0.42585915,  0.72270507,  0.16442387,  0.14645818,  0.3033623 ,\n",
            "        0.10099411,  0.46710968, -0.064224  ,  1.5157999 , -0.85586107,\n",
            "        1.2609109 , -0.9409145 ,  2.7507381 ], dtype=float32), 'agent_1': Array([ 0.43514296,  0.94965816, -0.00455227, -0.00997105,  0.31309643,\n",
            "        0.42585915,  0.16442387, -0.4956276 ,  0.14645818,  0.3033623 ,\n",
            "        0.10099411,  0.46710968, -0.064224  ,  1.5157999 , -0.85586107,\n",
            "        1.2609109 , -2.1381223 , -0.43574786], dtype=float32), 'agent_2': Array([ 4.3514296e-01,  9.4965816e-01, -4.5522694e-03, -9.9710496e-03,\n",
            "        3.1309643e-01,  4.2585915e-01,  1.6442387e-01,  1.4645818e-01,\n",
            "       -5.2418655e-01,  3.0336231e-01,  1.0099411e-01,  4.6710968e-01,\n",
            "       -6.4224005e-02,  1.5157999e+00, -8.5586107e-01,  1.2609109e+00,\n",
            "       -6.3525891e-01,  6.8687224e+00], dtype=float32), 'agent_3': Array([ 0.43514296,  0.94965816, -0.00455227, -0.00997105,  0.31309643,\n",
            "        0.42585915,  0.16442387,  0.14645818,  0.3033623 ,  0.82385683,\n",
            "        0.10099411,  0.46710968, -0.064224  ,  1.5157999 , -0.85586107,\n",
            "        1.2609109 , -1.7629018 ,  3.291525  ], dtype=float32)}\n",
            "ctrl action chosen: [0.4125318  1.9297343  0.4086057  1.9260312  0.4116252  1.928107\n",
            " 0.41056615 1.9302586 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.3473534, dtype=float32), 'agent_0': Array(0.3473534, dtype=float32), 'agent_1': Array(0.3473534, dtype=float32), 'agent_2': Array(0.3473534, dtype=float32), 'agent_3': Array(0.3473534, dtype=float32)}\n",
            "step: 439\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4637018 ,  0.9665447 ,  0.026075  , -0.0433911 ,  0.2514534 ,\n",
            "        0.56580883,  0.9846291 ,  0.30387232,  0.34037542,  0.41471946,\n",
            "        0.78754425,  0.30994415,  1.087606  ,  0.46228886, -1.8136494 ,\n",
            "       -2.0917084 ,  1.4211854 ,  5.801707  ], dtype=float32), 'agent_1': Array([ 0.4637018 ,  0.9665447 ,  0.026075  , -0.0433911 ,  0.2514534 ,\n",
            "        0.56580883,  0.30387232, -0.4764843 ,  0.34037542,  0.41471946,\n",
            "        0.78754425,  0.30994415,  1.087606  ,  0.46228886, -1.8136494 ,\n",
            "       -2.0917084 ,  2.9500418 , -0.00805974], dtype=float32), 'agent_2': Array([ 0.4637018 ,  0.9665447 ,  0.026075  , -0.0433911 ,  0.2514534 ,\n",
            "        0.56580883,  0.30387232,  0.34037542, -0.4612453 ,  0.41471946,\n",
            "        0.78754425,  0.30994415,  1.087606  ,  0.46228886, -1.8136494 ,\n",
            "       -2.0917084 ,  3.7981358 , -0.45109373], dtype=float32), 'agent_3': Array([ 0.4637018 ,  0.9665447 ,  0.026075  , -0.0433911 ,  0.2514534 ,\n",
            "        0.56580883,  0.30387232,  0.34037542,  0.41471946,  1.0590304 ,\n",
            "        0.78754425,  0.30994415,  1.087606  ,  0.46228886, -1.8136494 ,\n",
            "       -2.0917084 ,  1.877678  ,  4.467682  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.5428662   0.19204383 -0.5398452   0.18555208 -0.538145    0.18350132\n",
            " -0.54293966  0.19093364]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.129949, dtype=float32), 'agent_0': Array(-6.129949, dtype=float32), 'agent_1': Array(-6.129949, dtype=float32), 'agent_2': Array(-6.129949, dtype=float32), 'agent_3': Array(-6.129949, dtype=float32)}\n",
            "step: 440\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5271093 ,  0.9334091 ,  0.04094712, -0.07935899,  0.34752408,\n",
            "        0.30681983,  1.2022985 ,  0.05803101,  0.13169883,  0.1226193 ,\n",
            "        0.7703304 ,  0.28572083,  0.9963393 ,  0.381432  , -1.9764996 ,\n",
            "        6.064611  , -8.064994  ,  5.669029  ], dtype=float32), 'agent_1': Array([ 0.5271093 ,  0.9334091 ,  0.04094712, -0.07935899,  0.34752408,\n",
            "        0.30681983,  0.05803101, -0.52743673,  0.13169883,  0.1226193 ,\n",
            "        0.7703304 ,  0.28572083,  0.9963393 ,  0.381432  , -1.9764996 ,\n",
            "        6.064611  , -7.57835   , -0.321664  ], dtype=float32), 'agent_2': Array([ 0.5271093 ,  0.9334091 ,  0.04094712, -0.07935899,  0.34752408,\n",
            "        0.30681983,  0.05803101,  0.13169883, -0.5282796 ,  0.1226193 ,\n",
            "        0.7703304 ,  0.28572083,  0.9963393 ,  0.381432  , -1.9764996 ,\n",
            "        6.064611  , -6.966866  , -0.61865586], dtype=float32), 'agent_3': Array([ 0.5271093 ,  0.9334091 ,  0.04094712, -0.07935899,  0.34752408,\n",
            "        0.30681983,  0.05803101,  0.13169883,  0.1226193 ,  1.1674905 ,\n",
            "        0.7703304 ,  0.28572083,  0.9963393 ,  0.381432  , -1.9764996 ,\n",
            "        6.064611  , -8.337289  ,  3.6048748 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.5977288  -0.9767397   0.59102976 -0.97925335  0.59100646 -0.9814976\n",
            "  0.59425485 -0.9786943 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.1003034, dtype=float32), 'agent_0': Array(1.1003034, dtype=float32), 'agent_1': Array(1.1003034, dtype=float32), 'agent_2': Array(1.1003034, dtype=float32), 'agent_3': Array(1.1003034, dtype=float32)}\n",
            "step: 441\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.57113063,  0.95675194,  0.03814443, -0.07467052,  0.27855888,\n",
            "        0.45410642,  1.116657  ,  0.23270497,  0.32461444,  0.26640004,\n",
            "        0.23479462, -0.36201477,  1.1999011 , -0.6723035 ,  1.4760244 ,\n",
            "       -5.991117  ,  6.7065935 , -5.8214197 ], dtype=float32), 'agent_1': Array([ 0.57113063,  0.95675194,  0.03814443, -0.07467052,  0.27855888,\n",
            "        0.45410642,  0.23270497, -0.8481313 ,  0.32461444,  0.26640004,\n",
            "        0.23479462, -0.36201477,  1.1999011 , -0.6723035 ,  1.4760244 ,\n",
            "       -5.991117  ,  7.4476013 , -7.4085455 ], dtype=float32), 'agent_2': Array([ 0.57113063,  0.95675194,  0.03814443, -0.07467052,  0.27855888,\n",
            "        0.45410642,  0.23270497,  0.32461444, -0.8554316 ,  0.26640004,\n",
            "        0.23479462, -0.36201477,  1.1999011 , -0.6723035 ,  1.4760244 ,\n",
            "       -5.991117  ,  7.6327176 , -7.790635  ], dtype=float32), 'agent_3': Array([ 0.57113063,  0.95675194,  0.03814443, -0.07467052,  0.27855888,\n",
            "        0.45410642,  0.23270497,  0.32461444,  0.26640004,  1.0546212 ,\n",
            "        0.23479462, -0.36201477,  1.1999011 , -0.6723035 ,  1.4760244 ,\n",
            "       -5.991117  ,  7.0972486 , -5.915381  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.32574293 -0.30291092 -0.32547495 -0.3022884  -0.32369217 -0.3034833\n",
            " -0.32618782 -0.3029467 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.1015418, dtype=float32), 'agent_0': Array(-1.1015418, dtype=float32), 'agent_1': Array(-1.1015418, dtype=float32), 'agent_2': Array(-1.1015418, dtype=float32), 'agent_3': Array(-1.1015418, dtype=float32)}\n",
            "step: 442\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.633734  ,  0.95662165,  0.01966833, -0.05505854,  0.2854066 ,\n",
            "        0.41201138,  0.86194503,  0.20523496,  0.34413087,  0.24030869,\n",
            "        0.07147789, -0.4166603 ,  1.3872385 , -0.44108352,  1.2306275 ,\n",
            "        2.130834  , -3.1306884 , -5.493921  ], dtype=float32), 'agent_1': Array([ 0.633734  ,  0.95662165,  0.01966833, -0.05505854,  0.2854066 ,\n",
            "        0.41201138,  0.20523496, -1.0744079 ,  0.34413087,  0.24030869,\n",
            "        0.07147789, -0.4166603 ,  1.3872385 , -0.44108352,  1.2306275 ,\n",
            "        2.130834  , -3.353073  , -3.767424  ], dtype=float32), 'agent_2': Array([ 0.633734  ,  0.95662165,  0.01966833, -0.05505854,  0.2854066 ,\n",
            "        0.41201138,  0.20523496,  0.34413087, -1.0848703 ,  0.24030869,\n",
            "        0.07147789, -0.4166603 ,  1.3872385 , -0.44108352,  1.2306275 ,\n",
            "        2.130834  , -1.8465652 , -4.447096  ], dtype=float32), 'agent_3': Array([ 0.633734  ,  0.95662165,  0.01966833, -0.05505854,  0.2854066 ,\n",
            "        0.41201138,  0.20523496,  0.34413087,  0.24030869,  0.7834188 ,\n",
            "        0.07147789, -0.4166603 ,  1.3872385 , -0.44108352,  1.2306275 ,\n",
            "        2.130834  , -3.2323742 , -6.0286026 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.2133844   0.12260072 -1.2149619   0.12713458 -1.2112843   0.12073032\n",
            " -1.2134221   0.12179857]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.81151783, dtype=float32), 'agent_0': Array(0.81151783, dtype=float32), 'agent_1': Array(0.81151783, dtype=float32), 'agent_2': Array(0.81151783, dtype=float32), 'agent_3': Array(0.81151783, dtype=float32)}\n",
            "step: 443\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.8808472e-01,  8.4929115e-01,  1.3097432e-04, -3.5732485e-02,\n",
            "        5.2671421e-01, -2.5255373e-01,  6.9318855e-01, -4.8622110e-01,\n",
            "       -2.7030060e-01, -4.5249978e-01,  3.3426285e-02, -2.6731491e-01,\n",
            "        8.6921453e-01,  3.4053490e-01,  5.6474310e-01,  1.3219657e+01,\n",
            "       -1.6497890e+01, -2.4796579e+00], dtype=float32), 'agent_1': Array([ 6.8808472e-01,  8.4929115e-01,  1.3097432e-04, -3.5732485e-02,\n",
            "        5.2671421e-01, -2.5255373e-01, -4.8622110e-01, -1.1773498e+00,\n",
            "       -2.7030060e-01, -4.5249978e-01,  3.3426285e-02, -2.6731491e-01,\n",
            "        8.6921453e-01,  3.4053490e-01,  5.6474310e-01,  1.3219657e+01,\n",
            "       -1.7032394e+01, -1.3702565e+00], dtype=float32), 'agent_2': Array([ 6.8808472e-01,  8.4929115e-01,  1.3097432e-04, -3.5732485e-02,\n",
            "        5.2671421e-01, -2.5255373e-01, -4.8622110e-01, -2.7030060e-01,\n",
            "       -1.2346339e+00, -4.5249978e-01,  3.3426285e-02, -2.6731491e-01,\n",
            "        8.6921453e-01,  3.4053490e-01,  5.6474310e-01,  1.3219657e+01,\n",
            "       -1.5762102e+01, -1.4995080e+00], dtype=float32), 'agent_3': Array([ 6.8808472e-01,  8.4929115e-01,  1.3097432e-04, -3.5732485e-02,\n",
            "        5.2671421e-01, -2.5255373e-01, -4.8622110e-01, -2.7030060e-01,\n",
            "       -4.5249978e-01,  5.6618541e-01,  3.3426285e-02, -2.6731491e-01,\n",
            "        8.6921453e-01,  3.4053490e-01,  5.6474310e-01,  1.3219657e+01,\n",
            "       -1.7174011e+01, -3.5929744e+00], dtype=float32)}\n",
            "ctrl action chosen: [-1.7821513 -0.7720858 -1.7828277 -0.7714548 -1.7831168 -0.7732682\n",
            " -1.7833476 -0.7718317]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.9406848, dtype=float32), 'agent_0': Array(-1.9406848, dtype=float32), 'agent_1': Array(-1.9406848, dtype=float32), 'agent_2': Array(-1.9406848, dtype=float32), 'agent_3': Array(-1.9406848, dtype=float32)}\n",
            "step: 444\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7164763 ,  0.810691  , -0.00539643, -0.01722482,  0.58519596,\n",
            "       -0.55685484,  0.469894  , -0.5704557 , -0.5539899 , -0.5760187 ,\n",
            "        0.12583733, -0.28543472,  0.36159754, -0.44594008, -0.18894815,\n",
            "       -0.76434034, -1.1500193 ,  0.16067801], dtype=float32), 'agent_1': Array([ 0.7164763 ,  0.810691  , -0.00539643, -0.01722482,  0.58519596,\n",
            "       -0.55685484, -0.5704557 , -1.2627292 , -0.5539899 , -0.5760187 ,\n",
            "        0.12583733, -0.28543472,  0.36159754, -0.44594008, -0.18894815,\n",
            "       -0.76434034,  2.7336457 ,  0.79605424], dtype=float32), 'agent_2': Array([ 0.7164763 ,  0.810691  , -0.00539643, -0.01722482,  0.58519596,\n",
            "       -0.55685484, -0.5704557 , -0.5539899 , -1.2634238 , -0.5760187 ,\n",
            "        0.12583733, -0.28543472,  0.36159754, -0.44594008, -0.18894815,\n",
            "       -0.76434034, -1.2715607 ,  0.26293024], dtype=float32), 'agent_3': Array([ 0.7164763 ,  0.810691  , -0.00539643, -0.01722482,  0.58519596,\n",
            "       -0.55685484, -0.5704557 , -0.5539899 , -0.5760187 ,  0.48196205,\n",
            "        0.12583733, -0.28543472,  0.36159754, -0.44594008, -0.18894815,\n",
            "       -0.76434034,  2.188685  ,  1.2432662 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.34648934 -0.6645354  -0.34035796 -0.6639376  -0.34772387 -0.6675178\n",
            " -0.34115764 -0.66358936]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.536827, dtype=float32), 'agent_0': Array(-6.536827, dtype=float32), 'agent_1': Array(-6.536827, dtype=float32), 'agent_2': Array(-6.536827, dtype=float32), 'agent_3': Array(-6.536827, dtype=float32)}\n",
            "step: 445\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.2757643e-01,  8.3734548e-01, -1.1205650e-03, -2.4727857e-02,\n",
            "        5.4611349e-01, -5.4095429e-01,  4.8433664e-01, -3.5789150e-01,\n",
            "       -5.3804970e-01, -3.9446375e-01,  1.3265610e-01, -2.5672913e-01,\n",
            "        3.4010410e-02,  5.8696225e-02,  3.8175229e-02, -1.7336413e+00,\n",
            "        1.8422164e-01, -5.7012148e-02], dtype=float32), 'agent_1': Array([ 7.2757643e-01,  8.3734548e-01, -1.1205650e-03, -2.4727857e-02,\n",
            "        5.4611349e-01, -5.4095429e-01, -3.5789150e-01, -1.2467928e+00,\n",
            "       -5.3804970e-01, -3.9446375e-01,  1.3265610e-01, -2.5672913e-01,\n",
            "        3.4010410e-02,  5.8696225e-02,  3.8175229e-02, -1.7336413e+00,\n",
            "        3.5227969e+00,  9.2428818e-02], dtype=float32), 'agent_2': Array([ 7.2757643e-01,  8.3734548e-01, -1.1205650e-03, -2.4727857e-02,\n",
            "        5.4611349e-01, -5.4095429e-01, -3.5789150e-01, -5.3804970e-01,\n",
            "       -1.2383993e+00, -3.9446375e-01,  1.3265610e-01, -2.5672913e-01,\n",
            "        3.4010410e-02,  5.8696225e-02,  3.8175229e-02, -1.7336413e+00,\n",
            "        3.1900939e-01, -7.3368803e-02], dtype=float32), 'agent_3': Array([ 7.2757643e-01,  8.3734548e-01, -1.1205650e-03, -2.4727857e-02,\n",
            "        5.4611349e-01, -5.4095429e-01, -3.5789150e-01, -5.3804970e-01,\n",
            "       -3.9446375e-01,  5.0552356e-01,  1.3265610e-01, -2.5672913e-01,\n",
            "        3.4010410e-02,  5.8696225e-02,  3.8175229e-02, -1.7336413e+00,\n",
            "        3.0688419e+00,  5.9431799e-02], dtype=float32)}\n",
            "ctrl action chosen: [-0.9990636  -0.57104    -0.99640536 -0.56947154 -0.99913746 -0.5733328\n",
            " -0.99758434 -0.5694214 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.02791238, dtype=float32), 'agent_0': Array(0.02791238, dtype=float32), 'agent_1': Array(0.02791238, dtype=float32), 'agent_2': Array(0.02791238, dtype=float32), 'agent_3': Array(0.02791238, dtype=float32)}\n",
            "step: 446\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.1487826e-01,  8.1988800e-01,  4.9106988e-05, -2.5269328e-02,\n",
            "        5.7196611e-01, -5.8946431e-01,  5.0420874e-01, -4.8272273e-01,\n",
            "       -5.8637404e-01, -5.2822196e-01,  2.0747185e-01, -2.2706985e-01,\n",
            "       -4.6582222e-01,  9.7606122e-02, -4.2955406e-02,  8.6878496e-01,\n",
            "        6.7243087e-01,  3.1260949e-01], dtype=float32), 'agent_1': Array([ 7.1487826e-01,  8.1988800e-01,  4.9106988e-05, -2.5269328e-02,\n",
            "        5.7196611e-01, -5.8946431e-01, -4.8272273e-01, -1.2443092e+00,\n",
            "       -5.8637404e-01, -5.2822196e-01,  2.0747185e-01, -2.2706985e-01,\n",
            "       -4.6582222e-01,  9.7606122e-02, -4.2955406e-02,  8.6878496e-01,\n",
            "       -3.7265768e+00, -5.6841567e-02], dtype=float32), 'agent_2': Array([ 7.1487826e-01,  8.1988800e-01,  4.9106988e-05, -2.5269328e-02,\n",
            "        5.7196611e-01, -5.8946431e-01, -4.8272273e-01, -5.8637404e-01,\n",
            "       -1.2435430e+00, -5.2822196e-01,  2.0747185e-01, -2.2706985e-01,\n",
            "       -4.6582222e-01,  9.7606122e-02, -4.2955406e-02,  8.6878496e-01,\n",
            "        6.2935174e-01, -2.7426547e-01], dtype=float32), 'agent_3': Array([ 7.1487826e-01,  8.1988800e-01,  4.9106988e-05, -2.5269328e-02,\n",
            "        5.7196611e-01, -5.8946431e-01, -4.8272273e-01, -5.8637404e-01,\n",
            "       -5.2822196e-01,  5.0148410e-01,  2.0747185e-01, -2.2706985e-01,\n",
            "       -4.6582222e-01,  9.7606122e-02, -4.2955406e-02,  8.6878496e-01,\n",
            "       -3.1156464e+00, -2.3022923e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.30365634 -1.555194    0.29399    -1.5523158   0.30172288 -1.5596162\n",
            "  0.29513347 -1.5536872 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4825788, dtype=float32), 'agent_0': Array(-1.4825788, dtype=float32), 'agent_1': Array(-1.4825788, dtype=float32), 'agent_2': Array(-1.4825788, dtype=float32), 'agent_3': Array(-1.4825788, dtype=float32)}\n",
            "step: 447\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.7748553e-01,  8.6369973e-01,  3.0198367e-03, -2.1872755e-02,\n",
            "        5.0352287e-01, -3.1023374e-01,  4.9034804e-01, -4.0817663e-01,\n",
            "       -3.0756280e-01, -4.3604431e-01,  2.2091866e-01, -2.4747849e-01,\n",
            "       -9.9295378e-01, -6.6625357e-02, -1.5382263e-01, -4.3821850e+00,\n",
            "        7.5230384e+00, -9.3926914e-02], dtype=float32), 'agent_1': Array([ 6.7748553e-01,  8.6369973e-01,  3.0198367e-03, -2.1872755e-02,\n",
            "        5.0352287e-01, -3.1023374e-01, -4.0817663e-01, -1.2630695e+00,\n",
            "       -3.0756280e-01, -4.3604431e-01,  2.2091866e-01, -2.4747849e-01,\n",
            "       -9.9295378e-01, -6.6625357e-02, -1.5382263e-01, -4.3821850e+00,\n",
            "        2.6451001e+00,  1.3368773e-01], dtype=float32), 'agent_2': Array([ 6.7748553e-01,  8.6369973e-01,  3.0198367e-03, -2.1872755e-02,\n",
            "        5.0352287e-01, -3.1023374e-01, -4.0817663e-01, -3.0756280e-01,\n",
            "       -1.2693697e+00, -4.3604431e-01,  2.2091866e-01, -2.4747849e-01,\n",
            "       -9.9295378e-01, -6.6625357e-02, -1.5382263e-01, -4.3821850e+00,\n",
            "        7.3908410e+00,  1.6022956e-01], dtype=float32), 'agent_3': Array([ 6.77485526e-01,  8.63699734e-01,  3.01983673e-03, -2.18727551e-02,\n",
            "        5.03522873e-01, -3.10233742e-01, -4.08176631e-01, -3.07562798e-01,\n",
            "       -4.36044306e-01,  4.79065567e-01,  2.20918655e-01, -2.47478485e-01,\n",
            "       -9.92953777e-01, -6.66253567e-02, -1.53822631e-01, -4.38218498e+00,\n",
            "        3.10749269e+00,  1.23412974e-01], dtype=float32)}\n",
            "ctrl action chosen: [0.83875304 0.06788904 0.8409182  0.06917935 0.83872116 0.06609844\n",
            " 0.84028614 0.06849861]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.8095536, dtype=float32), 'agent_0': Array(-3.8095536, dtype=float32), 'agent_1': Array(-3.8095536, dtype=float32), 'agent_2': Array(-3.8095536, dtype=float32), 'agent_3': Array(-3.8095536, dtype=float32)}\n",
            "step: 448\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2630028e-01,  9.6093905e-01,  1.2627075e-02, -2.9358312e-02,\n",
            "        2.7490890e-01,  3.8572329e-01,  5.3966480e-01,  9.9607505e-02,\n",
            "        3.8027734e-01,  8.0155864e-02,  4.2209625e-01, -3.8137436e-01,\n",
            "       -5.1137209e-01, -7.4251167e-02,  3.8875756e-01, -1.1267871e+01,\n",
            "        1.5587081e+01, -5.1944606e-02], dtype=float32), 'agent_1': Array([  0.6263003 ,   0.96093905,   0.01262708,  -0.02935831,\n",
            "         0.2749089 ,   0.3857233 ,   0.0996075 ,  -1.191508  ,\n",
            "         0.38027734,   0.08015586,   0.42209625,  -0.38137436,\n",
            "        -0.5113721 ,  -0.07425117,   0.38875756, -11.267871  ,\n",
            "        12.550395  ,   0.7565067 ], dtype=float32), 'agent_2': Array([ 6.2630028e-01,  9.6093905e-01,  1.2627075e-02, -2.9358312e-02,\n",
            "        2.7490890e-01,  3.8572329e-01,  9.9607505e-02,  3.8027734e-01,\n",
            "       -1.1947308e+00,  8.0155864e-02,  4.2209625e-01, -3.8137436e-01,\n",
            "       -5.1137209e-01, -7.4251167e-02,  3.8875756e-01, -1.1267871e+01,\n",
            "        1.5422115e+01,  8.3017445e-01], dtype=float32), 'agent_3': Array([  0.6263003 ,   0.96093905,   0.01262708,  -0.02935831,\n",
            "         0.2749089 ,   0.3857233 ,   0.0996075 ,   0.38027734,\n",
            "         0.08015586,   0.55454636,   0.42209625,  -0.38137436,\n",
            "        -0.5113721 ,  -0.07425117,   0.38875756, -11.267871  ,\n",
            "        12.347879  ,   0.89115196], dtype=float32)}\n",
            "ctrl action chosen: [-1.5235116   0.05996741 -1.5203997   0.06066459 -1.5221515   0.05848778\n",
            " -1.5214963   0.0596319 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.10547042, dtype=float32), 'agent_0': Array(-0.10547042, dtype=float32), 'agent_1': Array(-0.10547042, dtype=float32), 'agent_2': Array(-0.10547042, dtype=float32), 'agent_3': Array(-0.10547042, dtype=float32)}\n",
            "step: 449\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.0013145e-01,  9.1801953e-01,  2.3612638e-03, -2.5788287e-02,\n",
            "        3.9568868e-01,  1.5831135e-01,  5.5748332e-01, -2.4281262e-01,\n",
            "        1.5752354e-01, -2.9450670e-01,  5.5427551e-01, -2.5043488e-01,\n",
            "       -3.9963722e-01, -1.3204336e-01,  1.3357912e-01,  9.9234047e+00,\n",
            "       -1.1104606e+01,  1.2115800e+00], dtype=float32), 'agent_1': Array([ 6.0013145e-01,  9.1801953e-01,  2.3612638e-03, -2.5788287e-02,\n",
            "        3.9568868e-01,  1.5831135e-01, -2.4281262e-01, -1.1151369e+00,\n",
            "        1.5752354e-01, -2.9450670e-01,  5.5427551e-01, -2.5043488e-01,\n",
            "       -3.9963722e-01, -1.3204336e-01,  1.3357912e-01,  9.9234047e+00,\n",
            "       -1.2994498e+01,  2.2626255e+00], dtype=float32), 'agent_2': Array([ 6.0013145e-01,  9.1801953e-01,  2.3612638e-03, -2.5788287e-02,\n",
            "        3.9568868e-01,  1.5831135e-01, -2.4281262e-01,  1.5752354e-01,\n",
            "       -1.1485875e+00, -2.9450670e-01,  5.5427551e-01, -2.5043488e-01,\n",
            "       -3.9963722e-01, -1.3204336e-01,  1.3357912e-01,  9.9234047e+00,\n",
            "       -1.0879622e+01,  7.8491402e-01], dtype=float32), 'agent_3': Array([ 6.0013145e-01,  9.1801953e-01,  2.3612638e-03, -2.5788287e-02,\n",
            "        3.9568868e-01,  1.5831135e-01, -2.4281262e-01,  1.5752354e-01,\n",
            "       -2.9450670e-01,  6.2688619e-01,  5.5427551e-01, -2.5043488e-01,\n",
            "       -3.9963722e-01, -1.3204336e-01,  1.3357912e-01,  9.9234047e+00,\n",
            "       -1.3768477e+01,  2.0483637e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.05269985 0.62643915 0.05176828 0.6283237  0.05263853 0.62535244\n",
            " 0.05349566 0.6261544 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.1166458, dtype=float32), 'agent_0': Array(-3.1166458, dtype=float32), 'agent_1': Array(-3.1166458, dtype=float32), 'agent_2': Array(-3.1166458, dtype=float32), 'agent_3': Array(-3.1166458, dtype=float32)}\n",
            "step: 450\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.7917762e-01,  8.8052964e-01,  4.8300386e-03, -3.8750950e-02,\n",
            "        4.7237971e-01, -1.2114526e-02,  7.9880619e-01, -5.2197337e-01,\n",
            "       -2.3671037e-02, -5.6353194e-01,  6.5584183e-01, -2.0503998e-02,\n",
            "       -6.1384439e-01, -6.1360609e-02, -7.7377760e-01,  4.6460950e-01,\n",
            "        9.7384967e-02,  6.0121040e+00], dtype=float32), 'agent_1': Array([ 5.7917762e-01,  8.8052964e-01,  4.8300386e-03, -3.8750950e-02,\n",
            "        4.7237971e-01, -1.2114526e-02, -5.2197337e-01, -8.5420656e-01,\n",
            "       -2.3671037e-02, -5.6353194e-01,  6.5584183e-01, -2.0503998e-02,\n",
            "       -6.1384439e-01, -6.1360609e-02, -7.7377760e-01,  4.6460950e-01,\n",
            "       -1.9844283e+00,  5.9196939e+00], dtype=float32), 'agent_2': Array([ 5.7917762e-01,  8.8052964e-01,  4.8300386e-03, -3.8750950e-02,\n",
            "        4.7237971e-01, -1.2114526e-02, -5.2197337e-01, -2.3671037e-02,\n",
            "       -9.2681569e-01, -5.6353194e-01,  6.5584183e-01, -2.0503998e-02,\n",
            "       -6.1384439e-01, -6.1360609e-02, -7.7377760e-01,  4.6460950e-01,\n",
            "       -3.5257426e-01,  5.9310040e+00], dtype=float32), 'agent_3': Array([ 5.7917762e-01,  8.8052964e-01,  4.8300386e-03, -3.8750950e-02,\n",
            "        4.7237971e-01, -1.2114526e-02, -5.2197337e-01, -2.3671037e-02,\n",
            "       -5.6353194e-01,  8.7362194e-01,  6.5584183e-01, -2.0503998e-02,\n",
            "       -6.1384439e-01, -6.1360609e-02, -7.7377760e-01,  4.6460950e-01,\n",
            "       -2.6469165e-01,  5.7989306e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.43340033 -0.93999004  0.42987183 -0.9398397   0.43260548 -0.94295025\n",
            "  0.4325189  -0.94112635]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.8448698, dtype=float32), 'agent_0': Array(0.8448698, dtype=float32), 'agent_1': Array(0.8448698, dtype=float32), 'agent_2': Array(0.8448698, dtype=float32), 'agent_3': Array(0.8448698, dtype=float32)}\n",
            "step: 451\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3142738e-01,  9.2880160e-01,  1.7400675e-03, -7.0358193e-03,\n",
            "        3.7050647e-01,  2.9027033e-01,  7.0304096e-01, -3.0198884e-01,\n",
            "        2.6921934e-01, -3.0036509e-01,  3.3903122e-01, -2.9001236e-01,\n",
            "       -1.1869311e+00,  2.0416431e-01,  1.8694150e+00, -6.1897016e+00,\n",
            "        7.7464142e+00, -4.1939120e+00], dtype=float32), 'agent_1': Array([ 5.3142738e-01,  9.2880160e-01,  1.7400675e-03, -7.0358193e-03,\n",
            "        3.7050647e-01,  2.9027033e-01, -3.0198884e-01, -9.6243089e-01,\n",
            "        2.6921934e-01, -3.0036509e-01,  3.3903122e-01, -2.9001236e-01,\n",
            "       -1.1869311e+00,  2.0416431e-01,  1.8694150e+00, -6.1897016e+00,\n",
            "        6.4946456e+00, -4.5474310e+00], dtype=float32), 'agent_2': Array([ 5.3142738e-01,  9.2880160e-01,  1.7400675e-03, -7.0358193e-03,\n",
            "        3.7050647e-01,  2.9027033e-01, -3.0198884e-01,  2.6921934e-01,\n",
            "       -1.0233225e+00, -3.0036509e-01,  3.3903122e-01, -2.9001236e-01,\n",
            "       -1.1869311e+00,  2.0416431e-01,  1.8694150e+00, -6.1897016e+00,\n",
            "        7.7395186e+00, -4.0677738e+00], dtype=float32), 'agent_3': Array([ 5.3142738e-01,  9.2880160e-01,  1.7400675e-03, -7.0358193e-03,\n",
            "        3.7050647e-01,  2.9027033e-01, -3.0198884e-01,  2.6921934e-01,\n",
            "       -3.0036509e-01,  7.7875739e-01,  3.3903122e-01, -2.9001236e-01,\n",
            "       -1.1869311e+00,  2.0416431e-01,  1.8694150e+00, -6.1897016e+00,\n",
            "        7.9129343e+00, -4.1328578e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.4113747  0.44279665 1.4087529  0.44188103 1.412254   0.44143316\n",
            " 1.410916   0.4415896 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.73582673, dtype=float32), 'agent_0': Array(-0.73582673, dtype=float32), 'agent_1': Array(-0.73582673, dtype=float32), 'agent_2': Array(-0.73582673, dtype=float32), 'agent_3': Array(-0.73582673, dtype=float32)}\n",
            "step: 452\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.0213009e-01,  9.7291756e-01, -8.1969169e-04,  1.5646352e-03,\n",
            "        2.3114572e-01,  5.9935707e-01,  7.6192755e-01,  9.6481286e-02,\n",
            "        6.1738628e-01,  1.5605858e-01,  1.2674332e+00, -1.1444092e-02,\n",
            "        1.8755198e-01, -3.3320463e-01,  2.2916196e-01, -7.8590512e-01,\n",
            "       -7.6508605e-01,  1.5084895e+00], dtype=float32), 'agent_1': Array([ 5.0213009e-01,  9.7291756e-01, -8.1969169e-04,  1.5646352e-03,\n",
            "        2.3114572e-01,  5.9935707e-01,  9.6481286e-02, -8.5625160e-01,\n",
            "        6.1738628e-01,  1.5605858e-01,  1.2674332e+00, -1.1444092e-02,\n",
            "        1.8755198e-01, -3.3320463e-01,  2.2916196e-01, -7.8590512e-01,\n",
            "        4.4269586e+00,  3.7926908e+00], dtype=float32), 'agent_2': Array([ 5.0213009e-01,  9.7291756e-01, -8.1969169e-04,  1.5646352e-03,\n",
            "        2.3114572e-01,  5.9935707e-01,  9.6481286e-02,  6.1738628e-01,\n",
            "       -8.6963946e-01,  1.5605858e-01,  1.2674332e+00, -1.1444092e-02,\n",
            "        1.8755198e-01, -3.3320463e-01,  2.2916196e-01, -7.8590512e-01,\n",
            "        2.7972576e-01,  4.3767381e+00], dtype=float32), 'agent_3': Array([ 5.0213009e-01,  9.7291756e-01, -8.1969169e-04,  1.5646352e-03,\n",
            "        2.3114572e-01,  5.9935707e-01,  9.6481286e-02,  6.1738628e-01,\n",
            "        1.5605858e-01,  8.3510679e-01,  1.2674332e+00, -1.1444092e-02,\n",
            "        1.8755198e-01, -3.3320463e-01,  2.2916196e-01, -7.8590512e-01,\n",
            "        4.9713993e+00,  1.7446377e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.32983387 -0.3510668  -0.3258932  -0.35618955 -0.32803732 -0.35602182\n",
            " -0.32658288 -0.35953534]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.6172943, dtype=float32), 'agent_0': Array(-2.6172943, dtype=float32), 'agent_1': Array(-2.6172943, dtype=float32), 'agent_2': Array(-2.6172943, dtype=float32), 'agent_3': Array(-2.6172943, dtype=float32)}\n",
            "step: 453\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.0144374e-01,  9.4818717e-01, -2.6688397e-02,  3.1484090e-02,\n",
            "        3.1502014e-01,  3.0640247e-01,  6.4374322e-01,  3.6615517e-03,\n",
            "        3.6295709e-01,  7.9550736e-02,  1.0636330e+00, -3.3378601e-03,\n",
            "       -2.3421049e-01, -5.7693189e-01,  1.7473981e+00,  5.1486688e+00,\n",
            "       -8.7319317e+00, -3.0064716e+00], dtype=float32), 'agent_1': Array([ 5.0144374e-01,  9.4818717e-01, -2.6688397e-02,  3.1484090e-02,\n",
            "        3.1502014e-01,  3.0640247e-01,  3.6615517e-03, -8.5777563e-01,\n",
            "        3.6295709e-01,  7.9550736e-02,  1.0636330e+00, -3.3378601e-03,\n",
            "       -2.3421049e-01, -5.7693189e-01,  1.7473981e+00,  5.1486688e+00,\n",
            "       -3.6281462e+00, -1.0875998e+00], dtype=float32), 'agent_2': Array([ 5.0144374e-01,  9.4818717e-01, -2.6688397e-02,  3.1484090e-02,\n",
            "        3.1502014e-01,  3.0640247e-01,  3.6615517e-03,  3.6295709e-01,\n",
            "       -8.8643003e-01,  7.9550736e-02,  1.0636330e+00, -3.3378601e-03,\n",
            "       -2.3421049e-01, -5.7693189e-01,  1.7473981e+00,  5.1486688e+00,\n",
            "       -8.1671877e+00, -1.5169672e+00], dtype=float32), 'agent_3': Array([ 5.0144374e-01,  9.4818717e-01, -2.6688397e-02,  3.1484090e-02,\n",
            "        3.1502014e-01,  3.0640247e-01,  3.6615517e-03,  3.6295709e-01,\n",
            "        7.9550736e-02,  7.4106723e-01,  1.0636330e+00, -3.3378601e-03,\n",
            "       -2.3421049e-01, -5.7693189e-01,  1.7473981e+00,  5.1486688e+00,\n",
            "       -3.2332845e+00, -2.4511211e+00], dtype=float32)}\n",
            "ctrl action chosen: [-2.121197   -0.25300285 -2.1206348  -0.25200284 -2.1181474  -0.2539526\n",
            " -2.1205359  -0.2560881 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.6492064, dtype=float32), 'agent_0': Array(1.6492064, dtype=float32), 'agent_1': Array(1.6492064, dtype=float32), 'agent_2': Array(1.6492064, dtype=float32), 'agent_3': Array(1.6492064, dtype=float32)}\n",
            "step: 454\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.4933539 ,   0.81327   ,  -0.03041523,   0.07648514,\n",
            "         0.57603544,  -0.49754584,   0.4948763 ,  -0.59573454,\n",
            "        -0.42340198,  -0.5178769 ,   0.82292557,  -0.08420944,\n",
            "        -0.3883183 ,   0.5801434 ,   1.6004852 ,  10.990554  ,\n",
            "       -15.467058  ,  -1.4754268 ], dtype=float32), 'agent_1': Array([ 0.4933539 ,  0.81327   , -0.03041523,  0.07648514,  0.57603544,\n",
            "       -0.49754584, -0.59573454, -0.9344397 , -0.42340198, -0.5178769 ,\n",
            "        0.82292557, -0.08420944, -0.3883183 ,  0.5801434 ,  1.6004852 ,\n",
            "       10.990554  , -9.956108  , -2.153279  ], dtype=float32), 'agent_2': Array([  0.4933539 ,   0.81327   ,  -0.03041523,   0.07648514,\n",
            "         0.57603544,  -0.49754584,  -0.59573454,  -0.42340198,\n",
            "        -0.97344613,  -0.5178769 ,   0.82292557,  -0.08420944,\n",
            "        -0.3883183 ,   0.5801434 ,   1.6004852 ,  10.990554  ,\n",
            "       -15.126857  ,  -2.2157152 ], dtype=float32), 'agent_3': Array([  0.4933539 ,   0.81327   ,  -0.03041523,   0.07648514,\n",
            "         0.57603544,  -0.49754584,  -0.59573454,  -0.42340198,\n",
            "        -0.5178769 ,   0.5855476 ,   0.82292557,  -0.08420944,\n",
            "        -0.3883183 ,   0.5801434 ,   1.6004852 ,  10.990554  ,\n",
            "       -11.926866  ,  -3.8825333 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.41140315 -1.3746872   0.40756416 -1.3746562   0.40964416 -1.3755695\n",
            "  0.40681836 -1.3759842 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.2251673, dtype=float32), 'agent_0': Array(-7.2251673, dtype=float32), 'agent_1': Array(-7.2251673, dtype=float32), 'agent_2': Array(-7.2251673, dtype=float32), 'agent_3': Array(-7.2251673, dtype=float32)}\n",
            "step: 455\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.4681435 ,  0.8186093 , -0.03954929,  0.13140196,  0.5577171 ,\n",
            "       -0.5112701 ,  0.45325467, -0.41316995, -0.47317305, -0.41182262,\n",
            "        0.7874489 , -0.21848679, -0.08336306,  0.39845598,  1.6088421 ,\n",
            "       -2.7356129 ,  3.0505195 , -0.5129435 ], dtype=float32), 'agent_1': Array([ 0.4681435 ,  0.8186093 , -0.03954929,  0.13140196,  0.5577171 ,\n",
            "       -0.5112701 , -0.41316995, -1.2858964 , -0.47317305, -0.41182262,\n",
            "        0.7874489 , -0.21848679, -0.08336306,  0.39845598,  1.6088421 ,\n",
            "       -2.7356129 ,  6.4411225 , -4.551276  ], dtype=float32), 'agent_2': Array([ 0.4681435 ,  0.8186093 , -0.03954929,  0.13140196,  0.5577171 ,\n",
            "       -0.5112701 , -0.41316995, -0.47317305, -1.2847624 , -0.41182262,\n",
            "        0.7874489 , -0.21848679, -0.08336306,  0.39845598,  1.6088421 ,\n",
            "       -2.7356129 ,  2.1197329 , -3.5194485 ], dtype=float32), 'agent_3': Array([ 0.4681435 ,  0.8186093 , -0.03954929,  0.13140196,  0.5577171 ,\n",
            "       -0.5112701 , -0.41316995, -0.47317305, -0.41182262,  0.44964063,\n",
            "        0.7874489 , -0.21848679, -0.08336306,  0.39845598,  1.6088421 ,\n",
            "       -2.7356129 ,  5.079028  ,  0.02041501], dtype=float32)}\n",
            "ctrl action chosen: [1.0655093 2.135187  1.062139  2.134373  1.0611176 2.130316  1.064235\n",
            " 2.1353462]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.319758, dtype=float32), 'agent_0': Array(-2.319758, dtype=float32), 'agent_1': Array(-2.319758, dtype=float32), 'agent_2': Array(-2.319758, dtype=float32), 'agent_3': Array(-2.319758, dtype=float32)}\n",
            "step: 456\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.53415567,   0.94143087,  -0.04802232,   0.06241166,\n",
            "         0.32788214,   0.17746407,   0.69746226,   0.40117955,\n",
            "         0.1097896 ,   0.32489833,   0.7909298 ,   0.38585663,\n",
            "         1.2750149 ,   0.53967714,  -2.9483137 , -12.652555  ,\n",
            "        17.04996   ,   6.7885737 ], dtype=float32), 'agent_1': Array([  0.53415567,   0.94143087,  -0.04802232,   0.06241166,\n",
            "         0.32788214,   0.17746407,   0.40117955,  -1.025916  ,\n",
            "         0.1097896 ,   0.32489833,   0.7909298 ,   0.38585663,\n",
            "         1.2750149 ,   0.53967714,  -2.9483137 , -12.652555  ,\n",
            "        18.761692  ,   6.775293  ], dtype=float32), 'agent_2': Array([  0.53415567,   0.94143087,  -0.04802232,   0.06241166,\n",
            "         0.32788214,   0.17746407,   0.40117955,   0.1097896 ,\n",
            "        -1.0497229 ,   0.32489833,   0.7909298 ,   0.38585663,\n",
            "         1.2750149 ,   0.53967714,  -2.9483137 , -12.652555  ,\n",
            "        14.32974   ,   6.131388  ], dtype=float32), 'agent_3': Array([  0.53415567,   0.94143087,  -0.04802232,   0.06241166,\n",
            "         0.32788214,   0.17746407,   0.40117955,   0.1097896 ,\n",
            "         0.32489833,   0.73801523,   0.7909298 ,   0.38585663,\n",
            "         1.2750149 ,   0.53967714,  -2.9483137 , -12.652555  ,\n",
            "        17.155447  ,   8.76849   ], dtype=float32)}\n",
            "ctrl action chosen: [1.4441952 1.0869418 1.443639  1.0859151 1.4460025 1.0863004 1.4448717\n",
            " 1.0867661]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.516916, dtype=float32), 'agent_0': Array(-9.516916, dtype=float32), 'agent_1': Array(-9.516916, dtype=float32), 'agent_2': Array(-9.516916, dtype=float32), 'agent_3': Array(-9.516916, dtype=float32)}\n",
            "step: 457\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5878012 ,  0.96931446,  0.01876394, -0.01394969,  0.24470969,\n",
            "        0.59450364,  1.1598508 ,  0.59110874,  0.43760777,  0.5671874 ,\n",
            "        0.748682  ,  0.52051544,  0.8580327 ,  3.1029508 , -4.3130956 ,\n",
            "        0.847689  ,  2.3322067 , 12.228454  ], dtype=float32), 'agent_1': Array([ 0.5878012 ,  0.96931446,  0.01876394, -0.01394969,  0.24470969,\n",
            "        0.59450364,  0.59110874, -0.5274777 ,  0.43760777,  0.5671874 ,\n",
            "        0.748682  ,  0.52051544,  0.8580327 ,  3.1029508 , -4.3130956 ,\n",
            "        0.847689  , -2.9872549 , 12.661151  ], dtype=float32), 'agent_2': Array([ 5.8780122e-01,  9.6931446e-01,  1.8763941e-02, -1.3949694e-02,\n",
            "        2.4470969e-01,  5.9450364e-01,  5.9110874e-01,  4.3760777e-01,\n",
            "       -5.2678186e-01,  5.6718743e-01,  7.4868202e-01,  5.2051544e-01,\n",
            "        8.5803270e-01,  3.1029508e+00, -4.3130956e+00,  8.4768897e-01,\n",
            "        3.2870107e+00,  1.4461852e+01], dtype=float32), 'agent_3': Array([ 0.5878012 ,  0.96931446,  0.01876394, -0.01394969,  0.24470969,\n",
            "        0.59450364,  0.59110874,  0.43760777,  0.5671874 ,  1.2577004 ,\n",
            "        0.748682  ,  0.52051544,  0.8580327 ,  3.1029508 , -4.3130956 ,\n",
            "        0.847689  , -1.2398055 , 10.087807  ], dtype=float32)}\n",
            "ctrl action chosen: [0.11279225 0.67484194 0.11056343 0.67598015 0.11204109 0.6734134\n",
            " 0.11162291 0.6746261 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.726189, dtype=float32), 'agent_0': Array(-4.726189, dtype=float32), 'agent_1': Array(-4.726189, dtype=float32), 'agent_2': Array(-4.726189, dtype=float32), 'agent_3': Array(-4.726189, dtype=float32)}\n",
            "step: 458\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.62755764,  0.9446984 ,  0.0484335 , -0.03324288,  0.32263637,\n",
            "        0.52699924,  1.2822652 ,  0.25831705,  0.4781537 ,  0.36422303,\n",
            "        0.26435852, -0.26140213,  0.7969618 ,  0.19371834, -0.2091994 ,\n",
            "        3.0265684 , -1.7744983 , -1.4398743 ], dtype=float32), 'agent_1': Array([ 0.62755764,  0.9446984 ,  0.0484335 , -0.03324288,  0.32263637,\n",
            "        0.52699924,  0.25831705, -0.47522613,  0.4781537 ,  0.36422303,\n",
            "        0.26435852, -0.26140213,  0.7969618 ,  0.19371834, -0.2091994 ,\n",
            "        3.0265684 , -6.468077  , -0.50960803], dtype=float32), 'agent_2': Array([ 0.62755764,  0.9446984 ,  0.0484335 , -0.03324288,  0.32263637,\n",
            "        0.52699924,  0.25831705,  0.4781537 , -0.47082508,  0.36422303,\n",
            "        0.26435852, -0.26140213,  0.7969618 ,  0.19371834, -0.2091994 ,\n",
            "        3.0265684 ,  1.8992863 , -1.7528819 ], dtype=float32), 'agent_3': Array([ 0.62755764,  0.9446984 ,  0.0484335 , -0.03324288,  0.32263637,\n",
            "        0.52699924,  0.25831705,  0.4781537 ,  0.36422303,  1.2668004 ,\n",
            "        0.26435852, -0.26140213,  0.7969618 ,  0.19371834, -0.2091994 ,\n",
            "        3.0265684 , -3.4395986 , -0.8080501 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.39413667  0.2897227  -0.39639407  0.29363874 -0.38882172  0.2832592\n",
            " -0.3968211   0.2902626 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.40361112, dtype=float32), 'agent_0': Array(0.40361112, dtype=float32), 'agent_1': Array(0.40361112, dtype=float32), 'agent_2': Array(0.40361112, dtype=float32), 'agent_3': Array(0.40361112, dtype=float32)}\n",
            "step: 459\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6497979 ,  0.888111  ,  0.06237657, -0.05406036,  0.45215654,\n",
            "        0.22870353,  1.2201829 , -0.18389507,  0.3793242 ,  0.0545903 ,\n",
            "        0.3841877 , -0.04434586,  0.09726286,  0.38737747, -0.7928481 ,\n",
            "        6.1291895 , -6.6189284 , -0.84011936], dtype=float32), 'agent_1': Array([ 0.6497979 ,  0.888111  ,  0.06237657, -0.05406036,  0.45215654,\n",
            "        0.22870353, -0.18389507, -0.525296  ,  0.3793242 ,  0.0545903 ,\n",
            "        0.3841877 , -0.04434586,  0.09726286,  0.38737747, -0.7928481 ,\n",
            "        6.1291895 , -9.096329  , -0.8225871 ], dtype=float32), 'agent_2': Array([ 0.6497979 ,  0.888111  ,  0.06237657, -0.05406036,  0.45215654,\n",
            "        0.22870353, -0.18389507,  0.3793242 , -0.54343164,  0.0545903 ,\n",
            "        0.3841877 , -0.04434586,  0.09726286,  0.38737747, -0.7928481 ,\n",
            "        6.1291895 , -3.150474  , -1.3064271 ], dtype=float32), 'agent_3': Array([ 0.6497979 ,  0.888111  ,  0.06237657, -0.05406036,  0.45215654,\n",
            "        0.22870353, -0.18389507,  0.3793242 ,  0.0545903 ,  1.2204328 ,\n",
            "        0.3841877 , -0.04434586,  0.09726286,  0.38737747, -0.7928481 ,\n",
            "        6.1291895 , -6.689704  , -0.66159993], dtype=float32)}\n",
            "ctrl action chosen: [-0.80745655 -0.6035583  -0.80866915 -0.602789   -0.8067125  -0.60723776\n",
            " -0.80930525 -0.60519147]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.8668432, dtype=float32), 'agent_0': Array(0.8668432, dtype=float32), 'agent_1': Array(0.8668432, dtype=float32), 'agent_2': Array(0.8668432, dtype=float32), 'agent_3': Array(0.8668432, dtype=float32)}\n",
            "step: 460\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6422637 ,  0.77327037,  0.05327042, -0.04697611,  0.630086  ,\n",
            "       -0.26183704,  0.9062639 , -0.66505903,  0.03275461, -0.46452078,\n",
            "        0.26578903,  0.1504898 , -0.3057599 ,  0.82247907,  0.9596347 ,\n",
            "        4.797577  , -6.7243676 , -8.222792  ], dtype=float32), 'agent_1': Array([ 0.6422637 ,  0.77327037,  0.05327042, -0.04697611,  0.630086  ,\n",
            "       -0.26183704, -0.66505903, -0.8312459 ,  0.03275461, -0.46452078,\n",
            "        0.26578903,  0.1504898 , -0.3057599 ,  0.82247907,  0.9596347 ,\n",
            "        4.797577  , -0.9501965 , -7.8612933 ], dtype=float32), 'agent_2': Array([ 0.6422637 ,  0.77327037,  0.05327042, -0.04697611,  0.630086  ,\n",
            "       -0.26183704, -0.66505903,  0.03275461, -0.85552335, -0.46452078,\n",
            "        0.26578903,  0.1504898 , -0.3057599 ,  0.82247907,  0.9596347 ,\n",
            "        4.797577  , -4.224586  , -7.0333824 ], dtype=float32), 'agent_3': Array([ 0.6422637 ,  0.77327037,  0.05327042, -0.04697611,  0.630086  ,\n",
            "       -0.26183704, -0.66505903,  0.03275461, -0.46452078,  0.90418386,\n",
            "        0.26578903,  0.1504898 , -0.3057599 ,  0.82247907,  0.9596347 ,\n",
            "        4.797577  , -7.3197904 , -8.24648   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.4999939   1.0080866  -0.4997413   1.01056    -0.49828663  1.0069966\n",
            " -0.4996326   1.0066881 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.75571346, dtype=float32), 'agent_0': Array(-0.75571346, dtype=float32), 'agent_1': Array(-0.75571346, dtype=float32), 'agent_2': Array(-0.75571346, dtype=float32), 'agent_3': Array(-0.75571346, dtype=float32)}\n",
            "step: 461\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6171893 ,  0.7385531 ,  0.07506371, -0.08096302,  0.66509384,\n",
            "       -0.45760122,  0.98164505, -0.5010988 , -0.06063234, -0.5884424 ,\n",
            "        0.48856735,  0.7515907 , -0.38660765, -0.5938036 , -2.6356404 ,\n",
            "        1.9451904 , -4.375347  ,  5.7796907 ], dtype=float32), 'agent_1': Array([ 0.6171893 ,  0.7385531 ,  0.07506371, -0.08096302,  0.66509384,\n",
            "       -0.45760122, -0.5010988 , -0.7781858 , -0.06063234, -0.5884424 ,\n",
            "        0.48856735,  0.7515907 , -0.38660765, -0.5938036 , -2.6356404 ,\n",
            "        1.9451904 ,  4.0342026 ,  4.955974  ], dtype=float32), 'agent_2': Array([ 0.6171893 ,  0.7385531 ,  0.07506371, -0.08096302,  0.66509384,\n",
            "       -0.45760122, -0.5010988 , -0.06063234, -0.73620856, -0.5884424 ,\n",
            "        0.48856735,  0.7515907 , -0.38660765, -0.5938036 , -2.6356404 ,\n",
            "        1.9451904 , -2.75427   ,  5.9289975 ], dtype=float32), 'agent_3': Array([ 0.6171893 ,  0.7385531 ,  0.07506371, -0.08096302,  0.66509384,\n",
            "       -0.45760122, -0.5010988 , -0.06063234, -0.5884424 ,  0.9804404 ,\n",
            "        0.48856735,  0.7515907 , -0.38660765, -0.5938036 , -2.6356404 ,\n",
            "        1.9451904 , -0.79697615,  5.3179827 ], dtype=float32)}\n",
            "ctrl action chosen: [1.5498544  0.2848674  1.551199   0.28181338 1.5495424  0.28443617\n",
            " 1.5505462  0.28331086]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0813758, dtype=float32), 'agent_0': Array(-1.0813758, dtype=float32), 'agent_1': Array(-1.0813758, dtype=float32), 'agent_2': Array(-1.0813758, dtype=float32), 'agent_3': Array(-1.0813758, dtype=float32)}\n",
            "step: 462\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8913785e-01,  8.6588001e-01,  1.2089459e-01, -9.9112839e-02,\n",
            "        4.7519794e-01,  8.3146635e-03,  1.1860467e+00,  3.8543215e-01,\n",
            "        4.7634572e-01,  2.5050058e-03,  4.7159195e-02,  6.3543320e-01,\n",
            "       -8.3489418e-01,  4.2447889e-01, -2.0555568e+00, -1.1720308e+01,\n",
            "        1.2902544e+01,  4.5957665e+00], dtype=float32), 'agent_1': Array([ 5.8913785e-01,  8.6588001e-01,  1.2089459e-01, -9.9112839e-02,\n",
            "        4.7519794e-01,  8.3146635e-03,  3.8543215e-01, -5.6258357e-01,\n",
            "        4.7634572e-01,  2.5050058e-03,  4.7159195e-02,  6.3543320e-01,\n",
            "       -8.3489418e-01,  4.2447889e-01, -2.0555568e+00, -1.1720308e+01,\n",
            "        1.9955439e+01,  4.8505034e+00], dtype=float32), 'agent_2': Array([ 5.8913785e-01,  8.6588001e-01,  1.2089459e-01, -9.9112839e-02,\n",
            "        4.7519794e-01,  8.3146635e-03,  3.8543215e-01,  4.7634572e-01,\n",
            "       -5.2125573e-01,  2.5050058e-03,  4.7159195e-02,  6.3543320e-01,\n",
            "       -8.3489418e-01,  4.2447889e-01, -2.0555568e+00, -1.1720308e+01,\n",
            "        1.4198423e+01,  5.3616762e+00], dtype=float32), 'agent_3': Array([ 5.8913785e-01,  8.6588001e-01,  1.2089459e-01, -9.9112839e-02,\n",
            "        4.7519794e-01,  8.3146635e-03,  3.8543215e-01,  4.7634572e-01,\n",
            "        2.5050058e-03,  1.1937532e+00,  4.7159195e-02,  6.3543320e-01,\n",
            "       -8.3489418e-01,  4.2447889e-01, -2.0555568e+00, -1.1720308e+01,\n",
            "        1.5826615e+01,  5.1551156e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.24017    -0.37782586  1.2351596  -0.38095853  1.2400672  -0.37933442\n",
            "  1.2387488  -0.37941694]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.8253274, dtype=float32), 'agent_0': Array(-3.8253274, dtype=float32), 'agent_1': Array(-3.8253274, dtype=float32), 'agent_2': Array(-3.8253274, dtype=float32), 'agent_3': Array(-3.8253274, dtype=float32)}\n",
            "step: 463\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5388682 ,  0.8962536 ,  0.14542876, -0.09989243,  0.40694165,\n",
            "        0.29520658,  1.2217283 ,  0.64906   ,  0.57773036,  0.40249944,\n",
            "        0.9634495 , -0.00572205, -0.54051876,  0.11564576, -0.03447315,\n",
            "       -0.40661943,  4.0077667 , -0.7346523 ], dtype=float32), 'agent_1': Array([ 0.5388682 ,  0.8962536 ,  0.14542876, -0.09989243,  0.40694165,\n",
            "        0.29520658,  0.64906   , -0.51640964,  0.57773036,  0.40249944,\n",
            "        0.9634495 , -0.00572205, -0.54051876,  0.11564576, -0.03447315,\n",
            "       -0.40661943, -1.340431  ,  0.00932907], dtype=float32), 'agent_2': Array([ 0.5388682 ,  0.8962536 ,  0.14542876, -0.09989243,  0.40694165,\n",
            "        0.29520658,  0.64906   ,  0.57773036, -0.5045408 ,  0.40249944,\n",
            "        0.9634495 , -0.00572205, -0.54051876,  0.11564576, -0.03447315,\n",
            "       -0.40661943, -1.2520679 ,  0.56657565], dtype=float32), 'agent_3': Array([ 5.3886819e-01,  8.9625359e-01,  1.4542876e-01, -9.9892430e-02,\n",
            "        4.0694165e-01,  2.9520658e-01,  6.4906001e-01,  5.7773036e-01,\n",
            "        4.0249944e-01,  1.2190206e+00,  9.6344948e-01, -5.7220459e-03,\n",
            "       -5.4051876e-01,  1.1564576e-01, -3.4473147e-02, -4.0661943e-01,\n",
            "        6.2216434e+00, -6.9188625e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 0.93127453 -1.1674782   0.9259375  -1.1588591   0.92709714 -1.1625618\n",
            "  0.93057483 -1.1684784 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8985665, dtype=float32), 'agent_0': Array(-1.8985665, dtype=float32), 'agent_1': Array(-1.8985665, dtype=float32), 'agent_2': Array(-1.8985665, dtype=float32), 'agent_3': Array(-1.8985665, dtype=float32)}\n",
            "step: 464\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5611713 ,   0.90003747,   0.0932709 ,  -0.07620817,\n",
            "         0.41883817,   0.535657  ,   0.86999756,   0.48618886,\n",
            "         0.52435964,   0.6244348 ,   0.86898804,   0.12903214,\n",
            "         1.0382771 ,  -2.6532612 ,   2.8879793 ,   1.4753307 ,\n",
            "         4.514853  , -11.063665  ], dtype=float32), 'agent_1': Array([ 0.5611713 ,  0.90003747,  0.0932709 , -0.07620817,  0.41883817,\n",
            "        0.535657  ,  0.48618886, -0.7157044 ,  0.52435964,  0.6244348 ,\n",
            "        0.86898804,  0.12903214,  1.0382771 , -2.6532612 ,  2.8879793 ,\n",
            "        1.4753307 , -3.056697  , -6.3895006 ], dtype=float32), 'agent_2': Array([ 0.5611713 ,  0.90003747,  0.0932709 , -0.07620817,  0.41883817,\n",
            "        0.535657  ,  0.48618886,  0.52435964, -0.68425226,  0.6244348 ,\n",
            "        0.86898804,  0.12903214,  1.0382771 , -2.6532612 ,  2.8879793 ,\n",
            "        1.4753307 , -0.26214927, -6.4899387 ], dtype=float32), 'agent_3': Array([ 0.5611713 ,  0.90003747,  0.0932709 , -0.07620817,  0.41883817,\n",
            "        0.535657  ,  0.48618886,  0.52435964,  0.6244348 ,  0.90555596,\n",
            "        0.86898804,  0.12903214,  1.0382771 , -2.6532612 ,  2.8879793 ,\n",
            "        1.4753307 ,  0.653362  , -9.715858  ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.6507226  -0.06891726  0.64469033 -0.06857216  0.6465747  -0.07153948\n",
            "  0.6476305  -0.06976175]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.4134083, dtype=float32), 'agent_0': Array(-2.4134083, dtype=float32), 'agent_1': Array(-2.4134083, dtype=float32), 'agent_2': Array(-2.4134083, dtype=float32), 'agent_3': Array(-2.4134083, dtype=float32)}\n",
            "step: 465\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6062355 ,  0.8782244 ,  0.02119226, -0.06151956,  0.47380203,\n",
            "        0.6015775 ,  0.49383026,  0.31428963,  0.5349375 ,  0.5189116 ,\n",
            "        0.11715889,  0.49991608,  0.7790327 , -1.7521647 ,  1.7788182 ,\n",
            "        2.0428724 ,  0.05942896, -4.973135  ], dtype=float32), 'agent_1': Array([ 0.6062355 ,  0.8782244 ,  0.02119226, -0.06151956,  0.47380203,\n",
            "        0.6015775 ,  0.31428963, -0.86670935,  0.5349375 ,  0.5189116 ,\n",
            "        0.11715889,  0.49991608,  0.7790327 , -1.7521647 ,  1.7788182 ,\n",
            "        2.0428724 , -1.6664879 , -2.0903609 ], dtype=float32), 'agent_2': Array([ 0.6062355 ,  0.8782244 ,  0.02119226, -0.06151956,  0.47380203,\n",
            "        0.6015775 ,  0.31428963,  0.5349375 , -0.88751197,  0.5189116 ,\n",
            "        0.11715889,  0.49991608,  0.7790327 , -1.7521647 ,  1.7788182 ,\n",
            "        2.0428724 ,  1.0305067 , -3.802847  ], dtype=float32), 'agent_3': Array([ 0.6062355 ,  0.8782244 ,  0.02119226, -0.06151956,  0.47380203,\n",
            "        0.6015775 ,  0.31428963,  0.5349375 ,  0.5189116 ,  0.5892977 ,\n",
            "        0.11715889,  0.49991608,  0.7790327 , -1.7521647 ,  1.7788182 ,\n",
            "        2.0428724 , -2.348913  , -5.5052347 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.04638019  0.04704514 -0.04817379  0.05274181 -0.0440704   0.04523389\n",
            " -0.04738168  0.04586406]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.60653776, dtype=float32), 'agent_0': Array(0.60653776, dtype=float32), 'agent_1': Array(0.60653776, dtype=float32), 'agent_2': Array(0.60653776, dtype=float32), 'agent_3': Array(0.60653776, dtype=float32)}\n",
            "step: 466\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6420003 ,  0.8319685 , -0.02110546, -0.04351069,  0.55271137,\n",
            "        0.48114038,  0.50998586,  0.13331267,  0.5081468 ,  0.2855459 ,\n",
            "       -0.03499985,  0.54540634,  0.759387  , -1.012684  ,  0.75948614,\n",
            "        3.050434  , -2.386283  ,  0.56924784], dtype=float32), 'agent_1': Array([ 0.6420003 ,  0.8319685 , -0.02110546, -0.04351069,  0.55271137,\n",
            "        0.48114038,  0.13331267, -0.9438542 ,  0.5081468 ,  0.2855459 ,\n",
            "       -0.03499985,  0.54540634,  0.759387  , -1.012684  ,  0.75948614,\n",
            "        3.050434  , -2.422647  , -0.6093488 ], dtype=float32), 'agent_2': Array([ 0.6420003 ,  0.8319685 , -0.02110546, -0.04351069,  0.55271137,\n",
            "        0.48114038,  0.13331267,  0.5081468 , -1.011526  ,  0.2855459 ,\n",
            "       -0.03499985,  0.54540634,  0.759387  , -1.012684  ,  0.75948614,\n",
            "        3.050434  ,  0.05194662, -1.1678369 ], dtype=float32), 'agent_3': Array([ 0.6420003 ,  0.8319685 , -0.02110546, -0.04351069,  0.55271137,\n",
            "        0.48114038,  0.13331267,  0.5081468 ,  0.2855459 ,  0.49868554,\n",
            "       -0.03499985,  0.54540634,  0.759387  , -1.012684  ,  0.75948614,\n",
            "        3.050434  , -3.46931   ,  1.1943204 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.78968936 -0.8869997  -0.7902588  -0.8869748  -0.78565764 -0.89415586\n",
            " -0.79099774 -0.88619095]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.94075847, dtype=float32), 'agent_0': Array(0.94075847, dtype=float32), 'agent_1': Array(0.94075847, dtype=float32), 'agent_2': Array(0.94075847, dtype=float32), 'agent_3': Array(0.94075847, dtype=float32)}\n",
            "step: 467\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.69145405e-01,  6.74644828e-01, -7.31414035e-02, -1.09416945e-02,\n",
            "        7.34428406e-01, -4.65003438e-02,  4.98605460e-01, -3.89906257e-01,\n",
            "        8.80288482e-02, -2.81428874e-01, -1.16920471e-01,  4.39834595e-01,\n",
            "        3.56006622e-01, -2.65711218e-01,  1.73276949e+00,  1.15946589e+01,\n",
            "       -1.29625006e+01,  2.76849747e-01], dtype=float32), 'agent_1': Array([ 6.69145405e-01,  6.74644828e-01, -7.31414035e-02, -1.09416945e-02,\n",
            "        7.34428406e-01, -4.65003438e-02, -3.89906257e-01, -1.19622552e+00,\n",
            "        8.80288482e-02, -2.81428874e-01, -1.16920471e-01,  4.39834595e-01,\n",
            "        3.56006622e-01, -2.65711218e-01,  1.73276949e+00,  1.15946589e+01,\n",
            "       -1.28894043e+01, -6.62888336e+00], dtype=float32), 'agent_2': Array([ 6.69145405e-01,  6.74644828e-01, -7.31414035e-02, -1.09416945e-02,\n",
            "        7.34428406e-01, -4.65003438e-02, -3.89906257e-01,  8.80288482e-02,\n",
            "       -1.27030265e+00, -2.81428874e-01, -1.16920471e-01,  4.39834595e-01,\n",
            "        3.56006622e-01, -2.65711218e-01,  1.73276949e+00,  1.15946589e+01,\n",
            "       -1.09761229e+01, -3.05676246e+00], dtype=float32), 'agent_3': Array([ 6.69145405e-01,  6.74644828e-01, -7.31414035e-02, -1.09416945e-02,\n",
            "        7.34428406e-01, -4.65003438e-02, -3.89906257e-01,  8.80288482e-02,\n",
            "       -2.81428874e-01,  4.96243477e-01, -1.16920471e-01,  4.39834595e-01,\n",
            "        3.56006622e-01, -2.65711218e-01,  1.73276949e+00,  1.15946589e+01,\n",
            "       -1.36156874e+01,  5.61037958e-01], dtype=float32)}\n",
            "ctrl action chosen: [ 1.2719064  -0.79503167  1.2675111  -0.7950765   1.2692053  -0.7961713\n",
            "  1.2715571  -0.79607797]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8997378, dtype=float32), 'agent_0': Array(-1.8997378, dtype=float32), 'agent_1': Array(-1.8997378, dtype=float32), 'agent_2': Array(-1.8997378, dtype=float32), 'agent_3': Array(-1.8997378, dtype=float32)}\n",
            "step: 468\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.70913279e-01,  7.39475787e-01, -1.00103311e-01, -7.25843385e-03,\n",
            "        6.65659308e-01,  2.45509341e-01,  4.99236286e-01, -1.04440816e-01,\n",
            "        4.71898139e-01, -1.44577902e-02,  1.64079666e-01,  6.01577759e-01,\n",
            "       -4.45091724e-01, -1.06181812e+00,  1.04512763e+00, -8.44867325e+00,\n",
            "        1.22759018e+01, -5.73598146e-01], dtype=float32), 'agent_1': Array([ 6.70913279e-01,  7.39475787e-01, -1.00103311e-01, -7.25843385e-03,\n",
            "        6.65659308e-01,  2.45509341e-01, -1.04440816e-01, -1.28747773e+00,\n",
            "        4.71898139e-01, -1.44577902e-02,  1.64079666e-01,  6.01577759e-01,\n",
            "       -4.45091724e-01, -1.06181812e+00,  1.04512763e+00, -8.44867325e+00,\n",
            "        1.18348923e+01, -1.96199417e-01], dtype=float32), 'agent_2': Array([ 6.70913279e-01,  7.39475787e-01, -1.00103311e-01, -7.25843385e-03,\n",
            "        6.65659308e-01,  2.45509341e-01, -1.04440816e-01,  4.71898139e-01,\n",
            "       -1.27808404e+00, -1.44577902e-02,  1.64079666e-01,  6.01577759e-01,\n",
            "       -4.45091724e-01, -1.06181812e+00,  1.04512763e+00, -8.44867325e+00,\n",
            "        1.35689039e+01, -2.59578973e-01], dtype=float32), 'agent_3': Array([ 6.70913279e-01,  7.39475787e-01, -1.00103311e-01, -7.25843385e-03,\n",
            "        6.65659308e-01,  2.45509341e-01, -1.04440816e-01,  4.71898139e-01,\n",
            "       -1.44577902e-02,  5.04358113e-01,  1.64079666e-01,  6.01577759e-01,\n",
            "       -4.45091724e-01, -1.06181812e+00,  1.04512763e+00, -8.44867325e+00,\n",
            "        1.17025032e+01,  1.29332170e-01], dtype=float32)}\n",
            "ctrl action chosen: [0.2291956  2.6504378  0.23030062 2.651629   0.22939867 2.648045\n",
            " 0.22916253 2.6498396 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.5284624, dtype=float32), 'agent_0': Array(-3.5284624, dtype=float32), 'agent_1': Array(-3.5284624, dtype=float32), 'agent_2': Array(-3.5284624, dtype=float32), 'agent_3': Array(-3.5284624, dtype=float32)}\n",
            "step: 469\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6331242 ,  0.7690674 , -0.10367039, -0.02990176,  0.6299951 ,\n",
            "        0.5021465 ,  0.74754167,  0.1582933 ,  0.5905667 ,  0.21984899,\n",
            "        0.27594566,  1.1981964 , -0.8415818 , -0.19535007, -0.7985384 ,\n",
            "        0.13319474,  2.7584586 ,  6.64373   ], dtype=float32), 'agent_1': Array([ 0.6331242 ,  0.7690674 , -0.10367039, -0.02990176,  0.6299951 ,\n",
            "        0.5021465 ,  0.1582933 , -1.0400959 ,  0.5905667 ,  0.21984899,\n",
            "        0.27594566,  1.1981964 , -0.8415818 , -0.19535007, -0.7985384 ,\n",
            "        0.13319474,  3.213962  ,  7.811621  ], dtype=float32), 'agent_2': Array([ 0.6331242 ,  0.7690674 , -0.10367039, -0.02990176,  0.6299951 ,\n",
            "        0.5021465 ,  0.1582933 ,  0.5905667 , -1.003063  ,  0.21984899,\n",
            "        0.27594566,  1.1981964 , -0.8415818 , -0.19535007, -0.7985384 ,\n",
            "        0.13319474, -2.2158835 ,  8.23973   ], dtype=float32), 'agent_3': Array([ 0.6331242 ,  0.7690674 , -0.10367039, -0.02990176,  0.6299951 ,\n",
            "        0.5021465 ,  0.1582933 ,  0.5905667 ,  0.21984899,  0.8247351 ,\n",
            "        0.27594566,  1.1981964 , -0.8415818 , -0.19535007, -0.7985384 ,\n",
            "        0.13319474,  2.2726064 ,  7.7388964 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.8157132 -1.6337436 -1.8166534 -1.6328388 -1.8170066 -1.6371211\n",
            " -1.8166658 -1.6350001]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-12.913532, dtype=float32), 'agent_0': Array(-12.913532, dtype=float32), 'agent_1': Array(-12.913532, dtype=float32), 'agent_2': Array(-12.913532, dtype=float32), 'agent_3': Array(-12.913532, dtype=float32)}\n",
            "step: 470\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6243254 ,   0.56886196,  -0.1293722 ,   0.02012504,\n",
            "         0.81194454,  -0.05011395,   0.566921  ,  -0.3641864 ,\n",
            "        -0.1792555 ,  -0.33070922,   1.0450363 ,   0.8031845 ,\n",
            "         0.28945208,   0.4512721 ,   1.5630713 ,  14.14231   ,\n",
            "       -15.938263  ,  -5.6607585 ], dtype=float32), 'agent_1': Array([  0.6243254 ,   0.56886196,  -0.1293722 ,   0.02012504,\n",
            "         0.81194454,  -0.05011395,  -0.3641864 ,  -1.0449831 ,\n",
            "        -0.1792555 ,  -0.33070922,   1.0450363 ,   0.8031845 ,\n",
            "         0.28945208,   0.4512721 ,   1.5630713 ,  14.14231   ,\n",
            "       -14.493408  ,  -2.6948469 ], dtype=float32), 'agent_2': Array([  0.6243254 ,   0.56886196,  -0.1293722 ,   0.02012504,\n",
            "         0.81194454,  -0.05011395,  -0.3641864 ,  -0.1792555 ,\n",
            "        -0.9938171 ,  -0.33070922,   1.0450363 ,   0.8031845 ,\n",
            "         0.28945208,   0.4512721 ,   1.5630713 ,  14.14231   ,\n",
            "       -19.82194   ,  -2.2937098 ], dtype=float32), 'agent_3': Array([  0.6243254 ,   0.56886196,  -0.1293722 ,   0.02012504,\n",
            "         0.81194454,  -0.05011395,  -0.3641864 ,  -0.1792555 ,\n",
            "        -0.33070922,   0.7341141 ,   1.0450363 ,   0.8031845 ,\n",
            "         0.28945208,   0.4512721 ,   1.5630713 ,  14.14231   ,\n",
            "       -14.3297    ,  -3.8242896 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.75930333 -2.8327253  -0.75935185 -2.8319948  -0.75658864 -2.8325584\n",
            " -0.7602019  -2.8329577 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-10.456657, dtype=float32), 'agent_0': Array(-10.456657, dtype=float32), 'agent_1': Array(-10.456657, dtype=float32), 'agent_2': Array(-10.456657, dtype=float32), 'agent_3': Array(-10.456657, dtype=float32)}\n",
            "step: 471\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6206377 ,  0.44671977, -0.13840589,  0.07842523,  0.88041747,\n",
            "       -0.4667505 ,  0.45209718, -0.56332695, -0.6081712 , -0.55022126,\n",
            "        0.7800579 ,  0.46663284, -0.24907589,  1.4657298 ,  1.1591705 ,\n",
            "        1.2470754 , -3.6050327 ,  0.02946142], dtype=float32), 'agent_1': Array([ 0.6206377 ,  0.44671977, -0.13840589,  0.07842523,  0.88041747,\n",
            "       -0.4667505 , -0.56332695, -1.292124  , -0.6081712 , -0.55022126,\n",
            "        0.7800579 ,  0.46663284, -0.24907589,  1.4657298 ,  1.1591705 ,\n",
            "        1.2470754 ,  1.2095394 , -3.1477313 ], dtype=float32), 'agent_2': Array([ 0.6206377 ,  0.44671977, -0.13840589,  0.07842523,  0.88041747,\n",
            "       -0.4667505 , -0.56332695, -0.6081712 , -1.2618394 , -0.55022126,\n",
            "        0.7800579 ,  0.46663284, -0.24907589,  1.4657298 ,  1.1591705 ,\n",
            "        1.2470754 , -0.6225537 , -5.9733353 ], dtype=float32), 'agent_3': Array([ 0.6206377 ,  0.44671977, -0.13840589,  0.07842523,  0.88041747,\n",
            "       -0.4667505 , -0.56332695, -0.6081712 , -0.55022126,  0.46278197,\n",
            "        0.7800579 ,  0.46663284, -0.24907589,  1.4657298 ,  1.1591705 ,\n",
            "        1.2470754 ,  0.60874736, -4.7152357 ], dtype=float32)}\n",
            "ctrl action chosen: [0.71270305 1.1527635  0.71545327 1.1476401  0.71294725 1.1447707\n",
            " 0.71271384 1.1468662 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-15.214112, dtype=float32), 'agent_0': Array(-15.214112, dtype=float32), 'agent_1': Array(-15.214112, dtype=float32), 'agent_2': Array(-15.214112, dtype=float32), 'agent_3': Array(-15.214112, dtype=float32)}\n",
            "step: 472\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.1503971e-01,  5.7815558e-01, -1.2156394e-01,  3.2194305e-02,\n",
            "        8.0617732e-01, -1.5394112e-01,  7.2610509e-01,  5.7094572e-03,\n",
            "       -2.0560850e-01, -4.7423832e-02,  7.1725845e-01,  9.4728470e-01,\n",
            "        3.5023689e-02,  1.7993560e-01, -1.8645779e+00, -9.5065145e+00,\n",
            "        9.8272219e+00,  6.6707392e+00], dtype=float32), 'agent_1': Array([ 6.1503971e-01,  5.7815558e-01, -1.2156394e-01,  3.2194305e-02,\n",
            "        8.0617732e-01, -1.5394112e-01,  5.7094572e-03, -1.0773309e+00,\n",
            "       -2.0560850e-01, -4.7423832e-02,  7.1725845e-01,  9.4728470e-01,\n",
            "        3.5023689e-02,  1.7993560e-01, -1.8645779e+00, -9.5065145e+00,\n",
            "        1.5633619e+01,  5.9574375e+00], dtype=float32), 'agent_2': Array([ 6.1503971e-01,  5.7815558e-01, -1.2156394e-01,  3.2194305e-02,\n",
            "        8.0617732e-01, -1.5394112e-01,  5.7094572e-03, -2.0560850e-01,\n",
            "       -1.1249952e+00, -4.7423832e-02,  7.1725845e-01,  9.4728470e-01,\n",
            "        3.5023689e-02,  1.7993560e-01, -1.8645779e+00, -9.5065145e+00,\n",
            "        1.2273478e+01,  3.3674943e+00], dtype=float32), 'agent_3': Array([ 6.1503971e-01,  5.7815558e-01, -1.2156394e-01,  3.2194305e-02,\n",
            "        8.0617732e-01, -1.5394112e-01,  5.7094572e-03, -2.0560850e-01,\n",
            "       -4.7423832e-02,  6.4702487e-01,  7.1725845e-01,  9.4728470e-01,\n",
            "        3.5023689e-02,  1.7993560e-01, -1.8645779e+00, -9.5065145e+00,\n",
            "        1.3899045e+01,  5.2770586e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 1.3168684  -0.19244507  1.315086   -0.19536719  1.315647   -0.19443397\n",
            "  1.3149918  -0.19451901]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.8564317, dtype=float32), 'agent_0': Array(-1.8564317, dtype=float32), 'agent_1': Array(-1.8564317, dtype=float32), 'agent_2': Array(-1.8564317, dtype=float32), 'agent_3': Array(-1.8564317, dtype=float32)}\n",
            "step: 473\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.63473624,  0.74300385, -0.09503096,  0.02315428,  0.6621014 ,\n",
            "        0.49704486,  0.7817204 ,  0.6447097 ,  0.43016052,  0.59381634,\n",
            "        0.38905144,  0.12636185,  0.46765804,  1.9729683 , -0.18322837,\n",
            "       -0.9972387 ,  7.4595203 , -0.7085054 ], dtype=float32), 'agent_1': Array([ 0.63473624,  0.74300385, -0.09503096,  0.02315428,  0.6621014 ,\n",
            "        0.49704486,  0.6447097 , -0.9694728 ,  0.43016052,  0.59381634,\n",
            "        0.38905144,  0.12636185,  0.46765804,  1.9729683 , -0.18322837,\n",
            "       -0.9972387 ,  0.06315683,  1.737405  ], dtype=float32), 'agent_2': Array([ 0.63473624,  0.74300385, -0.09503096,  0.02315428,  0.6621014 ,\n",
            "        0.49704486,  0.6447097 ,  0.43016052, -1.0725468 ,  0.59381634,\n",
            "        0.38905144,  0.12636185,  0.46765804,  1.9729683 , -0.18322837,\n",
            "       -0.9972387 ,  5.780789  ,  2.9720523 ], dtype=float32), 'agent_3': Array([ 0.63473624,  0.74300385, -0.09503096,  0.02315428,  0.6621014 ,\n",
            "        0.49704486,  0.6447097 ,  0.43016052,  0.59381634,  0.7108306 ,\n",
            "        0.38905144,  0.12636185,  0.46765804,  1.9729683 , -0.18322837,\n",
            "       -0.9972387 ,  2.5145895 ,  0.9265872 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.353101   -1.8371432   0.35060728 -1.8274882   0.35383576 -1.83647\n",
            "  0.3531611  -1.8338081 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.131101, dtype=float32), 'agent_0': Array(-2.131101, dtype=float32), 'agent_1': Array(-2.131101, dtype=float32), 'agent_2': Array(-2.131101, dtype=float32), 'agent_3': Array(-2.131101, dtype=float32)}\n",
            "step: 474\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6441536 ,  0.7051857 , -0.08879004,  0.06575274,  0.7003615 ,\n",
            "        0.557461  ,  0.520319  ,  0.4792221 ,  0.53646445,  0.5261401 ,\n",
            "        0.33574104, -0.18939972, -0.06828308,  0.5792822 ,  1.787911  ,\n",
            "        2.9986336 , -0.817723  , -7.1091714 ], dtype=float32), 'agent_1': Array([ 0.6441536 ,  0.7051857 , -0.08879004,  0.06575274,  0.7003615 ,\n",
            "        0.557461  ,  0.4792221 , -1.1922405 ,  0.53646445,  0.5261401 ,\n",
            "        0.33574104, -0.18939972, -0.06828308,  0.5792822 ,  1.787911  ,\n",
            "        2.9986336 , -4.5246572 , -7.6112895 ], dtype=float32), 'agent_2': Array([ 0.6441536 ,  0.7051857 , -0.08879004,  0.06575274,  0.7003615 ,\n",
            "        0.557461  ,  0.4792221 ,  0.53646445, -1.1920846 ,  0.5261401 ,\n",
            "        0.33574104, -0.18939972, -0.06828308,  0.5792822 ,  1.787911  ,\n",
            "        2.9986336 ,  1.4443552 , -6.3037133 ], dtype=float32), 'agent_3': Array([ 0.6441536 ,  0.7051857 , -0.08879004,  0.06575274,  0.7003615 ,\n",
            "        0.557461  ,  0.4792221 ,  0.53646445,  0.5261401 ,  0.5223241 ,\n",
            "        0.33574104, -0.18939972, -0.06828308,  0.5792822 ,  1.787911  ,\n",
            "        2.9986336 , -2.2666116 , -6.5919814 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9077172  1.3311093 -0.9090243  1.3297337 -0.9056815  1.3307339\n",
            " -0.9079024  1.3305826]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.611094, dtype=float32), 'agent_0': Array(-5.611094, dtype=float32), 'agent_1': Array(-5.611094, dtype=float32), 'agent_2': Array(-5.611094, dtype=float32), 'agent_3': Array(-5.611094, dtype=float32)}\n",
            "step: 475\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.2783998e-01,  4.7274917e-01, -1.3994114e-02,  1.0007718e-01,\n",
            "        8.7538391e-01,  1.3656975e-03,  6.4232814e-01, -2.8888473e-01,\n",
            "        7.3393069e-02, -1.3439879e-01,  6.4754486e-02,  2.2649765e-01,\n",
            "       -3.9471388e-01,  1.5074080e+00, -1.8194630e+00,  1.3531401e+01,\n",
            "       -1.4073283e+01,  4.0959282e+00], dtype=float32), 'agent_1': Array([ 6.2783998e-01,  4.7274917e-01, -1.3994114e-02,  1.0007718e-01,\n",
            "        8.7538391e-01,  1.3656975e-03, -2.8888473e-01, -1.1229346e+00,\n",
            "        7.3393069e-02, -1.3439879e-01,  6.4754486e-02,  2.2649765e-01,\n",
            "       -3.9471388e-01,  1.5074080e+00, -1.8194630e+00,  1.3531401e+01,\n",
            "       -1.6456797e+01,  3.3497090e+00], dtype=float32), 'agent_2': Array([ 6.2783998e-01,  4.7274917e-01, -1.3994114e-02,  1.0007718e-01,\n",
            "        8.7538391e-01,  1.3656975e-03, -2.8888473e-01,  7.3393069e-02,\n",
            "       -1.0942116e+00, -1.3439879e-01,  6.4754486e-02,  2.2649765e-01,\n",
            "       -3.9471388e-01,  1.5074080e+00, -1.8194630e+00,  1.3531401e+01,\n",
            "       -1.2204886e+01,  4.3150220e+00], dtype=float32), 'agent_3': Array([ 6.2783998e-01,  4.7274917e-01, -1.3994114e-02,  1.0007718e-01,\n",
            "        8.7538391e-01,  1.3656975e-03, -2.8888473e-01,  7.3393069e-02,\n",
            "       -1.3439879e-01,  6.4601463e-01,  6.4754486e-02,  2.2649765e-01,\n",
            "       -3.9471388e-01,  1.5074080e+00, -1.8194630e+00,  1.3531401e+01,\n",
            "       -1.5373123e+01,  4.1154923e+00], dtype=float32)}\n",
            "ctrl action chosen: [1.2460961 1.5232847 1.2438233 1.5238659 1.2466807 1.5242577 1.2455239\n",
            " 1.5231082]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.0413322, dtype=float32), 'agent_0': Array(-4.0413322, dtype=float32), 'agent_1': Array(-4.0413322, dtype=float32), 'agent_2': Array(-4.0413322, dtype=float32), 'agent_3': Array(-4.0413322, dtype=float32)}\n",
            "step: 476\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6322296 ,  0.5444503 ,  0.03161352,  0.10644684,  0.8314106 ,\n",
            "        0.32157278,  0.9527709 , -0.08825901,  0.4263068 ,  0.09530436,\n",
            "        0.35095215,  0.40540695,  0.40339231,  1.0843283 , -2.7430375 ,\n",
            "       -8.367539  , 13.364085  ,  8.932425  ], dtype=float32), 'agent_1': Array([ 0.6322296 ,  0.5444503 ,  0.03161352,  0.10644684,  0.8314106 ,\n",
            "        0.32157278, -0.08825901, -0.83728147,  0.4263068 ,  0.09530436,\n",
            "        0.35095215,  0.40540695,  0.40339231,  1.0843283 , -2.7430375 ,\n",
            "       -8.367539  , 10.759915  ,  8.832223  ], dtype=float32), 'agent_2': Array([ 0.6322296 ,  0.5444503 ,  0.03161352,  0.10644684,  0.8314106 ,\n",
            "        0.32157278, -0.08825901,  0.4263068 , -0.7457725 ,  0.09530436,\n",
            "        0.35095215,  0.40540695,  0.40339231,  1.0843283 , -2.7430375 ,\n",
            "       -8.367539  , 13.447192  , 10.278302  ], dtype=float32), 'agent_3': Array([ 0.6322296 ,  0.5444503 ,  0.03161352,  0.10644684,  0.8314106 ,\n",
            "        0.32157278, -0.08825901,  0.4263068 ,  0.09530436,  0.9202262 ,\n",
            "        0.35095215,  0.40540695,  0.40339231,  1.0843283 , -2.7430375 ,\n",
            "       -8.367539  , 10.854339  ,  6.4711485 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.44620776 -0.29498303 -0.44698665 -0.29413086 -0.44599828 -0.29576662\n",
            " -0.44705898 -0.2961858 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-6.6077924, dtype=float32), 'agent_0': Array(-6.6077924, dtype=float32), 'agent_1': Array(-6.6077924, dtype=float32), 'agent_2': Array(-6.6077924, dtype=float32), 'agent_3': Array(-6.6077924, dtype=float32)}\n",
            "step: 477\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.65564054,  0.5252983 ,  0.08939933,  0.09745044,  0.8405789 ,\n",
            "        0.43023136,  1.2225838 , -0.15721908,  0.5263352 ,  0.0531265 ,\n",
            "        0.74009895,  0.3548622 ,  0.5155802 ,  0.6362218 , -1.7366325 ,\n",
            "        3.8409715 , -1.4916677 ,  5.1260204 ], dtype=float32), 'agent_1': Array([ 0.65564054,  0.5252983 ,  0.08939933,  0.09745044,  0.8405789 ,\n",
            "        0.43023136, -0.15721908, -0.5600252 ,  0.5263352 ,  0.0531265 ,\n",
            "        0.74009895,  0.3548622 ,  0.5155802 ,  0.6362218 , -1.7366325 ,\n",
            "        3.8409715 , -5.5509167 ,  4.8711643 ], dtype=float32), 'agent_2': Array([ 0.65564054,  0.5252983 ,  0.08939933,  0.09745044,  0.8405789 ,\n",
            "        0.43023136, -0.15721908,  0.5263352 , -0.48844635,  0.0531265 ,\n",
            "        0.74009895,  0.3548622 ,  0.5155802 ,  0.6362218 , -1.7366325 ,\n",
            "        3.8409715 , -1.8378174 ,  1.1974971 ], dtype=float32), 'agent_3': Array([ 0.65564054,  0.5252983 ,  0.08939933,  0.09745044,  0.8405789 ,\n",
            "        0.43023136, -0.15721908,  0.5263352 ,  0.0531265 ,  0.95697725,\n",
            "        0.74009895,  0.3548622 ,  0.5155802 ,  0.6362218 , -1.7366325 ,\n",
            "        3.8409715 , -4.5998254 , -1.2659482 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.66865146 -0.19359201  0.6651189  -0.19352287  0.6686217  -0.19954847\n",
            "  0.66131693 -0.2006182 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.96782094, dtype=float32), 'agent_0': Array(0.96782094, dtype=float32), 'agent_1': Array(0.96782094, dtype=float32), 'agent_2': Array(0.96782094, dtype=float32), 'agent_3': Array(0.96782094, dtype=float32)}\n",
            "step: 478\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.67338854,  0.5233731 ,  0.11713692,  0.08470295,  0.839753  ,\n",
            "        0.5647711 ,  1.212009  , -0.14514796,  0.56619537,  0.10480215,\n",
            "        0.87451935,  0.64496994,  0.23394823,  0.44304395, -0.84279436,\n",
            "        0.53265536,  1.3741342 , -1.3722124 ], dtype=float32), 'agent_1': Array([ 0.67338854,  0.5233731 ,  0.11713692,  0.08470295,  0.839753  ,\n",
            "        0.5647711 , -0.14514796, -0.51361215,  0.56619537,  0.10480215,\n",
            "        0.87451935,  0.64496994,  0.23394823,  0.44304395, -0.84279436,\n",
            "        0.53265536,  1.3101026 , -1.0993887 ], dtype=float32), 'agent_2': Array([ 0.67338854,  0.5233731 ,  0.11713692,  0.08470295,  0.839753  ,\n",
            "        0.5647711 , -0.14514796,  0.56619537, -0.5336013 ,  0.10480215,\n",
            "        0.87451935,  0.64496994,  0.23394823,  0.44304395, -0.84279436,\n",
            "        0.53265536, -0.08447565, -1.2267622 ], dtype=float32), 'agent_3': Array([ 0.67338854,  0.5233731 ,  0.11713692,  0.08470295,  0.839753  ,\n",
            "        0.5647711 , -0.14514796,  0.56619537,  0.10480215,  0.9053981 ,\n",
            "        0.87451935,  0.64496994,  0.23394823,  0.44304395, -0.84279436,\n",
            "        0.53265536,  1.8776815 , -1.2452917 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.95975995  0.56548405 -0.962608    0.56544566 -0.9630061   0.56180125\n",
            " -0.9599754   0.5638278 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.8870058, dtype=float32), 'agent_0': Array(0.8870058, dtype=float32), 'agent_1': Array(0.8870058, dtype=float32), 'agent_2': Array(0.8870058, dtype=float32), 'agent_3': Array(0.8870058, dtype=float32)}\n",
            "step: 479\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.8054271e-01,  3.2515380e-01,  1.6273603e-01,  3.7254546e-02,\n",
            "        9.3080837e-01,  1.1904679e-01,  1.2318814e+00, -6.0403824e-01,\n",
            "        5.1013450e-03, -3.5061234e-01,  5.0058365e-01,  4.5166016e-01,\n",
            "        2.9135942e-01, -6.7433798e-01, -1.0028374e+00,  9.5790873e+00,\n",
            "       -1.0910066e+01, -2.1764183e-01], dtype=float32), 'agent_1': Array([ 6.8054271e-01,  3.2515380e-01,  1.6273603e-01,  3.7254546e-02,\n",
            "        9.3080837e-01,  1.1904679e-01, -6.0403824e-01, -5.1236838e-01,\n",
            "        5.1013450e-03, -3.5061234e-01,  5.0058365e-01,  4.5166016e-01,\n",
            "        2.9135942e-01, -6.7433798e-01, -1.0028374e+00,  9.5790873e+00,\n",
            "       -7.7574773e+00, -6.7367986e-02], dtype=float32), 'agent_2': Array([ 6.8054271e-01,  3.2515380e-01,  1.6273603e-01,  3.7254546e-02,\n",
            "        9.3080837e-01,  1.1904679e-01, -6.0403824e-01,  5.1013450e-03,\n",
            "       -5.1138663e-01, -3.5061234e-01,  5.0058365e-01,  4.5166016e-01,\n",
            "        2.9135942e-01, -6.7433798e-01, -1.0028374e+00,  9.5790873e+00,\n",
            "       -1.3613168e+01, -2.3661165e-01], dtype=float32), 'agent_3': Array([ 6.8054271e-01,  3.2515380e-01,  1.6273603e-01,  3.7254546e-02,\n",
            "        9.3080837e-01,  1.1904679e-01, -6.0403824e-01,  5.1013450e-03,\n",
            "       -3.5061234e-01,  1.0029567e+00,  5.0058365e-01,  4.5166016e-01,\n",
            "        2.9135942e-01, -6.7433798e-01, -1.0028374e+00,  9.5790873e+00,\n",
            "       -1.0586051e+01,  2.5701616e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.10423577  0.6675717  -0.10621203  0.667187   -0.10531894  0.6665703\n",
            " -0.10282903  0.66680115]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.7797179, dtype=float32), 'agent_0': Array(-0.7797179, dtype=float32), 'agent_1': Array(-0.7797179, dtype=float32), 'agent_2': Array(-0.7797179, dtype=float32), 'agent_3': Array(-0.7797179, dtype=float32)}\n",
            "step: 480\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6863389 ,  0.2561498 ,  0.1862049 , -0.00248102,  0.9485299 ,\n",
            "       -0.04889065,  1.2530462 , -0.53508145, -0.2842354 , -0.5243662 ,\n",
            "        0.16231537,  0.5730629 , -0.04782677, -0.9992335 , -1.2574888 ,\n",
            "        2.441899  , -2.3472567 ,  0.32498837], dtype=float32), 'agent_1': Array([ 6.8633890e-01,  2.5614980e-01,  1.8620490e-01, -2.4810152e-03,\n",
            "        9.4852990e-01, -4.8890647e-02, -5.3508145e-01, -4.9781266e-01,\n",
            "       -2.8423539e-01, -5.2436620e-01,  1.6231537e-01,  5.7306290e-01,\n",
            "       -4.7826767e-02, -9.9923348e-01, -1.2574888e+00,  2.4418991e+00,\n",
            "        2.7176852e+00,  4.5597768e-01], dtype=float32), 'agent_2': Array([ 6.8633890e-01,  2.5614980e-01,  1.8620490e-01, -2.4810152e-03,\n",
            "        9.4852990e-01, -4.8890647e-02, -5.3508145e-01, -2.8423539e-01,\n",
            "       -4.8138198e-01, -5.2436620e-01,  1.6231537e-01,  5.7306290e-01,\n",
            "       -4.7826767e-02, -9.9923348e-01, -1.2574888e+00,  2.4418991e+00,\n",
            "       -4.3734126e+00,  2.5393021e-01], dtype=float32), 'agent_3': Array([ 6.8633890e-01,  2.5614980e-01,  1.8620490e-01, -2.4810152e-03,\n",
            "        9.4852990e-01, -4.8890647e-02, -5.3508145e-01, -2.8423539e-01,\n",
            "       -5.2436620e-01,  1.2469720e+00,  1.6231537e-01,  5.7306290e-01,\n",
            "       -4.7826767e-02, -9.9923348e-01, -1.2574888e+00,  2.4418991e+00,\n",
            "       -2.6558883e+00,  5.9745059e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.31067446 -1.404472    0.31370384 -1.4080782   0.30482972 -1.4046286\n",
            "  0.31009886 -1.4010533 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.31267607, dtype=float32), 'agent_0': Array(0.31267607, dtype=float32), 'agent_1': Array(0.31267607, dtype=float32), 'agent_2': Array(0.31267607, dtype=float32), 'agent_3': Array(0.31267607, dtype=float32)}\n",
            "step: 481\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.68489844,  0.31055018,  0.1693192 ,  0.00854435,  0.9353163 ,\n",
            "        0.09957507,  1.0031185 , -0.11850137, -0.217182  , -0.36534563,\n",
            "        0.71077347,  0.07247925,  0.02856255, -0.49322078,  1.5809064 ,\n",
            "       -3.2601807 ,  3.8919384 , -7.0685515 ], dtype=float32), 'agent_1': Array([ 6.8489844e-01,  3.1055018e-01,  1.6931920e-01,  8.5443519e-03,\n",
            "        9.3531632e-01,  9.9575065e-02, -1.1850137e-01, -7.8127086e-01,\n",
            "       -2.1718200e-01, -3.6534563e-01,  7.1077347e-01,  7.2479248e-02,\n",
            "        2.8562546e-02, -4.9322078e-01,  1.5809064e+00, -3.2601807e+00,\n",
            "        9.0946407e+00, -8.1977882e+00], dtype=float32), 'agent_2': Array([ 0.68489844,  0.31055018,  0.1693192 ,  0.00854435,  0.9353163 ,\n",
            "        0.09957507, -0.11850137, -0.217182  , -0.710099  , -0.36534563,\n",
            "        0.71077347,  0.07247925,  0.02856255, -0.49322078,  1.5809064 ,\n",
            "       -3.2601807 ,  2.9675782 , -5.47749   ], dtype=float32), 'agent_3': Array([ 0.68489844,  0.31055018,  0.1693192 ,  0.00854435,  0.9353163 ,\n",
            "        0.09957507, -0.11850137, -0.217182  , -0.36534563,  1.1223097 ,\n",
            "        0.71077347,  0.07247925,  0.02856255, -0.49322078,  1.5809064 ,\n",
            "       -3.2601807 ,  4.6609955 , -4.2508087 ], dtype=float32)}\n",
            "ctrl action chosen: [0.11244708 1.5768707  0.11601247 1.5806992  0.11247049 1.5762029\n",
            " 0.11456276 1.5783842 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.701703, dtype=float32), 'agent_0': Array(-2.701703, dtype=float32), 'agent_1': Array(-2.701703, dtype=float32), 'agent_2': Array(-2.701703, dtype=float32), 'agent_3': Array(-2.701703, dtype=float32)}\n",
            "step: 482\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6964999 ,  0.3406851 ,  0.18625349, -0.02357753,  0.9212423 ,\n",
            "        0.18731982,  1.03751   ,  0.19091977, -0.10789628, -0.25243726,\n",
            "       -0.00934601,  0.61655045,  0.4225731 , -0.78053445, -1.9435408 ,\n",
            "       -0.61920667,  1.3354534 ,  2.6543472 ], dtype=float32), 'agent_1': Array([ 0.6964999 ,  0.3406851 ,  0.18625349, -0.02357753,  0.9212423 ,\n",
            "        0.18731982,  0.19091977, -0.68911684, -0.10789628, -0.25243726,\n",
            "       -0.00934601,  0.61655045,  0.4225731 , -0.78053445, -1.9435408 ,\n",
            "       -0.61920667,  5.746252  ,  5.473548  ], dtype=float32), 'agent_2': Array([ 0.6964999 ,  0.3406851 ,  0.18625349, -0.02357753,  0.9212423 ,\n",
            "        0.18731982,  0.19091977, -0.10789628, -0.5089269 , -0.25243726,\n",
            "       -0.00934601,  0.61655045,  0.4225731 , -0.78053445, -1.9435408 ,\n",
            "       -0.61920667,  1.9600152 ,  6.345981  ], dtype=float32), 'agent_3': Array([ 0.6964999 ,  0.3406851 ,  0.18625349, -0.02357753,  0.9212423 ,\n",
            "        0.18731982,  0.19091977, -0.10789628, -0.25243726,  1.2655137 ,\n",
            "       -0.00934601,  0.61655045,  0.4225731 , -0.78053445, -1.9435408 ,\n",
            "       -0.61920667,  1.7547264 ,  0.6751182 ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.1384219 -1.7242389  1.1375378 -1.7233541  1.1353043 -1.7232695\n",
            "  1.1431792 -1.7267336]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.6863165, dtype=float32), 'agent_0': Array(-3.6863165, dtype=float32), 'agent_1': Array(-3.6863165, dtype=float32), 'agent_2': Array(-3.6863165, dtype=float32), 'agent_3': Array(-3.6863165, dtype=float32)}\n",
            "step: 483\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7034768 ,  0.4731996 ,  0.13971801, -0.01360097,  0.8696988 ,\n",
            "        0.569368  ,  0.737517  ,  0.6526802 ,  0.32518908,  0.17418939,\n",
            "        0.8594036 ,  0.07591248, -0.35674572, -1.8928584 ,  2.1080759 ,\n",
            "       -0.5594627 ,  0.737803  , -7.8958206 ], dtype=float32), 'agent_1': Array([ 0.7034768 ,  0.4731996 ,  0.13971801, -0.01360097,  0.8696988 ,\n",
            "        0.569368  ,  0.6526802 , -0.94450784,  0.32518908,  0.17418939,\n",
            "        0.8594036 ,  0.07591248, -0.35674572, -1.8928584 ,  2.1080759 ,\n",
            "       -0.5594627 , -0.09564021, -8.634916  ], dtype=float32), 'agent_2': Array([ 0.7034768 ,  0.4731996 ,  0.13971801, -0.01360097,  0.8696988 ,\n",
            "        0.569368  ,  0.6526802 ,  0.32518908, -0.7457586 ,  0.17418939,\n",
            "        0.8594036 ,  0.07591248, -0.35674572, -1.8928584 ,  2.1080759 ,\n",
            "       -0.5594627 ,  4.5146527 , -7.8503127 ], dtype=float32), 'agent_3': Array([ 0.7034768 ,  0.4731996 ,  0.13971801, -0.01360097,  0.8696988 ,\n",
            "        0.569368  ,  0.6526802 ,  0.32518908,  0.17418939,  0.9548802 ,\n",
            "        0.8594036 ,  0.07591248, -0.35674572, -1.8928584 ,  2.1080759 ,\n",
            "       -0.5594627 ,  5.002818  , -8.641609  ], dtype=float32)}\n",
            "ctrl action chosen: [ 1.0256184  -0.62971324  1.0257504  -0.6276694   1.0291575  -0.62889713\n",
            "  1.0279661  -0.6279616 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.144252, dtype=float32), 'agent_0': Array(-7.144252, dtype=float32), 'agent_1': Array(-7.144252, dtype=float32), 'agent_2': Array(-7.144252, dtype=float32), 'agent_3': Array(-7.144252, dtype=float32)}\n",
            "step: 484\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.67490095,  0.4898572 ,  0.08735237, -0.03162977,  0.8668385 ,\n",
            "        0.5598674 ,  0.46158436,  0.53483105,  0.5824378 ,  0.47949684,\n",
            "        1.3453007 ,  0.05340576, -0.3416896 , -1.4971154 ,  1.3451406 ,\n",
            "        0.03435668, -1.2304561 , -1.5186338 ], dtype=float32), 'agent_1': Array([ 0.67490095,  0.4898572 ,  0.08735237, -0.03162977,  0.8668385 ,\n",
            "        0.5598674 ,  0.53483105, -1.2625213 ,  0.5824378 ,  0.47949684,\n",
            "        1.3453007 ,  0.05340576, -0.3416896 , -1.4971154 ,  1.3451406 ,\n",
            "        0.03435668, -4.453654  , -2.4542468 ], dtype=float32), 'agent_2': Array([ 0.67490095,  0.4898572 ,  0.08735237, -0.03162977,  0.8668385 ,\n",
            "        0.5598674 ,  0.53483105,  0.5824378 , -1.1007107 ,  0.47949684,\n",
            "        1.3453007 ,  0.05340576, -0.3416896 , -1.4971154 ,  1.3451406 ,\n",
            "        0.03435668,  3.7569592 , -7.6967053 ], dtype=float32), 'agent_3': Array([ 0.67490095,  0.4898572 ,  0.08735237, -0.03162977,  0.8668385 ,\n",
            "        0.5598674 ,  0.53483105,  0.5824378 ,  0.47949684,  0.5145845 ,\n",
            "        1.3453007 ,  0.05340576, -0.3416896 , -1.4971154 ,  1.3451406 ,\n",
            "        0.03435668,  6.0944247 , -8.745617  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.7100232  -0.11422874 -1.7109057  -0.11481868 -1.7054592  -0.12206745\n",
            " -1.7058893  -0.1194304 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.7531283, dtype=float32), 'agent_0': Array(-0.7531283, dtype=float32), 'agent_1': Array(-0.7531283, dtype=float32), 'agent_2': Array(-0.7531283, dtype=float32), 'agent_3': Array(-0.7531283, dtype=float32)}\n",
            "step: 485\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 7.0571500e-01,  2.4304914e-01,  6.2457997e-02, -6.3291349e-02,\n",
            "        9.6592981e-01, -1.2037124e-01,  5.0688523e-01, -3.8016421e-01,\n",
            "        1.6392994e-01,  7.5105824e-02,  4.0793419e-01,  4.7683716e-04,\n",
            "        1.3117313e+00,  2.3145536e-01,  2.0200661e-01,  1.2789895e+01,\n",
            "       -1.6554142e+01,  1.0361242e+00], dtype=float32), 'agent_1': Array([ 7.0571500e-01,  2.4304914e-01,  6.2457997e-02, -6.3291349e-02,\n",
            "        9.6592981e-01, -1.2037124e-01, -3.8016421e-01, -1.2326534e+00,\n",
            "        1.6392994e-01,  7.5105824e-02,  4.0793419e-01,  4.7683716e-04,\n",
            "        1.3117313e+00,  2.3145536e-01,  2.0200661e-01,  1.2789895e+01,\n",
            "       -2.1256834e+01,  6.8725288e-01], dtype=float32), 'agent_2': Array([ 7.0571500e-01,  2.4304914e-01,  6.2457997e-02, -6.3291349e-02,\n",
            "        9.6592981e-01, -1.2037124e-01, -3.8016421e-01,  1.6392994e-01,\n",
            "       -1.2650870e+00,  7.5105824e-02,  4.0793419e-01,  4.7683716e-04,\n",
            "        1.3117313e+00,  2.3145536e-01,  2.0200661e-01,  1.2789895e+01,\n",
            "       -1.2044117e+01,  3.6334285e-01], dtype=float32), 'agent_3': Array([ 7.0571500e-01,  2.4304914e-01,  6.2457997e-02, -6.3291349e-02,\n",
            "        9.6592981e-01, -1.2037124e-01, -3.8016421e-01,  1.6392994e-01,\n",
            "        7.5105824e-02,  4.8793271e-01,  4.0793419e-01,  4.7683716e-04,\n",
            "        1.3117313e+00,  2.3145536e-01,  2.0200661e-01,  1.2789895e+01,\n",
            "       -1.1108872e+01,  1.4709044e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.57852095 -1.7474091  -0.577177   -1.7464653  -0.578952   -1.7483917\n",
            " -0.58038783 -1.7481341 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.9268317, dtype=float32), 'agent_0': Array(-3.9268317, dtype=float32), 'agent_1': Array(-3.9268317, dtype=float32), 'agent_2': Array(-3.9268317, dtype=float32), 'agent_3': Array(-3.9268317, dtype=float32)}\n",
            "step: 486\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.74671465,  0.12718454,  0.04497525, -0.06009113,  0.98903507,\n",
            "       -0.5217005 ,  0.50594634, -0.66604   , -0.06025919, -0.11933117,\n",
            "       -0.5009651 ,  0.08907318,  0.48326254,  0.00573146,  0.14821205,\n",
            "        1.3573031 , -4.235212  ,  0.02089725], dtype=float32), 'agent_1': Array([ 0.74671465,  0.12718454,  0.04497525, -0.06009113,  0.98903507,\n",
            "       -0.5217005 , -0.66604   , -1.2618647 , -0.06025919, -0.11933117,\n",
            "       -0.5009651 ,  0.08907318,  0.48326254,  0.00573146,  0.14821205,\n",
            "        1.3573031 ,  2.4696255 , -0.06099606], dtype=float32), 'agent_2': Array([ 0.74671465,  0.12718454,  0.04497525, -0.06009113,  0.98903507,\n",
            "       -0.5217005 , -0.66604   , -0.06025919, -1.2616487 , -0.11933117,\n",
            "       -0.5009651 ,  0.08907318,  0.48326254,  0.00573146,  0.14821205,\n",
            "        1.3573031 , -1.48188   ,  1.1984668 ], dtype=float32), 'agent_3': Array([ 0.74671465,  0.12718454,  0.04497525, -0.06009113,  0.98903507,\n",
            "       -0.5217005 , -0.66604   , -0.06025919, -0.11933117,  0.4890745 ,\n",
            "       -0.5009651 ,  0.08907318,  0.48326254,  0.00573146,  0.14821205,\n",
            "        1.3573031 , -0.7955755 ,  1.1076608 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3551554  -1.1222758  -0.3485042  -1.1277997  -0.35051554 -1.1258582\n",
            " -0.35218984 -1.1237768 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.803008, dtype=float32), 'agent_0': Array(-5.803008, dtype=float32), 'agent_1': Array(-5.803008, dtype=float32), 'agent_2': Array(-5.803008, dtype=float32), 'agent_3': Array(-5.803008, dtype=float32)}\n",
            "step: 487\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7556631 ,  0.13068229,  0.03731004, -0.05702355,  0.9890796 ,\n",
            "       -0.5735772 ,  0.47459117, -0.39192766, -0.0941141 , -0.1105486 ,\n",
            "       -0.6808281 ,  0.2968788 , -0.03701448,  0.07029711,  0.32991046,\n",
            "       -0.3518321 ,  0.08254755, -0.60352206], dtype=float32), 'agent_1': Array([ 0.7556631 ,  0.13068229,  0.03731004, -0.05702355,  0.9890796 ,\n",
            "       -0.5735772 , -0.39192766, -1.2653626 , -0.0941141 , -0.1105486 ,\n",
            "       -0.6808281 ,  0.2968788 , -0.03701448,  0.07029711,  0.32991046,\n",
            "       -0.3518321 ,  6.281767  ,  0.09858387], dtype=float32), 'agent_2': Array([ 0.7556631 ,  0.13068229,  0.03731004, -0.05702355,  0.9890796 ,\n",
            "       -0.5735772 , -0.39192766, -0.0941141 , -1.245374  , -0.1105486 ,\n",
            "       -0.6808281 ,  0.2968788 , -0.03701448,  0.07029711,  0.32991046,\n",
            "       -0.3518321 , -1.2765111 , -0.2521672 ], dtype=float32), 'agent_3': Array([ 0.7556631 ,  0.13068229,  0.03731004, -0.05702355,  0.9890796 ,\n",
            "       -0.5735772 , -0.39192766, -0.0941141 , -0.1105486 ,  0.49938485,\n",
            "       -0.6808281 ,  0.2968788 , -0.03701448,  0.07029711,  0.32991046,\n",
            "       -0.3518321 , -0.5251827 , -0.20287415], dtype=float32)}\n",
            "ctrl action chosen: [0.08402951 0.26378715 0.08727614 0.26084152 0.08155801 0.25958988\n",
            " 0.0807509  0.2638255 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.41085, dtype=float32), 'agent_0': Array(-2.41085, dtype=float32), 'agent_1': Array(-2.41085, dtype=float32), 'agent_2': Array(-2.41085, dtype=float32), 'agent_3': Array(-2.41085, dtype=float32)}\n",
            "step: 488\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7453849 ,  0.15862048,  0.0516967 , -0.06188868,  0.9840411 ,\n",
            "       -0.4966413 ,  0.56232995, -0.07082427, -0.10014921, -0.07653722,\n",
            "       -0.5953312 ,  0.3534317 , -0.3938794 , -0.11472581, -0.28542906,\n",
            "       -0.51805854,  1.6743393 ,  1.6818    ], dtype=float32), 'agent_1': Array([ 0.7453849 ,  0.15862048,  0.0516967 , -0.06188868,  0.9840411 ,\n",
            "       -0.4966413 , -0.07082427, -1.1309478 , -0.10014921, -0.07653722,\n",
            "       -0.5953312 ,  0.3534317 , -0.3938794 , -0.11472581, -0.28542906,\n",
            "       -0.51805854,  4.9500237 ,  2.889969  ], dtype=float32), 'agent_2': Array([ 0.7453849 ,  0.15862048,  0.0516967 , -0.06188868,  0.9840411 ,\n",
            "       -0.4966413 , -0.07082427, -0.10014921, -1.1337199 , -0.07653722,\n",
            "       -0.5953312 ,  0.3534317 , -0.3938794 , -0.11472581, -0.28542906,\n",
            "       -0.51805854, -0.7744395 ,  1.9060347 ], dtype=float32), 'agent_3': Array([ 0.7453849 ,  0.15862048,  0.0516967 , -0.06188868,  0.9840411 ,\n",
            "       -0.4966413 , -0.07082427, -0.10014921, -0.07653722,  0.61921835,\n",
            "       -0.5953312 ,  0.3534317 , -0.3938794 , -0.11472581, -0.28542906,\n",
            "       -0.51805854,  0.08254546,  1.9799597 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.7594215  1.3433328 -1.7593845  1.341556  -1.7611758  1.3421926\n",
            " -1.7621261  1.3455919]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.15198053, dtype=float32), 'agent_0': Array(0.15198053, dtype=float32), 'agent_1': Array(0.15198053, dtype=float32), 'agent_2': Array(0.15198053, dtype=float32), 'agent_3': Array(0.15198053, dtype=float32)}\n",
            "step: 489\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.7164416 ,  0.02484803,  0.0932716 , -0.09232873,  0.9910391 ,\n",
            "       -0.62723756,  0.96438134, -0.25845847, -0.5405386 , -0.48712206,\n",
            "       -1.0094166 ,  1.0416031 , -0.7783413 , -1.3333254 , -3.1802642 ,\n",
            "        4.7014213 ,  0.3621532 , 11.598916  ], dtype=float32), 'agent_1': Array([ 0.7164416 ,  0.02484803,  0.0932716 , -0.09232873,  0.9910391 ,\n",
            "       -0.62723756, -0.25845847, -0.7110641 , -0.5405386 , -0.48712206,\n",
            "       -1.0094166 ,  1.0416031 , -0.7783413 , -1.3333254 , -3.1802642 ,\n",
            "        4.7014213 , -4.8616753 , 11.551674  ], dtype=float32), 'agent_2': Array([ 0.7164416 ,  0.02484803,  0.0932716 , -0.09232873,  0.9910391 ,\n",
            "       -0.62723756, -0.25845847, -0.5405386 , -0.77403945, -0.48712206,\n",
            "       -1.0094166 ,  1.0416031 , -0.7783413 , -1.3333254 , -3.1802642 ,\n",
            "        4.7014213 , -8.392373  , 10.555354  ], dtype=float32), 'agent_3': Array([ 0.7164416 ,  0.02484803,  0.0932716 , -0.09232873,  0.9910391 ,\n",
            "       -0.62723756, -0.25845847, -0.5405386 , -0.48712206,  0.9616486 ,\n",
            "       -1.0094166 ,  1.0416031 , -0.7783413 , -1.3333254 , -3.1802642 ,\n",
            "        4.7014213 , -8.884705  ,  9.867843  ], dtype=float32)}\n",
            "ctrl action chosen: [0.9440759  0.7362238  0.94493794 0.7379291  0.94558305 0.73509043\n",
            " 0.9462716  0.73429877]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.653602, dtype=float32), 'agent_0': Array(-9.653602, dtype=float32), 'agent_1': Array(-9.653602, dtype=float32), 'agent_2': Array(-9.653602, dtype=float32), 'agent_3': Array(-9.653602, dtype=float32)}\n",
            "step: 490\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.6582051 ,   0.18670803,   0.1550092 ,  -0.08761632,\n",
            "         0.9661447 ,   0.07493181,   1.3028692 ,   0.20591922,\n",
            "        -0.21370493,  -0.22879097,  -0.4875183 ,   0.35972595,\n",
            "        -1.250422  ,   0.32246697,   1.5656315 , -10.4963255 ,\n",
            "        19.656008  ,  -1.629804  ], dtype=float32), 'agent_1': Array([  0.6582051 ,   0.18670803,   0.1550092 ,  -0.08761632,\n",
            "         0.9661447 ,   0.07493181,   0.20591922,  -0.4432163 ,\n",
            "        -0.21370493,  -0.22879097,  -0.4875183 ,   0.35972595,\n",
            "        -1.250422  ,   0.32246697,   1.5656315 , -10.4963255 ,\n",
            "        13.943423  ,  -2.190743  ], dtype=float32), 'agent_2': Array([  0.6582051 ,   0.18670803,   0.1550092 ,  -0.08761632,\n",
            "         0.9661447 ,   0.07493181,   0.20591922,  -0.21370493,\n",
            "        -0.44111192,  -0.22879097,  -0.4875183 ,   0.35972595,\n",
            "        -1.250422  ,   0.32246697,   1.5656315 , -10.4963255 ,\n",
            "        11.861586  ,  -1.6909575 ], dtype=float32), 'agent_3': Array([  0.6582051 ,   0.18670803,   0.1550092 ,  -0.08761632,\n",
            "         0.9661447 ,   0.07493181,   0.20591922,  -0.21370493,\n",
            "        -0.22879097,   1.3102884 ,  -0.4875183 ,   0.35972595,\n",
            "        -1.250422  ,   0.32246697,   1.5656315 , -10.4963255 ,\n",
            "         9.755225  ,  -1.1393719 ], dtype=float32)}\n",
            "ctrl action chosen: [1.1247226  0.48945493 1.1239517  0.4906313  1.1245922  0.49116316\n",
            " 1.1253957  0.49111328]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.738156, dtype=float32), 'agent_0': Array(-2.738156, dtype=float32), 'agent_1': Array(-2.738156, dtype=float32), 'agent_2': Array(-2.738156, dtype=float32), 'agent_3': Array(-2.738156, dtype=float32)}\n",
            "step: 491\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5858134 ,  0.34870002,  0.1459581 , -0.05129358,  0.9243774 ,\n",
            "        0.6618617 ,  1.2518395 ,  0.6016456 ,  0.26585874,  0.1766284 ,\n",
            "        0.12483597,  0.00801086, -1.6718745 ,  0.37049422,  0.4583041 ,\n",
            "        0.26414293, -0.42325574, -0.45760542], dtype=float32), 'agent_1': Array([ 0.5858134 ,  0.34870002,  0.1459581 , -0.05129358,  0.9243774 ,\n",
            "        0.6618617 ,  0.6016456 , -0.49938914,  0.26585874,  0.1766284 ,\n",
            "        0.12483597,  0.00801086, -1.6718745 ,  0.37049422,  0.4583041 ,\n",
            "        0.26414293, -1.6104467 ,  0.5163027 ], dtype=float32), 'agent_2': Array([ 0.5858134 ,  0.34870002,  0.1459581 , -0.05129358,  0.9243774 ,\n",
            "        0.6618617 ,  0.6016456 ,  0.26585874, -0.49613762,  0.1766284 ,\n",
            "        0.12483597,  0.00801086, -1.6718745 ,  0.37049422,  0.4583041 ,\n",
            "        0.26414293,  3.4295912 , -0.44849783], dtype=float32), 'agent_3': Array([ 0.5858134 ,  0.34870002,  0.1459581 , -0.05129358,  0.9243774 ,\n",
            "        0.6618617 ,  0.6016456 ,  0.26585874,  0.1766284 ,  1.2456462 ,\n",
            "        0.12483597,  0.00801086, -1.6718745 ,  0.37049422,  0.4583041 ,\n",
            "        0.26414293,  2.2902942 , -0.7938304 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.7344231  1.4950968 -0.7355958  1.4973625 -0.7268393  1.4881811\n",
            " -0.7291885  1.4925278]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.2975936, dtype=float32), 'agent_0': Array(-2.2975936, dtype=float32), 'agent_1': Array(-2.2975936, dtype=float32), 'agent_2': Array(-2.2975936, dtype=float32), 'agent_3': Array(-2.2975936, dtype=float32)}\n",
            "step: 492\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.5305819 ,   0.15889496,   0.10695942,  -0.05646576,\n",
            "         0.979859  ,   0.17288862,   1.246831  ,   0.06296943,\n",
            "        -0.09949218,  -0.22846672,  -0.23322105,   0.95596313,\n",
            "        -0.5295038 ,   0.8594041 ,   1.8013351 ,  10.902174  ,\n",
            "       -14.685761  ,  -0.37088862], dtype=float32), 'agent_1': Array([  0.5305819 ,   0.15889496,   0.10695942,  -0.05646576,\n",
            "         0.979859  ,   0.17288862,   0.06296943,  -0.4713909 ,\n",
            "        -0.09949218,  -0.22846672,  -0.23322105,   0.95596313,\n",
            "        -0.5295038 ,   0.8594041 ,   1.8013351 ,  10.902174  ,\n",
            "       -15.436083  ,  -0.15348557], dtype=float32), 'agent_2': Array([  0.5305819 ,   0.15889496,   0.10695942,  -0.05646576,\n",
            "         0.979859  ,   0.17288862,   0.06296943,  -0.09949218,\n",
            "        -0.50272965,  -0.22846672,  -0.23322105,   0.95596313,\n",
            "        -0.5295038 ,   0.8594041 ,   1.8013351 ,  10.902174  ,\n",
            "       -10.678835  ,  -0.28912365], dtype=float32), 'agent_3': Array([  0.5305819 ,   0.15889496,   0.10695942,  -0.05646576,\n",
            "         0.979859  ,   0.17288862,   0.06296943,  -0.09949218,\n",
            "        -0.22846672,   1.2399344 ,  -0.23322105,   0.95596313,\n",
            "        -0.5295038 ,   0.8594041 ,   1.8013351 ,  10.902174  ,\n",
            "       -11.464059  ,   0.08475199], dtype=float32)}\n",
            "ctrl action chosen: [ 1.7180274e+00 -1.2667549e-03  1.7168784e+00 -1.2249304e-03\n",
            "  1.7152609e+00 -6.2215334e-04  1.7160786e+00 -1.9273593e-03]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-4.5437574, dtype=float32), 'agent_0': Array(-4.5437574, dtype=float32), 'agent_1': Array(-4.5437574, dtype=float32), 'agent_2': Array(-4.5437574, dtype=float32), 'agent_3': Array(-4.5437574, dtype=float32)}\n",
            "step: 493\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.1602983e-01,  2.7502748e-01,  6.7294508e-02, -1.1535480e-02,\n",
            "        9.5900905e-01,  4.2445976e-01,  1.1491511e+00,  2.8218573e-01,\n",
            "        2.9859024e-01,  1.3357015e-01, -2.8643608e-01,  8.5220337e-01,\n",
            "       -2.0197630e-01,  1.1016382e+00,  1.4462260e+00, -9.9496155e+00,\n",
            "        1.1949405e+01, -1.6074604e+00], dtype=float32), 'agent_1': Array([ 0.51602983,  0.27502748,  0.06729451, -0.01153548,  0.95900905,\n",
            "        0.42445976,  0.28218573, -0.53183156,  0.29859024,  0.13357015,\n",
            "       -0.28643608,  0.85220337, -0.2019763 ,  1.1016382 ,  1.446226  ,\n",
            "       -9.9496155 , 11.354653  , -0.48920208], dtype=float32), 'agent_2': Array([ 5.1602983e-01,  2.7502748e-01,  6.7294508e-02, -1.1535480e-02,\n",
            "        9.5900905e-01,  4.2445976e-01,  2.8218573e-01,  2.9859024e-01,\n",
            "       -5.6197530e-01,  1.3357015e-01, -2.8643608e-01,  8.5220337e-01,\n",
            "       -2.0197630e-01,  1.1016382e+00,  1.4462260e+00, -9.9496155e+00,\n",
            "        1.4395345e+01,  7.1893746e-01], dtype=float32), 'agent_3': Array([ 5.1602983e-01,  2.7502748e-01,  6.7294508e-02, -1.1535480e-02,\n",
            "        9.5900905e-01,  4.2445976e-01,  2.8218573e-01,  2.9859024e-01,\n",
            "        1.3357015e-01,  1.1729087e+00, -2.8643608e-01,  8.5220337e-01,\n",
            "       -2.0197630e-01,  1.1016382e+00,  1.4462260e+00, -9.9496155e+00,\n",
            "        1.3889296e+01, -9.0075308e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.83717513 -0.02919068 -0.8373175  -0.02743895 -0.83681715 -0.02871798\n",
            " -0.8374465  -0.02927837]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.1376696, dtype=float32), 'agent_0': Array(-5.1376696, dtype=float32), 'agent_1': Array(-5.1376696, dtype=float32), 'agent_2': Array(-5.1376696, dtype=float32), 'agent_3': Array(-5.1376696, dtype=float32)}\n",
            "step: 494\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.3106230e-01,  1.6878380e-01,  5.0586447e-02,  1.5435153e-02,\n",
            "        9.8423320e-01,  1.8123913e-01,  1.0948505e+00, -1.9047635e-03,\n",
            "        1.5365615e-01, -7.1982234e-03, -2.1424294e-01,  6.6800117e-01,\n",
            "        3.6954880e-01,  9.6107125e-01,  9.7532511e-01,  8.3029022e+00,\n",
            "       -9.9159489e+00, -7.1331912e-01], dtype=float32), 'agent_1': Array([ 5.31062305e-01,  1.68783799e-01,  5.05864471e-02,  1.54351527e-02,\n",
            "        9.84233201e-01,  1.81239128e-01, -1.90476351e-03, -5.95678449e-01,\n",
            "        1.53656155e-01, -7.19822338e-03, -2.14242935e-01,  6.68001175e-01,\n",
            "        3.69548798e-01,  9.61071253e-01,  9.75325108e-01,  8.30290222e+00,\n",
            "       -1.10237465e+01, -1.50478423e+00], dtype=float32), 'agent_2': Array([ 5.3106230e-01,  1.6878380e-01,  5.0586447e-02,  1.5435153e-02,\n",
            "        9.8423320e-01,  1.8123913e-01, -1.9047635e-03,  1.5365615e-01,\n",
            "       -5.1521623e-01, -7.1982234e-03, -2.1424294e-01,  6.6800117e-01,\n",
            "        3.6954880e-01,  9.6107125e-01,  9.7532511e-01,  8.3029022e+00,\n",
            "       -8.5834589e+00, -6.5154982e-01], dtype=float32), 'agent_3': Array([ 5.3106230e-01,  1.6878380e-01,  5.0586447e-02,  1.5435153e-02,\n",
            "        9.8423320e-01,  1.8123913e-01, -1.9047635e-03,  1.5365615e-01,\n",
            "       -7.1982234e-03,  1.1478263e+00, -2.1424294e-01,  6.6800117e-01,\n",
            "        3.6954880e-01,  9.6107125e-01,  9.7532511e-01,  8.3029022e+00,\n",
            "       -8.3174849e+00, -1.0440015e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.7889939  -0.34729606  0.7880427  -0.34683478  0.78749126 -0.3478562\n",
            "  0.786891   -0.34803882]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.8010014, dtype=float32), 'agent_0': Array(-0.8010014, dtype=float32), 'agent_1': Array(-0.8010014, dtype=float32), 'agent_2': Array(-0.8010014, dtype=float32), 'agent_3': Array(-0.8010014, dtype=float32)}\n",
            "step: 495\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5616212 ,  0.24733959,  0.01327957,  0.03669761,  0.9681426 ,\n",
            "        0.38842866,  0.9374149 ,  0.16458656,  0.4386345 ,  0.24735302,\n",
            "        0.2532959 ,  0.12769699,  0.7504821 ,  0.0506065 ,  1.5919037 ,\n",
            "       -6.6825447 ,  8.64273   , -4.2135963 ], dtype=float32), 'agent_1': Array([ 0.5616212 ,  0.24733959,  0.01327957,  0.03669761,  0.9681426 ,\n",
            "        0.38842866,  0.16458656, -0.7372443 ,  0.4386345 ,  0.24735302,\n",
            "        0.2532959 ,  0.12769699,  0.7504821 ,  0.0506065 ,  1.5919037 ,\n",
            "       -6.6825447 ,  8.184783  , -3.2544332 ], dtype=float32), 'agent_2': Array([ 0.5616212 ,  0.24733959,  0.01327957,  0.03669761,  0.9681426 ,\n",
            "        0.38842866,  0.16458656,  0.4386345 , -0.66527563,  0.24735302,\n",
            "        0.2532959 ,  0.12769699,  0.7504821 ,  0.0506065 ,  1.5919037 ,\n",
            "       -6.6825447 , 10.504763  , -4.1625743 ], dtype=float32), 'agent_3': Array([ 0.5616212 ,  0.24733959,  0.01327957,  0.03669761,  0.9681426 ,\n",
            "        0.38842866,  0.16458656,  0.4386345 ,  0.24735302,  0.97899854,\n",
            "        0.2532959 ,  0.12769699,  0.7504821 ,  0.0506065 ,  1.5919037 ,\n",
            "       -6.6825447 ,  9.547353  , -3.6408424 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.22636253 -0.03461988 -0.22590193 -0.03314405 -0.22504413 -0.03436879\n",
            " -0.22596684 -0.03479596]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.35895646, dtype=float32), 'agent_0': Array(-0.35895646, dtype=float32), 'agent_1': Array(-0.35895646, dtype=float32), 'agent_2': Array(-0.35895646, dtype=float32), 'agent_3': Array(-0.35895646, dtype=float32)}\n",
            "step: 496\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.591977  ,  0.25369027, -0.00951532,  0.04583272,  0.9661522 ,\n",
            "        0.43722713,  0.807208  ,  0.18632428,  0.53889227,  0.36154398,\n",
            "        0.05707741,  0.07500648,  0.389421  ,  0.15738735,  0.8730985 ,\n",
            "        1.9326241 , -1.7922925 , -1.9842194 ], dtype=float32), 'agent_1': Array([ 0.591977  ,  0.25369027, -0.00951532,  0.04583272,  0.9661522 ,\n",
            "        0.43722713,  0.18632428, -0.83953637,  0.53889227,  0.36154398,\n",
            "        0.05707741,  0.07500648,  0.389421  ,  0.15738735,  0.8730985 ,\n",
            "        1.9326241 , -2.4579072 , -1.9365809 ], dtype=float32), 'agent_2': Array([ 0.591977  ,  0.25369027, -0.00951532,  0.04583272,  0.9661522 ,\n",
            "        0.43722713,  0.18632428,  0.53889227, -0.8075663 ,  0.36154398,\n",
            "        0.05707741,  0.07500648,  0.389421  ,  0.15738735,  0.8730985 ,\n",
            "        1.9326241 , -1.4663918 , -2.5541184 ], dtype=float32), 'agent_3': Array([ 0.591977  ,  0.25369027, -0.00951532,  0.04583272,  0.9661522 ,\n",
            "        0.43722713,  0.18632428,  0.53889227,  0.36154398,  0.87273717,\n",
            "        0.05707741,  0.07500648,  0.389421  ,  0.15738735,  0.8730985 ,\n",
            "        1.9326241 , -0.62027735, -1.7401472 ], dtype=float32)}\n",
            "ctrl action chosen: [ 0.7150553  -0.92680657  0.7154061  -0.9254023   0.71830875 -0.9322304\n",
            "  0.71621585 -0.9287604 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(1.0304877, dtype=float32), 'agent_0': Array(1.0304877, dtype=float32), 'agent_1': Array(1.0304877, dtype=float32), 'agent_2': Array(1.0304877, dtype=float32), 'agent_3': Array(1.0304877, dtype=float32)}\n",
            "step: 497\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.59423697,  0.27527654, -0.07150072,  0.04708038,  0.9575458 ,\n",
            "        0.5540504 ,  0.46417227,  0.30870962,  0.5572384 ,  0.5463165 ,\n",
            "        0.11591911,  0.17318726, -0.33636093, -0.8047204 ,  2.9240654 ,\n",
            "        0.16146882,  0.7692386 , -5.285032  ], dtype=float32), 'agent_1': Array([ 0.59423697,  0.27527654, -0.07150072,  0.04708038,  0.9575458 ,\n",
            "        0.5540504 ,  0.30870962, -1.1993378 ,  0.5572384 ,  0.5463165 ,\n",
            "        0.11591911,  0.17318726, -0.33636093, -0.8047204 ,  2.9240654 ,\n",
            "        0.16146882,  2.3532214 , -9.246371  ], dtype=float32), 'agent_2': Array([ 0.59423697,  0.27527654, -0.07150072,  0.04708038,  0.9575458 ,\n",
            "        0.5540504 ,  0.30870962,  0.5572384 , -1.1837956 ,  0.5463165 ,\n",
            "        0.11591911,  0.17318726, -0.33636093, -0.8047204 ,  2.9240654 ,\n",
            "        0.16146882, -1.2479953 , -9.444287  ], dtype=float32), 'agent_3': Array([ 0.59423697,  0.27527654, -0.07150072,  0.04708038,  0.9575458 ,\n",
            "        0.5540504 ,  0.30870962,  0.5572384 ,  0.5463165 ,  0.51262164,\n",
            "        0.11591911,  0.17318726, -0.33636093, -0.8047204 ,  2.9240654 ,\n",
            "        0.16146882,  2.3254468 , -8.944497  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.18959099 -1.3609259  -0.18763965 -1.3584334  -0.18496126 -1.3638743\n",
            " -0.18742745 -1.3614736 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6282563, dtype=float32), 'agent_0': Array(-1.6282563, dtype=float32), 'agent_1': Array(-1.6282563, dtype=float32), 'agent_2': Array(-1.6282563, dtype=float32), 'agent_3': Array(-1.6282563, dtype=float32)}\n",
            "step: 498\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5755799 ,  0.21880592, -0.07995966,  0.06358865,  0.9704056 ,\n",
            "        0.47208893,  0.46734202,  0.26882732,  0.359637  ,  0.50865614,\n",
            "       -0.36787987,  0.27513504, -0.16210079,  0.33630577, -0.15052885,\n",
            "        3.0190911 , -2.8710134 ,  0.54943436], dtype=float32), 'agent_1': Array([ 0.5755799 ,  0.21880592, -0.07995966,  0.06358865,  0.9704056 ,\n",
            "        0.47208893,  0.26882732, -1.2871672 ,  0.359637  ,  0.50865614,\n",
            "       -0.36787987,  0.27513504, -0.16210079,  0.33630577, -0.15052885,\n",
            "        3.0190911 , -1.39403   ,  0.531662  ], dtype=float32), 'agent_2': Array([ 0.5755799 ,  0.21880592, -0.07995966,  0.06358865,  0.9704056 ,\n",
            "        0.47208893,  0.26882732,  0.359637  , -1.2864974 ,  0.50865614,\n",
            "       -0.36787987,  0.27513504, -0.16210079,  0.33630577, -0.15052885,\n",
            "        3.0190911 , -5.096034  ,  0.46620476], dtype=float32), 'agent_3': Array([ 0.5755799 ,  0.21880592, -0.07995966,  0.06358865,  0.9704056 ,\n",
            "        0.47208893,  0.26882732,  0.359637  ,  0.50865614,  0.46727517,\n",
            "       -0.36787987,  0.27513504, -0.16210079,  0.33630577, -0.15052885,\n",
            "        3.0190911 , -1.8575865 ,  0.6268549 ], dtype=float32)}\n",
            "ctrl action chosen: [-1.1917462 -1.638587  -1.1871732 -1.6374813 -1.1897658 -1.6413618\n",
            " -1.1903871 -1.6387622]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-2.9644904, dtype=float32), 'agent_0': Array(-2.9644904, dtype=float32), 'agent_1': Array(-2.9644904, dtype=float32), 'agent_2': Array(-2.9644904, dtype=float32), 'agent_3': Array(-2.9644904, dtype=float32)}\n",
            "step: 499\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.57532865,  -0.0626559 ,  -0.07206835,   0.09193002,\n",
            "         0.9911757 ,  -0.1702289 ,   0.49100775,  -0.3163337 ,\n",
            "        -0.40209237,  -0.11072708,  -0.39081573,  -0.32219887,\n",
            "        -0.1185894 ,   0.61626   ,   0.42974463,  13.260372  ,\n",
            "       -15.620758  ,   0.37437442], dtype=float32), 'agent_1': Array([  0.57532865,  -0.0626559 ,  -0.07206835,   0.09193002,\n",
            "         0.9911757 ,  -0.1702289 ,  -0.3163337 ,  -1.2646606 ,\n",
            "        -0.40209237,  -0.11072708,  -0.39081573,  -0.32219887,\n",
            "        -0.1185894 ,   0.61626   ,   0.42974463,  13.260372  ,\n",
            "       -14.380463  ,   0.66071373], dtype=float32), 'agent_2': Array([  0.57532865,  -0.0626559 ,  -0.07206835,   0.09193002,\n",
            "         0.9911757 ,  -0.1702289 ,  -0.3163337 ,  -0.40209237,\n",
            "        -1.2625339 ,  -0.11072708,  -0.39081573,  -0.32219887,\n",
            "        -0.1185894 ,   0.61626   ,   0.42974463,  13.260372  ,\n",
            "       -18.088509  ,   1.28347   ], dtype=float32), 'agent_3': Array([  0.57532865,  -0.0626559 ,  -0.07206835,   0.09193002,\n",
            "         0.9911757 ,  -0.1702289 ,  -0.3163337 ,  -0.40209237,\n",
            "        -0.11072708,   0.48517296,  -0.39081573,  -0.32219887,\n",
            "        -0.1185894 ,   0.61626   ,   0.42974463,  13.260372  ,\n",
            "       -15.218599  ,  -0.25872037], dtype=float32)}\n",
            "ctrl action chosen: [-0.66108143  2.152881   -0.66181725  2.1544087  -0.6597393   2.1532266\n",
            " -0.6624763   2.1526413 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-7.5942783, dtype=float32), 'agent_0': Array(-7.5942783, dtype=float32), 'agent_1': Array(-7.5942783, dtype=float32), 'agent_2': Array(-7.5942783, dtype=float32), 'agent_3': Array(-7.5942783, dtype=float32)}\n",
            "step: 500\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8681279e-01, -1.8140510e-01, -6.8244915e-03,  8.2104288e-02,\n",
            "        9.7995132e-01, -5.3390992e-01,  8.8217998e-01, -5.6129122e-01,\n",
            "       -6.1122465e-01, -5.0126308e-01, -6.8073273e-01, -4.3716431e-01,\n",
            "        2.0637512e-01, -1.9705733e+00, -2.7518096e+00,  8.9365989e-01,\n",
            "       -2.5801156e+00,  1.0790772e+01], dtype=float32), 'agent_1': Array([ 5.8681279e-01, -1.8140510e-01, -6.8244915e-03,  8.2104288e-02,\n",
            "        9.7995132e-01, -5.3390992e-01, -5.6129122e-01, -8.3669364e-01,\n",
            "       -6.1122465e-01, -5.0126308e-01, -6.8073273e-01, -4.3716431e-01,\n",
            "        2.0637512e-01, -1.9705733e+00, -2.7518096e+00,  8.9365989e-01,\n",
            "        5.2934015e-01,  1.2408806e+01], dtype=float32), 'agent_2': Array([ 5.8681279e-01, -1.8140510e-01, -6.8244915e-03,  8.2104288e-02,\n",
            "        9.7995132e-01, -5.3390992e-01, -5.6129122e-01, -6.1122465e-01,\n",
            "       -8.0859613e-01, -5.0126308e-01, -6.8073273e-01, -4.3716431e-01,\n",
            "        2.0637512e-01, -1.9705733e+00, -2.7518096e+00,  8.9365989e-01,\n",
            "        2.8128371e+00,  1.1917203e+01], dtype=float32), 'agent_3': Array([ 5.8681279e-01, -1.8140510e-01, -6.8244915e-03,  8.2104288e-02,\n",
            "        9.7995132e-01, -5.3390992e-01, -5.6129122e-01, -6.1122465e-01,\n",
            "       -5.0126308e-01,  7.7792704e-01, -6.8073273e-01, -4.3716431e-01,\n",
            "        2.0637512e-01, -1.9705733e+00, -2.7518096e+00,  8.9365989e-01,\n",
            "       -4.0960155e+00,  7.9914665e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 3.3140678  -0.6632086   3.3119214  -0.6641469   3.3128703  -0.6651613\n",
            "  3.3139791  -0.66289586]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-9.659482, dtype=float32), 'agent_0': Array(-9.659482, dtype=float32), 'agent_1': Array(-9.659482, dtype=float32), 'agent_2': Array(-9.659482, dtype=float32), 'agent_3': Array(-9.659482, dtype=float32)}\n",
            "step: 501\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([  0.58912176,   0.05485735,  -0.01700288,   0.07017359,\n",
            "         0.9958802 ,  -0.02312488,   1.0029714 ,   0.07137136,\n",
            "         0.18839267,  -0.0405733 ,   0.08320808,  -0.5713463 ,\n",
            "         0.03273487,  -0.34067374,   0.7323842 , -13.48858   ,\n",
            "        14.76873   ,  -0.8296222 ], dtype=float32), 'agent_1': Array([ 5.8912176e-01,  5.4857347e-02, -1.7002884e-02,  7.0173591e-02,\n",
            "        9.9588019e-01, -2.3124877e-02,  7.1371362e-02, -6.6271436e-01,\n",
            "        1.8839267e-01, -4.0573303e-02,  8.3208084e-02, -5.7134628e-01,\n",
            "        3.2734871e-02, -3.4067374e-01,  7.3238420e-01, -1.3488580e+01,\n",
            "        1.7445690e+01, -8.1997806e-01], dtype=float32), 'agent_2': Array([ 5.8912176e-01,  5.4857347e-02, -1.7002884e-02,  7.0173591e-02,\n",
            "        9.9588019e-01, -2.3124877e-02,  7.1371362e-02,  1.8839267e-01,\n",
            "       -7.0010126e-01, -4.0573303e-02,  8.3208084e-02, -5.7134628e-01,\n",
            "        3.2734871e-02, -3.4067374e-01,  7.3238420e-01, -1.3488580e+01,\n",
            "        2.1442844e+01, -1.2268960e+00], dtype=float32), 'agent_3': Array([  0.58912176,   0.05485735,  -0.01700288,   0.07017359,\n",
            "         0.9958802 ,  -0.02312488,   0.07137136,   0.18839267,\n",
            "        -0.0405733 ,   0.7735497 ,   0.08320808,  -0.5713463 ,\n",
            "         0.03273487,  -0.34067374,   0.7323842 , -13.48858   ,\n",
            "        14.200624  ,  -2.901368  ], dtype=float32)}\n",
            "ctrl action chosen: [-0.49020654  0.15466894 -0.49181977  0.15479904 -0.49282092  0.1523621\n",
            " -0.4924641   0.15271018]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-22.03478, dtype=float32), 'agent_0': Array(-22.03478, dtype=float32), 'agent_1': Array(-22.03478, dtype=float32), 'agent_2': Array(-22.03478, dtype=float32), 'agent_3': Array(-22.03478, dtype=float32)}\n",
            "step: 502\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8300388e-01,  5.8763415e-02, -7.7743371e-06,  6.4250655e-02,\n",
            "        9.9620217e-01, -6.9017686e-02,  1.1036413e+00,  1.2632747e-01,\n",
            "        4.1322148e-01, -7.5637154e-02, -2.8300285e-01, -6.0563087e-01,\n",
            "       -3.6720037e-01, -1.2911250e-01, -8.1241560e-01,  3.6406147e+00,\n",
            "       -5.7110310e+00,  2.6480722e+00], dtype=float32), 'agent_1': Array([ 5.8300388e-01,  5.8763415e-02, -7.7743371e-06,  6.4250655e-02,\n",
            "        9.9620217e-01, -6.9017686e-02,  1.2632747e-01, -5.6203747e-01,\n",
            "        4.1322148e-01, -7.5637154e-02, -2.8300285e-01, -6.0563087e-01,\n",
            "       -3.6720037e-01, -1.2911250e-01, -8.1241560e-01,  3.6406147e+00,\n",
            "       -3.8722954e+00,  2.4543686e+00], dtype=float32), 'agent_2': Array([ 5.8300388e-01,  5.8763415e-02, -7.7743371e-06,  6.4250655e-02,\n",
            "        9.9620217e-01, -6.9017686e-02,  1.2632747e-01,  4.1322148e-01,\n",
            "       -5.9398282e-01, -7.5637154e-02, -2.8300285e-01, -6.0563087e-01,\n",
            "       -3.6720037e-01, -1.2911250e-01, -8.1241560e-01,  3.6406147e+00,\n",
            "       -9.1194665e-01,  2.1283972e+00], dtype=float32), 'agent_3': Array([ 5.8300388e-01,  5.8763415e-02, -7.7743371e-06,  6.4250655e-02,\n",
            "        9.9620217e-01, -6.9017686e-02,  1.2632747e-01,  4.1322148e-01,\n",
            "       -7.5637154e-02,  7.7612674e-01, -2.8300285e-01, -6.0563087e-01,\n",
            "       -3.6720037e-01, -1.2911250e-01, -8.1241560e-01,  3.6406147e+00,\n",
            "       -5.3485236e+00,  1.1270352e-01], dtype=float32)}\n",
            "ctrl action chosen: [-0.4318061   0.24109834 -0.4309228   0.24222629 -0.42454007  0.24004072\n",
            " -0.43415064  0.23848249]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.31864727, dtype=float32), 'agent_0': Array(0.31864727, dtype=float32), 'agent_1': Array(0.31864727, dtype=float32), 'agent_2': Array(0.31864727, dtype=float32), 'agent_3': Array(0.31864727, dtype=float32)}\n",
            "step: 503\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5521393 , -0.09772447,  0.02076195,  0.05628496,  0.9934037 ,\n",
            "       -0.5074432 ,  1.2188755 , -0.2239305 ,  0.18289673, -0.50813687,\n",
            "       -0.25610924, -0.53162575, -0.82485676, -0.22825156, -0.21915978,\n",
            "        7.4046874 , -9.785472  ,  1.8119242 ], dtype=float32), 'agent_1': Array([ 0.5521393 , -0.09772447,  0.02076195,  0.05628496,  0.9934037 ,\n",
            "       -0.5074432 , -0.2239305 , -0.5103184 ,  0.18289673, -0.50813687,\n",
            "       -0.25610924, -0.53162575, -0.82485676, -0.22825156, -0.21915978,\n",
            "        7.4046874 , -8.175607  , -0.27200973], dtype=float32), 'agent_2': Array([ 0.5521393 , -0.09772447,  0.02076195,  0.05628496,  0.9934037 ,\n",
            "       -0.5074432 , -0.2239305 ,  0.18289673, -0.51519096, -0.50813687,\n",
            "       -0.25610924, -0.53162575, -0.82485676, -0.22825156, -0.21915978,\n",
            "        7.4046874 , -6.0772767 ,  1.0026681 ], dtype=float32), 'agent_3': Array([ 0.5521393 , -0.09772447,  0.02076195,  0.05628496,  0.9934037 ,\n",
            "       -0.5074432 , -0.2239305 ,  0.18289673, -0.50813687,  0.7989796 ,\n",
            "       -0.25610924, -0.53162575, -0.82485676, -0.22825156, -0.21915978,\n",
            "        7.4046874 , -9.722059  ,  0.907278  ], dtype=float32)}\n",
            "ctrl action chosen: [-1.7627248  -0.48042235 -1.7673006  -0.48039442 -1.7633692  -0.48070645\n",
            " -1.7641138  -0.48228952]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.23076084, dtype=float32), 'agent_0': Array(0.23076084, dtype=float32), 'agent_1': Array(0.23076084, dtype=float32), 'agent_2': Array(0.23076084, dtype=float32), 'agent_3': Array(0.23076084, dtype=float32)}\n",
            "step: 504\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5207739 , -0.17011869,  0.01381708,  0.04921636,  0.98409677,\n",
            "       -0.5991256 ,  1.0933521 , -0.49638808,  0.00566041, -0.5985304 ,\n",
            "        0.04386902,  0.5627632 , -0.44959784, -0.15986888,  0.3312623 ,\n",
            "        1.775506  ,  0.62691367, -3.1999295 ], dtype=float32), 'agent_1': Array([ 0.5207739 , -0.17011869,  0.01381708,  0.04921636,  0.98409677,\n",
            "       -0.5991256 , -0.49638808, -0.63449776,  0.00566041, -0.5985304 ,\n",
            "        0.04386902,  0.5627632 , -0.44959784, -0.15986888,  0.3312623 ,\n",
            "        1.775506  , -5.254385  , -3.3136926 ], dtype=float32), 'agent_2': Array([ 0.5207739 , -0.17011869,  0.01381708,  0.04921636,  0.98409677,\n",
            "       -0.5991256 , -0.49638808,  0.00566041, -0.61085314, -0.5985304 ,\n",
            "        0.04386902,  0.5627632 , -0.44959784, -0.15986888,  0.3312623 ,\n",
            "        1.775506  , -3.4183614 , -2.4559531 ], dtype=float32), 'agent_3': Array([ 0.5207739 , -0.17011869,  0.01381708,  0.04921636,  0.98409677,\n",
            "       -0.5991256 , -0.49638808,  0.00566041, -0.5985304 ,  0.6573971 ,\n",
            "        0.04386902,  0.5627632 , -0.44959784, -0.15986888,  0.3312623 ,\n",
            "        1.775506  ,  0.7423126 , -3.55488   ], dtype=float32)}\n",
            "ctrl action chosen: [-0.87549615  0.23606886 -0.88004345  0.2387658  -0.8795448   0.23684427\n",
            " -0.8768787   0.23419093]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-5.798966, dtype=float32), 'agent_0': Array(-5.798966, dtype=float32), 'agent_1': Array(-5.798966, dtype=float32), 'agent_2': Array(-5.798966, dtype=float32), 'agent_3': Array(-5.798966, dtype=float32)}\n",
            "step: 505\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.48926932, -0.19588971,  0.03148792,  0.03456441,  0.97951066,\n",
            "       -0.5154173 ,  1.0829401 , -0.62491703, -0.21285044, -0.5105469 ,\n",
            "       -0.7595062 ,  0.6746769 , -0.54990053, -0.9022377 , -0.5808978 ,\n",
            "        1.5668674 ,  0.4642203 ,  0.00263862], dtype=float32), 'agent_1': Array([ 0.48926932, -0.19588971,  0.03148792,  0.03456441,  0.97951066,\n",
            "       -0.5154173 , -0.62491703, -0.654937  , -0.21285044, -0.5105469 ,\n",
            "       -0.7595062 ,  0.6746769 , -0.54990053, -0.9022377 , -0.5808978 ,\n",
            "        1.5668674 , -0.9470996 ,  0.16650869], dtype=float32), 'agent_2': Array([ 0.48926932, -0.19588971,  0.03148792,  0.03456441,  0.97951066,\n",
            "       -0.5154173 , -0.62491703, -0.21285044, -0.58570623, -0.5105469 ,\n",
            "       -0.7595062 ,  0.6746769 , -0.54990053, -0.9022377 , -0.5808978 ,\n",
            "        1.5668674 , -6.2355914 ,  1.3152705 ], dtype=float32), 'agent_3': Array([ 0.48926932, -0.19588971,  0.03148792,  0.03456441,  0.97951066,\n",
            "       -0.5154173 , -0.62491703, -0.21285044, -0.5105469 ,  0.6579707 ,\n",
            "       -0.7595062 ,  0.6746769 , -0.54990053, -0.9022377 , -0.5808978 ,\n",
            "        1.5668674 ,  0.42962945,  0.7913294 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.9082491  -0.17523505 -0.91401327 -0.17561908 -0.92027766 -0.17246094\n",
            " -0.9090025  -0.1754894 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.9300232, dtype=float32), 'agent_0': Array(-0.9300232, dtype=float32), 'agent_1': Array(-0.9300232, dtype=float32), 'agent_2': Array(-0.9300232, dtype=float32), 'agent_3': Array(-0.9300232, dtype=float32)}\n",
            "step: 506\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.46398714, -0.24046317,  0.03414665,  0.0187844 ,  0.9698756 ,\n",
            "       -0.54023474,  0.97530705, -0.5503158 , -0.5690681 , -0.54713714,\n",
            "       -0.81977844,  0.58517456, -0.38431883, -0.37951544,  0.08072598,\n",
            "        0.74061507,  0.3939904 , -2.0904033 ], dtype=float32), 'agent_1': Array([ 0.46398714, -0.24046317,  0.03414665,  0.0187844 ,  0.9698756 ,\n",
            "       -0.54023474, -0.5503158 , -0.7357937 , -0.5690681 , -0.54713714,\n",
            "       -0.81977844,  0.58517456, -0.38431883, -0.37951544,  0.08072598,\n",
            "        0.74061507,  3.5759177 , -1.6641765 ], dtype=float32), 'agent_2': Array([ 0.46398714, -0.24046317,  0.03414665,  0.0187844 ,  0.9698756 ,\n",
            "       -0.54023474, -0.5503158 , -0.5690681 , -0.5924786 , -0.54713714,\n",
            "       -0.81977844,  0.58517456, -0.38431883, -0.37951544,  0.08072598,\n",
            "        0.74061507, -5.0198145 , -0.03933475], dtype=float32), 'agent_3': Array([ 0.46398714, -0.24046317,  0.03414665,  0.0187844 ,  0.9698756 ,\n",
            "       -0.54023474, -0.5503158 , -0.5690681 , -0.54713714,  0.58879745,\n",
            "       -0.81977844,  0.58517456, -0.38431883, -0.37951544,  0.08072598,\n",
            "        0.74061507,  0.15267405, -1.8997899 ], dtype=float32)}\n",
            "ctrl action chosen: [-0.3994982  -0.9668655  -0.39526156 -0.967186   -0.40740496 -0.9588369\n",
            " -0.4014915  -0.9668793 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6992713, dtype=float32), 'agent_0': Array(-1.6992713, dtype=float32), 'agent_1': Array(-1.6992713, dtype=float32), 'agent_2': Array(-1.6992713, dtype=float32), 'agent_3': Array(-1.6992713, dtype=float32)}\n",
            "step: 507\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.7013783e-01, -2.2741751e-01, -5.3431219e-03,  1.5492002e-02,\n",
            "        9.7365946e-01, -5.0192958e-01,  6.2075365e-01, -3.7099451e-01,\n",
            "       -5.8135253e-01, -5.0064367e-01, -1.2207031e-02,  1.2474060e-01,\n",
            "        4.5518875e-01, -1.5555061e-01,  2.4341815e+00, -7.5355768e-01,\n",
            "        1.9983338e-01, -9.8784018e+00], dtype=float32), 'agent_1': Array([ 0.47013783, -0.22741751, -0.00534312,  0.015492  ,  0.97365946,\n",
            "       -0.5019296 , -0.3709945 , -0.9898234 , -0.58135253, -0.5006437 ,\n",
            "       -0.01220703,  0.1247406 ,  0.45518875, -0.15555061,  2.4341815 ,\n",
            "       -0.7535577 ,  2.3917327 , -5.166194  ], dtype=float32), 'agent_2': Array([ 4.7013783e-01, -2.2741751e-01, -5.3431219e-03,  1.5492002e-02,\n",
            "        9.7365946e-01, -5.0192958e-01, -3.7099451e-01, -5.8135253e-01,\n",
            "       -8.1913960e-01, -5.0064367e-01, -1.2207031e-02,  1.2474060e-01,\n",
            "        4.5518875e-01, -1.5555061e-01,  2.4341815e+00, -7.5355768e-01,\n",
            "        1.9272021e+00, -6.3629622e+00], dtype=float32), 'agent_3': Array([ 0.47013783, -0.22741751, -0.00534312,  0.015492  ,  0.97365946,\n",
            "       -0.5019296 , -0.3709945 , -0.58135253, -0.5006437 ,  0.46509257,\n",
            "       -0.01220703,  0.1247406 ,  0.45518875, -0.15555061,  2.4341815 ,\n",
            "       -0.7535577 ,  0.64255273,  0.32218066], dtype=float32)}\n",
            "ctrl action chosen: [0.46666855 0.68311095 0.46486312 0.6850367  0.4645371  0.6839496\n",
            " 0.46524638 0.6895575 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.4895728, dtype=float32), 'agent_0': Array(-1.4895728, dtype=float32), 'agent_1': Array(-1.4895728, dtype=float32), 'agent_2': Array(-1.4895728, dtype=float32), 'agent_3': Array(-1.4895728, dtype=float32)}\n",
            "step: 508\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.0784492e-01, -8.9910917e-02, -2.6868833e-03, -8.0301758e-04,\n",
            "        9.9594593e-01, -2.0322821e-01,  5.5300003e-01, -1.4124140e-02,\n",
            "       -1.7249289e-01, -1.7620106e-01, -4.6243668e-01, -1.8572807e-01,\n",
            "        7.2660446e-01, -2.3115228e-01, -8.9566141e-01, -6.4010282e+00,\n",
            "        7.0124545e+00,  2.0578060e+00], dtype=float32), 'agent_1': Array([ 5.0784492e-01, -8.9910917e-02, -2.6868833e-03, -8.0301758e-04,\n",
            "        9.9594593e-01, -2.0322821e-01, -1.4124140e-02, -8.0939484e-01,\n",
            "       -1.7249289e-01, -1.7620106e-01, -4.6243668e-01, -1.8572807e-01,\n",
            "        7.2660446e-01, -2.3115228e-01, -8.9566141e-01, -6.4010282e+00,\n",
            "        8.0741501e+00,  5.2038460e+00], dtype=float32), 'agent_2': Array([ 5.0784492e-01, -8.9910917e-02, -2.6868833e-03, -8.0301758e-04,\n",
            "        9.9594593e-01, -2.0322821e-01, -1.4124140e-02, -1.7249289e-01,\n",
            "       -7.4068081e-01, -1.7620106e-01, -4.6243668e-01, -1.8572807e-01,\n",
            "        7.2660446e-01, -2.3115228e-01, -8.9566141e-01, -6.4010282e+00,\n",
            "        9.6312275e+00,  4.1015964e+00], dtype=float32), 'agent_3': Array([ 5.0784492e-01, -8.9910917e-02, -2.6868833e-03, -8.0301758e-04,\n",
            "        9.9594593e-01, -2.0322821e-01, -1.4124140e-02, -1.7249289e-01,\n",
            "       -1.7620106e-01,  6.6369724e-01, -4.6243668e-01, -1.8572807e-01,\n",
            "        7.2660446e-01, -2.3115228e-01, -8.9566141e-01, -6.4010282e+00,\n",
            "        7.4677587e+00,  5.7214465e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.00414024 -0.4087323   0.0046406  -0.40847     0.00445655 -0.41056716\n",
            "  0.00394479 -0.40796477]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.60951877, dtype=float32), 'agent_0': Array(-0.60951877, dtype=float32), 'agent_1': Array(-0.60951877, dtype=float32), 'agent_2': Array(-0.60951877, dtype=float32), 'agent_3': Array(-0.60951877, dtype=float32)}\n",
            "step: 509\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.51899934, -0.02103843, -0.02566515, -0.0069278 ,  0.9994252 ,\n",
            "       -0.06153167,  0.4878087 ,  0.17081884,  0.05941174, -0.02611607,\n",
            "       -0.13194084, -0.08912086, -0.03734827,  0.0356635 ,  1.0653263 ,\n",
            "       -1.6053535 ,  1.2303014 ,  0.37372705], dtype=float32), 'agent_1': Array([ 0.51899934, -0.02103843, -0.02566515, -0.0069278 ,  0.9994252 ,\n",
            "       -0.06153167,  0.17081884, -0.8624923 ,  0.05941174, -0.02611607,\n",
            "       -0.13194084, -0.08912086, -0.03734827,  0.0356635 ,  1.0653263 ,\n",
            "       -1.6053535 ,  2.1676013 , -2.5814104 ], dtype=float32), 'agent_2': Array([ 0.51899934, -0.02103843, -0.02566515, -0.0069278 ,  0.9994252 ,\n",
            "       -0.06153167,  0.17081884,  0.05941174, -0.8188495 , -0.02611607,\n",
            "       -0.13194084, -0.08912086, -0.03734827,  0.0356635 ,  1.0653263 ,\n",
            "       -1.6053535 ,  2.91645   , -2.7196848 ], dtype=float32), 'agent_3': Array([ 0.51899934, -0.02103843, -0.02566515, -0.0069278 ,  0.9994252 ,\n",
            "       -0.06153167,  0.17081884,  0.05941174, -0.02611607,  0.7341536 ,\n",
            "       -0.13194084, -0.08912086, -0.03734827,  0.0356635 ,  1.0653263 ,\n",
            "       -1.6053535 ,  1.5096595 , -0.15902787], dtype=float32)}\n",
            "ctrl action chosen: [ 0.31469595 -0.35026604  0.31394416 -0.35325375  0.31530035 -0.35533586\n",
            "  0.3151901  -0.3506768 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.45566124, dtype=float32), 'agent_0': Array(0.45566124, dtype=float32), 'agent_1': Array(0.45566124, dtype=float32), 'agent_2': Array(0.45566124, dtype=float32), 'agent_3': Array(0.45566124, dtype=float32)}\n",
            "step: 510\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5173909 ,  0.06378584, -0.0457434 , -0.00536713,  0.9969003 ,\n",
            "        0.11129754,  0.5186362 ,  0.3889931 ,  0.31775114,  0.16706993,\n",
            "       -0.21796227, -0.09651184, -0.1675129 ,  0.0732553 ,  1.0269896 ,\n",
            "       -3.9930143 ,  4.354573  ,  0.48287192], dtype=float32), 'agent_1': Array([ 0.5173909 ,  0.06378584, -0.0457434 , -0.00536713,  0.9969003 ,\n",
            "        0.11129754,  0.3889931 , -0.97747856,  0.31775114,  0.16706993,\n",
            "       -0.21796227, -0.09651184, -0.1675129 ,  0.0732553 ,  1.0269896 ,\n",
            "       -3.9930143 ,  5.1256547 , -2.8284376 ], dtype=float32), 'agent_2': Array([ 5.1739091e-01,  6.3785836e-02, -4.5743398e-02, -5.3671296e-03,\n",
            "        9.9690032e-01,  1.1129754e-01,  3.8899311e-01,  3.1775114e-01,\n",
            "       -9.0247571e-01,  1.6706993e-01, -2.1796227e-01, -9.6511841e-02,\n",
            "       -1.6751289e-01,  7.3255301e-02,  1.0269896e+00, -3.9930143e+00,\n",
            "        6.0167313e+00, -2.1732635e+00], dtype=float32), 'agent_3': Array([ 0.5173909 ,  0.06378584, -0.0457434 , -0.00536713,  0.9969003 ,\n",
            "        0.11129754,  0.3889931 ,  0.31775114,  0.16706993,  0.66400415,\n",
            "       -0.21796227, -0.09651184, -0.1675129 ,  0.0732553 ,  1.0269896 ,\n",
            "       -3.9930143 ,  4.783605  , -2.5445902 ], dtype=float32)}\n",
            "ctrl action chosen: [0.583181   0.69762737 0.58065814 0.696191   0.58307415 0.69533336\n",
            " 0.579176   0.69494057]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.35048702, dtype=float32), 'agent_0': Array(0.35048702, dtype=float32), 'agent_1': Array(0.35048702, dtype=float32), 'agent_2': Array(0.35048702, dtype=float32), 'agent_3': Array(0.35048702, dtype=float32)}\n",
            "step: 511\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 4.9084660e-01,  1.6232182e-01, -3.3227179e-02,  1.5522791e-03,\n",
            "        9.8617715e-01,  3.6991030e-01,  7.9173410e-01,  5.8034301e-01,\n",
            "        5.7763302e-01,  4.4542068e-01, -5.0864220e-01,  2.2916794e-01,\n",
            "       -7.9601407e-01,  7.4783760e-01, -8.5406709e-01, -8.9450729e-01,\n",
            "        2.6648016e+00,  5.6735978e+00], dtype=float32), 'agent_1': Array([ 4.9084660e-01,  1.6232182e-01, -3.3227179e-02,  1.5522791e-03,\n",
            "        9.8617715e-01,  3.6991030e-01,  5.8034301e-01, -8.7241066e-01,\n",
            "        5.7763302e-01,  4.4542068e-01, -5.0864220e-01,  2.2916794e-01,\n",
            "       -7.9601407e-01,  7.4783760e-01, -8.5406709e-01, -8.9450729e-01,\n",
            "       -6.9750392e-01,  3.8150494e+00], dtype=float32), 'agent_2': Array([ 4.90846604e-01,  1.62321821e-01, -3.32271792e-02,  1.55227911e-03,\n",
            "        9.86177146e-01,  3.69910300e-01,  5.80343008e-01,  5.77633023e-01,\n",
            "       -7.91931570e-01,  4.45420682e-01, -5.08642197e-01,  2.29167938e-01,\n",
            "       -7.96014071e-01,  7.47837603e-01, -8.54067087e-01, -8.94507289e-01,\n",
            "        1.17307946e-01,  3.69429636e+00], dtype=float32), 'agent_3': Array([ 4.9084660e-01,  1.6232182e-01, -3.3227179e-02,  1.5522791e-03,\n",
            "        9.8617715e-01,  3.6991030e-01,  5.8034301e-01,  5.7763302e-01,\n",
            "        4.4542068e-01,  7.8207541e-01, -5.0864220e-01,  2.2916794e-01,\n",
            "       -7.9601407e-01,  7.4783760e-01, -8.5406709e-01, -8.9450729e-01,\n",
            "        3.0522950e+00,  3.2983201e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.34568095 0.5183889  0.34610245 0.5212228  0.3474969  0.5152426\n",
            " 0.34747204 0.515155  ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.0315883, dtype=float32), 'agent_0': Array(-1.0315883, dtype=float32), 'agent_1': Array(-1.0315883, dtype=float32), 'agent_2': Array(-1.0315883, dtype=float32), 'agent_3': Array(-1.0315883, dtype=float32)}\n",
            "step: 512\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.49820766,  0.182055  ,  0.00717432,  0.0125433 ,  0.98318213,\n",
            "        0.5202997 ,  0.9637655 ,  0.516301  ,  0.53641033,  0.5350654 ,\n",
            "       -0.653553  ,  0.53019524,  0.5851865 ,  0.7128606 , -2.318085  ,\n",
            "       -1.2896788 ,  4.1170573 ,  2.3696952 ], dtype=float32), 'agent_1': Array([ 0.49820766,  0.182055  ,  0.00717432,  0.0125433 ,  0.98318213,\n",
            "        0.5202997 ,  0.516301  , -0.61971295,  0.53641033,  0.5350654 ,\n",
            "       -0.653553  ,  0.53019524,  0.5851865 ,  0.7128606 , -2.318085  ,\n",
            "       -1.2896788 , -0.96964055,  6.9303756 ], dtype=float32), 'agent_2': Array([ 0.49820766,  0.182055  ,  0.00717432,  0.0125433 ,  0.98318213,\n",
            "        0.5202997 ,  0.516301  ,  0.53641033, -0.55913305,  0.5350654 ,\n",
            "       -0.653553  ,  0.53019524,  0.5851865 ,  0.7128606 , -2.318085  ,\n",
            "       -1.2896788 , -0.77579296,  6.0312862 ], dtype=float32), 'agent_3': Array([ 0.49820766,  0.182055  ,  0.00717432,  0.0125433 ,  0.98318213,\n",
            "        0.5202997 ,  0.516301  ,  0.53641033,  0.5350654 ,  0.9162125 ,\n",
            "       -0.653553  ,  0.53019524,  0.5851865 ,  0.7128606 , -2.318085  ,\n",
            "       -1.2896788 ,  1.0792636 ,  3.3070922 ], dtype=float32)}\n",
            "ctrl action chosen: [0.3537512  0.06011418 0.34987524 0.06750721 0.35075486 0.06438105\n",
            " 0.35176343 0.0636783 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-0.48832065, dtype=float32), 'agent_0': Array(-0.48832065, dtype=float32), 'agent_1': Array(-0.48832065, dtype=float32), 'agent_2': Array(-0.48832065, dtype=float32), 'agent_3': Array(-0.48832065, dtype=float32)}\n",
            "step: 513\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.5232619 ,  0.19233681,  0.0476439 ,  0.00750455,  0.980143  ,\n",
            "        0.57863957,  1.0188705 ,  0.45700452,  0.5116713 ,  0.5280559 ,\n",
            "       -0.21195412,  0.2922535 ,  0.4416108 ,  0.0547535 , -0.9047388 ,\n",
            "       -0.41399208, -0.32098836,  1.2865826 ], dtype=float32), 'agent_1': Array([ 0.5232619 ,  0.19233681,  0.0476439 ,  0.00750455,  0.980143  ,\n",
            "        0.57863957,  0.45700452, -0.48874483,  0.5116713 ,  0.5280559 ,\n",
            "       -0.21195412,  0.2922535 ,  0.4416108 ,  0.0547535 , -0.9047388 ,\n",
            "       -0.41399208, -0.5544808 , -0.9003349 ], dtype=float32), 'agent_2': Array([ 0.5232619 ,  0.19233681,  0.0476439 ,  0.00750455,  0.980143  ,\n",
            "        0.57863957,  0.45700452,  0.5116713 , -0.5003455 ,  0.5280559 ,\n",
            "       -0.21195412,  0.2922535 ,  0.4416108 ,  0.0547535 , -0.9047388 ,\n",
            "       -0.41399208,  0.09822899, -0.26773804], dtype=float32), 'agent_3': Array([ 0.5232619 ,  0.19233681,  0.0476439 ,  0.00750455,  0.980143  ,\n",
            "        0.57863957,  0.45700452,  0.5116713 ,  0.5280559 ,  1.0153493 ,\n",
            "       -0.21195412,  0.2922535 ,  0.4416108 ,  0.0547535 , -0.9047388 ,\n",
            "       -0.41399208, -0.01028704,  1.513142  ], dtype=float32)}\n",
            "ctrl action chosen: [1.0492682  0.3015435  1.0471307  0.2979829  1.052732   0.29443932\n",
            " 1.0486497  0.30062774]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.35379168, dtype=float32), 'agent_0': Array(0.35379168, dtype=float32), 'agent_1': Array(0.35379168, dtype=float32), 'agent_2': Array(0.35379168, dtype=float32), 'agent_3': Array(0.35379168, dtype=float32)}\n",
            "step: 514\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.54379433,  0.21833946,  0.08286233,  0.0106431 ,  0.9722904 ,\n",
            "        0.5360762 ,  1.1786791 ,  0.5498037 ,  0.5591316 ,  0.5531927 ,\n",
            "       -0.37779808,  0.04892349,  0.24317503,  0.313933  , -1.4631608 ,\n",
            "       -0.546993  , -1.3829775 ,  3.875015  ], dtype=float32), 'agent_1': Array([ 0.54379433,  0.21833946,  0.08286233,  0.0106431 ,  0.9722904 ,\n",
            "        0.5360762 ,  0.5498037 , -0.5124533 ,  0.5591316 ,  0.5531927 ,\n",
            "       -0.37779808,  0.04892349,  0.24317503,  0.313933  , -1.4631608 ,\n",
            "       -0.546993  ,  1.4307851 , -0.8899755 ], dtype=float32), 'agent_2': Array([ 0.54379433,  0.21833946,  0.08286233,  0.0106431 ,  0.9722904 ,\n",
            "        0.5360762 ,  0.5498037 ,  0.5591316 , -0.51126385,  0.5531927 ,\n",
            "       -0.37779808,  0.04892349,  0.24317503,  0.313933  , -1.4631608 ,\n",
            "       -0.546993  ,  0.32921967, -0.75822043], dtype=float32), 'agent_3': Array([ 0.54379433,  0.21833946,  0.08286233,  0.0106431 ,  0.9722904 ,\n",
            "        0.5360762 ,  0.5498037 ,  0.5591316 ,  0.5531927 ,  1.160755  ,\n",
            "       -0.37779808,  0.04892349,  0.24317503,  0.313933  , -1.4631608 ,\n",
            "       -0.546993  , -0.02230204,  3.7069511 ], dtype=float32)}\n",
            "ctrl action chosen: [ 2.420144  -2.546879   2.4252706 -2.5544822  2.4259734 -2.5570045\n",
            "  2.4205754 -2.5480435]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-1.6902854, dtype=float32), 'agent_0': Array(-1.6902854, dtype=float32), 'agent_1': Array(-1.6902854, dtype=float32), 'agent_2': Array(-1.6902854, dtype=float32), 'agent_3': Array(-1.6902854, dtype=float32)}\n",
            "step: 515\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.5681598e-01,  2.3250583e-01,  5.7332553e-02, -5.1991246e-03,\n",
            "        9.7088981e-01,  5.1775479e-01,  9.8251104e-01,  5.7516378e-01,\n",
            "        5.4971421e-01,  5.4567158e-01,  6.0791969e-01,  2.7098656e-01,\n",
            "        6.5817833e-01, -1.3850138e+00,  2.4309900e+00, -4.1175038e-01,\n",
            "        4.2448661e-01, -7.3379574e+00], dtype=float32), 'agent_1': Array([ 5.5681598e-01,  2.3250583e-01,  5.7332553e-02, -5.1991246e-03,\n",
            "        9.7088981e-01,  5.1775479e-01,  5.7516378e-01, -8.5529542e-01,\n",
            "        5.4971421e-01,  5.4567158e-01,  6.0791969e-01,  2.7098656e-01,\n",
            "        6.5817833e-01, -1.3850138e+00,  2.4309900e+00, -4.1175038e-01,\n",
            "       -5.9051758e-01, -8.2865105e+00], dtype=float32), 'agent_2': Array([ 5.5681598e-01,  2.3250583e-01,  5.7332553e-02, -5.1991246e-03,\n",
            "        9.7088981e-01,  5.1775479e-01,  5.7516378e-01,  5.4971421e-01,\n",
            "       -8.8357955e-01,  5.4567158e-01,  6.0791969e-01,  2.7098656e-01,\n",
            "        6.5817833e-01, -1.3850138e+00,  2.4309900e+00, -4.1175038e-01,\n",
            "       -4.1090316e-01, -9.6939116e+00], dtype=float32), 'agent_3': Array([ 5.5681598e-01,  2.3250583e-01,  5.7332553e-02, -5.1991246e-03,\n",
            "        9.7088981e-01,  5.1775479e-01,  5.7516378e-01,  5.4971421e-01,\n",
            "        5.4567158e-01,  9.5564938e-01,  6.0791969e-01,  2.7098656e-01,\n",
            "        6.5817833e-01, -1.3850138e+00,  2.4309900e+00, -4.1175038e-01,\n",
            "       -6.1813582e-02, -7.7769589e+00], dtype=float32)}\n",
            "ctrl action chosen: [ 0.27028552 -0.5791594   0.2704197  -0.57709765  0.2731483  -0.58060884\n",
            "  0.26999083 -0.57893336]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-23.701927, dtype=float32), 'agent_0': Array(-23.701927, dtype=float32), 'agent_1': Array(-23.701927, dtype=float32), 'agent_2': Array(-23.701927, dtype=float32), 'agent_3': Array(-23.701927, dtype=float32)}\n",
            "step: 516\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 5.8576310e-01,  2.3647605e-01, -4.6482789e-03, -2.1548433e-02,\n",
            "        9.7138721e-01,  5.4004896e-01,  6.0591912e-01,  5.0478178e-01,\n",
            "        5.3101766e-01,  5.2700084e-01,  7.5430870e-01,  2.3636818e-01,\n",
            "        7.6779127e-01, -1.0777714e+00,  2.3999796e+00, -2.7875087e-01,\n",
            "        7.0910835e-01, -8.3401718e+00], dtype=float32), 'agent_1': Array([ 0.5857631 ,  0.23647605, -0.00464828, -0.02154843,  0.9713872 ,\n",
            "        0.54004896,  0.5047818 , -1.1384562 ,  0.53101766,  0.52700084,\n",
            "        0.7543087 ,  0.23636818,  0.7677913 , -1.0777714 ,  2.3999796 ,\n",
            "       -0.27875087, -1.3928591 , -4.4177165 ], dtype=float32), 'agent_2': Array([ 0.5857631 ,  0.23647605, -0.00464828, -0.02154843,  0.9713872 ,\n",
            "        0.54004896,  0.5047818 ,  0.53101766, -1.2733129 ,  0.52700084,\n",
            "        0.7543087 ,  0.23636818,  0.7677913 , -1.0777714 ,  2.3999796 ,\n",
            "       -0.27875087,  0.20619541, -3.8626995 ], dtype=float32), 'agent_3': Array([ 5.8576310e-01,  2.3647605e-01, -4.6482789e-03, -2.1548433e-02,\n",
            "        9.7138721e-01,  5.4004896e-01,  5.0478178e-01,  5.3101766e-01,\n",
            "        5.2700084e-01,  5.5189186e-01,  7.5430870e-01,  2.3636818e-01,\n",
            "        7.6779127e-01, -1.0777714e+00,  2.3999796e+00, -2.7875087e-01,\n",
            "       -3.8653588e-01, -8.8972559e+00], dtype=float32)}\n",
            "ctrl action chosen: [-0.47665107 -1.4511399  -0.47889867 -1.446584   -0.47608513 -1.4531479\n",
            " -0.47657403 -1.4514701 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.8886501, dtype=float32), 'agent_0': Array(0.8886501, dtype=float32), 'agent_1': Array(0.8886501, dtype=float32), 'agent_2': Array(0.8886501, dtype=float32), 'agent_3': Array(0.8886501, dtype=float32)}\n",
            "step: 517\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 0.6108996 ,  0.13385971, -0.03923251, -0.01012137,  0.99017173,\n",
            "        0.32884026,  0.45839754,  0.14806867,  0.28678873,  0.22138067,\n",
            "        0.43182373, -0.03848076,  0.48730373,  0.41547614,  0.00796831,\n",
            "        5.4535446 , -6.0001373 ,  0.78778636], dtype=float32), 'agent_1': Array([ 6.1089963e-01,  1.3385971e-01, -3.9232507e-02, -1.0121370e-02,\n",
            "        9.9017173e-01,  3.2884026e-01,  1.4806867e-01, -1.2824228e+00,\n",
            "        2.8678873e-01,  2.2138067e-01,  4.3182373e-01, -3.8480759e-02,\n",
            "        4.8730373e-01,  4.1547614e-01,  7.9683075e-03,  5.4535446e+00,\n",
            "       -8.4489603e+00,  6.5126151e-01], dtype=float32), 'agent_2': Array([ 0.6108996 ,  0.13385971, -0.03923251, -0.01012137,  0.99017173,\n",
            "        0.32884026,  0.14806867,  0.28678873, -1.2801261 ,  0.22138067,\n",
            "        0.43182373, -0.03848076,  0.48730373,  0.41547614,  0.00796831,\n",
            "        5.4535446 , -6.77573   ,  0.9702689 ], dtype=float32), 'agent_3': Array([ 0.6108996 ,  0.13385971, -0.03923251, -0.01012137,  0.99017173,\n",
            "        0.32884026,  0.14806867,  0.28678873,  0.22138067,  0.4467442 ,\n",
            "        0.43182373, -0.03848076,  0.48730373,  0.41547614,  0.00796831,\n",
            "        5.4535446 , -7.8051167 ,  0.9306438 ], dtype=float32)}\n",
            "ctrl action chosen: [0.70677125 0.1163687  0.70734406 0.11806901 0.709494   0.11395712\n",
            " 0.70655894 0.11658786]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(-3.0567312, dtype=float32), 'agent_0': Array(-3.0567312, dtype=float32), 'agent_1': Array(-3.0567312, dtype=float32), 'agent_2': Array(-3.0567312, dtype=float32), 'agent_3': Array(-3.0567312, dtype=float32)}\n",
            "step: 518\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n",
            "{'agent_0': Array([ 6.3353622e-01,  2.3435108e-01, -4.1328926e-02, -5.3260210e-03,\n",
            "        9.7125858e-01,  5.8779550e-01,  5.3112906e-01,  3.2973364e-01,\n",
            "        5.2182782e-01,  4.2286128e-01,  6.2470436e-01, -1.9550323e-03,\n",
            "        1.7997026e-01,  2.0562057e-01,  5.8068097e-01, -4.6189027e+00,\n",
            "        4.4632645e+00,  1.1257259e+00], dtype=float32), 'agent_1': Array([ 6.3353622e-01,  2.3435108e-01, -4.1328926e-02, -5.3260210e-03,\n",
            "        9.7125858e-01,  5.8779550e-01,  3.2973364e-01, -1.2213187e+00,\n",
            "        5.2182782e-01,  4.2286128e-01,  6.2470436e-01, -1.9550323e-03,\n",
            "        1.7997026e-01,  2.0562057e-01,  5.8068097e-01, -4.6189027e+00,\n",
            "        5.2327766e+00,  4.9202025e-01], dtype=float32), 'agent_2': Array([ 6.3353622e-01,  2.3435108e-01, -4.1328926e-02, -5.3260210e-03,\n",
            "        9.7125858e-01,  5.8779550e-01,  3.2973364e-01,  5.2182782e-01,\n",
            "       -1.1332428e+00,  4.2286128e-01,  6.2470436e-01, -1.9550323e-03,\n",
            "        1.7997026e-01,  2.0562057e-01,  5.8068097e-01, -4.6189027e+00,\n",
            "        5.8531528e+00,  3.2959490e+00], dtype=float32), 'agent_3': Array([ 6.3353622e-01,  2.3435108e-01, -4.1328926e-02, -5.3260210e-03,\n",
            "        9.7125858e-01,  5.8779550e-01,  3.2973364e-01,  5.2182782e-01,\n",
            "        4.2286128e-01,  5.6946146e-01,  6.2470436e-01, -1.9550323e-03,\n",
            "        1.7997026e-01,  2.0562057e-01,  5.8068097e-01, -4.6189027e+00,\n",
            "        5.6845970e+00,  2.6979380e+00], dtype=float32)}\n",
            "ctrl action chosen: [0.44080392 0.411936   0.44133857 0.41316366 0.44194525 0.40950474\n",
            " 0.44080985 0.4110713 ]\n",
            "state.done: {'__all__': Array(False, dtype=bool), 'agent_0': Array(False, dtype=bool), 'agent_1': Array(False, dtype=bool), 'agent_2': Array(False, dtype=bool), 'agent_3': Array(False, dtype=bool)}\n",
            "state.reward: {'__all__': Array(0.4627297, dtype=float32), 'agent_0': Array(0.4627297, dtype=float32), 'agent_1': Array(0.4627297, dtype=float32), 'agent_2': Array(0.4627297, dtype=float32), 'agent_3': Array(0.4627297, dtype=float32)}\n",
            "step: 519\n",
            "info: {'returned_episode': Array([False, False, False, False], dtype=bool), 'returned_episode_lengths': Array([0., 0., 0., 0.], dtype=float32), 'returned_episode_returns': Array([0., 0., 0., 0.], dtype=float32)}\n"
          ]
        }
      ],
      "source": [
        "policy = out['network']\n",
        "# env = IPPO_Ant_Env()\n",
        "rng = jr.PRNGKey(0)\n",
        "# policy = ActorCritic(\n",
        "#         key=rng,\n",
        "#         actor_layer_sizes=[env.observation_space(env.agents[0]).shape[0], 64, 64, env.action_space(env.agents[0]).shape[0]],\n",
        "#         critic_layer_sizes=[env.observation_space(env.agents[0]).shape[0], 64, 64, 1],\n",
        "#         actor_kernel_init=[jnp.sqrt(2), jnp.sqrt(2), 0.01],\n",
        "#         critic_kernel_init=[jnp.sqrt(2), jnp.sqrt(2), 1],\n",
        "#         activation=jax.nn.tanh,\n",
        "# )\n",
        "\n",
        "def test_generate_rollout(env, policy, rng, jit=True, num_timesteps=100):\n",
        "    agent_obs, state = env.reset(rng=rng)\n",
        "    rng, _rng = jr.split(rng)\n",
        "    rollout = []\n",
        "\n",
        "    env_step = jax.jit(env.step) if jit else env.step\n",
        "\n",
        "    def get_actions(agent_obs_dict, rng):\n",
        "        actions = []\n",
        "        scales = []\n",
        "        for agent_id in env.agents:\n",
        "            obs = agent_obs_dict[agent_id]# [None, :]  # (1, obs_dim)\n",
        "            mean, scale, value = policy(obs)        # 不用 vmap\n",
        "            pi = dist.MultivariateNormalDiag(mean, scale)\n",
        "            action = pi.sample(rng)\n",
        "            actions.append(action)\n",
        "        return jnp.concatenate(actions)\n",
        "\n",
        "    ctrl = get_actions(agent_obs, rng); _rng, rng = jr.split(rng)\n",
        "    agent_ctrls = {\n",
        "        \"agent_0\": ctrl[:2],\n",
        "        \"agent_1\": ctrl[2:4],\n",
        "        \"agent_2\": ctrl[4:6],\n",
        "        \"agent_3\": ctrl[6:]\n",
        "    }\n",
        "\n",
        "    for i in range(num_timesteps):\n",
        "        agent_obs, state, reward, done, info = env_step(rng, state, agent_ctrls)\n",
        "        rollout.append(state.env_state.pipeline_state)\n",
        "        print(agent_obs)\n",
        "        ctrl = get_actions(agent_obs, rng); _rng, rng = jr.split(rng)\n",
        "        print(f\"ctrl action chosen: {ctrl}\")\n",
        "        agent_ctrls = {\n",
        "            \"agent_0\": ctrl[:2],\n",
        "            \"agent_1\": ctrl[2:4],\n",
        "            \"agent_2\": ctrl[4:6],\n",
        "            \"agent_3\": ctrl[6:]\n",
        "        }\n",
        "        print(f\"state.done: {done}\")\n",
        "        print(f\"state.reward: {reward}\")\n",
        "        print(f\"step: {i}\")\n",
        "        print(f\"info: {info}\")\n",
        "\n",
        "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_name = f'data/rollouts/{current_datetime}.html'\n",
        "    os.makedirs(\"data/rollouts\", exist_ok=True)\n",
        "    with open(save_name, 'w') as f:\n",
        "        f.write(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))\n",
        "\n",
        "test_generate_rollout(env, policy, rng, jit=True, num_timesteps=520)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
